<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>507</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    507
                    <a href="506.html">prev</a>
                    <a href="508.html">next</a>
                    <a href="507_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd_rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd^1:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd^2:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;55715c184d537500eff25ccea853833950100929:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [bj], [bj]], subset: [[b], [bj], [bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.api.java.tuple.Tuple2;
  23 import org.apache.flink.configuration.Configuration;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 
  27 
  28 import com.dtstack.flink.sql.side.BaseAllReqRow;
  29 import com.dtstack.flink.sql.side.BaseSideInfo;
  30 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  31 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  32 import com.google.common.collect.Lists;
  33 import com.google.common.collect.Maps;
  34 import org.apache.calcite.sql.JoinType;
  35 import org.apache.commons.collections.CollectionUtils;
  36 import org.apache.commons.lang3.StringUtils;
  37 import org.apache.flink.util.Collector;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  48 import java.time.LocalDateTime;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  49 import java.util.Calendar;</span>
  50 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  51 import java.util.Calendar;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  52 import java.util.List;</span>
  53 =======
  54 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  55 import java.util.List;
  56 import java.util.Map;
  57 import java.util.Objects;
  58 import java.util.Calendar;
  59 import java.util.concurrent.atomic.AtomicReference;
  60 import java.util.stream.Collectors;
  61 
  62 /**
  63  * side operator with cache for all(period reload)
  64  * Date: 2018/11/26
  65  * Company: www.dtstack.com
  66  *
  67  * @author maqi
  68  */
  69 
  70 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  71 
  72     private static final long serialVersionUID = 2098635140857937718L;
  73 
  74     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  75 
  76     private static final int CONN_RETRY_NUM = 3;
  77 
  78     private static final int DEFAULT_FETCH_SIZE = 1000;
  79 
  80     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  81 
  82     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  83         super(sideInfo);
  84     }
  85 
  86     @Override
  87     public void open(Configuration parameters) throws Exception {
  88         super.open(parameters);
  89         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  90         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  91     }
  92 
  93 
  94     @Override
  95     protected void initCache() throws SQLException {
  96         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  97         cacheRef.set(newCache);
  98         loadData(newCache);
  99     }
 100 
 101     @Override
 102     protected void reloadCache() {
 103         //reload cacheRef and replace to old cacheRef
 104         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
 105         cacheRef.set(newCache);
 106         try {
 107             loadData(newCache);
 108         } catch (SQLException e) {
 109             throw new RuntimeException(e);
 110         }
 111         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 112     }
 113 
 114     @Override
 115     public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 116         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 117         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 118 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 119                 .map(value.f1::getField)</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 120                 .filter(object -&gt; null != object)</span>
 121 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 122                 .filter(object -&gt; null != object)</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 123                 .collect(Collectors.toCollection(ArrayList::new));</span>
 124 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 125                 .map(value.row()::getField)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 126                 .filter(Objects::nonNull)</span>
 127 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 128                 .collect(Collectors.toCollection(ArrayList::new));
 129 
 130         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 131             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 132             return;
 133         }
 134 
 135         String cacheKey = inputParams.stream()
 136                 .map(Object::toString)
 137                 .collect(Collectors.joining(&quot;_&quot;));
 138 
 139         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 140         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 141             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 142         }
 143 
 144 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 145         cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 146 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 147     }</span>
 148 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 149         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 150 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 151     }
 152 
 153     @Override
 154     public Row fillData(Row input, Object sideInput) {
 155         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 156         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 157 
 158         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 159             // origin value
 160             Object obj = input.getField(entry.getValue());
<abbr title=" 161             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 161             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 162             row.setField(entry.getKey(), obj);
 163         }
 164 
 165         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 166             if (cacheInfo == null) {
 167                 row.setField(entry.getKey(), null);
 168             } else {
 169                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 170             }
 171 
 172         }
 173         return row;
 174     }
 175 
 176     /**
 177      *  covert flink time attribute.Type information for indicating event or processing time.
 178      *  However, it behaves like a regular SQL timestamp but is serialized as Long.
 179      *
 180      * @param entry
 181      * @param obj
 182      * @return
 183      */
 184     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 185         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 186         if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 187             obj = Timestamp.valueOf(((LocalDateTime) obj));
 188         }
 189         return obj;
 190     }
 191 
 192     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 193         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 194         Connection connection = null;
 195 
 196         try {
 197             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 198                 try {
<abbr title=" 199                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 199                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 200                     break;
 201                 } catch (Exception e) {
 202                     if (i == CONN_RETRY_NUM - 1) {
 203                         throw new RuntimeException(&quot;&quot;, e);
 204                     }
 205                     try {
<abbr title=" 206                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 206                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 207                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 208                         Thread.sleep(5 * 1000);
 209                     } catch (InterruptedException e1) {
 210                         LOG.error(&quot;&quot;, e1);
 211                     }
 212                 }
 213             }
 214             queryAndFillData(tmpCache, connection);
 215         } catch (Exception e) {
 216             LOG.error(&quot;&quot;, e);
 217             throw new SQLException(e);
 218         } finally {
 219             if (connection != null) {
 220                 connection.close();
 221             }
 222         }
 223     }
 224 
<abbr title=" 225     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 225     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 226         //load data from table
 227         String sql = sideInfo.getSqlCondition();
 228         Statement statement = connection.createStatement();
 229         statement.setFetchSize(getFetchSize());
 230         ResultSet resultSet = statement.executeQuery(sql);
 231 
 232         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 233         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 234         while (resultSet.next()) {
 235             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 236             for (String fieldName : sideFieldNames) {
 237                 Object object = resultSet.getObject(fieldName.trim());
 238                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 239                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 240                 oneRow.put(fieldName.trim(), object);
 241             }
 242 
 243             String cacheKey = sideInfo.getEqualFieldList().stream()
 244                     .map(oneRow::get)
 245                     .map(Object::toString)
 246                     .collect(Collectors.joining(&quot;_&quot;));
 247 
 248             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 249                     .add(oneRow);
 250         }
 251     }
 252 
 253     public int getFetchSize() {
 254         return DEFAULT_FETCH_SIZE;
 255     }
 256 
 257     /**
 258      *  get jdbc connection
 259      * @param dbURL
 260      * @param userName
 261      * @param password
 262      * @return
 263      */
 264     public abstract Connection getConn(String dbURL, String userName, String password);
 265 
 266 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.api.java.tuple.Tuple2;
  23 import org.apache.flink.configuration.Configuration;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 import org.apache.flink.util.Collector;
  27 
  28 
  29 import com.dtstack.flink.sql.side.BaseAllReqRow;
  30 import com.dtstack.flink.sql.side.BaseSideInfo;
  31 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33 import com.google.common.collect.Lists;
  34 import com.google.common.collect.Maps;
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.CollectionUtils;
  37 import org.apache.commons.lang3.StringUtils;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 import java.time.LocalDateTime;
  48 import java.util.List;
  49 import java.util.Map;
  50 import java.util.Objects;
  51 import java.util.Calendar;
  52 import java.util.concurrent.atomic.AtomicReference;
  53 import java.util.stream.Collectors;
  54 
  55 /**
  56  * side operator with cache for all(period reload)
  57  * Date: 2018/11/26
  58  * Company: www.dtstack.com
  59  *
  60  * @author maqi
  61  */
  62 
  63 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  64 
  65     private static final long serialVersionUID = 2098635140857937718L;
  66 
  67     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  68 
  69     private static final int CONN_RETRY_NUM = 3;
  70 
  71     private static final int DEFAULT_FETCH_SIZE = 1000;
  72 
  73     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  74 
  75     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  76         super(sideInfo);
  77     }
  78 
  79     @Override
  80     public void open(Configuration parameters) throws Exception {
  81         super.open(parameters);
  82         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  83         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  84     }
  85 
  86 
  87     @Override
  88     protected void initCache() throws SQLException {
  89         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  90         cacheRef.set(newCache);
  91         loadData(newCache);
  92     }
  93 
  94     @Override
  95     protected void reloadCache() {
  96         //reload cacheRef and replace to old cacheRef
  97         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  98         cacheRef.set(newCache);
  99         try {
 100             loadData(newCache);
 101         } catch (SQLException e) {
 102             throw new RuntimeException(e);
 103         }
 104         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 105     }
 106 
 107     @Override
 108     public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 109         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 110         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 111 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 112                 .map(value.f1::getField)</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 113                 .filter(object -&gt; null != object)</span>
 114 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 115                 .map(value.row()::getField)</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 116                 .filter(object -&gt; null != object)</span>
 117 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 118                 .map(value.row()::getField)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 119                 .filter(Objects::nonNull)</span>
 120 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 121                 .collect(Collectors.toCollection(ArrayList::new));
 122 
 123         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 124             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 125             return;
 126         }
 127 
 128         String cacheKey = inputParams.stream()
 129                 .map(Object::toString)
 130                 .collect(Collectors.joining(&quot;_&quot;));
 131 
 132         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 133         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 134             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 135         }
 136 
 137 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 138         cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 139 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 140         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));"> 140         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change()🔵</abbr></span>
 141 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 142         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 143 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 144     }
 145 
 146     @Override
 147     public Row fillData(Row input, Object sideInput) {
 148         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 149         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 150 
 151         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 152             // origin value
 153             Object obj = input.getField(entry.getValue());
<abbr title=" 154             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 154             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 155             row.setField(entry.getKey(), obj);
 156         }
 157 
 158         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 159             if (cacheInfo == null) {
 160                 row.setField(entry.getKey(), null);
 161             } else {
 162                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 163             }
 164 
 165         }
 166         return row;
 167     }
 168 
 169     /**
 170      *  covert flink time attribute.Type information for indicating event or processing time.
 171      *  However, it behaves like a regular SQL timestamp but is serialized as Long.
 172      *
 173      * @param entry
 174      * @param obj
 175      * @return
 176      */
 177     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 178         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 179         if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 180             obj = Timestamp.valueOf(((LocalDateTime) obj));
 181         }
 182         return obj;
 183     }
 184 
 185     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 186         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 187         Connection connection = null;
 188 
 189         try {
 190             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 191                 try {
<abbr title=" 192                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 192                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 193                     break;
 194                 } catch (Exception e) {
 195                     if (i == CONN_RETRY_NUM - 1) {
 196                         throw new RuntimeException(&quot;&quot;, e);
 197                     }
 198                     try {
<abbr title=" 199                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 199                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 200                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 201                         Thread.sleep(5 * 1000);
 202                     } catch (InterruptedException e1) {
 203                         LOG.error(&quot;&quot;, e1);
 204                     }
 205                 }
 206             }
 207             queryAndFillData(tmpCache, connection);
 208         } catch (Exception e) {
 209             LOG.error(&quot;&quot;, e);
 210             throw new SQLException(e);
 211         } finally {
 212             if (connection != null) {
 213                 connection.close();
 214             }
 215         }
 216     }
 217 
<abbr title=" 218     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 218     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 219         //load data from table
 220         String sql = sideInfo.getSqlCondition();
 221         Statement statement = connection.createStatement();
 222         statement.setFetchSize(getFetchSize());
 223         ResultSet resultSet = statement.executeQuery(sql);
 224 
 225         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 226         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 227         while (resultSet.next()) {
 228             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 229             for (String fieldName : sideFieldNames) {
 230                 Object object = resultSet.getObject(fieldName.trim());
 231                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 232                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 233                 oneRow.put(fieldName.trim(), object);
 234             }
 235 
 236             String cacheKey = sideInfo.getEqualFieldList().stream()
 237                     .map(oneRow::get)
 238                     .map(Object::toString)
 239                     .collect(Collectors.joining(&quot;_&quot;));
 240 
 241             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 242                     .add(oneRow);
 243         }
 244     }
 245 
 246     public int getFetchSize() {
 247         return DEFAULT_FETCH_SIZE;
 248     }
 249 
 250     /**
 251      *  get jdbc connection
 252      * @param dbURL
 253      * @param userName
 254      * @param password
 255      * @return
 256      */
 257     public abstract Connection getConn(String dbURL, String userName, String password);
 258 
 259 }
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.rdb.all;
  19 
  20 import com.dtstack.flink.sql.side.BaseAllReqRow;
  21 import com.dtstack.flink.sql.side.BaseSideInfo;
  22 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  23 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  24 import com.google.common.collect.Lists;
  25 import com.google.common.collect.Maps;
  26 import java.sql.Connection;
  27 import java.sql.ResultSet;
  28 import java.sql.SQLException;
  29 import java.sql.Statement;
  30 import java.sql.Timestamp;
  31 import java.time.LocalDateTime;
  32 import java.util.ArrayList;
  33 import java.util.Calendar;
  34 import java.util.List;
  35 import java.util.Map;
  36 import java.util.Objects;
  37 import java.util.concurrent.atomic.AtomicReference;
  38 import java.util.stream.Collectors;
  39 import org.apache.calcite.sql.JoinType;
  40 import org.apache.commons.collections.CollectionUtils;
  41 import org.apache.commons.lang3.StringUtils;
  42 import org.apache.flink.api.common.typeinfo.TypeInformation;
  43 import org.apache.flink.api.java.tuple.Tuple2;
  44 import org.apache.flink.configuration.Configuration;
  45 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  46 import org.apache.flink.types.Row;
  47 import org.apache.flink.util.Collector;
  48 import org.slf4j.Logger;
  49 import org.slf4j.LoggerFactory;
  50 
  51 
  52 /**
  53  * side operator with cache for all(period reload)
  54  * Date: 2018/11/26
  55  * Company: www.dtstack.com
  56  *
  57  * @author maqi
  58  */
  59 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  60     private static final long serialVersionUID = 2098635140857937718L;
  61 
  62     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  63 
  64     private static final int CONN_RETRY_NUM = 3;
  65 
  66     private static final int DEFAULT_FETCH_SIZE = 1000;
  67 
  68     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  69 
  70     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  71         super(sideInfo);
  72     }
  73 
  74     @Override
  75     public void open(Configuration parameters) throws Exception {
  76         super.open(parameters);
  77         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  78         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  79     }
  80 
  81     @Override
  82     protected void initCache() throws SQLException {
  83         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  84         cacheRef.set(newCache);
  85         loadData(newCache);
  86     }
  87 
  88     @Override
  89     protected void reloadCache() {
  90         //reload cacheRef and replace to old cacheRef
  91         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  92         cacheRef.set(newCache);
  93         try {
  94             loadData(newCache);
  95         } catch (SQLException e) {
  96             throw new RuntimeException(e);
  97         }
  98         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
  99     }
 100 
 101     @Override
<abbr title=" 102     public void flatMap(Tuple2&lt;Boolean, Row&gt; value, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception {"> 102     public void flatMap(Tuple2&lt;Boolean, Row&gt; value, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception🔵</abbr>
 103         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
<abbr title=" 104         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.f1::getField).filter(Objects::nonNull).collect(Collectors.toCollection(ArrayList::new));"> 104         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.f1::getField).filter(Objects::no🔵</abbr>
 105         if ((inputParams.size() != equalValIndex.size()) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 106             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 107             return;
 108         }
 109         String cacheKey = inputParams.stream().map(Object::toString).collect(Collectors.joining(&quot;_&quot;));
 110         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 111         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 112             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 113         }
 114         cacheList.forEach(( one) -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));
 115     }
 116 
 117     @Override
 118     public Row fillData(Row input, Object sideInput) {
 119         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 120         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 121 
 122         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 123             // origin value
 124             Object obj = input.getField(entry.getValue());
<abbr title=" 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 126             row.setField(entry.getKey(), obj);
 127         }
 128 
 129         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 130             if (cacheInfo == null) {
 131                 row.setField(entry.getKey(), null);
 132             } else {
 133                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 134             }
 135 
 136         }
 137         return row;
 138     }
 139 
 140     /**
 141      *  covert flink time attribute.Type information for indicating event or processing time.
 142      *  However, it behaves like a regular SQL timestamp but is serialized as Long.
 143      *
 144      * @param entry
 145      * @param obj
 146      * @return
 147      */
 148     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 149         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 150         if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
 151             obj = Timestamp.valueOf(((LocalDateTime) (obj)));
 152         }
 153         return obj;
 154     }
 155 
 156     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 157         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 158         Connection connection = null;
 159 
 160         try {
 161             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 162                 try {
<abbr title=" 163                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 163                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 164                     break;
 165                 } catch (Exception e) {
 166                     if (i == CONN_RETRY_NUM - 1) {
 167                         throw new RuntimeException(&quot;&quot;, e);
 168                     }
 169                     try {
<abbr title=" 170                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 170                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 171                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 172                         Thread.sleep(5 * 1000);
 173                     } catch (InterruptedException e1) {
 174                         LOG.error(&quot;&quot;, e1);
 175                     }
 176                 }
 177             }
 178             queryAndFillData(tmpCache, connection);
 179         } catch (Exception e) {
 180             LOG.error(&quot;&quot;, e);
 181             throw new SQLException(e);
 182         } finally {
 183             if (connection != null) {
 184                 connection.close();
 185             }
 186         }
 187     }
 188 
<abbr title=" 189     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 189     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 190         // load data from table
 191         String sql = sideInfo.getSqlCondition();
 192         Statement statement = connection.createStatement();
 193         statement.setFetchSize(getFetchSize());
 194         ResultSet resultSet = statement.executeQuery(sql);
 195         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 196         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 197         while (resultSet.next()) {
 198             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 199             for (String fieldName : sideFieldNames) {
 200                 Object object = resultSet.getObject(fieldName.trim());
 201                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 202                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 203                 oneRow.put(fieldName.trim(), object);
 204             }
<abbr title=" 205             String cacheKey = sideInfo.getEqualFieldList().stream().map(oneRow::get).map(Object::toString).collect(Collectors.joining(&quot;_&quot;));"> 205             String cacheKey = sideInfo.getEqualFieldList().stream().map(oneRow::get).map(Object::toString🔵</abbr>
 206             tmpCache.computeIfAbsent(cacheKey, ( key) -&gt; Lists.newArrayList()).add(oneRow);
 207         }
 208     }
 209 
 210     public int getFetchSize() {
 211         return DEFAULT_FETCH_SIZE;
 212     }
 213 
 214     /**
 215      *  get jdbc connection
 216      * @param dbURL
 217      * @param userName
 218      * @param password
 219      * @return
 220      */
 221     public abstract Connection getConn(String dbURL, String userName, String password);
 222 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  22 +import org.apache.flink.api.java.tuple.Tuple2;</span>
  23  import org.apache.flink.configuration.Configuration;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import org.apache.flink.table.runtime.types.CRow;</span>
  25  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  26  import org.apache.flink.types.Row;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  27 -import org.apache.flink.util.Collector;</span>
  28  
  29  
  30  import com.dtstack.flink.sql.side.BaseAllReqRow;
  31  import com.dtstack.flink.sql.side.BaseSideInfo;
  32  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  33  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  34  import com.google.common.collect.Lists;
  35  import com.google.common.collect.Maps;
  36  import org.apache.calcite.sql.JoinType;
  37  import org.apache.commons.collections.CollectionUtils;
  38  import org.apache.commons.lang3.StringUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  39 +import org.apache.flink.util.Collector;</span>
  40  import org.slf4j.Logger;
  41  import org.slf4j.LoggerFactory;
  42  
  43  import java.sql.Connection;
  44  import java.sql.ResultSet;
  45  import java.sql.SQLException;
  46  import java.sql.Statement;
  47  import java.sql.Timestamp;
  48  import java.util.ArrayList;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  49 +import java.time.LocalDateTime;</span>
  50  import java.util.Calendar;
  51  import java.util.List;
  52  import java.util.Map;


  53  import java.util.concurrent.atomic.AtomicReference;
  54  import java.util.stream.Collectors;
  55  
  56  /**
  57   * side operator with cache for all(period reload)
  58   * Date: 2018/11/26
  59   * Company: www.dtstack.com
  60   *
  61   * @author maqi
  62   */
  63  
  64  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  65  
  66      private static final long serialVersionUID = 2098635140857937718L;
  67  
  68      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  69  
  70      private static final int CONN_RETRY_NUM = 3;
  71  
  72      private static final int DEFAULT_FETCH_SIZE = 1000;
  73  
  74      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  75  
  76      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  77          super(sideInfo);
  78      }
  79  
  80      @Override
  81      public void open(Configuration parameters) throws Exception {
  82          super.open(parameters);
  83          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  84          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  85      }
  86  
  87  
  88      @Override
  89      protected void initCache() throws SQLException {
  90          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  91          cacheRef.set(newCache);
  92          loadData(newCache);
  93      }
  94  
  95      @Override
  96      protected void reloadCache() {
  97          //reload cacheRef and replace to old cacheRef
  98          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  99          cacheRef.set(newCache);
 100          try {
 101              loadData(newCache);
 102          } catch (SQLException e) {
 103              throw new RuntimeException(e);
 104          }
 105          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 106      }
 107  
 108      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 109 -    public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 110 +    public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {</span>
 111          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 112          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 113 -                .map(value.row()::getField)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 114 +                .map(value.f1::getField)</span>
 115                  .filter(object -&gt; null != object)

 116                  .collect(Collectors.toCollection(ArrayList::new));
 117  
 118          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 119 -            out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 120 +            out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
 121              return;
 122          }
 123  
 124          String cacheKey = inputParams.stream()
 125                  .map(Object::toString)
 126                  .collect(Collectors.joining(&quot;_&quot;));
 127  
 128          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 129          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 130 -            out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 131 -        }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 132 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 133 -        cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 134 +            out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 135 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 136 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 137 +        cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 138      }
 139  
 140      @Override
 141      public Row fillData(Row input, Object sideInput) {
 142          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 143          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 144  
 145          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 146              // origin value
 147              Object obj = input.getField(entry.getValue());
 148              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 149              row.setField(entry.getKey(), obj);
 150          }
 151  
 152          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 153              if (cacheInfo == null) {
 154                  row.setField(entry.getKey(), null);
 155              } else {
 156                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 157              }
 158  
 159          }
 160          return row;
 161      }
 162  
 163      /**
 164       *  covert flink time attribute.Type information for indicating event or processing time.
 165       *  However, it behaves like a regular SQL timestamp but is serialized as Long.
 166       *
 167       * @param entry
 168       * @param obj
 169       * @return
 170       */
 171      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 172          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 173 -        if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 174 -            obj = ((Timestamp) obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 175 +        if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 176 +            obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 177          }
 178          return obj;
 179      }
 180  
 181      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 182          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 183          Connection connection = null;
 184  
 185          try {
 186              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 187                  try {
 188                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 189                      break;
 190                  } catch (Exception e) {
 191                      if (i == CONN_RETRY_NUM - 1) {
 192                          throw new RuntimeException(&quot;&quot;, e);
 193                      }
 194                      try {
<abbr title=" 195                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 195                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;🔵</abbr>
 196                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 197                          Thread.sleep(5 * 1000);
 198                      } catch (InterruptedException e1) {
 199                          LOG.error(&quot;&quot;, e1);
 200                      }
 201                  }
 202              }
 203              queryAndFillData(tmpCache, connection);
 204          } catch (Exception e) {
 205              LOG.error(&quot;&quot;, e);
 206              throw new SQLException(e);
 207          } finally {
 208              if (connection != null) {
 209                  connection.close();
 210              }
 211          }
 212      }
 213  
<abbr title=" 214      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 214      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws S🔵</abbr>
 215          //load data from table
 216          String sql = sideInfo.getSqlCondition();
 217          Statement statement = connection.createStatement();
 218          statement.setFetchSize(getFetchSize());
 219          ResultSet resultSet = statement.executeQuery(sql);
 220  
 221          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 222          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 223          while (resultSet.next()) {
 224              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 225              for (String fieldName : sideFieldNames) {
 226                  Object object = resultSet.getObject(fieldName.trim());
 227                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 228                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 229                  oneRow.put(fieldName.trim(), object);
 230              }
 231  
 232              String cacheKey = sideInfo.getEqualFieldList().stream()
 233                      .map(equalField -&gt; oneRow.get(equalField))

 234                      .map(Object::toString)
 235                      .collect(Collectors.joining(&quot;_&quot;));
 236  
 237              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 238                      .add(oneRow);
 239          }
 240      }
 241  
 242      public int getFetchSize() {
 243          return DEFAULT_FETCH_SIZE;
 244      }
 245  
 246      /**
 247       *  get jdbc connection
 248       * @param dbURL
 249       * @param userName
 250       * @param password
 251       * @return
 252       */
 253      public abstract Connection getConn(String dbURL, String userName, String password);
 254  
 255  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;

  22  import org.apache.flink.configuration.Configuration;
  23  import org.apache.flink.table.runtime.types.CRow;
  24  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25  import org.apache.flink.types.Row;
  26  import org.apache.flink.util.Collector;
  27  
  28  
  29  import com.dtstack.flink.sql.side.BaseAllReqRow;
  30  import com.dtstack.flink.sql.side.BaseSideInfo;
  31  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33  import com.google.common.collect.Lists;
  34  import com.google.common.collect.Maps;
  35  import org.apache.calcite.sql.JoinType;
  36  import org.apache.commons.collections.CollectionUtils;
  37  import org.apache.commons.lang3.StringUtils;

  38  import org.slf4j.Logger;
  39  import org.slf4j.LoggerFactory;
  40  
  41  import java.sql.Connection;
  42  import java.sql.ResultSet;
  43  import java.sql.SQLException;
  44  import java.sql.Statement;
  45  import java.sql.Timestamp;
  46  import java.util.ArrayList;

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  47 -import java.util.Calendar;</span>
  48  import java.util.List;
  49  import java.util.Map;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import java.util.Objects;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import java.util.Calendar;</span>
  52  import java.util.concurrent.atomic.AtomicReference;
  53  import java.util.stream.Collectors;
  54  
  55  /**
  56   * side operator with cache for all(period reload)
  57   * Date: 2018/11/26
  58   * Company: www.dtstack.com
  59   *
  60   * @author maqi
  61   */
  62  
  63  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  64  
  65      private static final long serialVersionUID = 2098635140857937718L;
  66  
  67      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  68  
  69      private static final int CONN_RETRY_NUM = 3;
  70  
  71      private static final int DEFAULT_FETCH_SIZE = 1000;
  72  
  73      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  74  
  75      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  76          super(sideInfo);
  77      }
  78  
  79      @Override
  80      public void open(Configuration parameters) throws Exception {
  81          super.open(parameters);
  82          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  83          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  84      }
  85  
  86  
  87      @Override
  88      protected void initCache() throws SQLException {
  89          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  90          cacheRef.set(newCache);
  91          loadData(newCache);
  92      }
  93  
  94      @Override
  95      protected void reloadCache() {
  96          //reload cacheRef and replace to old cacheRef
  97          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  98          cacheRef.set(newCache);
  99          try {
 100              loadData(newCache);
 101          } catch (SQLException e) {
 102              throw new RuntimeException(e);
 103          }
 104          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 105      }
 106  
 107      @Override
 108      public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {

 109          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 110          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 111                  .map(value.row()::getField)

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 112 -                .filter(object -&gt; null != object)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 113 +                .filter(Objects::nonNull)</span>
 114                  .collect(Collectors.toCollection(ArrayList::new));
 115  
 116          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 117              out.collect(new CRow(fillData(value.row(), null), value.change()));

 118              return;
 119          }
 120  
 121          String cacheKey = inputParams.stream()
 122                  .map(Object::toString)
 123                  .collect(Collectors.joining(&quot;_&quot;));
 124  
 125          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 126          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 127              out.collect(new CRow(fillData(value.row(), null), value.change()));
 128          }
 129  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 130 -        cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 131 +        cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>



 132      }
 133  
 134      @Override
 135      public Row fillData(Row input, Object sideInput) {
 136          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 137          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 138  
 139          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 140              // origin value
 141              Object obj = input.getField(entry.getValue());
 142              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 143              row.setField(entry.getKey(), obj);
 144          }
 145  
 146          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 147              if (cacheInfo == null) {
 148                  row.setField(entry.getKey(), null);
 149              } else {
 150                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 151              }
 152  
 153          }
 154          return row;
 155      }
 156  
 157      /**
 158       *  covert flink time attribute.Type information for indicating event or processing time.
 159       *  However, it behaves like a regular SQL timestamp but is serialized as Long.
 160       *
 161       * @param entry
 162       * @param obj
 163       * @return
 164       */
 165      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 166          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 167          if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 168              obj = ((Timestamp) obj).getTime();


 169          }
 170          return obj;
 171      }
 172  
 173      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 174          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 175          Connection connection = null;
 176  
 177          try {
 178              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 179                  try {
 180                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 181                      break;
 182                  } catch (Exception e) {
 183                      if (i == CONN_RETRY_NUM - 1) {
 184                          throw new RuntimeException(&quot;&quot;, e);
 185                      }
 186                      try {
<abbr title=" 187                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 187                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;🔵</abbr>
 188                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 189                          Thread.sleep(5 * 1000);
 190                      } catch (InterruptedException e1) {
 191                          LOG.error(&quot;&quot;, e1);
 192                      }
 193                  }
 194              }
 195              queryAndFillData(tmpCache, connection);
 196          } catch (Exception e) {
 197              LOG.error(&quot;&quot;, e);
 198              throw new SQLException(e);
 199          } finally {
 200              if (connection != null) {
 201                  connection.close();
 202              }
 203          }
 204      }
 205  
<abbr title=" 206      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 206      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws S🔵</abbr>
 207          //load data from table
 208          String sql = sideInfo.getSqlCondition();
 209          Statement statement = connection.createStatement();
 210          statement.setFetchSize(getFetchSize());
 211          ResultSet resultSet = statement.executeQuery(sql);
 212  
 213          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 214          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 215          while (resultSet.next()) {
 216              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 217              for (String fieldName : sideFieldNames) {
 218                  Object object = resultSet.getObject(fieldName.trim());
 219                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 220                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 221                  oneRow.put(fieldName.trim(), object);
 222              }
 223  
 224              String cacheKey = sideInfo.getEqualFieldList().stream()
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 225 -                    .map(equalField -&gt; oneRow.get(equalField))</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 226 +                    .map(oneRow::get)</span>
 227                      .map(Object::toString)
 228                      .collect(Collectors.joining(&quot;_&quot;));
 229  
 230              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 231                      .add(oneRow);
 232          }
 233      }
 234  
 235      public int getFetchSize() {
 236          return DEFAULT_FETCH_SIZE;
 237      }
 238  
 239      /**
 240       *  get jdbc connection
 241       * @param dbURL
 242       * @param userName
 243       * @param password
 244       * @return
 245       */
 246      public abstract Connection getConn(String dbURL, String userName, String password);
 247  
 248  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            