<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>539 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;spork&#x27;, &#x27;jfstmerge&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Licensed to the Apache Software Foundation &#x27;
                           &#x27;(ASF) under one\n&#x27;
                           &#x27; * or more contributor license agreements.  See &#x27;
                           &#x27;the NOTICE file\n&#x27;
                           &#x27; * distributed with this work for additional &#x27;
                           &#x27;information\n&#x27;
                           &#x27; * regarding copyright ownership.  The ASF &#x27;
                           &#x27;licenses this file\n&#x27;
                           &#x27; * to you under the Apache License, Version 2.0 &#x27;
                           &#x27;(the\n&#x27;
                           &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                           &#x27;compliance\n&#x27;
                           &#x27; * with the License.  You may obtain a copy of the &#x27;
                           &#x27;License at\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                           &#x27; * &lt;p&gt;\n&#x27;
                           &#x27; * Unless required by applicable law or agreed to &#x27;
                           &#x27;in writing, software\n&#x27;
                           &#x27; * distributed under the License is distributed on &#x27;
                           &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                           &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                           &#x27;either express or implied.\n&#x27;
                           &#x27; * See the License for the specific language &#x27;
                           &#x27;governing permissions and\n&#x27;
                           &#x27; * limitations under the License.\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;package com.dtstack.flink.sql.launcher.perjob;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.enums.EPluginLoadMode;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.launcher.YarnConfLoader;\n&#x27;
                           &#x27;import com.dtstack.flink.sql.option.Options;\n&#x27;
                           &#x27;import org.apache.commons.lang3.StringUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.cache.DistributedCache;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.configuration.Configuration;\n&#x27;
                           &#x27;import com.google.common.base.Strings;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.jobgraph.JobGraph;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityConfiguration;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.runtime.security.SecurityUtils;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.AbstractYarnClusterDescriptor;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.yarn.YarnClusterDescriptor;\n&#x27;
                           &#x27;import org.apache.hadoop.fs.Path;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.client.api.YarnClient;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.hadoop.yarn.conf.YarnConfiguration;\n&#x27;
                           &#x27;import org.slf4j.Logger;\n&#x27;
                           &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import java.io.File;\n&#x27;
                           &#x27;import java.net.MalformedURLException;\n&#x27;
                           &#x27;import java.net.URL;\n&#x27;
                           &#x27;import java.util.ArrayList;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.Properties;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * Reason:\n&#x27;
                           &#x27; * Date: 2018/11/16\n&#x27;
                           &#x27; * Company: www.dtstack.com\n&#x27;
                           &#x27; * @author xuchao\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;public class PerJobClusterClientBuilder {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final Logger LOG = &#x27;
                           &#x27;LoggerFactory.getLogger(PerJobClusterClientBuilder.class);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static final String DEFAULT_CONF_DIR = &#x27;
                           &#x27;&quot;./&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnClient yarnClient;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private YarnConfiguration yarnConf;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private Configuration flinkConfig;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public void init(String yarnConfDir, &#x27;
                           &#x27;Configuration flinkConfig, Properties userConf) &#x27;
                           &#x27;throws Exception {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (Strings.isNullOrEmpty(yarnConfDir)) {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;parameters &#x27;
                           &#x27;of yarn is required&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        userConf.forEach((key, val) -&gt; &#x27;
                           &#x27;flinkConfig.setString(key.toString(), &#x27;
                           &#x27;val.toString()));\n&#x27;
                           &#x27;        this.flinkConfig = flinkConfig;\n&#x27;
                           &#x27;        SecurityUtils.install(new &#x27;
                           &#x27;SecurityConfiguration(flinkConfig));\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        yarnConf = &#x27;
                           &#x27;YarnConfLoader.getYarnConf(yarnConfDir);\n&#x27;
                           &#x27;        yarnClient = &#x27;
                           &#x27;YarnClient.createYarnClient();\n&#x27;
                           &#x27;        yarnClient.init(yarnConf);\n&#x27;
                           &#x27;        yarnClient.start();\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        LOG.info(&quot;----init yarn success ----&quot;);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    public AbstractYarnClusterDescriptor &#x27;
                           &#x27;createPerJobClusterDescriptor(String flinkJarPath, &#x27;
                           &#x27;Options launcherOptions, JobGraph jobGraph)\n&#x27;
                           &#x27;            throws MalformedURLException {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        String flinkConf = &#x27;
                           &#x27;StringUtils.isEmpty(launcherOptions.getFlinkconf()) &#x27;
                           &#x27;? DEFAULT_CONF_DIR : &#x27;
                           &#x27;launcherOptions.getFlinkconf();\n&#x27;
                           &#x27;        AbstractYarnClusterDescriptor &#x27;
                           &#x27;clusterDescriptor = &#x27;
                           &#x27;getClusterDescriptor(flinkConfig, yarnConf, &#x27;
                           &#x27;flinkConf);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        if (StringUtils.isNotBlank(flinkJarPath)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;            if (!new File(flinkJarPath).exists()) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                throw new RuntimeException(&quot;The &#x27;
                           &#x27;param \&#x27;-flinkJarPath\&#x27; ref dir is not exist&quot;);\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        if (flinkJarPath != null) {\n&#x27;
                           &#x27;            File[] jars = new &#x27;
                           &#x27;File(flinkJarPath).listFiles();\n&#x27;
                           &#x27;            for (File file : jars) {\n&#x27;
                           &#x27;                if &#x27;
                           &#x27;(file.toURI().toURL().toString().contains(&quot;flink-dist&quot;)) &#x27;
                           &#x27;{\n&#x27;
                           &#x27;                    &#x27;
                           &#x27;clusterDescriptor.setLocalJarPath(new &#x27;
                           &#x27;Path(file.toURI().toURL().toString()));\n&#x27;
                           &#x27;                } else {\n&#x27;
                           &#x27;                    shipFiles.add(file);\n&#x27;
                           &#x27;                }\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new RuntimeException(&quot;The Flink &#x27;
                           &#x27;jar path is null&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        // classpath , all node need contain &#x27;
                           &#x27;plugin jar\n&#x27;
                           &#x27;        String pluginLoadMode = &#x27;
                           &#x27;launcherOptions.getPluginLoadMode();\n&#x27;
                           &#x27;        if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.CLASSPATH.name())) {\n&#x27;
                           &#x27;            fillJobGraphClassPath(jobGraph);\n&#x27;
                           &#x27;        } else if &#x27;
                           &#x27;(StringUtils.equalsIgnoreCase(pluginLoadMode, &#x27;
                           &#x27;EPluginLoadMode.SHIPFILE.name())) {\n&#x27;
                           &#x27;            List&lt;File&gt; pluginPaths = &#x27;
                           &#x27;getPluginPathToShipFiles(jobGraph);\n&#x27;
                           &#x27;            shipFiles.addAll(pluginPaths);\n&#x27;
                           &#x27;        } else {\n&#x27;
                           &#x27;            throw new &#x27;
                           &#x27;IllegalArgumentException(&quot;Unsupported plugin &#x27;
                           &#x27;loading mode &quot; + pluginLoadMode\n&#x27;
                           &#x27;                    + &quot; Currently only classpath &#x27;
                           &#x27;and shipfile are supported.&quot;);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.addShipFiles(shipFiles);\n&#x27;
                           &#x27;        &#x27;
                           &#x27;clusterDescriptor.setName(launcherOptions.getName());\n&#x27;
                           &#x27;        String queue = &#x27;
                           &#x27;launcherOptions.getQueue();\n&#x27;
                           &#x27;        if (!Strings.isNullOrEmpty(queue)) {\n&#x27;
                           &#x27;            clusterDescriptor.setQueue(queue);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return clusterDescriptor;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private static void &#x27;
                           &#x27;fillJobGraphClassPath(JobGraph jobGraph) throws &#x27;
                           &#x27;MalformedURLException {\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                jobGraph.getClasspaths().add(new &#x27;
                           &#x27;URL(&quot;file:&quot; + tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;File&gt; &#x27;
                           &#x27;getPluginPathToShipFiles(JobGraph jobGraph) {\n&#x27;
                           &#x27;        List&lt;File&gt; shipFiles = new ArrayList&lt;&gt;();\n&#x27;
                           &#x27;        Map&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; &#x27;
                           &#x27;jobCacheFileConfig = jobGraph.getUserArtifacts();\n&#x27;
                           &#x27;        for (Map.Entry&lt;String, &#x27;
                           &#x27;DistributedCache.DistributedCacheEntry&gt; tmp : &#x27;
                           &#x27;jobCacheFileConfig.entrySet()) {\n&#x27;
                           &#x27;            if &#x27;
                           &#x27;(tmp.getKey().startsWith(&quot;class_path&quot;)) {\n&#x27;
                           &#x27;                shipFiles.add(new &#x27;
                           &#x27;File(tmp.getValue().filePath));\n&#x27;
                           &#x27;            }\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;        return shipFiles;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private AbstractYarnClusterDescriptor &#x27;
                           &#x27;getClusterDescriptor(\n&#x27;
                           &#x27;            Configuration configuration,\n&#x27;
                           &#x27;            YarnConfiguration yarnConfiguration,\n&#x27;
                           &#x27;            String configurationDirectory) {\n&#x27;
                           &#x27;        return new YarnClusterDescriptor(\n&#x27;
                           &#x27;                configuration,\n&#x27;
                           &#x27;                yarnConfiguration,\n&#x27;
                           &#x27;                configurationDirectory,\n&#x27;
                           &#x27;                yarnClient,\n&#x27;
                           &#x27;                false);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;spork&#x27;, &#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        