<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>599 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    public ElasticsearchSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;    public ElasticsearchSink &#x27;
                           &#x27;genStreamSink(TargetTableInfo targetTableInfo) &#x27;
                           &#x27;{\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.table.AbstractTargetTableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.api.java.tuple.Tuple2;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.java.typeutils.RowTypeInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.java.typeutils.TupleTypeInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStream;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.table.sinks.RetractStreamTableSink;\n&#x27;
                         &#x27;import org.apache.flink.table.sinks.TableSink;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.sink.IStreamSinkGener;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.sink.elasticsearch.table.ElasticsearchTableInfo;\n&#x27;
                         &#x27;import com.google.common.collect.Maps;\n&#x27;
                         &#x27;import org.apache.commons.lang.StringUtils;\n&#x27;
                         &#x27;import org.apache.http.HttpHost;\n&#x27;
                         &#x27;import java.util.Arrays;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.stream.Collectors;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * @author yinxi\n&#x27;
                         &#x27; * @date 2020/1/9 - 15:08\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;public class ElasticsearchSink implements &#x27;
                         &#x27;RetractStreamTableSink&lt;Row&gt;, &#x27;
                         &#x27;IStreamSinkGener&lt;ElasticsearchSink&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private final int ES_DEFAULT_PORT = 9200;\n&#x27;
                         &#x27;    private final String ES_DEFAULT_SCHEMA = &#x27;
                         &#x27;&quot;http&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String clusterName;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private int bulkFlushMaxActions = 1;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private List&lt;String&gt; esAddressList;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String index = &quot;&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String type = &quot;&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private List&lt;Integer&gt; idIndexList;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected String[] fieldNames;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected String[] columnTypes;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private TypeInformation[] fieldTypes;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private int parallelism = -1;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private ElasticsearchTableInfo esTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] &#x27;
                         &#x27;fieldTypes) {\n&#x27;
                         &#x27;        this.fieldNames = fieldNames;\n&#x27;
                         &#x27;        this.fieldTypes = fieldTypes;\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;getOutputType() {\n&#x27;
                         &#x27;        return new &#x27;
                         &#x27;TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), &#x27;
                         &#x27;getRecordType());\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                         &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                         &#x27;fieldNames);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public String[] getFieldNames() {\n&#x27;
                         &#x27;        return fieldNames;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;?&gt;[] getFieldTypes() {\n&#x27;
                         &#x27;        return fieldTypes;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private RichSinkFunction createEsSinkFunction() &#x27;
                         &#x27;{\n&#x27;
                         &#x27;        Map&lt;String, String&gt; userConfig = &#x27;
                         &#x27;Maps.newHashMap();\n&#x27;
                         &#x27;        userConfig.put(&quot;cluster.name&quot;, &#x27;
                         &#x27;clusterName);\n&#x27;
                         &#x27;        // This instructs the sink to emit after &#x27;
                         &#x27;every element, otherwise they would be buffered\n&#x27;
                         &#x27;        &#x27;
                         &#x27;userConfig.put(org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.CONFIG_KEY_BULK_FLUSH_MAX_ACTIONS, &#x27;
                         &#x27;&quot;&quot; + bulkFlushMaxActions);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        List&lt;HttpHost&gt; transports = &#x27;
                         &#x27;esAddressList.stream()\n&#x27;
                         &#x27;                .map(address -&gt; address.split(&quot;:&quot;))\n&#x27;
                         &#x27;                .map(addressArray -&gt; {\n&#x27;
                         &#x27;                    String host = &#x27;
                         &#x27;addressArray[0].trim();\n&#x27;
                         &#x27;                    int port = addressArray.length &gt; &#x27;
                         &#x27;1 ? Integer.valueOf(addressArray[1].trim()) : &#x27;
                         &#x27;ES_DEFAULT_PORT;\n&#x27;
                         &#x27;                    return new HttpHost(host.trim(), &#x27;
                         &#x27;port, ES_DEFAULT_SCHEMA);\n&#x27;
                         &#x27;                }).collect(Collectors.toList());\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        CustomerSinkFunc customerSinkFunc = new &#x27;
                         &#x27;CustomerSinkFunc(index, type, &#x27;
                         &#x27;Arrays.asList(fieldNames), &#x27;
                         &#x27;Arrays.asList(columnTypes), idIndexList);\n&#x27;
                         &#x27;        return new &#x27;
                         &#x27;MetricElasticsearch6Sink(userConfig, transports, &#x27;
                         &#x27;customerSinkFunc, esTableInfo);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public void &#x27;
                         &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        RichSinkFunction richSinkFunction = &#x27;
                         &#x27;createEsSinkFunction();\n&#x27;
                         &#x27;        DataStreamSink streamSink = &#x27;
                         &#x27;dataStream.addSink(richSinkFunction);\n&#x27;
                         &#x27;        if (parallelism &gt; 0) {\n&#x27;
                         &#x27;            streamSink.setParallelism(parallelism);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public ElasticsearchSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                           &#x27;import org.apache.flink.api.java.tuple.Tuple2;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.java.typeutils.RowTypeInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.java.typeutils.TupleTypeInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.datastream.DataStream;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.table.sinks.RetractStreamTableSink;\n&#x27;
                           &#x27;import org.apache.flink.table.sinks.TableSink;\n&#x27;
                           &#x27;import org.apache.flink.types.Row;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.sink.IStreamSinkGener;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.sink.elasticsearch.table.ElasticsearchTableInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.table.TargetTableInfo;\n&#x27;
                           &#x27;import com.google.common.collect.Maps;\n&#x27;
                           &#x27;import org.apache.commons.lang.StringUtils;\n&#x27;
                           &#x27;import org.apache.http.HttpHost;\n&#x27;
                           &#x27;import java.util.Arrays;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.stream.Collectors;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * @author yinxi\n&#x27;
                           &#x27; * @date 2020/1/9 - 15:08\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;public class ElasticsearchSink implements &#x27;
                           &#x27;RetractStreamTableSink&lt;Row&gt;, &#x27;
                           &#x27;IStreamSinkGener&lt;ElasticsearchSink&gt; {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private final int ES_DEFAULT_PORT = 9200;\n&#x27;
                           &#x27;    private final String ES_DEFAULT_SCHEMA = &#x27;
                           &#x27;&quot;http&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String clusterName;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private int bulkFlushMaxActions = 1;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;String&gt; esAddressList;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String index = &quot;&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String type = &quot;&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;Integer&gt; idIndexList;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    protected String[] fieldNames;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    protected String[] columnTypes;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private TypeInformation[] fieldTypes;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private int parallelism = -1;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private ElasticsearchTableInfo esTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;configure(String[] fieldNames, &#x27;
                           &#x27;TypeInformation&lt;?&gt;[] fieldTypes) {\n&#x27;
                           &#x27;        this.fieldNames = fieldNames;\n&#x27;
                           &#x27;        this.fieldTypes = fieldTypes;\n&#x27;
                           &#x27;        return this;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;getOutputType() {\n&#x27;
                           &#x27;        return new &#x27;
                           &#x27;TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), &#x27;
                           &#x27;getRecordType());\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                           &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                           &#x27;fieldNames);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public String[] getFieldNames() {\n&#x27;
                           &#x27;        return fieldNames;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TypeInformation&lt;?&gt;[] getFieldTypes() {\n&#x27;
                           &#x27;        return fieldTypes;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private RichSinkFunction &#x27;
                           &#x27;createEsSinkFunction() {\n&#x27;
                           &#x27;        Map&lt;String, String&gt; userConfig = &#x27;
                           &#x27;Maps.newHashMap();\n&#x27;
                           &#x27;        userConfig.put(&quot;cluster.name&quot;, &#x27;
                           &#x27;clusterName);\n&#x27;
                           &#x27;        // This instructs the sink to emit after &#x27;
                           &#x27;every element, otherwise they would be buffered\n&#x27;
                           &#x27;        &#x27;
                           &#x27;userConfig.put(org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.CONFIG_KEY_BULK_FLUSH_MAX_ACTIONS, &#x27;
                           &#x27;&quot;&quot; + bulkFlushMaxActions);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;HttpHost&gt; transports = &#x27;
                           &#x27;esAddressList.stream()\n&#x27;
                           &#x27;                .map(address -&gt; &#x27;
                           &#x27;address.split(&quot;:&quot;))\n&#x27;
                           &#x27;                .map(addressArray -&gt; {\n&#x27;
                           &#x27;                    String host = &#x27;
                           &#x27;addressArray[0].trim();\n&#x27;
                           &#x27;                    int port = addressArray.length &#x27;
                           &#x27;&gt; 1 ? Integer.valueOf(addressArray[1].trim()) : &#x27;
                           &#x27;ES_DEFAULT_PORT;\n&#x27;
                           &#x27;                    return new &#x27;
                           &#x27;HttpHost(host.trim(), port, ES_DEFAULT_SCHEMA);\n&#x27;
                           &#x27;                }).collect(Collectors.toList());\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        CustomerSinkFunc customerSinkFunc = new &#x27;
                           &#x27;CustomerSinkFunc(index, type, &#x27;
                           &#x27;Arrays.asList(fieldNames), &#x27;
                           &#x27;Arrays.asList(columnTypes), idIndexList);\n&#x27;
                           &#x27;        return new &#x27;
                           &#x27;MetricElasticsearch6Sink(userConfig, transports, &#x27;
                           &#x27;customerSinkFunc, esTableInfo);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public void &#x27;
                           &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;dataStream) {\n&#x27;
                           &#x27;        RichSinkFunction richSinkFunction = &#x27;
                           &#x27;createEsSinkFunction();\n&#x27;
                           &#x27;        DataStreamSink streamSink = &#x27;
                           &#x27;dataStream.addSink(richSinkFunction);\n&#x27;
                           &#x27;        if (parallelism &gt; 0) {\n&#x27;
                           &#x27;            &#x27;
                           &#x27;streamSink.setParallelism(parallelism);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public ElasticsearchSink &#x27;
                           &#x27;genStreamSink(TargetTableInfo targetTableInfo) &#x27;
                           &#x27;{\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;AbstractTargetTableInfo\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\nTargetTableInfo\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    public ElasticsearchSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;    public ElasticsearchSink &#x27;
                           &#x27;genStreamSink(TargetTableInfo targetTableInfo) &#x27;
                           &#x27;{\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.table.AbstractTargetTableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.api.java.tuple.Tuple2;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.java.typeutils.RowTypeInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.java.typeutils.TupleTypeInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStream;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.table.sinks.RetractStreamTableSink;\n&#x27;
                         &#x27;import org.apache.flink.table.sinks.TableSink;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.sink.IStreamSinkGener;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.sink.elasticsearch.table.ElasticsearchTableInfo;\n&#x27;
                         &#x27;import com.google.common.collect.Maps;\n&#x27;
                         &#x27;import org.apache.commons.lang.StringUtils;\n&#x27;
                         &#x27;import org.apache.http.HttpHost;\n&#x27;
                         &#x27;import java.util.Arrays;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.stream.Collectors;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * @author yinxi\n&#x27;
                         &#x27; * @date 2020/1/9 - 15:08\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;public class ElasticsearchSink implements &#x27;
                         &#x27;RetractStreamTableSink&lt;Row&gt;, &#x27;
                         &#x27;IStreamSinkGener&lt;ElasticsearchSink&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private final int ES_DEFAULT_PORT = 9200;\n&#x27;
                         &#x27;    private final String ES_DEFAULT_SCHEMA = &#x27;
                         &#x27;&quot;http&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String clusterName;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private int bulkFlushMaxActions = 1;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private List&lt;String&gt; esAddressList;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String index = &quot;&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private String type = &quot;&quot;;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private List&lt;Integer&gt; idIndexList;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected String[] fieldNames;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected String[] columnTypes;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private TypeInformation[] fieldTypes;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private int parallelism = -1;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private ElasticsearchTableInfo esTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] &#x27;
                         &#x27;fieldTypes) {\n&#x27;
                         &#x27;        this.fieldNames = fieldNames;\n&#x27;
                         &#x27;        this.fieldTypes = fieldTypes;\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;getOutputType() {\n&#x27;
                         &#x27;        return new &#x27;
                         &#x27;TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), &#x27;
                         &#x27;getRecordType());\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                         &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                         &#x27;fieldNames);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public String[] getFieldNames() {\n&#x27;
                         &#x27;        return fieldNames;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;?&gt;[] getFieldTypes() {\n&#x27;
                         &#x27;        return fieldTypes;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private RichSinkFunction createEsSinkFunction() &#x27;
                         &#x27;{\n&#x27;
                         &#x27;        Map&lt;String, String&gt; userConfig = &#x27;
                         &#x27;Maps.newHashMap();\n&#x27;
                         &#x27;        userConfig.put(&quot;cluster.name&quot;, &#x27;
                         &#x27;clusterName);\n&#x27;
                         &#x27;        // This instructs the sink to emit after &#x27;
                         &#x27;every element, otherwise they would be buffered\n&#x27;
                         &#x27;        &#x27;
                         &#x27;userConfig.put(org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.CONFIG_KEY_BULK_FLUSH_MAX_ACTIONS, &#x27;
                         &#x27;&quot;&quot; + bulkFlushMaxActions);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        List&lt;HttpHost&gt; transports = &#x27;
                         &#x27;esAddressList.stream()\n&#x27;
                         &#x27;                .map(address -&gt; address.split(&quot;:&quot;))\n&#x27;
                         &#x27;                .map(addressArray -&gt; {\n&#x27;
                         &#x27;                    String host = &#x27;
                         &#x27;addressArray[0].trim();\n&#x27;
                         &#x27;                    int port = addressArray.length &gt; &#x27;
                         &#x27;1 ? Integer.valueOf(addressArray[1].trim()) : &#x27;
                         &#x27;ES_DEFAULT_PORT;\n&#x27;
                         &#x27;                    return new HttpHost(host.trim(), &#x27;
                         &#x27;port, ES_DEFAULT_SCHEMA);\n&#x27;
                         &#x27;                }).collect(Collectors.toList());\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        CustomerSinkFunc customerSinkFunc = new &#x27;
                         &#x27;CustomerSinkFunc(index, type, &#x27;
                         &#x27;Arrays.asList(fieldNames), &#x27;
                         &#x27;Arrays.asList(columnTypes), idIndexList);\n&#x27;
                         &#x27;        return new &#x27;
                         &#x27;MetricElasticsearch6Sink(userConfig, transports, &#x27;
                         &#x27;customerSinkFunc, esTableInfo);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public void &#x27;
                         &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        RichSinkFunction richSinkFunction = &#x27;
                         &#x27;createEsSinkFunction();\n&#x27;
                         &#x27;        DataStreamSink streamSink = &#x27;
                         &#x27;dataStream.addSink(richSinkFunction);\n&#x27;
                         &#x27;        if (parallelism &gt; 0) {\n&#x27;
                         &#x27;            streamSink.setParallelism(parallelism);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public ElasticsearchSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;import &#x27;
                           &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                           &#x27;import org.apache.flink.api.java.tuple.Tuple2;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.java.typeutils.RowTypeInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.api.java.typeutils.TupleTypeInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.datastream.DataStream;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;org.apache.flink.table.sinks.RetractStreamTableSink;\n&#x27;
                           &#x27;import org.apache.flink.table.sinks.TableSink;\n&#x27;
                           &#x27;import org.apache.flink.types.Row;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.sink.IStreamSinkGener;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.sink.elasticsearch.table.ElasticsearchTableInfo;\n&#x27;
                           &#x27;import &#x27;
                           &#x27;com.dtstack.flink.sql.table.TargetTableInfo;\n&#x27;
                           &#x27;import com.google.common.collect.Maps;\n&#x27;
                           &#x27;import org.apache.commons.lang.StringUtils;\n&#x27;
                           &#x27;import org.apache.http.HttpHost;\n&#x27;
                           &#x27;import java.util.Arrays;\n&#x27;
                           &#x27;import java.util.List;\n&#x27;
                           &#x27;import java.util.Map;\n&#x27;
                           &#x27;import java.util.stream.Collectors;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;/**\n&#x27;
                           &#x27; * @author yinxi\n&#x27;
                           &#x27; * @date 2020/1/9 - 15:08\n&#x27;
                           &#x27; */\n&#x27;
                           &#x27;public class ElasticsearchSink implements &#x27;
                           &#x27;RetractStreamTableSink&lt;Row&gt;, &#x27;
                           &#x27;IStreamSinkGener&lt;ElasticsearchSink&gt; {\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private final int ES_DEFAULT_PORT = 9200;\n&#x27;
                           &#x27;    private final String ES_DEFAULT_SCHEMA = &#x27;
                           &#x27;&quot;http&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String clusterName;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private int bulkFlushMaxActions = 1;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;String&gt; esAddressList;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String index = &quot;&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private String type = &quot;&quot;;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private List&lt;Integer&gt; idIndexList;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    protected String[] fieldNames;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    protected String[] columnTypes;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private TypeInformation[] fieldTypes;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private int parallelism = -1;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private ElasticsearchTableInfo esTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;configure(String[] fieldNames, &#x27;
                           &#x27;TypeInformation&lt;?&gt;[] fieldTypes) {\n&#x27;
                           &#x27;        this.fieldNames = fieldNames;\n&#x27;
                           &#x27;        this.fieldTypes = fieldTypes;\n&#x27;
                           &#x27;        return this;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;getOutputType() {\n&#x27;
                           &#x27;        return new &#x27;
                           &#x27;TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), &#x27;
                           &#x27;getRecordType());\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                           &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                           &#x27;fieldNames);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public String[] getFieldNames() {\n&#x27;
                           &#x27;        return fieldNames;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public TypeInformation&lt;?&gt;[] getFieldTypes() {\n&#x27;
                           &#x27;        return fieldTypes;\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    private RichSinkFunction &#x27;
                           &#x27;createEsSinkFunction() {\n&#x27;
                           &#x27;        Map&lt;String, String&gt; userConfig = &#x27;
                           &#x27;Maps.newHashMap();\n&#x27;
                           &#x27;        userConfig.put(&quot;cluster.name&quot;, &#x27;
                           &#x27;clusterName);\n&#x27;
                           &#x27;        // This instructs the sink to emit after &#x27;
                           &#x27;every element, otherwise they would be buffered\n&#x27;
                           &#x27;        &#x27;
                           &#x27;userConfig.put(org.apache.flink.streaming.connectors.elasticsearch6.ElasticsearchSink.CONFIG_KEY_BULK_FLUSH_MAX_ACTIONS, &#x27;
                           &#x27;&quot;&quot; + bulkFlushMaxActions);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        List&lt;HttpHost&gt; transports = &#x27;
                           &#x27;esAddressList.stream()\n&#x27;
                           &#x27;                .map(address -&gt; &#x27;
                           &#x27;address.split(&quot;:&quot;))\n&#x27;
                           &#x27;                .map(addressArray -&gt; {\n&#x27;
                           &#x27;                    String host = &#x27;
                           &#x27;addressArray[0].trim();\n&#x27;
                           &#x27;                    int port = addressArray.length &#x27;
                           &#x27;&gt; 1 ? Integer.valueOf(addressArray[1].trim()) : &#x27;
                           &#x27;ES_DEFAULT_PORT;\n&#x27;
                           &#x27;                    return new &#x27;
                           &#x27;HttpHost(host.trim(), port, ES_DEFAULT_SCHEMA);\n&#x27;
                           &#x27;                }).collect(Collectors.toList());\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        CustomerSinkFunc customerSinkFunc = new &#x27;
                           &#x27;CustomerSinkFunc(index, type, &#x27;
                           &#x27;Arrays.asList(fieldNames), &#x27;
                           &#x27;Arrays.asList(columnTypes), idIndexList);\n&#x27;
                           &#x27;        return new &#x27;
                           &#x27;MetricElasticsearch6Sink(userConfig, transports, &#x27;
                           &#x27;customerSinkFunc, esTableInfo);\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public void &#x27;
                           &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;dataStream) {\n&#x27;
                           &#x27;        RichSinkFunction richSinkFunction = &#x27;
                           &#x27;createEsSinkFunction();\n&#x27;
                           &#x27;        DataStreamSink streamSink = &#x27;
                           &#x27;dataStream.addSink(richSinkFunction);\n&#x27;
                           &#x27;        if (parallelism &gt; 0) {\n&#x27;
                           &#x27;            &#x27;
                           &#x27;streamSink.setParallelism(parallelism);\n&#x27;
                           &#x27;        }\n&#x27;
                           &#x27;    }\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;    @Override\n&#x27;
                           &#x27;    public ElasticsearchSink &#x27;
                           &#x27;genStreamSink(TargetTableInfo targetTableInfo) &#x27;
                           &#x27;{\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;AbstractTargetTableInfo\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\nTargetTableInfo\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        