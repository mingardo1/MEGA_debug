<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>484</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    484
                    <a href="483.html">prev</a>
                    <a href="485.html">next</a>
                    <a href="484_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_cb68efb9e51ba697e771581059b9c11c3fe66ccb_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;cb68efb9e51ba697e771581059b9c11c3fe66ccb:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;cb68efb9e51ba697e771581059b9c11c3fe66ccb^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;cb68efb9e51ba697e771581059b9c11c3fe66ccb^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;828062ef514a8028632086b1c19ef248140da519:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [b]], subset: [[b], [b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import org.apache.calcite.sql.JoinType;
  30 import org.apache.commons.collections.map.HashedMap;
  31 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  32 import org.apache.flink.api.java.tuple.Tuple2;</span>
  33 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  34 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  35 import com.google.common.collect.Maps;</span>
  36 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  37 import org.apache.commons.lang.StringUtils;</span>
  38 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  39 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  40 import com.google.common.collect.Maps;
  41 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  42 import org.apache.flink.types.Row;
  43 import org.apache.flink.util.Collector;
  44 import org.apache.hadoop.conf.Configuration;
  45 import org.apache.hadoop.hbase.Cell;
  46 import org.apache.hadoop.hbase.CellUtil;
  47 import org.apache.hadoop.hbase.HBaseConfiguration;
  48 import org.apache.hadoop.hbase.TableName;
  49 import org.apache.hadoop.hbase.client.Connection;
  50 import org.apache.hadoop.hbase.client.ConnectionFactory;
  51 import org.apache.hadoop.hbase.client.Result;
  52 import org.apache.hadoop.hbase.client.ResultScanner;
  53 import org.apache.hadoop.hbase.client.Scan;
  54 import org.apache.hadoop.hbase.client.Table;
  55 import org.apache.hadoop.hbase.util.Bytes;
  56 import org.apache.hadoop.security.UserGroupInformation;
  57 import org.slf4j.Logger;
  58 import org.slf4j.LoggerFactory;
  59 
  60 import java.io.File;
  61 import java.io.IOException;
  62 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  63 </span>
  64 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  65 import java.sql.SQLException;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  66 import java.sql.Timestamp;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  67 import java.util.Calendar;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  68 import java.util.HashMap;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  69 import java.util.List;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  70 import java.util.Map;</span>
  71 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  72 import java.security.PrivilegedAction;</span>
  73 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  74 import java.sql.SQLException;
  75 import java.sql.Timestamp;
  76 import java.time.LocalDateTime;
  77 import java.util.Calendar;
  78 import java.util.HashMap;
  79 import java.util.List;
  80 import java.util.Map;
  81 import java.util.concurrent.atomic.AtomicReference;
  82 
  83 public class HbaseAllReqRow extends BaseAllReqRow {
  84 
  85     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  86 
  87     private String tableName;
  88 
  89     private Map&lt;String, String&gt; aliasNameInversion;
  90 
  91     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  92     private Connection conn = null;
  93     private Table table = null;
  94     private ResultScanner resultScanner = null;
  95     private Configuration conf = null;
  96 
<abbr title="  97     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  97     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  98         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  99         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
 100 
 101         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 102         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
 103         aliasNameInversion = new HashMap&lt;&gt;();
 104         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
 105             aliasNameInversion.put(entry.getValue(), entry.getKey());
 106         }
 107     }
 108 
 109     @Override
 110     public Row fillData(Row input, Object sideInput) {
 111         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
 112         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 113         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 114             Object obj = input.getField(entry.getValue());
<abbr title=" 115             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 115             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
 116 
<abbr title=" 117             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 117             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
 118             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 119                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 120             }
 121             row.setField(entry.getKey(), obj);
 122         }
 123 
 124         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 125             if(sideInputList == null){
 126                 row.setField(entry.getKey(), null);
 127             }else{
 128                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 129                 row.setField(entry.getKey(), sideInputList.get(key));
 130             }
 131         }
 132 
 133         return row;
 134     }
 135 
 136     @Override
 137     protected void initCache() throws SQLException {
 138         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 139         cacheRef.set(newCache);
 140         loadData(newCache);
 141     }
 142 
 143     @Override
 144     protected void reloadCache() {
 145         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 146         try {
 147             loadData(newCache);
 148         } catch (SQLException e) {
 149             LOG.error(&quot;&quot;, e);
 150         }
 151 
 152         cacheRef.set(newCache);
 153         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 154     }
 155 
 156     @Override
 157     public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 158         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 159         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 160             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 161             Object equalObj = input.f1.getField(conValIndex);
 162             if (equalObj == null) {
 163                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 164                     Row data = fillData(input.f1, null);
 165                     out.collect(Tuple2.of(input.f0, data));
 166                 }
 167                 return;
 168             }
 169             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 170         }
 171 
 172         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 173 
 174         Map&lt;String, Object&gt; cacheList = null;
 175 
 176         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 177         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 178         if (hbaseSideTableInfo.isPreRowKey()) {
 179             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 180                 if (entry.getKey().startsWith(rowKeyStr)) {
 181                     cacheList = cacheRef.get().get(entry.getKey());
 182                     Row row = fillData(input.f1, cacheList);
 183                     out.collect(Tuple2.of(input.f0, row));
 184                 }
 185             }
 186         } else {
 187             cacheList = cacheRef.get().get(rowKeyStr);
 188             Row row = fillData(input.f1, cacheList);
 189             out.collect(Tuple2.of(input.f0, row));
 190         }
 191 
 192     }
 193 
 194     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 195         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 196         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 197         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 198         int loadDataCount = 0;
 199         try {
 200             if (openKerberos) {
 201                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 202                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 204                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 205                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 206 
<abbr title=" 207                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 207                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 208                 Configuration finalConf = conf;
 209                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 210                     @Override
 211                     public Connection run() {
 212                         try {
 213                             return ConnectionFactory.createConnection(finalConf);
 214                         } catch (IOException e) {
 215                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 216                             throw new RuntimeException(e);
 217                         }
 218                     }
 219                 });
 220 
 221             } else {
 222                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 223                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 224                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 224                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 225                 conn = ConnectionFactory.createConnection(conf);
 226             }
 227 
 228             table = conn.getTable(TableName.valueOf(tableName));
 229             resultScanner = table.getScanner(new Scan());
 230             for (Result r : resultScanner) {
 231                 Map&lt;String, Object&gt; kv = new HashedMap();
 232                 for (Cell cell : r.listCells())
 233                 {
 234                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 235                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 236                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 237                     StringBuilder key = new StringBuilder();
 238                     key.append(family).append(&quot;:&quot;).append(qualifier);
 239 
 240                     kv.put(aliasNameInversion.get(key.toString()), value);
 241                 }
 242                 loadDataCount++;
 243                 tmpCache.put(new String(r.getRow()), kv);
 244             }
 245         } catch (IOException e) {
 246             throw new RuntimeException(e);
 247         } finally {
 248             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 249             try {
 250                 if (null != conn) {
 251                     conn.close();
 252                 }
 253 
 254                 if (null != table) {
 255                     table.close();
 256                 }
 257 
 258                 if (null != resultScanner) {
 259                     resultScanner.close();
 260                 }
 261             } catch (IOException e) {
 262                 LOG.error(&quot;&quot;, e);
 263             }
 264         }
 265     }
 266 
 267 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import org.apache.calcite.sql.JoinType;
  30 import org.apache.commons.collections.map.HashedMap;
  31 import org.apache.flink.api.java.tuple.Tuple2;
  32 import org.apache.commons.lang.StringUtils;
  33 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  34 import com.google.common.collect.Maps;
  35 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  36 import org.apache.flink.types.Row;
  37 import org.apache.flink.util.Collector;
  38 import org.apache.hadoop.conf.Configuration;
  39 import org.apache.hadoop.hbase.Cell;
  40 import org.apache.hadoop.hbase.CellUtil;
  41 import org.apache.hadoop.hbase.HBaseConfiguration;
  42 import org.apache.hadoop.hbase.TableName;
  43 import org.apache.hadoop.hbase.client.Connection;
  44 import org.apache.hadoop.hbase.client.ConnectionFactory;
  45 import org.apache.hadoop.hbase.client.Result;
  46 import org.apache.hadoop.hbase.client.ResultScanner;
  47 import org.apache.hadoop.hbase.client.Scan;
  48 import org.apache.hadoop.hbase.client.Table;
  49 import org.apache.hadoop.hbase.util.Bytes;
  50 import org.apache.hadoop.security.UserGroupInformation;
  51 import org.slf4j.Logger;
  52 import org.slf4j.LoggerFactory;
  53 
  54 import java.io.File;
  55 import java.io.IOException;
  56 import java.security.PrivilegedAction;
  57 
  58 import java.sql.SQLException;
  59 import java.sql.Timestamp;
  60 import java.time.LocalDateTime;
  61 import java.util.Calendar;
  62 import java.util.HashMap;
  63 import java.util.List;
  64 import java.util.Map;
  65 import java.util.concurrent.atomic.AtomicReference;
  66 
  67 public class HbaseAllReqRow extends BaseAllReqRow {
  68 
  69     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  70 
  71     private String tableName;
  72 
  73     private Map&lt;String, String&gt; aliasNameInversion;
  74 
  75     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  76     private Connection conn = null;
  77     private Table table = null;
  78     private ResultScanner resultScanner = null;
  79     private Configuration conf = null;
  80 
<abbr title="  81     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  81     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  82         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  83         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  84 
  85         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  86         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  87         aliasNameInversion = new HashMap&lt;&gt;();
  88         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  89             aliasNameInversion.put(entry.getValue(), entry.getKey());
  90         }
  91     }
  92 
  93     @Override
  94     public Row fillData(Row input, Object sideInput) {
  95         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  96         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  97         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  98             Object obj = input.getField(entry.getValue());
<abbr title="  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
 100 
<abbr title=" 101             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 101             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
 102             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 103                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 104             }
 105             row.setField(entry.getKey(), obj);
 106         }
 107 
 108         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 109             if(sideInputList == null){
 110                 row.setField(entry.getKey(), null);
 111             }else{
 112                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 113                 row.setField(entry.getKey(), sideInputList.get(key));
 114             }
 115         }
 116 
 117         return row;
 118     }
 119 
 120     @Override
 121     protected void initCache() throws SQLException {
 122         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 123         cacheRef.set(newCache);
 124         loadData(newCache);
 125     }
 126 
 127     @Override
 128     protected void reloadCache() {
 129         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 130         try {
 131             loadData(newCache);
 132         } catch (SQLException e) {
 133             LOG.error(&quot;&quot;, e);
 134         }
 135 
 136         cacheRef.set(newCache);
 137         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 138     }
 139 
 140     @Override
 141     public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 142         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 143         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 144             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 145             Object equalObj = input.f1.getField(conValIndex);
 146             if (equalObj == null) {
 147                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 148                     Row data = fillData(input.f1, null);
 149                     out.collect(Tuple2.of(input.f0, data));
 150                 }
 151                 return;
 152             }
 153             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 154         }
 155 
 156         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 157 
 158         Map&lt;String, Object&gt; cacheList = null;
 159 
 160         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 161         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 162         if (hbaseSideTableInfo.isPreRowKey()) {
 163             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 164                 if (entry.getKey().startsWith(rowKeyStr)) {
 165                     cacheList = cacheRef.get().get(entry.getKey());
 166                     Row row = fillData(input.f1, cacheList);
 167                     out.collect(Tuple2.of(input.f0, row));
 168                 }
 169             }
 170         } else {
 171             cacheList = cacheRef.get().get(rowKeyStr);
 172             Row row = fillData(input.f1, cacheList);
 173             out.collect(Tuple2.of(input.f0, row));
 174         }
 175 
 176     }
 177 
 178     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 179         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 180         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 181         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 182         int loadDataCount = 0;
 183         try {
 184             if (openKerberos) {
 185                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 186                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 187                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 187                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 188                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 189                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 190 
<abbr title=" 191                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 191                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 192                 Configuration finalConf = conf;
 193                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 194                     @Override
 195                     public Connection run() {
 196                         try {
 197                             return ConnectionFactory.createConnection(finalConf);
 198                         } catch (IOException e) {
 199                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 200                             throw new RuntimeException(e);
 201                         }
 202                     }
 203                 });
 204 
 205             } else {
 206                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 207                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 208                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 208                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 209             conn = ConnectionFactory.createConnection(conf);
 210             }
 211 
 212             table = conn.getTable(TableName.valueOf(tableName));
 213             resultScanner = table.getScanner(new Scan());
 214             for (Result r : resultScanner) {
 215                 Map&lt;String, Object&gt; kv = new HashedMap();
 216                 for (Cell cell : r.listCells())
 217                 {
 218                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 219                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 220                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 221                     StringBuilder key = new StringBuilder();
 222                     key.append(family).append(&quot;:&quot;).append(qualifier);
 223 
 224                     kv.put(aliasNameInversion.get(key.toString()), value);
 225                 }
 226                 loadDataCount++;
 227                 tmpCache.put(new String(r.getRow()), kv);
 228             }
 229         } catch (IOException e) {
 230             throw new RuntimeException(e);
 231         } finally {
 232             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 233             try {
 234                 if (null != conn) {
 235                     conn.close();
 236                 }
 237 
 238                 if (null != table) {
 239                     table.close();
 240                 }
 241 
 242                 if (null != resultScanner) {
 243                     resultScanner.close();
 244                 }
 245             } catch (IOException e) {
 246                 LOG.error(&quot;&quot;, e);
 247             }
 248         }
 249     }
 250 
 251 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  26 import com.google.common.collect.Maps;
  27 import java.io.File;
  28 import java.io.IOException;
  29 import java.security.PrivilegedAction;
  30 import java.sql.SQLException;
  31 import java.sql.Timestamp;
  32 import java.time.LocalDateTime;
  33 import java.util.Calendar;
  34 import java.util.HashMap;
  35 import java.util.List;
  36 import java.util.Map;
  37 import java.util.concurrent.atomic.AtomicReference;
  38 import org.apache.calcite.sql.JoinType;
  39 import org.apache.commons.collections.map.HashedMap;
  40 import org.apache.commons.lang.StringUtils;
  41 import org.apache.flink.api.java.tuple.Tuple2;
  42 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  43 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  44 import org.apache.flink.types.Row;
  45 import org.apache.flink.util.Collector;
  46 import org.apache.hadoop.conf.Configuration;
  47 import org.apache.hadoop.hbase.Cell;
  48 import org.apache.hadoop.hbase.CellUtil;
  49 import org.apache.hadoop.hbase.HBaseConfiguration;
  50 import org.apache.hadoop.hbase.TableName;
  51 import org.apache.hadoop.hbase.client.Connection;
  52 import org.apache.hadoop.hbase.client.ConnectionFactory;
  53 import org.apache.hadoop.hbase.client.Result;
  54 import org.apache.hadoop.hbase.client.ResultScanner;
  55 import org.apache.hadoop.hbase.client.Scan;
  56 import org.apache.hadoop.hbase.client.Table;
  57 import org.apache.hadoop.hbase.util.Bytes;
  58 import org.apache.hadoop.security.UserGroupInformation;
  59 import org.slf4j.Logger;
  60 import org.slf4j.LoggerFactory;
  61 
  62 
  63 public class HbaseAllReqRow extends BaseAllReqRow {
  64     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  65 
  66     private String tableName;
  67 
  68     private Map&lt;String, String&gt; aliasNameInversion;
  69 
  70     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  71 
  72     private Connection conn = null;
  73 
  74     private Table table = null;
  75 
  76     private ResultScanner resultScanner = null;
  77 
  78     private Configuration conf = null;
  79 
<abbr title="  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  81         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  82         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  83         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  84         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  85         aliasNameInversion = new HashMap&lt;&gt;();
  86         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  87             aliasNameInversion.put(entry.getValue(), entry.getKey());
  88         }
  89     }
  90 
  91     @Override
  92     public Row fillData(Row input, Object sideInput) {
  93         Map&lt;String, Object&gt; sideInputList = ((Map&lt;String, Object&gt;) (sideInput));
  94         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  95         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
  96             Object obj = input.getField(entry.getValue());
<abbr title="  97             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  97             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
<abbr title="  98             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  98             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
  99             if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
 100                 obj = Timestamp.valueOf(((LocalDateTime) (obj)));
 101             }
 102             row.setField(entry.getKey(), obj);
 103         }
 104         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 105             if (sideInputList == null) {
 106                 row.setField(entry.getKey(), null);
 107             } else {
 108                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 109                 row.setField(entry.getKey(), sideInputList.get(key));
 110             }
 111         }
 112         return row;
 113     }
 114 
 115     @Override
 116     protected void initCache() throws SQLException {
 117         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 118         cacheRef.set(newCache);
 119         loadData(newCache);
 120     }
 121 
 122     @Override
 123     protected void reloadCache() {
 124         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 125         try {
 126             loadData(newCache);
 127         } catch (SQLException e) {
 128             LOG.error(&quot;&quot;, e);
 129         }
 130 
 131         cacheRef.set(newCache);
 132         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 133     }
 134 
 135     @Override
<abbr title=" 136     public void flatMap(Tuple2&lt;Boolean, Row&gt; input, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception {"> 136     public void flatMap(Tuple2&lt;Boolean, Row&gt; input, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws ExceptionðŸ”µ</abbr>
 137         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 138         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 139             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 140             Object equalObj = input.f1.getField(conValIndex);
 141             if (equalObj == null) {
 142                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 143                     Row data = fillData(input.f1, null);
 144                     out.collect(Tuple2.of(input.f0, data));
 145                 }
 146                 return;
 147             }
 148             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 149         }
 150         String rowKeyStr = ((HbaseAllSideInfo) (sideInfo)).getRowKeyBuilder().getRowKey(refData);
 151         Map&lt;String, Object&gt; cacheList = null;
 152         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 153         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 154         if (hbaseSideTableInfo.isPreRowKey()) {
 155             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 156                 if (entry.getKey().startsWith(rowKeyStr)) {
 157                     cacheList = cacheRef.get().get(entry.getKey());
 158                     Row row = fillData(input.f1, cacheList);
 159                     out.collect(Tuple2.of(input.f0, row));
 160                 }
 161             }
 162         } else {
 163             cacheList = cacheRef.get().get(rowKeyStr);
 164             Row row = fillData(input.f1, cacheList);
 165             out.collect(Tuple2.of(input.f0, row));
 166         }
 167     }
 168 
 169     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 170         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 171         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 172         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 173         int loadDataCount = 0;
 174         try {
 175             if (openKerberos) {
 176                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 177                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 178                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 178                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 179                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 180                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
<abbr title=" 181                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 181                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 182                 Configuration finalConf = conf;
 183                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 184                     @Override
 185                     public Connection run() {
 186                         try {
 187                             return ConnectionFactory.createConnection(finalConf);
 188                         } catch (IOException e) {
 189                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 190                             throw new RuntimeException(e);
 191                         }
 192                     }
 193                 });
 194             } else {
 195                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 196                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 197                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 197                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 198                 conn = ConnectionFactory.createConnection(conf);
 199             }
 200             table = conn.getTable(TableName.valueOf(tableName));
 201             resultScanner = table.getScanner(new Scan());
 202             for (Result r : resultScanner) {
 203                 Map&lt;String, Object&gt; kv = new HashedMap();
 204                 for (Cell cell : r.listCells()) {
 205                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 206                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 207                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 208                     StringBuilder key = new StringBuilder();
 209                     key.append(family).append(&quot;:&quot;).append(qualifier);
 210                     kv.put(aliasNameInversion.get(key.toString()), value);
 211                 }
 212                 loadDataCount++;
 213                 tmpCache.put(new String(r.getRow()), kv);
 214             }
 215         } catch (IOException e) {
 216             throw new RuntimeException(e);
 217         } finally {
 218             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 219             try {
 220                 if (null != conn) {
 221                     conn.close();
 222                 }
 223                 if (null != table) {
 224                     table.close();
 225                 }
 226                 if (null != resultScanner) {
 227                     resultScanner.close();
 228                 }
 229             } catch (IOException e) {
 230                 LOG.error(&quot;&quot;, e);
 231             }
 232         }
 233     }
 234 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;

  28  import org.apache.calcite.sql.JoinType;
  29  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  30 +import org.apache.flink.api.java.tuple.Tuple2;</span>
  31  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32  import com.google.common.collect.Maps;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  33 -import org.apache.flink.table.runtime.types.CRow;</span>
  34  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  35  import org.apache.flink.types.Row;
  36  import org.apache.flink.util.Collector;
  37  import org.apache.hadoop.conf.Configuration;
  38  import org.apache.hadoop.hbase.Cell;
  39  import org.apache.hadoop.hbase.CellUtil;

  40  import org.apache.hadoop.hbase.TableName;
  41  import org.apache.hadoop.hbase.client.Connection;
  42  import org.apache.hadoop.hbase.client.ConnectionFactory;
  43  import org.apache.hadoop.hbase.client.Result;
  44  import org.apache.hadoop.hbase.client.ResultScanner;
  45  import org.apache.hadoop.hbase.client.Scan;
  46  import org.apache.hadoop.hbase.client.Table;
  47  import org.apache.hadoop.hbase.util.Bytes;

  48  import org.slf4j.Logger;
  49  import org.slf4j.LoggerFactory;
  50  

  51  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  52 +</span>
  53  import java.sql.SQLException;
  54  import java.sql.Timestamp;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  55 +import java.time.LocalDateTime;</span>
  56  import java.util.Calendar;
  57  import java.util.HashMap;
  58  import java.util.List;
  59  import java.util.Map;
  60  import java.util.concurrent.atomic.AtomicReference;
  61  
  62  public class HbaseAllReqRow extends BaseAllReqRow {
  63  
  64      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  65  
  66      private String tableName;
  67  
  68      private Map&lt;String, String&gt; aliasNameInversion;
  69  
  70      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();




  71  
<abbr title="  72      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  72      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  73          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  74          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  75  
  76          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  77          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  78          aliasNameInversion = new HashMap&lt;&gt;();
  79          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  80              aliasNameInversion.put(entry.getValue(), entry.getKey());
  81          }
  82      }
  83  
  84      @Override
  85      public Row fillData(Row input, Object sideInput) {
  86          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  87          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  88          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  89              Object obj = input.getField(entry.getValue());
<abbr title="  90              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  90              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  91  
<abbr title="  92              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  92              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  93 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  94 -                obj = ((Timestamp)obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  95 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  96 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
  97              }
  98              row.setField(entry.getKey(), obj);
  99          }
 100  
 101          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 102              if(sideInputList == null){
 103                  row.setField(entry.getKey(), null);
 104              }else{
 105                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 106                  row.setField(entry.getKey(), sideInputList.get(key));
 107              }
 108          }
 109  
 110          return row;
 111      }
 112  
 113      @Override
 114      protected void initCache() throws SQLException {
 115          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 116          cacheRef.set(newCache);
 117          loadData(newCache);
 118      }
 119  
 120      @Override
 121      protected void reloadCache() {
 122          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 123          try {
 124              loadData(newCache);
 125          } catch (SQLException e) {
 126              LOG.error(&quot;&quot;, e);
 127          }
 128  
 129          cacheRef.set(newCache);
 130          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 131      }
 132  
 133      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 134 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 135 +    public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {</span>
 136          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 137          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 138              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 139 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 140 +            Object equalObj = input.f1.getField(conValIndex);</span>
 141              if (equalObj == null) {
 142                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 143 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 144 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 145 +                    Row data = fillData(input.f1, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 146 +                    out.collect(Tuple2.of(input.f0, data));</span>
 147                  }
 148                  return;
 149              }
 150              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 151          }
 152  
 153          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 154  
 155          Map&lt;String, Object&gt; cacheList = null;
 156  
 157          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 158          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 159          if (hbaseSideTableInfo.isPreRowKey()) {
 160              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 161                  if (entry.getKey().startsWith(rowKeyStr)) {
 162                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 163 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 164 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 165 +                    Row row = fillData(input.f1, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 166 +                    out.collect(Tuple2.of(input.f0, row));</span>
 167                  }
 168              }
 169          } else {
 170              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 171 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 172 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 173 +            Row row = fillData(input.f1, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 174 +            out.collect(Tuple2.of(input.f0, row));</span>
 175          }
 176  
 177      }
 178  
 179      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 180          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 181          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 182          Configuration conf = new Configuration();
 183          conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 184          Connection conn = null;
 185          Table table = null;
 186          ResultScanner resultScanner = null;


 187          try {
 188              conn = ConnectionFactory.createConnection(conf);




























 189              table = conn.getTable(TableName.valueOf(tableName));
 190              resultScanner = table.getScanner(new Scan());
 191              for (Result r : resultScanner) {
 192                  Map&lt;String, Object&gt; kv = new HashedMap();
 193                  for (Cell cell : r.listCells())
 194                  {
 195                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 196                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 197                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 198                      StringBuilder key = new StringBuilder();
 199                      key.append(family).append(&quot;:&quot;).append(qualifier);
 200  
 201                      kv.put(aliasNameInversion.get(key.toString()), value);
 202                  }

 203                  tmpCache.put(new String(r.getRow()), kv);
 204              }
 205          } catch (IOException e) {
 206              LOG.error(&quot;&quot;, e);

 207          } finally {

 208              try {
 209                  if (null != conn &amp;&amp; !conn.isClosed()) {

 210                      conn.close();
 211                  }
 212  
 213                  if (null != table) {
 214                      table.close();
 215                  }
 216  
 217                  if (null != resultScanner) {
 218                      resultScanner.close();
 219                  }
 220              } catch (IOException e) {
 221                  LOG.error(&quot;&quot;, e);
 222              }
 223          }
 224      }

 225  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  28 +import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;</span>
  29  import org.apache.calcite.sql.JoinType;
  30  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  31 +import org.apache.commons.lang.StringUtils;</span>
  32  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  33  import com.google.common.collect.Maps;
  34  import org.apache.flink.table.runtime.types.CRow;
  35  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  36  import org.apache.flink.types.Row;
  37  import org.apache.flink.util.Collector;
  38  import org.apache.hadoop.conf.Configuration;
  39  import org.apache.hadoop.hbase.Cell;
  40  import org.apache.hadoop.hbase.CellUtil;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  41 +import org.apache.hadoop.hbase.HBaseConfiguration;</span>
  42  import org.apache.hadoop.hbase.TableName;
  43  import org.apache.hadoop.hbase.client.Connection;
  44  import org.apache.hadoop.hbase.client.ConnectionFactory;
  45  import org.apache.hadoop.hbase.client.Result;
  46  import org.apache.hadoop.hbase.client.ResultScanner;
  47  import org.apache.hadoop.hbase.client.Scan;
  48  import org.apache.hadoop.hbase.client.Table;
  49  import org.apache.hadoop.hbase.util.Bytes;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import org.apache.hadoop.security.UserGroupInformation;</span>
  51  import org.slf4j.Logger;
  52  import org.slf4j.LoggerFactory;
  53  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  54 +import java.io.File;</span>
  55  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  56 +import java.security.PrivilegedAction;</span>
  57  import java.sql.SQLException;
  58  import java.sql.Timestamp;

  59  import java.util.Calendar;
  60  import java.util.HashMap;
  61  import java.util.List;
  62  import java.util.Map;
  63  import java.util.concurrent.atomic.AtomicReference;
  64  
  65  public class HbaseAllReqRow extends BaseAllReqRow {
  66  
  67      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  68  
  69      private String tableName;
  70  
  71      private Map&lt;String, String&gt; aliasNameInversion;
  72  
  73      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  74 +    private Connection conn = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  75 +    private Table table = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  76 +    private ResultScanner resultScanner = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  77 +    private Configuration conf = null;</span>
  78  
<abbr title="  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  80          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  81          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  82  
  83          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  84          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  85          aliasNameInversion = new HashMap&lt;&gt;();
  86          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  87              aliasNameInversion.put(entry.getValue(), entry.getKey());
  88          }
  89      }
  90  
  91      @Override
  92      public Row fillData(Row input, Object sideInput) {
  93          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  94          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  95          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  96              Object obj = input.getField(entry.getValue());
<abbr title="  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  98  
<abbr title="  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
 100              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 101                  obj = ((Timestamp)obj).getTime();


 102              }
 103              row.setField(entry.getKey(), obj);
 104          }
 105  
 106          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 107              if(sideInputList == null){
 108                  row.setField(entry.getKey(), null);
 109              }else{
 110                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 111                  row.setField(entry.getKey(), sideInputList.get(key));
 112              }
 113          }
 114  
 115          return row;
 116      }
 117  
 118      @Override
 119      protected void initCache() throws SQLException {
 120          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 121          cacheRef.set(newCache);
 122          loadData(newCache);
 123      }
 124  
 125      @Override
 126      protected void reloadCache() {
 127          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 128          try {
 129              loadData(newCache);
 130          } catch (SQLException e) {
 131              LOG.error(&quot;&quot;, e);
 132          }
 133  
 134          cacheRef.set(newCache);
 135          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 136      }
 137  
 138      @Override
 139      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {

 140          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 141          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 142              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 143              Object equalObj = input.row().getField(conValIndex);

 144              if (equalObj == null) {
 145                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 146                      Row data = fillData(input.row(), null);
 147                      out.collect(new CRow(data, input.change()));


 148                  }
 149                  return;
 150              }
 151              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 152          }
 153  
 154          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 155  
 156          Map&lt;String, Object&gt; cacheList = null;
 157  
 158          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 159          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 160          if (hbaseSideTableInfo.isPreRowKey()) {
 161              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 162                  if (entry.getKey().startsWith(rowKeyStr)) {
 163                      cacheList = cacheRef.get().get(entry.getKey());
 164                      Row row = fillData(input.row(), cacheList);
 165                      out.collect(new CRow(row, input.change()));


 166                  }
 167              }
 168          } else {
 169              cacheList = cacheRef.get().get(rowKeyStr);
 170              Row row = fillData(input.row(), cacheList);
 171              out.collect(new CRow(row, input.change()));


 172          }
 173  
 174      }
 175  
 176      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 177          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 178          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 179 -        Configuration conf = new Configuration();</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 180 -        conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 181 -        Connection conn = null;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 182 -        Table table = null;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 183 -        ResultScanner resultScanner = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 184 +        boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 185 +        int loadDataCount = 0;</span>
 186          try {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 187 -            conn = ConnectionFactory.createConnection(conf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 188 +            if (openKerberos) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 189 +                conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 190 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 191 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 192 +                String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 193 +                String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 194 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 195 +                UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 195 +                UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 196 +                Configuration finalConf = conf;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 197 +                conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 198 +                    @Override</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 199 +                    public Connection run() {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 200 +                        try {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 201 +                            return ConnectionFactory.createConnection(finalConf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 202 +                        } catch (IOException e) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 203 +                            LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 204 +                            throw new RuntimeException(e);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 205 +                        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 206 +                    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 207 +                });</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 208 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 209 +            } else {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 210 +                conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 211 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 212 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 213 +                conn = ConnectionFactory.createConnection(conf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 214 +            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 215 +</span>
 216              table = conn.getTable(TableName.valueOf(tableName));
 217              resultScanner = table.getScanner(new Scan());
 218              for (Result r : resultScanner) {
 219                  Map&lt;String, Object&gt; kv = new HashedMap();
 220                  for (Cell cell : r.listCells())
 221                  {
 222                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 223                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 224                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 225                      StringBuilder key = new StringBuilder();
 226                      key.append(family).append(&quot;:&quot;).append(qualifier);
 227  
 228                      kv.put(aliasNameInversion.get(key.toString()), value);
 229                  }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 230 +                loadDataCount++;</span>
 231                  tmpCache.put(new String(r.getRow()), kv);
 232              }
 233          } catch (IOException e) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 234 -            LOG.error(&quot;&quot;, e);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 235 +            throw new RuntimeException(e);</span>
 236          } finally {
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 237 +            LOG.info(&quot;load Data count: {}&quot;, loadDataCount);</span>
 238              try {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 239 -                if (null != conn &amp;&amp; !conn.isClosed()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 240 +                if (null != conn) {</span>
 241                      conn.close();
 242                  }
 243  
 244                  if (null != table) {
 245                      table.close();
 246                  }
 247  
 248                  if (null != resultScanner) {
 249                      resultScanner.close();
 250                  }
 251              } catch (IOException e) {
 252                  LOG.error(&quot;&quot;, e);
 253              }
 254          }
 255      }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 256 +</span>
 257  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            