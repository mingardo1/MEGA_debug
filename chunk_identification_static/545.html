<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>545</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    545
                    <a href="544.html">prev</a>
                    <a href="546.html">next</a>
                    <a href="545_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_b43aec0679d705647015fd4416ad6dc326ea7890_core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b43aec0679d705647015fd4416ad6dc326ea7890:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b43aec0679d705647015fd4416ad6dc326ea7890^1:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b43aec0679d705647015fd4416ad6dc326ea7890^2:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;6159bb9bb9904f950c489b50fb7dcbe399c3d327:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [b]], subset: [[b], [b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.exec;
  20 
  21 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  22 import com.dtstack.flink.sql.parser.*;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  23 import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  24 import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  25 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  26 import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  27 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  28 import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  29 import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  30 import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  31 import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  32 import org.apache.flink.table.calcite.FlinkPlannerImpl;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  33 import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  34 import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  35 </span>
  36 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  37 import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  38 import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  39 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  40 import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  41 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  42 import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  43 import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  44 import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  45 import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  46 import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  47 import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  48 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  49 import com.dtstack.flink.sql.classloader.ClassLoaderManager;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  50 import com.dtstack.flink.sql.config.CalciteConfig;</span>
  51 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  52 import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;</span>
  53 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  54 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  55 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
  56 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  57 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  58 import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  59 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  60 import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  61 import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  62 import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  63 import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  64 import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  65 import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  66 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  67 import com.dtstack.flink.sql.classloader.ClassLoaderManager;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  68 import com.dtstack.flink.sql.config.CalciteConfig;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  69 import com.dtstack.flink.sql.enums.ClusterMode;</span>
  70 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  71 import com.dtstack.flink.sql.config.CalciteConfig;</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  72 import com.dtstack.flink.sql.constrant.ConfigConstrant;</span>
  73 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  74 import com.dtstack.flink.sql.enums.ClusterMode;
  75 import com.dtstack.flink.sql.enums.ECacheType;
  76 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  77 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  78 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  79 import com.dtstack.flink.sql.function.FunctionManager;
  80 import com.dtstack.flink.sql.option.OptionParser;
  81 import com.dtstack.flink.sql.option.Options;
  82 import com.dtstack.flink.sql.side.SideSqlExec;
  83 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  84 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  85 import com.dtstack.flink.sql.source.StreamSourceFactory;
  86 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  87 import com.dtstack.flink.sql.table.AbstractTableInfo;
  88 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  89 import com.dtstack.flink.sql.util.DtStringUtil;
  90 import com.dtstack.flink.sql.util.PluginUtil;
  91 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  92 import com.fasterxml.jackson.databind.ObjectMapper;
  93 import com.google.common.base.Preconditions;
  94 import com.google.common.base.Strings;
  95 import com.google.common.collect.Lists;
  96 import com.google.common.collect.Maps;
  97 import com.google.common.collect.Sets;
  98 import org.apache.calcite.sql.SqlInsert;
  99 import org.apache.calcite.sql.SqlNode;
 100 import org.apache.commons.io.Charsets;
 101 import org.apache.commons.lang3.StringUtils;
 102 import org.apache.flink.api.common.typeinfo.TypeInformation;
 103 import org.apache.flink.api.java.tuple.Tuple2;
 104 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 105 import org.apache.flink.streaming.api.datastream.DataStream;
 106 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 107 import org.apache.flink.table.api.StreamQueryConfig;
 108 import org.apache.flink.table.api.Table;
 109 import org.apache.flink.table.api.TableEnvironment;
 110 import org.apache.flink.table.api.java.StreamTableEnvironment;
 111 import org.apache.flink.table.sinks.TableSink;
 112 import org.apache.flink.types.Row;
 113 import org.slf4j.Logger;
 114 import org.slf4j.LoggerFactory;
 115 
 116 import java.io.File;
 117 import java.lang.reflect.InvocationTargetException;
 118 import java.net.URL;
 119 import java.net.URLClassLoader;
 120 import java.net.URLDecoder;
 121 import java.util.Arrays;
 122 import java.util.List;
 123 import java.util.Map;
 124 import java.util.Properties;
 125 import java.util.Set;
 126 
 127 /**
 128  *  任务执行时的流程方法
 129  * Date: 2020/2/17
 130  * Company: www.dtstack.com
 131  * @author maqi
 132  */
 133 public class ExecuteProcessHelper {
 134 
 135     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
 136     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
 137     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
 138 
 139 
 140     public static ParamsInfo parseParams(String[] args) throws Exception {
 141         LOG.info(&quot;------------program params-------------------------&quot;);
 142         Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 143         LOG.info(&quot;-------------------------------------------&quot;);
 144 
 145         OptionParser optionParser = new OptionParser(args);
 146         Options options = optionParser.getOptions();
 147 
 148         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 149         String name = options.getName();
 150         String localSqlPluginPath = options.getLocalSqlPluginPath();
 151         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 152         String pluginLoadMode = options.getPluginLoadMode();
 153         String deployMode = options.getMode();
 154         String logLevel = options.getLogLevel();
 155 
<abbr title=" 156         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),"> 156         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 157                 &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 158         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 159         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 160 
 161         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 162 
 163         return ParamsInfo.builder()
 164                 .setSql(sql)
 165                 .setName(name)
 166                 .setLocalSqlPluginPath(localSqlPluginPath)
 167                 .setRemoteSqlPluginPath(remoteSqlPluginPath)
 168                 .setPluginLoadMode(pluginLoadMode)
 169                 .setDeployMode(deployMode)
 170                 .setConfProp(confProperties)
 171                 .setJarUrlList(jarUrlList)
 172                 .build();
 173 
 174     }
 175 
 176     /**
 177      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 178      * @param remoteSqlPluginPath
 179      * @param deployMode
 180      * @param pluginLoadMode
 181      * @return
 182      */
<abbr title=" 183     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 183     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 184         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 185             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 186                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 187         }
 188         return true;
 189     }
 190 
 191 
 192     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 193         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 193         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 194         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 195         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 195         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr>
 196 
 197         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 198         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 199 
 200         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 201         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 202 
 203         //register udf
 204         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 205         //register table schema
<abbr title=" 206         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 206         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
<abbr title=" 207                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 207                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, regist🔵</abbr>
 208         // cache classPathSets
 209         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 210 
<abbr title=" 211         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 211         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 212 
 213         if (env instanceof MyLocalStreamEnvironment) {
 214             ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 215         }
 216         return env;
 217     }
 218 
 219 
 220     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 221         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 222         if (Strings.isNullOrEmpty(addJarListStr)) {
 223             return jarUrlList;
 224         }
 225 
<abbr title=" 226         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 226         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 227         //Get External jar to load
 228         for (String addJarPath : addJarFileList) {
 229             jarUrlList.add(new File(addJarPath).toURI().toURL());
 230         }
 231         return jarUrlList;
 232     }
 233 
 234     private static void sqlTranslation(String localSqlPluginPath,
 235                                        StreamTableEnvironment tableEnv,
 236                                        SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 237                                        Map&lt;String, Table&gt; registerTableCache,
 238                                        StreamQueryConfig queryConfig) throws Exception {
 239 
 240         SideSqlExec sideSqlExec = new SideSqlExec();
 241         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 242         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<abbr title=" 243             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 243             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr>
 244         }
 245 
 246         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 247             if (LOG.isInfoEnabled()) {
 248                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 249             }
 250             boolean isSide = false;
 251             for (String tableName : result.getTargetTableList()) {
 252                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 253                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 254                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 255 
 256                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 257                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 258                     String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 259                     tmp.setExecSql(tmpSql);
<abbr title=" 260                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 260                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr>
 261                 } else {
 262                     for (String sourceTable : result.getSourceTableList()) {
 263                         if (sideTableMap.containsKey(sourceTable)) {
 264                             isSide = true;
 265                             break;
 266                         }
 267                     }
 268                     if (isSide) {
 269                         //sql-dimensional table contains the dimension table of execution
<abbr title=" 270                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 270                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr>
 271                     } else {
 272                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 273                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 273                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 274                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);
 275                         if (LOG.isInfoEnabled()) {
 276                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 277                         }
 278                     }
 279                 }
 280             }
 281         }
 282     }
 283 
<abbr title=" 284     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 284     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 285             throws IllegalAccessException, InvocationTargetException {
 286         // udf和tableEnv须由同一个类加载器加载
 287         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 288         URLClassLoader classLoader = null;
 289         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 290         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 291             //classloader
 292             if (classLoader == null) {
<abbr title=" 293                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);"> 293                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoad🔵</abbr>
 294             }
<abbr title=" 295             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 295             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 296         }
 297     }
 298 
 299     /**
 300      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 301      * @param sqlTree
 302      * @param env
 303      * @param tableEnv
 304      * @param localSqlPluginPath
 305      * @param remoteSqlPluginPath
 306      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 307      * @param sideTableMap
 308      * @param registerTableCache
 309      * @return
 310      * @throws Exception
 311      */
<abbr title=" 312     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 312     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
<abbr title=" 313                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 313                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, A🔵</abbr>
 314         Set&lt;URL&gt; pluginClassPatshSets = Sets.newHashSet();
 315         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 316         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 317 
 318             if (tableInfo instanceof AbstractSourceTableInfo) {
 319 
 320                 AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 321                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 321                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 322                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 323                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 323                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 324                 //Create table in which the function is arranged only need adaptation sql
 325                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 326                 Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 327 
<abbr title=" 328                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 328                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
 329                 DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)
 330                         .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {
 331                             return f0.f1;
 332                         })
 333                         .returns(typeInfo);
 334 
 335                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 336 
 337                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 338                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 338                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 339                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 340                 } else {
 341                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 342                 }
 343 
 344                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 345                 tableEnv.registerTable(tableInfo.getName(), regTable);
 346                 if (LOG.isInfoEnabled()) {
 347                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 348                 }
 349                 registerTableCache.put(tableInfo.getName(), regTable);
 350 
<abbr title=" 351                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 351                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 352                 pluginClassPatshSets.add(sourceTablePathUrl);
 353             } else if (tableInfo instanceof AbstractTargetTableInfo) {
 354 
<abbr title=" 355                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 355                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo,🔵</abbr>
<abbr title=" 356                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 356                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 357                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 357                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
 358 
<abbr title=" 359                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 359                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 360                 pluginClassPatshSets.add(sinkTablePathUrl);
 361             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 362                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 362                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).ge🔵</abbr>
 363                 sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 364 
<abbr title=" 365                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 365                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 366                 pluginClassPatshSets.add(sideTablePathUrl);
 367             } else {
 368                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 369             }
 370         }
 371         return pluginClassPatshSets;
 372     }
 373 
 374     /**
 375      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 376      * @param env
 377      * @param classPathSet
 378      */
<abbr title=" 379     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 379     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 380         int i = 0;
 381         for (URL url : classPathSet) {
 382             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 383             env.registerCachedFile(url.getPath(), classFileName, true);
 384             i++;
 385         }
 386     }
 387 
<abbr title=" 388     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 388     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 389         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 390                 StreamExecutionEnvironment.getExecutionEnvironment() :
 391                 new MyLocalStreamEnvironment();
 392 
 393         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 394         return env;
 395     }
 396 
 397 
 398     public static void setLogLevel(ParamsInfo paramsInfo){
 399         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);
 400         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){
 401             return;
 402         }
 403         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();
 404         logLevelProcess.process(logLevel);
 405     }
 406 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.exec;
  20 
  21 import com.dtstack.flink.sql.parser.*;
  22 
  23 import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;
  24 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  25 import com.dtstack.flink.sql.constrant.ConfigConstrant;
  26 import com.dtstack.flink.sql.enums.ClusterMode;
  27 import com.dtstack.flink.sql.enums.ECacheType;
  28 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  29 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  30 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  31 import com.dtstack.flink.sql.function.FunctionManager;
  32 import com.dtstack.flink.sql.option.OptionParser;
  33 import com.dtstack.flink.sql.option.Options;
  34 import com.dtstack.flink.sql.side.SideSqlExec;
  35 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  36 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  37 import com.dtstack.flink.sql.source.StreamSourceFactory;
  38 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  39 import com.dtstack.flink.sql.table.AbstractTableInfo;
  40 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  41 import com.dtstack.flink.sql.util.DtStringUtil;
  42 import com.dtstack.flink.sql.util.PluginUtil;
  43 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  44 import com.fasterxml.jackson.databind.ObjectMapper;
  45 import com.google.common.base.Preconditions;
  46 import com.google.common.base.Strings;
  47 import com.google.common.collect.Lists;
  48 import com.google.common.collect.Maps;
  49 import com.google.common.collect.Sets;
  50 import org.apache.calcite.sql.SqlInsert;
  51 import org.apache.calcite.sql.SqlNode;
  52 import org.apache.commons.io.Charsets;
  53 import org.apache.commons.lang3.StringUtils;
  54 import org.apache.flink.api.common.typeinfo.TypeInformation;
  55 import org.apache.flink.api.java.tuple.Tuple2;
  56 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  57 import org.apache.flink.streaming.api.datastream.DataStream;
  58 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  59 import org.apache.flink.table.api.StreamQueryConfig;
  60 import org.apache.flink.table.api.Table;
  61 import org.apache.flink.table.api.TableEnvironment;
  62 import org.apache.flink.table.api.java.StreamTableEnvironment;
  63 import org.apache.flink.table.calcite.FlinkPlannerImpl;
  64 import org.apache.flink.table.sinks.TableSink;
  65 import org.apache.flink.types.Row;
  66 import org.slf4j.Logger;
  67 import org.slf4j.LoggerFactory;
  68 
  69 import java.io.File;
  70 import java.lang.reflect.InvocationTargetException;
  71 import java.net.URL;
  72 import java.net.URLClassLoader;
  73 import java.net.URLDecoder;
  74 import java.util.Arrays;
  75 import java.util.List;
  76 import java.util.Map;
  77 import java.util.Properties;
  78 import java.util.Set;
  79 
  80 /**
  81  *  任务执行时的流程方法
  82  * Date: 2020/2/17
  83  * Company: www.dtstack.com
  84  * @author maqi
  85  */
  86 public class ExecuteProcessHelper {
  87 
  88     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  89     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  90     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  91 
  92 
  93     public static ParamsInfo parseParams(String[] args) throws Exception {
  94         LOG.info(&quot;------------program params-------------------------&quot;);
  95         Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
  96         LOG.info(&quot;-------------------------------------------&quot;);
  97 
  98         OptionParser optionParser = new OptionParser(args);
  99         Options options = optionParser.getOptions();
 100 
 101         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 102         String name = options.getName();
 103         String localSqlPluginPath = options.getLocalSqlPluginPath();
 104         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 105         String pluginLoadMode = options.getPluginLoadMode();
 106         String deployMode = options.getMode();
 107         String logLevel = options.getLogLevel();
 108 
<abbr title=" 109         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),"> 109         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 110                 &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 111         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 112         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 113 
 114         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 115 
 116         return ParamsInfo.builder()
 117                 .setSql(sql)
 118                 .setName(name)
 119                 .setLocalSqlPluginPath(localSqlPluginPath)
 120                 .setRemoteSqlPluginPath(remoteSqlPluginPath)
 121                 .setPluginLoadMode(pluginLoadMode)
 122                 .setDeployMode(deployMode)
 123                 .setConfProp(confProperties)
 124                 .setJarUrlList(jarUrlList)
 125                 .build();
 126 
 127     }
 128 
 129     /**
 130      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 131      * @param remoteSqlPluginPath
 132      * @param deployMode
 133      * @param pluginLoadMode
 134      * @return
 135      */
<abbr title=" 136     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 136     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 137         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 138             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 139                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 140         }
 141         return true;
 142     }
 143 
 144 
 145     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 146         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 146         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 147         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 148         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 148         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr>
 149 
 150         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 151         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 152 
 153         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 154         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 155 
 156         //register udf
 157         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 158         //register table schema
<abbr title=" 159         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 159         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
<abbr title=" 160                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 160                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, regist🔵</abbr>
 161         // cache classPathSets
 162         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 163 
<abbr title=" 164         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 164         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 165 
 166         if (env instanceof MyLocalStreamEnvironment) {
 167             ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 168         }
 169         return env;
 170     }
 171 
 172 
 173     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 174         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 175         if (Strings.isNullOrEmpty(addJarListStr)) {
 176             return jarUrlList;
 177         }
 178 
<abbr title=" 179         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 179         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 180         //Get External jar to load
 181         for (String addJarPath : addJarFileList) {
 182             jarUrlList.add(new File(addJarPath).toURI().toURL());
 183         }
 184         return jarUrlList;
 185     }
 186 
 187     private static void sqlTranslation(String localSqlPluginPath,
 188             StreamTableEnvironment tableEnv,
 189                                        SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 190             Map&lt;String, Table&gt; registerTableCache,
 191             StreamQueryConfig queryConfig) throws Exception {
 192 
 193     	SideSqlExec sideSqlExec = new SideSqlExec();
 194         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 195         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<abbr title=" 196             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 196             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr>
 197         }
 198 
 199         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 200             if (LOG.isInfoEnabled()) {
 201                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 202             }
 203             boolean isSide = false;
 204             for (String tableName : result.getTargetTableList()) {
 205                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 206                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 207                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 208 
 209                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 210                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 211                     String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 212                     tmp.setExecSql(tmpSql);
<abbr title=" 213                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 213                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr>
 214                 } else {
 215                     for (String sourceTable : result.getSourceTableList()) {
 216                         if (sideTableMap.containsKey(sourceTable)) {
 217                             isSide = true;
 218                             break;
 219                         }
 220                     }
 221                     if (isSide) {
 222                         //sql-dimensional table contains the dimension table of execution
<abbr title=" 223                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 223                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr>
 224                     } else {
 225                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 226                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 226                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 227                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);
 228                         if (LOG.isInfoEnabled()) {
 229                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 230                         }
 231                     }
 232                 }
 233             }
 234         }
 235     }
 236 
<abbr title=" 237     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 237     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 238             throws IllegalAccessException, InvocationTargetException {
 239         // udf和tableEnv须由同一个类加载器加载
 240         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 241         URLClassLoader classLoader = null;
 242         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 243         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 244             //classloader
 245             if (classLoader == null) {
<abbr title=" 246                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);"> 246                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoad🔵</abbr>
 247             }
<abbr title=" 248             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 248             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 249         }
 250     }
 251 
 252     /**
 253      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 254      * @param sqlTree
 255      * @param env
 256      * @param tableEnv
 257      * @param localSqlPluginPath
 258      * @param remoteSqlPluginPath
 259      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 260      * @param sideTableMap
 261      * @param registerTableCache
 262      * @return
 263      * @throws Exception
 264      */
<abbr title=" 265     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 265     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
<abbr title=" 266                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 266                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, A🔵</abbr>
 267         Set&lt;URL&gt; pluginClassPatshSets = Sets.newHashSet();
 268         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 269         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 270 
 271             if (tableInfo instanceof AbstractSourceTableInfo) {
 272 
 273                 AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 274                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 274                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 275                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 276                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 276                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 277                 //Create table in which the function is arranged only need adaptation sql
 278                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 279                 Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 280 
<abbr title=" 281                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 281                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
 282                 DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)
 283                         .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {
 284                             return f0.f1;
 285                         })
 286                         .returns(typeInfo);
 287 
 288                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 289 
 290                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 291                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 291                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 292                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 293                 } else {
 294                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 295                 }
 296 
 297                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 298                 tableEnv.registerTable(tableInfo.getName(), regTable);
 299                 if (LOG.isInfoEnabled()) {
 300                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 301                 }
 302                 registerTableCache.put(tableInfo.getName(), regTable);
 303 
<abbr title=" 304                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 304                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 305                 pluginClassPatshSets.add(sourceTablePathUrl);
 306             } else if (tableInfo instanceof AbstractTargetTableInfo) {
 307 
<abbr title=" 308                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 308                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo,🔵</abbr>
<abbr title=" 309                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 309                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 310                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 310                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
 311 
<abbr title=" 312                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 312                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 313                 pluginClassPatshSets.add(sinkTablePathUrl);
 314             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 315                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 315                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).ge🔵</abbr>
 316                 sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 317 
<abbr title=" 318                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 318                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 319                 pluginClassPatshSets.add(sideTablePathUrl);
 320             } else {
 321                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 322             }
 323         }
 324         return pluginClassPatshSets;
 325     }
 326 
 327     /**
 328      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 329      * @param env
 330      * @param classPathSet
 331      */
<abbr title=" 332     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 332     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 333         int i = 0;
 334         for (URL url : classPathSet) {
 335             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 336             env.registerCachedFile(url.getPath(), classFileName, true);
 337             i++;
 338         }
 339     }
 340 
<abbr title=" 341     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 341     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 342         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 343                 StreamExecutionEnvironment.getExecutionEnvironment() :
 344                 new MyLocalStreamEnvironment();
 345 
 346         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 347         return env;
 348     }
 349 
 350 
 351     public static void setLogLevel(ParamsInfo paramsInfo){
 352         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);
 353         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){
 354             return;
 355         }
 356         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();
 357         logLevelProcess.process(logLevel);
 358     }
 359 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.exec;
  19 
  20 import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;
  21 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  22 import com.dtstack.flink.sql.constrant.ConfigConstrant;
  23 import com.dtstack.flink.sql.enums.ClusterMode;
  24 import com.dtstack.flink.sql.enums.ECacheType;
  25 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  26 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  27 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  28 import com.dtstack.flink.sql.function.FunctionManager;
  29 import com.dtstack.flink.sql.option.OptionParser;
  30 import com.dtstack.flink.sql.option.Options;
  31 import com.dtstack.flink.sql.parser.*;
  32 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  33 import com.dtstack.flink.sql.side.SideSqlExec;
  34 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  35 import com.dtstack.flink.sql.source.StreamSourceFactory;
  36 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  37 import com.dtstack.flink.sql.table.AbstractTableInfo;
  38 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  39 import com.dtstack.flink.sql.util.DtStringUtil;
  40 import com.dtstack.flink.sql.util.PluginUtil;
  41 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  42 import com.fasterxml.jackson.databind.ObjectMapper;
  43 import com.google.common.base.Preconditions;
  44 import com.google.common.base.Strings;
  45 import com.google.common.collect.Lists;
  46 import com.google.common.collect.Maps;
  47 import com.google.common.collect.Sets;
  48 import java.io.File;
  49 import java.lang.reflect.InvocationTargetException;
  50 import java.net.URL;
  51 import java.net.URLClassLoader;
  52 import java.net.URLDecoder;
  53 import java.util.Arrays;
  54 import java.util.List;
  55 import java.util.Map;
  56 import java.util.Properties;
  57 import java.util.Set;
  58 import org.apache.calcite.sql.SqlInsert;
  59 import org.apache.calcite.sql.SqlNode;
  60 import org.apache.commons.io.Charsets;
  61 import org.apache.commons.lang3.StringUtils;
  62 import org.apache.flink.api.common.typeinfo.TypeInformation;
  63 import org.apache.flink.api.java.tuple.Tuple2;
  64 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  65 import org.apache.flink.streaming.api.datastream.DataStream;
  66 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  67 import org.apache.flink.table.api.StreamQueryConfig;
  68 import org.apache.flink.table.api.Table;
  69 import org.apache.flink.table.api.TableEnvironment;
  70 import org.apache.flink.table.api.java.StreamTableEnvironment;
  71 import org.apache.flink.table.calcite.FlinkPlannerImpl;
  72 import org.apache.flink.table.sinks.TableSink;
  73 import org.apache.flink.types.Row;
  74 import org.slf4j.Logger;
  75 import org.slf4j.LoggerFactory;
  76 
  77 
  78 /**
  79  *  任务执行时的流程方法
  80  * Date: 2020/2/17
  81  * Company: www.dtstack.com
  82  * @author maqi
  83  */
  84 public class ExecuteProcessHelper {
  85     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  86 
  87     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  88 
  89     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  90 
  91     public static ParamsInfo parseParams(String[] args) throws Exception {
  92         LOG.info(&quot;------------program params-------------------------&quot;);
  93         Arrays.stream(args).forEach(( arg) -&gt; LOG.info(&quot;{}&quot;, arg));
  94         LOG.info(&quot;-------------------------------------------&quot;);
  95         OptionParser optionParser = new OptionParser(args);
  96         Options options = optionParser.getOptions();
  97         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
  98         String name = options.getName();
  99         String localSqlPluginPath = options.getLocalSqlPluginPath();
 100         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 101         String pluginLoadMode = options.getPluginLoadMode();
 102         String deployMode = options.getMode();
 103         String logLevel = options.getLogLevel();
<abbr title=" 104         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode), &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);"> 104         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 105         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 106         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 107         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
<abbr title=" 108         return ParamsInfo.builder().setSql(sql).setName(name).setLocalSqlPluginPath(localSqlPluginPath).setRemoteSqlPluginPath(remoteSqlPluginPath).setPluginLoadMode(pluginLoadMode).setDeployMode(deployMode).setConfProp(confProperties).setJarUrlList(jarUrlList).build();"> 108         return ParamsInfo.builder().setSql(sql).setName(name).setLocalSqlPluginPath(localSqlPluginPath).s🔵</abbr>
 109     }
 110 
 111     /**
 112      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 113      * @param remoteSqlPluginPath
 114      * @param deployMode
 115      * @param pluginLoadMode
 116      * @return
 117      */
<abbr title=" 118     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 118     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 119         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 120             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 121                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 122         }
 123         return true;
 124     }
 125 
 126     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 127         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 127         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 128         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 129         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 129         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr>
 130         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 131         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 132         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 133         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 134         //register udf
 135         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 136         //register table schema
<abbr title=" 137         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(), paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 137         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
 138         // cache classPathSets
 139         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
<abbr title=" 140         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 140         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 141         if (env instanceof MyLocalStreamEnvironment) {
 142             ((MyLocalStreamEnvironment) (env)).setClasspaths(ClassLoaderManager.getClassPath());
 143         }
 144         return env;
 145     }
 146 
 147     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 148         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 149         if (Strings.isNullOrEmpty(addJarListStr)) {
 150             return jarUrlList;
 151         }
 152 
<abbr title=" 153         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 153         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 154         //Get External jar to load
 155         for (String addJarPath : addJarFileList) {
 156             jarUrlList.add(new File(addJarPath).toURI().toURL());
 157         }
 158         return jarUrlList;
 159     }
 160 
<abbr title=" 161     private static void sqlTranslation(String localSqlPluginPath, StreamTableEnvironment tableEnv, SqlTree sqlTree, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache, StreamQueryConfig queryConfig) throws Exception {"> 161     private static void sqlTranslation(String localSqlPluginPath, StreamTableEnvironment tableEnv, SqlTre🔵</abbr>
 162         SideSqlExec sideSqlExec = new SideSqlExec();
 163         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 164         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<abbr title=" 165             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 165             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr>
 166         }
 167         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 168             if (LOG.isInfoEnabled()) {
 169                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 170             }
 171             boolean isSide = false;
 172             for (String tableName : result.getTargetTableList()) {
 173                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 174                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 175                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 176                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 177                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 178                     String tmpSql = ((SqlInsert) (sqlNode)).getSource().toString();
 179                     tmp.setExecSql(tmpSql);
<abbr title=" 180                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 180                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr>
 181                 } else {
 182                     for (String sourceTable : result.getSourceTableList()) {
 183                         if (sideTableMap.containsKey(sourceTable)) {
 184                             isSide = true;
 185                             break;
 186                         }
 187                     }
 188                     if (isSide) {
 189                         //sql-dimensional table contains the dimension table of execution
<abbr title=" 190                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 190                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr>
 191                     } else {
 192                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 193                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 193                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 194                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);
 195                         if (LOG.isInfoEnabled()) {
 196                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 197                         }
 198                     }
 199                 }
 200             }
 201         }
 202     }
 203 
<abbr title=" 204     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv) throws IllegalAccessException, InvocationTargetException {"> 204     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 205         // udf和tableEnv须由同一个类加载器加载
 206         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 207         URLClassLoader classLoader = null;
 208         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 209         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 210             // classloader
 211             if (classLoader == null) {
<abbr title=" 212                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, ((URLClassLoader) (levelClassLoader)));"> 212                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, ((URLClassLoader) (levelClassLo🔵</abbr>
 213             }
<abbr title=" 214             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 214             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 215         }
 216     }
 217 
 218     /**
 219      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 220      * @param sqlTree
 221      * @param env
 222      * @param tableEnv
 223      * @param localSqlPluginPath
 224      * @param remoteSqlPluginPath
 225      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 226      * @param sideTableMap
 227      * @param registerTableCache
 228      * @return
 229      * @throws Exception
 230      */
<abbr title=" 231     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath, String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 231     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
 232         Set&lt;URL&gt; pluginClassPatshSets = Sets.newHashSet();
 233         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 234         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 235             if (tableInfo instanceof AbstractSourceTableInfo) {
 236                 AbstractSourceTableInfo sourceTableInfo = ((AbstractSourceTableInfo) (tableInfo));
<abbr title=" 237                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 237                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 238                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 239                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 239                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 240                 //Create table in which the function is arranged only need adaptation sql
 241                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 242                 Table adaptTable = (adaptSql == null) ? table : tableEnv.sqlQuery(adaptSql);
<abbr title=" 243                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 243                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
<abbr title=" 244                 DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo).map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {"> 244                 DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo).map((Tuple2&lt;Boole🔵</abbr>
 245                     return f0.f1;
 246                 }).returns(typeInfo);
 247                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 248                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 249                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 249                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 250                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 251                 } else {
 252                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 253                 }
 254                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 255                 tableEnv.registerTable(tableInfo.getName(), regTable);
 256                 if (LOG.isInfoEnabled()) {
 257                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 258                 }
 259                 registerTableCache.put(tableInfo.getName(), regTable);
<abbr title=" 260                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 260                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 261                 pluginClassPatshSets.add(sourceTablePathUrl);
 262             } else if (tableInfo instanceof AbstractTargetTableInfo) {
<abbr title=" 263                 TableSink tableSink = StreamSinkFactory.getTableSink(((AbstractTargetTableInfo) (tableInfo)), localSqlPluginPath);"> 263                 TableSink tableSink = StreamSinkFactory.getTableSink(((AbstractTargetTableInfo) (tableInf🔵</abbr>
<abbr title=" 264                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 264                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 265                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 265                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
<abbr title=" 266                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 266                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 267                 pluginClassPatshSets.add(sinkTablePathUrl);
 268             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 269                 String sideOperator = (ECacheType.ALL.name().equals(((AbstractSideTableInfo) (tableInfo)).getCacheType())) ? &quot;all&quot; : &quot;async&quot;;"> 269                 String sideOperator = (ECacheType.ALL.name().equals(((AbstractSideTableInfo) (tableInfo))🔵</abbr>
 270                 sideTableMap.put(tableInfo.getName(), ((AbstractSideTableInfo) (tableInfo)));
<abbr title=" 271                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 271                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 272                 pluginClassPatshSets.add(sideTablePathUrl);
 273             } else {
 274                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 275             }
 276         }
 277         return pluginClassPatshSets;
 278     }
 279 
 280     /**
 281      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 282      * @param env
 283      * @param classPathSet
 284      */
<abbr title=" 285     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 285     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 286         int i = 0;
 287         for (URL url : classPathSet) {
 288             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 289             env.registerCachedFile(url.getPath(), classFileName, true);
 290             i++;
 291         }
 292     }
 293 
<abbr title=" 294     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 294     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 295         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 296                 StreamExecutionEnvironment.getExecutionEnvironment() :
 297                 new MyLocalStreamEnvironment();
 298 
 299         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 300         return env;
 301     }
 302 
 303     public static void setLogLevel(ParamsInfo paramsInfo){
 304         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);
 305         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){
 306             return;
 307         }
 308         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();
 309         logLevelProcess.process(logLevel);
 310     }
 311 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.exec;
  20  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  21 +import com.dtstack.flink.sql.parser.*;</span>
  22  import org.apache.flink.api.common.typeinfo.TypeInformation;
  23  import org.apache.flink.api.java.tuple.Tuple2;
  24  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  25  import org.apache.flink.streaming.api.datastream.DataStream;
  26  import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  27  import org.apache.flink.table.api.StreamQueryConfig;
  28  import org.apache.flink.table.api.Table;
  29  import org.apache.flink.table.api.TableEnvironment;
  30  import org.apache.flink.table.api.java.StreamTableEnvironment;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  31 +import org.apache.flink.table.calcite.FlinkPlannerImpl;</span>
  32  import org.apache.flink.table.sinks.TableSink;
  33  import org.apache.flink.types.Row;
  34  

  35  import com.dtstack.flink.sql.classloader.ClassLoaderManager;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  36 -import com.dtstack.flink.sql.config.CalciteConfig;</span>

  37  import com.dtstack.flink.sql.enums.ClusterMode;
  38  import com.dtstack.flink.sql.enums.ECacheType;
  39  import com.dtstack.flink.sql.enums.EPluginLoadMode;
  40  import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  41  import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  42  import com.dtstack.flink.sql.function.FunctionManager;
  43  import com.dtstack.flink.sql.option.OptionParser;
  44  import com.dtstack.flink.sql.option.Options;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  45 -import com.dtstack.flink.sql.parser.CreateFuncParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  46 -import com.dtstack.flink.sql.parser.CreateTmpTableParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  47 -import com.dtstack.flink.sql.parser.InsertSqlParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  48 -import com.dtstack.flink.sql.parser.SqlParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  49 -import com.dtstack.flink.sql.parser.SqlTree;</span>
  50  import com.dtstack.flink.sql.side.SideSqlExec;
  51  import com.dtstack.flink.sql.side.SideTableInfo;

  52  import com.dtstack.flink.sql.sink.StreamSinkFactory;
  53  import com.dtstack.flink.sql.source.StreamSourceFactory;
  54  import com.dtstack.flink.sql.table.SourceTableInfo;
  55  import com.dtstack.flink.sql.table.TableInfo;
  56  import com.dtstack.flink.sql.table.TargetTableInfo;



  57  import com.dtstack.flink.sql.util.DtStringUtil;
  58  import com.dtstack.flink.sql.util.PluginUtil;
  59  import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  60  import com.fasterxml.jackson.databind.ObjectMapper;
  61  import com.google.common.base.Preconditions;
  62  import com.google.common.base.Strings;
  63  import com.google.common.collect.Lists;
  64  import com.google.common.collect.Maps;
  65  import com.google.common.collect.Sets;
  66  import org.apache.calcite.sql.SqlInsert;
  67  import org.apache.calcite.sql.SqlNode;
  68  import org.apache.commons.io.Charsets;
  69  import org.apache.commons.lang3.StringUtils;











  70  import org.slf4j.Logger;
  71  import org.slf4j.LoggerFactory;
  72  
  73  import java.io.File;
  74  import java.lang.reflect.InvocationTargetException;
  75  import java.net.URL;
  76  import java.net.URLClassLoader;
  77  import java.net.URLDecoder;
  78  import java.util.Arrays;
  79  import java.util.List;
  80  import java.util.Map;
  81  import java.util.Properties;
  82  import java.util.Set;
  83  
  84  /**
  85   *  任务执行时的流程方法
  86   * Date: 2020/2/17
  87   * Company: www.dtstack.com
  88   * @author maqi
  89   */
  90  public class ExecuteProcessHelper {
  91  
  92      private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  93      private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  94      private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  95  
  96  
  97      public static ParamsInfo parseParams(String[] args) throws Exception {
  98          LOG.info(&quot;------------program params-------------------------&quot;);
  99          System.out.println(&quot;------------program params-------------------------&quot;);
 100          Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 101          Arrays.stream(args).forEach(System.out::println);
 102          LOG.info(&quot;-------------------------------------------&quot;);
 103          System.out.println(&quot;----------------------------------------&quot;);
 104  
 105          OptionParser optionParser = new OptionParser(args);
 106          Options options = optionParser.getOptions();
 107  
 108          String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 109          String name = options.getName();
 110          String localSqlPluginPath = options.getLocalSqlPluginPath();
 111          String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 112          String pluginLoadMode = options.getPluginLoadMode();
 113          String deployMode = options.getMode();

 114  
 115          Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),
 116                  &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 117          String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 118          Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 119  
 120          List&lt;URL&gt; jarURList = getExternalJarUrls(options.getAddjar());

 121  
 122          return ParamsInfo.builder()
 123                  .setSql(sql)
 124                  .setName(name)
 125                  .setLocalSqlPluginPath(localSqlPluginPath)
 126                  .setRemoteSqlPluginPath(remoteSqlPluginPath)
 127                  .setPluginLoadMode(pluginLoadMode)
 128                  .setDeployMode(deployMode)
 129                  .setConfProp(confProperties)
 130                  .setJarUrlList(jarURList)

 131                  .build();
 132  
 133      }
 134  
 135      /**
 136       *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 137       * @param remoteSqlPluginPath
 138       * @param deployMode
 139       * @param pluginLoadMode
 140       * @return
 141       */
<abbr title=" 142      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 142      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoa🔵</abbr>
 143          if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 144              return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 145                      || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 146          }
 147          return true;
 148      }
 149  
 150  
 151      public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 152          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 152          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo🔵</abbr>
 153          StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 154          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 154          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.get🔵</abbr>
 155  
 156          SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 157          SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 158  
 159          Map&lt;String, SideTableInfo&gt; sideTableMap = Maps.newHashMap();

 160          Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 161  
 162          //register udf
 163          ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 164          //register table schema
<abbr title=" 165          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 165          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSql🔵</abbr>
<abbr title=" 166                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 166                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCa🔵</abbr>
 167          // cache classPathSets
 168          ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 169  
<abbr title=" 170          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 170          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, r🔵</abbr>
 171  
 172          if (env instanceof MyLocalStreamEnvironment) {
 173              ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 174          }
 175          return env;
 176      }
 177  
 178  
 179      public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 180          List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 181          if (Strings.isNullOrEmpty(addJarListStr)) {
 182              return jarUrlList;
 183          }
 184  
<abbr title=" 185          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 185          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name🔵</abbr>
 186          //Get External jar to load
 187          for (String addJarPath : addJarFileList) {
 188              jarUrlList.add(new File(addJarPath).toURI().toURL());
 189          }
 190          return jarUrlList;
 191      }
 192  
 193      private static void sqlTranslation(String localSqlPluginPath,
 194              StreamTableEnvironment tableEnv,
 195              SqlTree sqlTree,Map&lt;String, SideTableInfo&gt; sideTableMap,
 196              Map&lt;String, Table&gt; registerTableCache,
 197              StreamQueryConfig queryConfig) throws Exception {
 198  
 199      	SideSqlExec sideSqlExec = new SideSqlExec();






 200          sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 201          for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<abbr title=" 202              sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 202              sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result)🔵</abbr>
 203          }
 204  
 205          for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 206              if (LOG.isInfoEnabled()) {
 207                  LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 208              }
 209              boolean isSide = false;
 210              for (String tableName : result.getTargetTableList()) {
 211                  if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 212                      CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 213                      String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 214  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 215 -                    SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_LEX_CONFIG).parseStmt();"> 215 -                    SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 216 +                    FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 217 +                    SqlNode sqlNode = flinkPlanner.parse(realSql);</span>
 218                      String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 219                      tmp.setExecSql(tmpSql);
<abbr title=" 220                      sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 220                      sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tm🔵</abbr>
 221                  } else {
 222                      for (String sourceTable : result.getSourceTableList()) {
 223                          if (sideTableMap.containsKey(sourceTable)) {
 224                              isSide = true;
 225                              break;
 226                          }
 227                      }
 228                      if (isSide) {
 229                          //sql-dimensional table contains the dimension table of execution
<abbr title=" 230                          sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 230                          sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryCon🔵</abbr>
 231                      } else {
 232                          System.out.println(&quot;----------exec sql without dimension join-----------&quot;);
 233                          System.out.println(&quot;----------real sql exec is--------------------------&quot;);
 234                          System.out.println(result.getExecSql());


 235                          FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);
 236                          if (LOG.isInfoEnabled()) {
 237                              LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 238                          }
 239                      }
 240                  }
 241              }
 242          }
 243      }
 244  
<abbr title=" 245      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 245      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEn🔵</abbr>
 246              throws IllegalAccessException, InvocationTargetException {
 247          // udf和tableEnv须由同一个类加载器加载
 248          ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 249          URLClassLoader classLoader = null;
 250          List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 251          for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 252              //classloader
 253              if (classLoader == null) {
 254                  classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);
 255              }
<abbr title=" 256              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 256              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv,🔵</abbr>
 257          }
 258      }
 259  
 260      /**
 261       *    向Flink注册源表和结果表，返回执行时插件包的全路径
 262       * @param sqlTree
 263       * @param env
 264       * @param tableEnv
 265       * @param localSqlPluginPath
 266       * @param remoteSqlPluginPath
 267       * @param pluginLoadMode   插件加载模式 classpath or shipfile
 268       * @param sideTableMap
 269       * @param registerTableCache
 270       * @return
 271       * @throws Exception
 272       */
<abbr title=" 273      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 273      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment t🔵</abbr>
<abbr title=" 274                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, SideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 274                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, SideTableI🔵</abbr>

 275          Set&lt;URL&gt; pluginClassPatshSets = Sets.newHashSet();
 276          WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 277          for (TableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 278  
 279              if (tableInfo instanceof SourceTableInfo) {
 280  
 281                  SourceTableInfo sourceTableInfo = (SourceTableInfo) tableInfo;





<abbr title=" 282                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 282                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPa🔵</abbr>
 283                  tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 284                  //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 284                  //Note --- parameter conversion function can not be used inside a function of the type of polymeri🔵</abbr>
 285                  //Create table in which the function is arranged only need adaptation sql
 286                  String adaptSql = sourceTableInfo.getAdaptSelectSql();
 287                  Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 288  
<abbr title=" 289                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 289                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchem🔵</abbr>
 290                  DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)
 291                          .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {
 292                              return f0.f1;
 293                          })
 294                          .returns(typeInfo);
 295  
 296                  String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 297  
 298                  if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
 299                      adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);
 300                      fields += &quot;,ROWTIME.ROWTIME&quot;;
 301                  } else {
 302                      fields += &quot;,PROCTIME.PROCTIME&quot;;
 303                  }
 304  
 305                  Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 306                  tableEnv.registerTable(tableInfo.getName(), regTable);
 307                  if (LOG.isInfoEnabled()) {
 308                      LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 309                  }
 310                  registerTableCache.put(tableInfo.getName(), regTable);
 311  
<abbr title=" 312                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), SourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 312                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), SourceTa🔵</abbr>

 313                  pluginClassPatshSets.add(sourceTablePathUrl);
 314              } else if (tableInfo instanceof TargetTableInfo) {
 315  
<abbr title=" 316                  TableSink tableSink = StreamSinkFactory.getTableSink((TargetTableInfo) tableInfo, localSqlPluginPath);"> 316                  TableSink tableSink = StreamSinkFactory.getTableSink((TargetTableInfo) tableInfo, localSqlPluginPa🔵</abbr>



 317                  TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());
 318                  tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);
 319  
<abbr title=" 320                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), TargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 320                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), TargetTabl🔵</abbr>

 321                  pluginClassPatshSets.add(sinkTablePathUrl);
 322              } else if (tableInfo instanceof SideTableInfo) {
<abbr title=" 323                  String sideOperator = ECacheType.ALL.name().equals(((SideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 323                  String sideOperator = ECacheType.ALL.name().equals(((SideTableInfo) tableInfo).getCacheType()) ? &quot;🔵</abbr>
 324                  sideTableMap.put(tableInfo.getName(), (SideTableInfo) tableInfo);
 325  
<abbr title=" 326                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, SideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 326                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, SideT🔵</abbr>





 327                  pluginClassPatshSets.add(sideTablePathUrl);
 328              } else {
 329                  throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 330              }
 331          }
 332          return pluginClassPatshSets;
 333      }
 334  
 335      /**
 336       *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 337       * @param env
 338       * @param classPathSet
 339       */
 340      public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {
 341          int i = 0;
 342          for (URL url : classPathSet) {
 343              String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 344              env.registerCachedFile(url.getPath(), classFileName, true);
 345              i++;
 346          }
 347      }
 348  
<abbr title=" 349      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 349      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws 🔵</abbr>
 350          StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 351                  StreamExecutionEnvironment.getExecutionEnvironment() :
 352                  new MyLocalStreamEnvironment();
 353  
 354          StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 355          return env;
 356      }
 357  
 358  








 359  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.exec;
  20  

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  21 -import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  22 -import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  23 -import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  25 -import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  26 -import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  27 -import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  28 -import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  29 -import org.apache.flink.table.api.java.StreamTableEnvironment;</span>

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  30 -import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  31 -import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  32 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  33 +import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;</span>
  34  import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  35  import com.dtstack.flink.sql.config.CalciteConfig;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  36 +import com.dtstack.flink.sql.constrant.ConfigConstrant;</span>
  37  import com.dtstack.flink.sql.enums.ClusterMode;
  38  import com.dtstack.flink.sql.enums.ECacheType;
  39  import com.dtstack.flink.sql.enums.EPluginLoadMode;
  40  import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  41  import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  42  import com.dtstack.flink.sql.function.FunctionManager;
  43  import com.dtstack.flink.sql.option.OptionParser;
  44  import com.dtstack.flink.sql.option.Options;
  45  import com.dtstack.flink.sql.parser.CreateFuncParser;
  46  import com.dtstack.flink.sql.parser.CreateTmpTableParser;
  47  import com.dtstack.flink.sql.parser.InsertSqlParser;
  48  import com.dtstack.flink.sql.parser.SqlParser;
  49  import com.dtstack.flink.sql.parser.SqlTree;
  50  import com.dtstack.flink.sql.side.SideSqlExec;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  51 -import com.dtstack.flink.sql.side.SideTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  52 +import com.dtstack.flink.sql.side.AbstractSideTableInfo;</span>
  53  import com.dtstack.flink.sql.sink.StreamSinkFactory;
  54  import com.dtstack.flink.sql.source.StreamSourceFactory;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  55 -import com.dtstack.flink.sql.table.SourceTableInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  56 -import com.dtstack.flink.sql.table.TableInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  57 -import com.dtstack.flink.sql.table.TargetTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +import com.dtstack.flink.sql.table.AbstractSourceTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  59 +import com.dtstack.flink.sql.table.AbstractTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  60 +import com.dtstack.flink.sql.table.AbstractTargetTableInfo;</span>
  61  import com.dtstack.flink.sql.util.DtStringUtil;
  62  import com.dtstack.flink.sql.util.PluginUtil;
  63  import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  64  import com.fasterxml.jackson.databind.ObjectMapper;
  65  import com.google.common.base.Preconditions;
  66  import com.google.common.base.Strings;
  67  import com.google.common.collect.Lists;
  68  import com.google.common.collect.Maps;
  69  import com.google.common.collect.Sets;
  70  import org.apache.calcite.sql.SqlInsert;
  71  import org.apache.calcite.sql.SqlNode;
  72  import org.apache.commons.io.Charsets;
  73  import org.apache.commons.lang3.StringUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  74 +import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  75 +import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  76 +import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  77 +import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  78 +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  79 +import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  80 +import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  81 +import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  82 +import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  83 +import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  84 +import org.apache.flink.types.Row;</span>
  85  import org.slf4j.Logger;
  86  import org.slf4j.LoggerFactory;
  87  
  88  import java.io.File;
  89  import java.lang.reflect.InvocationTargetException;
  90  import java.net.URL;
  91  import java.net.URLClassLoader;
  92  import java.net.URLDecoder;
  93  import java.util.Arrays;
  94  import java.util.List;
  95  import java.util.Map;
  96  import java.util.Properties;
  97  import java.util.Set;
  98  
  99  /**
 100   *  任务执行时的流程方法
 101   * Date: 2020/2/17
 102   * Company: www.dtstack.com
 103   * @author maqi
 104   */
 105  public class ExecuteProcessHelper {
 106  
 107      private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
 108      private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
 109      private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
 110  
 111  
 112      public static ParamsInfo parseParams(String[] args) throws Exception {
 113          LOG.info(&quot;------------program params-------------------------&quot;);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 114 -        System.out.println(&quot;------------program params-------------------------&quot;);</span>
 115          Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 116 -        Arrays.stream(args).forEach(System.out::println);</span>
 117          LOG.info(&quot;-------------------------------------------&quot;);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 118 -        System.out.println(&quot;----------------------------------------&quot;);</span>
 119  
 120          OptionParser optionParser = new OptionParser(args);
 121          Options options = optionParser.getOptions();
 122  
 123          String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 124          String name = options.getName();
 125          String localSqlPluginPath = options.getLocalSqlPluginPath();
 126          String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 127          String pluginLoadMode = options.getPluginLoadMode();
 128          String deployMode = options.getMode();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 129 +        String logLevel = options.getLogLevel();</span>
 130  
 131          Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),
 132                  &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 133          String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 134          Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 135  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 136 -        List&lt;URL&gt; jarURList = getExternalJarUrls(options.getAddjar());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 137 +        List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());</span>
 138  
 139          return ParamsInfo.builder()
 140                  .setSql(sql)
 141                  .setName(name)
 142                  .setLocalSqlPluginPath(localSqlPluginPath)
 143                  .setRemoteSqlPluginPath(remoteSqlPluginPath)
 144                  .setPluginLoadMode(pluginLoadMode)
 145                  .setDeployMode(deployMode)
 146                  .setConfProp(confProperties)
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 147 -                .setJarUrlList(jarURList)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 148 +                .setJarUrlList(jarUrlList)</span>
 149                  .build();
 150  
 151      }
 152  
 153      /**
 154       *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 155       * @param remoteSqlPluginPath
 156       * @param deployMode
 157       * @param pluginLoadMode
 158       * @return
 159       */
<abbr title=" 160      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 160      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoa🔵</abbr>
 161          if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 162              return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 163                      || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 164          }
 165          return true;
 166      }
 167  
 168  
 169      public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 170          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 170          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo🔵</abbr>
 171          StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 172          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 172          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.get🔵</abbr>
 173  
 174          SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 175          SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 176  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 177 -        Map&lt;String, SideTableInfo&gt; sideTableMap = Maps.newHashMap();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 178 +        Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();</span>
 179          Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 180  
 181          //register udf
 182          ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 183          //register table schema
<abbr title=" 184          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 184          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSql🔵</abbr>
<abbr title=" 185                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 185                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCa🔵</abbr>
 186          // cache classPathSets
 187          ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 188  
<abbr title=" 189          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 189          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, r🔵</abbr>
 190  
 191          if (env instanceof MyLocalStreamEnvironment) {
 192              ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 193          }
 194          return env;
 195      }
 196  
 197  
 198      public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 199          List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 200          if (Strings.isNullOrEmpty(addJarListStr)) {
 201              return jarUrlList;
 202          }
 203  
<abbr title=" 204          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 204          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name🔵</abbr>
 205          //Get External jar to load
 206          for (String addJarPath : addJarFileList) {
 207              jarUrlList.add(new File(addJarPath).toURI().toURL());
 208          }
 209          return jarUrlList;
 210      }
 211  
 212      private static void sqlTranslation(String localSqlPluginPath,
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 213 -            StreamTableEnvironment tableEnv,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 214 -            SqlTree sqlTree,Map&lt;String, SideTableInfo&gt; sideTableMap,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 215 -            Map&lt;String, Table&gt; registerTableCache,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 216 -            StreamQueryConfig queryConfig) throws Exception {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 217 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 218 -    	SideSqlExec sideSqlExec = new SideSqlExec();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 219 +                                       StreamTableEnvironment tableEnv,</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 220 +                                       SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 221 +                                       Map&lt;String, Table&gt; registerTableCache,</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 222 +                                       StreamQueryConfig queryConfig) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 223 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 224 +        SideSqlExec sideSqlExec = new SideSqlExec();</span>
 225          sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 226          for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<abbr title=" 227              sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 227              sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result)🔵</abbr>
 228          }
 229  
 230          for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 231              if (LOG.isInfoEnabled()) {
 232                  LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 233              }
 234              boolean isSide = false;
 235              for (String tableName : result.getTargetTableList()) {
 236                  if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 237                      CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 238                      String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 239  
<abbr title=" 240                      SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_LEX_CONFIG).parseStmt();"> 240                      SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_🔵</abbr>


 241                      String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 242                      tmp.setExecSql(tmpSql);
<abbr title=" 243                      sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 243                      sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tm🔵</abbr>
 244                  } else {
 245                      for (String sourceTable : result.getSourceTableList()) {
 246                          if (sideTableMap.containsKey(sourceTable)) {
 247                              isSide = true;
 248                              break;
 249                          }
 250                      }
 251                      if (isSide) {
 252                          //sql-dimensional table contains the dimension table of execution
<abbr title=" 253                          sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 253                          sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryCon🔵</abbr>
 254                      } else {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 255 -                        System.out.println(&quot;----------exec sql without dimension join-----------&quot;);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 256 -                        System.out.println(&quot;----------real sql exec is--------------------------&quot;);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 257 -                        System.out.println(result.getExecSql());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 258 +                        LOG.info(&quot;----------exec sql without dimension join-----------&quot;);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 259 +                        LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());</span>
 260                          FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);
 261                          if (LOG.isInfoEnabled()) {
 262                              LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 263                          }
 264                      }
 265                  }
 266              }
 267          }
 268      }
 269  
<abbr title=" 270      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 270      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEn🔵</abbr>
 271              throws IllegalAccessException, InvocationTargetException {
 272          // udf和tableEnv须由同一个类加载器加载
 273          ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 274          URLClassLoader classLoader = null;
 275          List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 276          for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 277              //classloader
 278              if (classLoader == null) {
 279                  classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);
 280              }
<abbr title=" 281              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 281              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv,🔵</abbr>
 282          }
 283      }
 284  
 285      /**
 286       *    向Flink注册源表和结果表，返回执行时插件包的全路径
 287       * @param sqlTree
 288       * @param env
 289       * @param tableEnv
 290       * @param localSqlPluginPath
 291       * @param remoteSqlPluginPath
 292       * @param pluginLoadMode   插件加载模式 classpath or shipfile
 293       * @param sideTableMap
 294       * @param registerTableCache
 295       * @return
 296       * @throws Exception
 297       */
<abbr title=" 298      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 298      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment t🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 299 -                                         String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, SideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 299 -                                         String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, SideTableI🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 300 +                                         String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 300 +                                         String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSi🔵</abbr></span>
 301          Set&lt;URL&gt; pluginClassPatshSets = Sets.newHashSet();
 302          WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 303 -        for (TableInfo tableInfo : sqlTree.getTableInfoMap().values()) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 304 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 305 -            if (tableInfo instanceof SourceTableInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 306 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 307 -                SourceTableInfo sourceTableInfo = (SourceTableInfo) tableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 308 +        for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 309 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 310 +            if (tableInfo instanceof AbstractSourceTableInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 311 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 312 +                AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;</span>
<abbr title=" 313                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 313                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPa🔵</abbr>
 314                  tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 315                  //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 315                  //Note --- parameter conversion function can not be used inside a function of the type of polymeri🔵</abbr>
 316                  //Create table in which the function is arranged only need adaptation sql
 317                  String adaptSql = sourceTableInfo.getAdaptSelectSql();
 318                  Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 319  
<abbr title=" 320                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 320                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchem🔵</abbr>
 321                  DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)
 322                          .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {
 323                              return f0.f1;
 324                          })
 325                          .returns(typeInfo);
 326  
 327                  String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 328  
 329                  if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
 330                      adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);
 331                      fields += &quot;,ROWTIME.ROWTIME&quot;;
 332                  } else {
 333                      fields += &quot;,PROCTIME.PROCTIME&quot;;
 334                  }
 335  
 336                  Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 337                  tableEnv.registerTable(tableInfo.getName(), regTable);
 338                  if (LOG.isInfoEnabled()) {
 339                      LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 340                  }
 341                  registerTableCache.put(tableInfo.getName(), regTable);
 342  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 343 -                URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), SourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 343 -                URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), SourceTa🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 344 +                URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 344 +                URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), Abstract🔵</abbr></span>
 345                  pluginClassPatshSets.add(sourceTablePathUrl);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 346 -            } else if (tableInfo instanceof TargetTableInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 347 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 348 -                TableSink tableSink = StreamSinkFactory.getTableSink((TargetTableInfo) tableInfo, localSqlPluginPath);"> 348 -                TableSink tableSink = StreamSinkFactory.getTableSink((TargetTableInfo) tableInfo, localSqlPluginPa🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 349 +            } else if (tableInfo instanceof AbstractTargetTableInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 350 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 351 +                TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 351 +                TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSql🔵</abbr></span>
 352                  TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());
 353                  tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);
 354  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 355 -                URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), TargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 355 -                URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), TargetTabl🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 356 +                URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 356 +                URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTa🔵</abbr></span>
 357                  pluginClassPatshSets.add(sinkTablePathUrl);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 358 -            } else if (tableInfo instanceof SideTableInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 359 -                String sideOperator = ECacheType.ALL.name().equals(((SideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 359 -                String sideOperator = ECacheType.ALL.name().equals(((SideTableInfo) tableInfo).getCacheType()) ? &quot;🔵</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 360 -                sideTableMap.put(tableInfo.getName(), (SideTableInfo) tableInfo);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 361 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 362 -                URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, SideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 362 -                URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, SideT🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 363 +            } else if (tableInfo instanceof AbstractSideTableInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 364 +                String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 364 +                String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheTyp🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 365 +                sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 366 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 367 +                URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 367 +                URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, Abstr🔵</abbr></span>
 368                  pluginClassPatshSets.add(sideTablePathUrl);
 369              } else {
 370                  throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 371              }
 372          }
 373          return pluginClassPatshSets;
 374      }
 375  
 376      /**
 377       *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 378       * @param env
 379       * @param classPathSet
 380       */
 381      public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {
 382          int i = 0;
 383          for (URL url : classPathSet) {
 384              String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 385              env.registerCachedFile(url.getPath(), classFileName, true);
 386              i++;
 387          }
 388      }
 389  
<abbr title=" 390      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 390      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws 🔵</abbr>
 391          StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 392                  StreamExecutionEnvironment.getExecutionEnvironment() :
 393                  new MyLocalStreamEnvironment();
 394  
 395          StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 396          return env;
 397      }
 398  
 399  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 400 +    public static void setLogLevel(ParamsInfo paramsInfo){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 401 +        String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 402 +        if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 403 +            return;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 404 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 405 +        ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 406 +        logLevelProcess.process(logLevel);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 407 +    }</span>
 408  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            