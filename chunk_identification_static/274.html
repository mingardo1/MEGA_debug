<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>274</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    274
                    <a href="273.html">prev</a>
                    <a href="275.html">next</a>
                    <a href="274_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_19af9aee8a11baeec3d762122e0750770ea31cd1_hbase/hbase-sink/src/main/java/com/dtstack/flink/sql/sink/hbase/HbaseOutputFormat.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;19af9aee8a11baeec3d762122e0750770ea31cd1:hbase/hbase-sink/src/main/java/com/dtstack/flink/sql/sink/hbase/HbaseOutputFormat.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;19af9aee8a11baeec3d762122e0750770ea31cd1^1:hbase/hbase-sink/src/main/java/com/dtstack/flink/sql/sink/hbase/HbaseOutputFormat.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;19af9aee8a11baeec3d762122e0750770ea31cd1^2:hbase/hbase-sink/src/main/java/com/dtstack/flink/sql/sink/hbase/HbaseOutputFormat.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;40c2c0fe4eb270d5956d2f1e6b11ef26336e7a9e:hbase/hbase-sink/src/main/java/com/dtstack/flink/sql/sink/hbase/HbaseOutputFormat.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[sbj], [sbj], [bs], [j]], subset: [[sbj], [sbj], [bs], [j]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.sink.hbase;
  21 
  22 import com.dtstack.flink.sql.dirtyManager.manager.DirtyDataManager;
  23 import com.dtstack.flink.sql.exception.ExceptionTrace;
  24 import com.dtstack.flink.sql.factory.DTThreadFactory;
  25 import com.dtstack.flink.sql.outputformat.AbstractDtRichOutputFormat;
  26 import com.google.common.collect.Maps;
  27 import org.apache.commons.lang3.StringUtils;
  28 import org.apache.flink.api.java.tuple.Tuple2;
  29 import org.apache.flink.configuration.Configuration;
  30 import org.apache.flink.types.Row;
  31 import org.apache.flink.util.Preconditions;
  32 import org.apache.hadoop.hbase.AuthUtil;
  33 import org.apache.hadoop.hbase.ChoreService;
  34 import org.apache.hadoop.hbase.HBaseConfiguration;
  35 import org.apache.hadoop.hbase.ScheduledChore;
  36 import org.apache.hadoop.hbase.TableName;
  37 import org.apache.hadoop.hbase.client.Connection;
  38 import org.apache.hadoop.hbase.client.ConnectionFactory;
  39 import org.apache.hadoop.hbase.client.Put;
  40 import org.apache.hadoop.hbase.client.Table;
  41 import org.apache.hadoop.security.UserGroupInformation;
  42 import org.slf4j.Logger;
  43 import org.slf4j.LoggerFactory;
  44 
  45 import java.io.File;
  46 import java.io.IOException;
  47 import java.security.PrivilegedAction;
  48 import java.util.ArrayList;
  49 import java.util.LinkedList;
  50 import java.util.List;
  51 import java.util.Map;
  52 import java.util.Objects;
  53 import java.util.concurrent.ScheduledExecutorService;
  54 import java.util.concurrent.ScheduledFuture;
  55 import java.util.concurrent.ScheduledThreadPoolExecutor;
  56 import java.util.concurrent.TimeUnit;
  57 
  58 /**
  59  * @author: jingzhen@dtstack.com
  60  * date: 2017-6-29
  61  */
  62 public class HbaseOutputFormat extends AbstractDtRichOutputFormat&lt;Tuple2&lt;Boolean, Row&gt;&gt; {
  63 
  64     private static final Logger LOG = LoggerFactory.getLogger(HbaseOutputFormat.class);
  65     private String host;
  66     private String zkParent;
  67     private String rowkey;
  68     private String tableName;
  69     private String[] columnNames;
  70     private Map&lt;String, String&gt; columnNameFamily;
  71     private boolean kerberosAuthEnable;
  72     private String regionserverKeytabFile;
  73     private String regionserverPrincipal;
  74     private String securityKrb5Conf;
  75     private String zookeeperSaslClient;
  76     private String clientPrincipal;
  77     private String clientKeytabFile;
  78     private String[] families;
  79     private String[] qualifiers;
  80     private transient org.apache.hadoop.conf.Configuration conf;
  81     private transient Connection conn;
  82     private transient Table table;
  83     private transient ChoreService choreService;
  84     private transient List&lt;Row&gt; records;
  85     private transient volatile boolean closed = false;
  86     /**
  87      * 批量写入的参数
  88      */
  89     private Integer batchSize;
  90     private Long batchWaitInterval;
  91     /**
  92      * 定时任务
  93      */
  94     private transient ScheduledExecutorService scheduler;
  95     private transient ScheduledFuture&lt;?&gt; scheduledFuture;
  96 
  97     /**
  98      * 脏数据管理
  99      */
 100     private DirtyDataManager dirtyDataManager;
 101 
 102     private HbaseOutputFormat() {
 103     }
 104 
 105     public static HbaseOutputFormatBuilder buildHbaseOutputFormat() {
 106         return new HbaseOutputFormatBuilder();
 107     }
 108 
 109     @Override
 110     public void configure(Configuration parameters) {
 111         // 这里不要做耗时较长的操作，否则会导致AKKA通信超时
 112         // DO NOTHING
 113     }
 114 
 115     @Override
 116     public void open(int taskNumber, int numTasks) throws IOException {
 117         LOG.warn(&quot;---open---&quot;);
 118         records = new ArrayList&lt;&gt;();
 119         conf = HBaseConfiguration.create();
 120         openConn();
 121         table = conn.getTable(TableName.valueOf(tableName));
 122         LOG.warn(&quot;---open end(get table from hbase) ---&quot;);
 123         initMetric();
 124     }
 125 
 126     private void openConn() {
 127         try {
 128             if (kerberosAuthEnable) {
 129                 LOG.info(&quot;open kerberos conn&quot;);
 130                 openKerberosConn();
 131             } else {
 132                 LOG.info(&quot;open conn&quot;);
 133                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 134                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 135                 conn = ConnectionFactory.createConnection(conf);
 136             }
 137         } catch (Exception e) {
 138             throw new RuntimeException(e);
 139         }
 140         initScheduledTask(batchWaitInterval);
 141     }
 142 
 143     /**
 144      * 初始化定时写入任务
 145      *
 146      * @param batchWaitInterval 定时任务时间
 147      */
 148     private void initScheduledTask(Long batchWaitInterval) {
 149         try {
 150             if (batchWaitInterval &gt; 0) {
 151                 this.scheduler = new ScheduledThreadPoolExecutor(
 152                         1,
 153                         new DTThreadFactory(&quot;hbase-batch-flusher&quot;)
 154                 );
 155 
 156                 this.scheduledFuture = this.scheduler.scheduleWithFixedDelay(
 157                         () -&gt; {
 158                             synchronized (HbaseOutputFormat.this) {
 159                                 if (!records.isEmpty()) {
 160                                     dealBatchOperation(records);
 161                                 }
 162                             }
 163                         }, batchWaitInterval, batchWaitInterval, TimeUnit.MILLISECONDS
 164                 );
 165             }
 166         } catch (Exception e) {
 167             LOG.error(&quot;init schedule task failed !&quot;);
 168             throw new RuntimeException(e);
 169         }
 170     }
 171 
 172     private void openKerberosConn() throws Exception {
 173         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 174         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 175 
 176         LOG.info(&quot;kerberos config:{}&quot;, this.conf.toString());
 177         Preconditions.checkArgument(!StringUtils.isEmpty(clientPrincipal), &quot; clientPrincipal not null!&quot;);
<abbr title=" 178         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;);"> 178         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;🔵</abbr>
 179 
 180         fillSyncKerberosConfig(conf, regionserverPrincipal, zookeeperSaslClient, securityKrb5Conf);
 181 
 182         clientKeytabFile = System.getProperty(&quot;user.dir&quot;) + File.separator + clientKeytabFile;
<abbr title=" 183         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal;"> 183         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal🔵</abbr>
 184 
 185         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KEYTAB_FILE, clientKeytabFile);
 186         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KERBEROS_PRINCIPAL, clientPrincipal);
 187 
<abbr title=" 188         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clientKeytabFile);"> 188         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrinci🔵</abbr>
 189         org.apache.hadoop.conf.Configuration finalConf = conf;
 190         conn = userGroupInformation.doAs((PrivilegedAction&lt;Connection&gt;) () -&gt; {
 191             try {
 192                 ScheduledChore authChore = AuthUtil.getAuthChore(finalConf);
 193                 if (authChore != null) {
 194                     choreService = new ChoreService(&quot;hbaseKerberosSink&quot;);
 195                     choreService.scheduleChore(authChore);
 196                 }
 197 
 198                 return ConnectionFactory.createConnection(finalConf);
 199             } catch (IOException e) {
 200                 LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 201                 throw new RuntimeException(e);
 202             }
 203         });
 204     }
 205 
 206     @Override
 207     public void writeRecord(Tuple2&lt;Boolean, Row&gt; record) {
 208         if (record.f0) {
 209             if (this.batchSize &gt; 1) {
 210                 writeBatchRecord(record.f1);
 211             } else {
 212                 dealInsert(record.f1);
 213             }
 214         }
 215     }
 216 
 217     public void writeBatchRecord(Row row) {
 218         records.add(row);
 219         // 数据累计到batchSize之后开始处理
 220         if (records.size() == this.batchSize) {
 221             dealBatchOperation(records);
 222         }
 223     }
 224 
 225     protected synchronized void dealBatchOperation(List&lt;Row&gt; records) {
 226         // A null in the result array means that the call for that action failed, even after retries.
 227         Object[] results = null;
 228         try {
 229             List&lt;Put&gt; puts = new ArrayList&lt;&gt;();
 230             for (Row record : records) {
 231                 Put put = getPutByRow(record);
 232                 if (put == null || put.isEmpty()) {
 233 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 234                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 235                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 236                         record.toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 237                         &quot;HBase put is empty, check record please!&quot;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 238                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 239                     outDirtyRecords.inc();</span>
 240 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 241 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 242             // 打印结果</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 243             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 244                 // 只打印最后一条数据</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 245                 LOG.info(records.get(records.size() - 1).toString());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 247         } catch (IOException | InterruptedException ignored) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 248         } finally {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 249             // 判断数据是否插入成功</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 250             for (int i = 0; i &lt; results.length; i++) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 251                 if (results[i] instanceof Exception) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 252                     if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0) {</span>
 253 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 254                     dealError(</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 255                         record,</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 256                         &quot;HBase put is empty, please check the record.&quot;);</span>
 257 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 258                 } else {
 259                     puts.add(put);
 260                 }
 261             }
 262             results = new Object[puts.size()];
 263             table.batch(puts, results);
 264 
 265             // 打印结果
 266             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 267                 // 只打印最后一条数据
 268                 LOG.info(records.get(records.size() - 1).toString());
 269             }
 270         } catch (IOException | InterruptedException e) {
 271             // ignore exception
 272         } finally {
 273             // 判断数据是否插入成功
 274             for (int i = 0; i &lt; Objects.requireNonNull(results).length; i++) {
 275                 if (results[i] instanceof Exception) {
 276 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 277                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 278                     // 脏数据记录</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 279                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 280                         records.get(i).toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 281                         ExceptionTrace.traceOriginalCause((Exception) results[i])</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 282                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 283                     outDirtyRecords.inc();</span>
 284 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 285             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 286             // 添加完数据之后数据清空records</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 287             records.clear();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 288         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 289     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 290 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 291     protected void dealInsert(Row record) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 292         Put put = getPutByRow(record);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 293         if (put == null || put.isEmpty()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 294             // 记录脏数据</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 295             outDirtyRecords.inc();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 296             return;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 297         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 298 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 299         try {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 300             table.put(put);</span>
 301 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 302                     dealError(records.get(i), ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
 303 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 304                 } else {
 305                     // 输出结果条数记录
 306                     outRecords.inc();
 307                 }
 308             }
 309             // 添加完数据之后数据清空records
 310             records.clear();
 311         }
 312     }
 313 
 314     protected void dealInsert(Row record) {
 315         Put put = getPutByRow(record);
 316         if (put == null || put.isEmpty()) {
 317             // 记录脏数据
 318             outDirtyRecords.inc();
 319             return;
 320         }
 321 
 322         try {
 323             table.put(put);
 324 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 325             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 326                 LOG.info(record.toString());</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 327             }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 328         } catch (Exception e) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 329             dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 330                 record.toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 331                 ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 332             outDirtyRecords.inc();</span>
 333 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 334             outDirtyRecords.inc();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 335         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 336 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 337         if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 338             LOG.info(record.toString());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 339         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 340         outRecords.inc();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 341     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 342 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 343     private Put getPutByRow(Row record) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 344         String rowKey = buildRowKey(record);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 345         if (StringUtils.isEmpty(rowKey)) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 346             return null;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 347         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 348         Put put = new Put(rowKey.getBytes());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 349         for (int i = 0; i &lt; record.getArity(); ++i) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 350             Object fieldVal = record.getField(i);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 351             if (fieldVal != null) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 352                 byte[] val = fieldVal.toString().getBytes();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 353                 byte[] cf = families[i].getBytes();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 354                 byte[] qualifier = qualifiers[i].getBytes();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 355 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 356                 put.addColumn(cf, qualifier, val);</span>
 357 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 358         } catch (Exception e) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 359             dealError(record, ExceptionTrace.traceOriginalCause(e));</span>
 360 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 361         }
 362 
 363         outRecords.inc();
 364     }
 365 
 366     private void dealError(Row record, String cause) {
 367         if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {
 368             LOG.error(&quot;Get dirty data: {}&quot;, record.toString());
 369             LOG.error(&quot;Error cause: &quot; + cause);
 370         }
 371         outDirtyRecords.inc();
 372     }
 373 
 374     private Put getPutByRow(Row record) {
 375         String rowKey = buildRowKey(record);
 376         if (StringUtils.isEmpty(rowKey)) {
 377             return null;
 378         }
 379         Put put = new Put(rowKey.getBytes());
 380         for (int i = 0; i &lt; record.getArity(); ++i) {
 381             Object fieldVal = record.getField(i);
 382             if (fieldVal != null) {
 383                 byte[] val = fieldVal.toString().getBytes();
 384                 byte[] cf = families[i].getBytes();
 385                 byte[] qualifier = qualifiers[i].getBytes();
 386 
 387                 put.addColumn(cf, qualifier, val);
 388             }
 389         }
 390         return put;
 391     }
 392 
 393     private String buildRowKey(Row record) {
 394         String rowKeyValues = getRowKeyValues(record);
 395         // all rowkey not null
 396         if (StringUtils.isBlank(rowKeyValues)) {
 397             LOG.error(&quot;row key value must not null,record is ..{}&quot;, record);
 398             outDirtyRecords.inc();
 399             return &quot;&quot;;
 400         }
 401         return rowKeyValues;
 402     }
 403 
 404     private String getRowKeyValues(Row record) {
 405         Map&lt;String, Object&gt; row = rowConvertMap(record);
 406         RowKeyBuilder rowKeyBuilder = new RowKeyBuilder();
 407         rowKeyBuilder.init(rowkey);
 408         return rowKeyBuilder.getRowKey(row);
 409     }
 410 
 411     private Map&lt;String, Object&gt; rowConvertMap(Row record) {
 412         Map&lt;String, Object&gt; rowValue = Maps.newHashMap();
 413         for (int i = 0; i &lt; columnNames.length; i++) {
 414             rowValue.put(columnNames[i], record.getField(i));
 415         }
 416         return rowValue;
 417     }
 418 
 419     @Override
 420     public synchronized void close() throws IOException {
 421         if (closed) {
 422             return;
 423         }
 424 
 425         closed = true;
 426         if (!records.isEmpty()) {
 427             dealBatchOperation(records);
 428         }
 429 
 430         if (scheduledFuture != null) {
 431             scheduledFuture.cancel(false);
 432             if (scheduler != null) {
 433                 scheduler.shutdownNow();
 434             }
 435         }
 436 
 437         if (conn != null) {
 438             conn.close();
 439             conn = null;
 440         }
 441 
 442         if (dirtyDataManager != null) {
 443             dirtyDataManager.close();
 444         }
 445     }
 446 
 447     private void fillSyncKerberosConfig(org.apache.hadoop.conf.Configuration config,
 448                                         String regionserverPrincipal,
 449                                         String zookeeperSaslClient,
 450                                         String securityKrb5Conf) {
 451         if (StringUtils.isEmpty(regionserverPrincipal)) {
<abbr title=" 452             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos&quot;);"> 452             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is🔵</abbr>
 453         }
 454         config.set(HbaseConfigUtils.KEY_HBASE_MASTER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 455         config.set(HbaseConfigUtils.KEY_HBASE_REGIONSERVER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 456         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHORIZATION, &quot;true&quot;);
 457         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHENTICATION, &quot;kerberos&quot;);
 458 
 459 
 460         if (!StringUtils.isEmpty(zookeeperSaslClient)) {
 461             System.setProperty(HbaseConfigUtils.KEY_ZOOKEEPER_SASL_CLIENT, zookeeperSaslClient);
 462         }
 463 
 464         if (!StringUtils.isEmpty(securityKrb5Conf)) {
 465             String krb5ConfPath = System.getProperty(&quot;user.dir&quot;) + File.separator + securityKrb5Conf;
 466             LOG.info(&quot;krb5ConfPath:{}&quot;, krb5ConfPath);
 467             System.setProperty(HbaseConfigUtils.KEY_JAVA_SECURITY_KRB5_CONF, krb5ConfPath);
 468         }
 469     }
 470 
 471     @Override
 472     public String toString() {
 473         return &quot;HbaseOutputFormat kerberos{&quot; +
 474                 &quot;kerberosAuthEnable=&quot; + kerberosAuthEnable +
 475                 &quot;, regionserverKeytabFile=&#x27;&quot; + regionserverKeytabFile + &#x27;\&#x27;&#x27; +
 476                 &quot;, regionserverPrincipal=&#x27;&quot; + regionserverPrincipal + &#x27;\&#x27;&#x27; +
 477                 &quot;, securityKrb5Conf=&#x27;&quot; + securityKrb5Conf + &#x27;\&#x27;&#x27; +
 478                 &quot;, zookeeperSaslClient=&#x27;&quot; + zookeeperSaslClient + &#x27;\&#x27;&#x27; +
 479                 &quot;, clientPrincipal=&#x27;&quot; + clientPrincipal + &#x27;\&#x27;&#x27; +
 480                 &quot;, clientKeytabFile=&#x27;&quot; + clientKeytabFile + &#x27;\&#x27;&#x27; +
 481                 &quot;, batchSize=&#x27;&quot; + batchSize + &#x27;\&#x27;&#x27; +
 482                 &quot;, batchWaitInterval=&#x27;&quot; + batchWaitInterval + &#x27;\&#x27;&#x27; +
 483                 &#x27;}&#x27;;
 484     }
 485 
 486     public static class HbaseOutputFormatBuilder {
 487 
 488         private final HbaseOutputFormat format;
 489 
 490         private HbaseOutputFormatBuilder() {
 491             format = new HbaseOutputFormat();
 492         }
 493 
 494         public HbaseOutputFormatBuilder setHost(String host) {
 495             format.host = host;
 496             return this;
 497         }
 498 
 499         public HbaseOutputFormatBuilder setZkParent(String parent) {
 500             format.zkParent = parent;
 501             return this;
 502         }
 503 
 504 
 505         public HbaseOutputFormatBuilder setTable(String tableName) {
 506             format.tableName = tableName;
 507             return this;
 508         }
 509 
 510         public HbaseOutputFormatBuilder setRowkey(String rowkey) {
 511             format.rowkey = rowkey;
 512             return this;
 513         }
 514 
 515         public HbaseOutputFormatBuilder setColumnNames(String[] columnNames) {
 516             format.columnNames = columnNames;
 517             return this;
 518         }
 519 
 520         public HbaseOutputFormatBuilder setColumnNameFamily(Map&lt;String, String&gt; columnNameFamily) {
 521             format.columnNameFamily = columnNameFamily;
 522             return this;
 523         }
 524 
 525         public HbaseOutputFormatBuilder setKerberosAuthEnable(boolean kerberosAuthEnable) {
 526             format.kerberosAuthEnable = kerberosAuthEnable;
 527             return this;
 528         }
 529 
 530         public HbaseOutputFormatBuilder setRegionserverKeytabFile(String regionserverKeytabFile) {
 531             format.regionserverKeytabFile = regionserverKeytabFile;
 532             return this;
 533         }
 534 
 535         public HbaseOutputFormatBuilder setRegionserverPrincipal(String regionserverPrincipal) {
 536             format.regionserverPrincipal = regionserverPrincipal;
 537             return this;
 538         }
 539 
 540         public HbaseOutputFormatBuilder setSecurityKrb5Conf(String securityKrb5Conf) {
 541             format.securityKrb5Conf = securityKrb5Conf;
 542             return this;
 543         }
 544 
 545         public HbaseOutputFormatBuilder setZookeeperSaslClient(String zookeeperSaslClient) {
 546             format.zookeeperSaslClient = zookeeperSaslClient;
 547             return this;
 548         }
 549 
 550         public HbaseOutputFormatBuilder setClientPrincipal(String clientPrincipal) {
 551             format.clientPrincipal = clientPrincipal;
 552             return this;
 553         }
 554 
 555         public HbaseOutputFormatBuilder setClientKeytabFile(String clientKeytabFile) {
 556             format.clientKeytabFile = clientKeytabFile;
 557             return this;
 558         }
 559 
 560         public HbaseOutputFormatBuilder setDirtyManager(DirtyDataManager dirtyDataManager) {
 561             format.dirtyDataManager = dirtyDataManager;
 562             return this;
 563         }
 564 
 565         public HbaseOutputFormatBuilder setBatchSize(Integer batchSize) {
 566             format.batchSize = batchSize;
 567             return this;
 568         }
 569 
 570         public HbaseOutputFormatBuilder setBatchWaitInterval(Long batchWaitInterval) {
 571             format.batchWaitInterval = batchWaitInterval;
 572             return this;
 573         }
 574 
 575         public HbaseOutputFormat finish() {
 576             Preconditions.checkNotNull(format.host, &quot;zookeeperQuorum should be specified&quot;);
 577             Preconditions.checkNotNull(format.tableName, &quot;tableName should be specified&quot;);
 578             Preconditions.checkNotNull(format.columnNames, &quot;columnNames should be specified&quot;);
<abbr title=" 579             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be zero&quot;);"> 579             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be🔵</abbr>
 580 
 581             String[] families = new String[format.columnNames.length];
 582             String[] qualifiers = new String[format.columnNames.length];
 583 
 584             if (format.columnNameFamily != null) {
 585                 List&lt;String&gt; keyList = new LinkedList&lt;&gt;(format.columnNameFamily.keySet());
 586                 String[] columns = keyList.toArray(new String[0]);
 587                 for (int i = 0; i &lt; columns.length; ++i) {
 588                     String col = columns[i];
 589                     String[] part = col.split(&quot;:&quot;);
 590                     families[i] = part[0];
 591                     qualifiers[i] = part[1];
 592                 }
 593             }
 594             format.families = families;
 595             format.qualifiers = qualifiers;
 596 
 597             return format;
 598         }
 599     }
 600 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.sink.hbase;
  21 
  22 import com.dtstack.flink.sql.dirtyManager.manager.DirtyDataManager;
  23 import com.dtstack.flink.sql.exception.ExceptionTrace;
  24 import com.dtstack.flink.sql.factory.DTThreadFactory;
  25 import com.dtstack.flink.sql.outputformat.AbstractDtRichOutputFormat;
  26 import com.google.common.collect.Maps;
  27 import org.apache.commons.lang3.StringUtils;
  28 import org.apache.flink.api.java.tuple.Tuple2;
  29 import org.apache.flink.configuration.Configuration;
  30 import org.apache.flink.types.Row;
  31 import org.apache.flink.util.Preconditions;
  32 import org.apache.hadoop.hbase.AuthUtil;
  33 import org.apache.hadoop.hbase.ChoreService;
  34 import org.apache.hadoop.hbase.HBaseConfiguration;
  35 import org.apache.hadoop.hbase.ScheduledChore;
  36 import org.apache.hadoop.hbase.TableName;
  37 import org.apache.hadoop.hbase.client.Connection;
  38 import org.apache.hadoop.hbase.client.ConnectionFactory;
  39 import org.apache.hadoop.hbase.client.Put;
  40 import org.apache.hadoop.hbase.client.Table;
  41 import org.apache.hadoop.security.UserGroupInformation;
  42 import org.slf4j.Logger;
  43 import org.slf4j.LoggerFactory;
  44 
  45 import java.io.File;
  46 import java.io.IOException;
  47 import java.security.PrivilegedAction;
  48 import java.util.ArrayList;
  49 import java.util.LinkedList;
  50 import java.util.List;
  51 import java.util.Map;
  52 import java.util.Objects;
  53 import java.util.concurrent.ScheduledExecutorService;
  54 import java.util.concurrent.ScheduledFuture;
  55 import java.util.concurrent.ScheduledThreadPoolExecutor;
  56 import java.util.concurrent.TimeUnit;
  57 
  58 /**
  59  * @author: jingzhen@dtstack.com
  60  * date: 2017-6-29
  61  */
  62 public class HbaseOutputFormat extends AbstractDtRichOutputFormat&lt;Tuple2&lt;Boolean, Row&gt;&gt; {
  63 
  64     private static final Logger LOG = LoggerFactory.getLogger(HbaseOutputFormat.class);
  65     private String host;
  66     private String zkParent;
  67     private String rowkey;
  68     private String tableName;
  69     private String[] columnNames;
  70     private Map&lt;String, String&gt; columnNameFamily;
  71     private boolean kerberosAuthEnable;
  72     private String regionserverKeytabFile;
  73     private String regionserverPrincipal;
  74     private String securityKrb5Conf;
  75     private String zookeeperSaslClient;
  76     private String clientPrincipal;
  77     private String clientKeytabFile;
  78     private String[] families;
  79     private String[] qualifiers;
  80     private transient org.apache.hadoop.conf.Configuration conf;
  81     private transient Connection conn;
  82     private transient Table table;
  83     private transient ChoreService choreService;
  84     private transient List&lt;Row&gt; records;
  85     private transient volatile boolean closed = false;
  86     /**
  87      * 批量写入的参数
  88      */
  89     private Integer batchSize;
  90     private Long batchWaitInterval;
  91     /**
  92      * 定时任务
  93      */
  94     private transient ScheduledExecutorService scheduler;
  95     private transient ScheduledFuture&lt;?&gt; scheduledFuture;
  96 
  97     /**
  98      * 脏数据管理
  99      */
 100     private DirtyDataManager dirtyDataManager;
 101 
 102     private HbaseOutputFormat() {
 103     }
 104 
 105     public static HbaseOutputFormatBuilder buildHbaseOutputFormat() {
 106         return new HbaseOutputFormatBuilder();
 107     }
 108 
 109     @Override
 110     public void configure(Configuration parameters) {
 111         // 这里不要做耗时较长的操作，否则会导致AKKA通信超时
 112         // DO NOTHING
 113     }
 114 
 115     @Override
 116     public void open(int taskNumber, int numTasks) throws IOException {
 117         LOG.warn(&quot;---open---&quot;);
 118         records = new ArrayList&lt;&gt;();
 119         conf = HBaseConfiguration.create();
 120         openConn();
 121         table = conn.getTable(TableName.valueOf(tableName));
 122         LOG.warn(&quot;---open end(get table from hbase) ---&quot;);
 123         initMetric();
 124     }
 125 
 126     private void openConn() {
 127         try {
 128             if (kerberosAuthEnable) {
 129                 LOG.info(&quot;open kerberos conn&quot;);
 130                 openKerberosConn();
 131             } else {
 132                 LOG.info(&quot;open conn&quot;);
 133                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 134                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 135                 conn = ConnectionFactory.createConnection(conf);
 136             }
 137         } catch (Exception e) {
 138             throw new RuntimeException(e);
 139         }
 140         initScheduledTask(batchWaitInterval);
 141     }
 142 
 143     /**
 144      * 初始化定时写入任务
 145      *
 146      * @param batchWaitInterval 定时任务时间
 147      */
 148     private void initScheduledTask(Long batchWaitInterval) {
 149         try {
 150             if (batchWaitInterval &gt; 0) {
 151                 this.scheduler = new ScheduledThreadPoolExecutor(
 152                         1,
 153                         new DTThreadFactory(&quot;hbase-batch-flusher&quot;)
 154                 );
 155 
 156                 this.scheduledFuture = this.scheduler.scheduleWithFixedDelay(
 157                         () -&gt; {
 158                             synchronized (HbaseOutputFormat.this) {
 159                                 if (!records.isEmpty()) {
 160                                     dealBatchOperation(records);
 161                                 }
 162                             }
 163                         }, batchWaitInterval, batchWaitInterval, TimeUnit.MILLISECONDS
 164                 );
 165             }
 166         } catch (Exception e) {
 167             LOG.error(&quot;init schedule task failed !&quot;);
 168             throw new RuntimeException(e);
 169         }
 170     }
 171 
 172     private void openKerberosConn() throws Exception {
 173         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 174         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 175 
 176         LOG.info(&quot;kerberos config:{}&quot;, this.conf.toString());
 177         Preconditions.checkArgument(!StringUtils.isEmpty(clientPrincipal), &quot; clientPrincipal not null!&quot;);
<abbr title=" 178         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;);"> 178         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;🔵</abbr>
 179 
 180         fillSyncKerberosConfig(conf, regionserverPrincipal, zookeeperSaslClient, securityKrb5Conf);
 181 
 182         clientKeytabFile = System.getProperty(&quot;user.dir&quot;) + File.separator + clientKeytabFile;
<abbr title=" 183         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal;"> 183         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal🔵</abbr>
 184 
 185         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KEYTAB_FILE, clientKeytabFile);
 186         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KERBEROS_PRINCIPAL, clientPrincipal);
 187 
<abbr title=" 188         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clientKeytabFile);"> 188         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrinci🔵</abbr>
 189         org.apache.hadoop.conf.Configuration finalConf = conf;
 190         conn = userGroupInformation.doAs((PrivilegedAction&lt;Connection&gt;) () -&gt; {
 191             try {
 192                 ScheduledChore authChore = AuthUtil.getAuthChore(finalConf);
 193                 if (authChore != null) {
 194                     choreService = new ChoreService(&quot;hbaseKerberosSink&quot;);
 195                     choreService.scheduleChore(authChore);
 196                 }
 197 
 198                 return ConnectionFactory.createConnection(finalConf);
 199             } catch (IOException e) {
 200                 LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 201                 throw new RuntimeException(e);
 202             }
 203         });
 204     }
 205 
 206     @Override
 207     public void writeRecord(Tuple2&lt;Boolean, Row&gt; record) {
 208         if (record.f0) {
 209             if (this.batchSize &gt; 1) {
 210                 writeBatchRecord(record.f1);
 211             } else {
 212                 dealInsert(record.f1);
 213             }
 214         }
 215     }
 216 
 217     public void writeBatchRecord(Row row) {
 218         records.add(row);
 219         // 数据累计到batchSize之后开始处理
 220         if (records.size() == this.batchSize) {
 221             dealBatchOperation(records);
 222         }
 223     }
 224 
 225     protected synchronized void dealBatchOperation(List&lt;Row&gt; records) {
 226         // A null in the result array means that the call for that action failed, even after retries.
 227         Object[] results = null;
 228         try {
 229             List&lt;Put&gt; puts = new ArrayList&lt;&gt;();
 230             for (Row record : records) {
 231                 Put put = getPutByRow(record);
 232                 if (put == null || put.isEmpty()) {
 233 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 234                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 235                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 236                         record.toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 237                         &quot;HBase put is empty, check record please!&quot;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 238                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 239                     outDirtyRecords.inc();</span>
 240 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 241             table.batch(puts, results);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 242 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 243             // 打印结果</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 244             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 245                 // 只打印最后一条数据</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246                 LOG.info(records.get(records.size() - 1).toString());</span>
 247 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 248                     dealError(</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 249                         record,</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 250                         &quot;HBase put is empty, please check the record.&quot;);</span>
 251 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 252                 } else {
 253                     puts.add(put);
 254             }
 255             }
 256             results = new Object[puts.size()];
 257             table.batch(puts, results);
 258 
 259             // 打印结果
 260             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 261                 // 只打印最后一条数据
 262                 LOG.info(records.get(records.size() - 1).toString());
 263             }
 264         } catch (IOException | InterruptedException e) {
 265             // ignore exception
 266         } finally {
 267             // 判断数据是否插入成功
 268             for (int i = 0; i &lt; Objects.requireNonNull(results).length; i++) {
 269                 if (results[i] instanceof Exception) {
 270 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 271                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 272                     // 脏数据记录</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 273                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 274                         records.get(i).toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 275                         ExceptionTrace.traceOriginalCause((Exception) results[i])</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 276                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 277                     outDirtyRecords.inc();</span>
 278 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 279                 }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 280             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 281             // 添加完数据之后数据清空records</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 282             records.clear();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 283         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 284     }</span>
 285 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 286                     dealError(records.get(i), ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
 287 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 288                 } else {
 289                     // 输出结果条数记录
 290                     outRecords.inc();
 291                 }
 292             }
 293             // 添加完数据之后数据清空records
 294             records.clear();
 295         }
 296     }
 297 
 298     protected void dealInsert(Row record) {
 299         Put put = getPutByRow(record);
 300         if (put == null || put.isEmpty()) {
 301             // 记录脏数据
 302             outDirtyRecords.inc();
 303             return;
 304         }
 305 
 306         try {
 307             table.put(put);
 308 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
 309 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 310         } catch (Exception e) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 311             if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 312                 LOG.error(&quot;Get dirty data: {}&quot;, record.toString());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 313                 LOG.error(&quot;Error cause: &quot; + ExceptionTrace.traceOriginalCause(e));</span>
 314 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 315         } catch (Exception e) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 316             dealError(record, ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 317         }</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 318 </span>
 319 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 320         if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 321             LOG.info(record.toString());
 322         }
 323         } catch (Exception e) {
 324             dirtyDataManager.collectDirtyData(
 325                 record.toString(),
 326                 ExceptionTrace.traceOriginalCause(e));
 327             outDirtyRecords.inc();
 328         }
 329 
 330         outRecords.inc();
 331     }
 332 
 333     private void dealError(Row record, String cause) {
 334         if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {
 335             LOG.error(&quot;Get dirty data: {}&quot;, record.toString());
 336             LOG.error(&quot;Error cause: &quot; + cause);
 337         }
 338         outDirtyRecords.inc();
 339     }
 340 
 341     private Put getPutByRow(Row record) {
 342         String rowKey = buildRowKey(record);
 343         if (StringUtils.isEmpty(rowKey)) {
 344             return null;
 345         }
 346         Put put = new Put(rowKey.getBytes());
 347         for (int i = 0; i &lt; record.getArity(); ++i) {
 348             Object fieldVal = record.getField(i);
 349             if (fieldVal != null) {
 350                 byte[] val = fieldVal.toString().getBytes();
 351                 byte[] cf = families[i].getBytes();
 352                 byte[] qualifier = qualifiers[i].getBytes();
 353 
 354                 put.addColumn(cf, qualifier, val);
 355             }
 356         }
 357         return put;
 358     }
 359 
 360     private String buildRowKey(Row record) {
 361         String rowKeyValues = getRowKeyValues(record);
 362         // all rowkey not null
 363         if (StringUtils.isBlank(rowKeyValues)) {
 364             LOG.error(&quot;row key value must not null,record is ..{}&quot;, record);
 365             outDirtyRecords.inc();
 366             return &quot;&quot;;
 367         }
 368         return rowKeyValues;
 369     }
 370 
 371     private String getRowKeyValues(Row record) {
 372         Map&lt;String, Object&gt; row = rowConvertMap(record);
 373         RowKeyBuilder rowKeyBuilder = new RowKeyBuilder();
 374         rowKeyBuilder.init(rowkey);
 375         return rowKeyBuilder.getRowKey(row);
 376     }
 377 
 378     private Map&lt;String, Object&gt; rowConvertMap(Row record) {
 379         Map&lt;String, Object&gt; rowValue = Maps.newHashMap();
 380         for (int i = 0; i &lt; columnNames.length; i++) {
 381             rowValue.put(columnNames[i], record.getField(i));
 382         }
 383         return rowValue;
 384     }
 385 
 386     @Override
 387     public synchronized void close() throws IOException {
 388         if (closed) {
 389             return;
 390         }
 391 
 392         closed = true;
 393         if (!records.isEmpty()) {
 394             dealBatchOperation(records);
 395         }
 396 
 397         if (scheduledFuture != null) {
 398             scheduledFuture.cancel(false);
 399             if (scheduler != null) {
 400                 scheduler.shutdownNow();
 401             }
 402         }
 403 
 404         if (conn != null) {
 405             conn.close();
 406             conn = null;
 407         }
 408 
 409         if (dirtyDataManager != null) {
 410             dirtyDataManager.close();
 411         }
 412     }
 413 
 414     private void fillSyncKerberosConfig(org.apache.hadoop.conf.Configuration config,
 415                                         String regionserverPrincipal,
 416                                         String zookeeperSaslClient,
 417                                         String securityKrb5Conf) {
 418         if (StringUtils.isEmpty(regionserverPrincipal)) {
<abbr title=" 419             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos&quot;);"> 419             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is🔵</abbr>
 420         }
 421         config.set(HbaseConfigUtils.KEY_HBASE_MASTER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 422         config.set(HbaseConfigUtils.KEY_HBASE_REGIONSERVER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 423         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHORIZATION, &quot;true&quot;);
 424         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHENTICATION, &quot;kerberos&quot;);
 425 
 426 
 427         if (!StringUtils.isEmpty(zookeeperSaslClient)) {
 428             System.setProperty(HbaseConfigUtils.KEY_ZOOKEEPER_SASL_CLIENT, zookeeperSaslClient);
 429         }
 430 
 431         if (!StringUtils.isEmpty(securityKrb5Conf)) {
 432             String krb5ConfPath = System.getProperty(&quot;user.dir&quot;) + File.separator + securityKrb5Conf;
 433             LOG.info(&quot;krb5ConfPath:{}&quot;, krb5ConfPath);
 434             System.setProperty(HbaseConfigUtils.KEY_JAVA_SECURITY_KRB5_CONF, krb5ConfPath);
 435         }
 436     }
 437 
 438     @Override
 439     public String toString() {
 440         return &quot;HbaseOutputFormat kerberos{&quot; +
 441                 &quot;kerberosAuthEnable=&quot; + kerberosAuthEnable +
 442                 &quot;, regionserverKeytabFile=&#x27;&quot; + regionserverKeytabFile + &#x27;\&#x27;&#x27; +
 443                 &quot;, regionserverPrincipal=&#x27;&quot; + regionserverPrincipal + &#x27;\&#x27;&#x27; +
 444                 &quot;, securityKrb5Conf=&#x27;&quot; + securityKrb5Conf + &#x27;\&#x27;&#x27; +
 445                 &quot;, zookeeperSaslClient=&#x27;&quot; + zookeeperSaslClient + &#x27;\&#x27;&#x27; +
 446                 &quot;, clientPrincipal=&#x27;&quot; + clientPrincipal + &#x27;\&#x27;&#x27; +
 447                 &quot;, clientKeytabFile=&#x27;&quot; + clientKeytabFile + &#x27;\&#x27;&#x27; +
 448                 &quot;, batchSize=&#x27;&quot; + batchSize + &#x27;\&#x27;&#x27; +
 449                 &quot;, batchWaitInterval=&#x27;&quot; + batchWaitInterval + &#x27;\&#x27;&#x27; +
 450                 &#x27;}&#x27;;
 451     }
 452 
 453     public static class HbaseOutputFormatBuilder {
 454 
 455         private final HbaseOutputFormat format;
 456 
 457         private HbaseOutputFormatBuilder() {
 458             format = new HbaseOutputFormat();
 459         }
 460 
 461         public HbaseOutputFormatBuilder setHost(String host) {
 462             format.host = host;
 463             return this;
 464         }
 465 
 466         public HbaseOutputFormatBuilder setZkParent(String parent) {
 467             format.zkParent = parent;
 468             return this;
 469         }
 470 
 471 
 472         public HbaseOutputFormatBuilder setTable(String tableName) {
 473             format.tableName = tableName;
 474             return this;
 475         }
 476 
 477         public HbaseOutputFormatBuilder setRowkey(String rowkey) {
 478             format.rowkey = rowkey;
 479             return this;
 480         }
 481 
 482         public HbaseOutputFormatBuilder setColumnNames(String[] columnNames) {
 483             format.columnNames = columnNames;
 484             return this;
 485         }
 486 
 487         public HbaseOutputFormatBuilder setColumnNameFamily(Map&lt;String, String&gt; columnNameFamily) {
 488             format.columnNameFamily = columnNameFamily;
 489             return this;
 490         }
 491 
 492         public HbaseOutputFormatBuilder setKerberosAuthEnable(boolean kerberosAuthEnable) {
 493             format.kerberosAuthEnable = kerberosAuthEnable;
 494             return this;
 495         }
 496 
 497         public HbaseOutputFormatBuilder setRegionserverKeytabFile(String regionserverKeytabFile) {
 498             format.regionserverKeytabFile = regionserverKeytabFile;
 499             return this;
 500         }
 501 
 502         public HbaseOutputFormatBuilder setRegionserverPrincipal(String regionserverPrincipal) {
 503             format.regionserverPrincipal = regionserverPrincipal;
 504             return this;
 505         }
 506 
 507         public HbaseOutputFormatBuilder setSecurityKrb5Conf(String securityKrb5Conf) {
 508             format.securityKrb5Conf = securityKrb5Conf;
 509             return this;
 510         }
 511 
 512         public HbaseOutputFormatBuilder setZookeeperSaslClient(String zookeeperSaslClient) {
 513             format.zookeeperSaslClient = zookeeperSaslClient;
 514             return this;
 515         }
 516 
 517         public HbaseOutputFormatBuilder setClientPrincipal(String clientPrincipal) {
 518             format.clientPrincipal = clientPrincipal;
 519             return this;
 520         }
 521 
 522         public HbaseOutputFormatBuilder setClientKeytabFile(String clientKeytabFile) {
 523             format.clientKeytabFile = clientKeytabFile;
 524             return this;
 525         }
 526 
 527         public HbaseOutputFormatBuilder setDirtyManager(DirtyDataManager dirtyDataManager) {
 528             format.dirtyDataManager = dirtyDataManager;
 529             return this;
 530         }
 531 
 532         public HbaseOutputFormatBuilder setBatchSize(Integer batchSize) {
 533             format.batchSize = batchSize;
 534             return this;
 535         }
 536 
 537         public HbaseOutputFormatBuilder setBatchWaitInterval(Long batchWaitInterval) {
 538             format.batchWaitInterval = batchWaitInterval;
 539             return this;
 540         }
 541 
 542         public HbaseOutputFormat finish() {
 543             Preconditions.checkNotNull(format.host, &quot;zookeeperQuorum should be specified&quot;);
 544             Preconditions.checkNotNull(format.tableName, &quot;tableName should be specified&quot;);
 545             Preconditions.checkNotNull(format.columnNames, &quot;columnNames should be specified&quot;);
<abbr title=" 546             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be zero&quot;);"> 546             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be🔵</abbr>
 547 
 548             String[] families = new String[format.columnNames.length];
 549             String[] qualifiers = new String[format.columnNames.length];
 550 
 551             if (format.columnNameFamily != null) {
 552                 List&lt;String&gt; keyList = new LinkedList&lt;&gt;(format.columnNameFamily.keySet());
 553                 String[] columns = keyList.toArray(new String[0]);
 554                 for (int i = 0; i &lt; columns.length; ++i) {
 555                     String col = columns[i];
 556                     String[] part = col.split(&quot;:&quot;);
 557                     families[i] = part[0];
 558                     qualifiers[i] = part[1];
 559                 }
 560             }
 561             format.families = families;
 562             format.qualifiers = qualifiers;
 563 
 564             return format;
 565         }
 566     }
 567 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.sink.hbase;
  19 
  20 import com.dtstack.flink.sql.dirtyManager.manager.DirtyDataManager;
  21 import com.dtstack.flink.sql.exception.ExceptionTrace;
  22 import com.dtstack.flink.sql.factory.DTThreadFactory;
  23 import com.dtstack.flink.sql.outputformat.AbstractDtRichOutputFormat;
  24 import com.google.common.collect.Maps;
  25 import java.io.File;
  26 import java.io.IOException;
  27 import java.security.PrivilegedAction;
  28 import java.util.ArrayList;
  29 import java.util.LinkedList;
  30 import java.util.List;
  31 import java.util.Map;
  32 import java.util.Objects;
  33 import java.util.concurrent.ScheduledExecutorService;
  34 import java.util.concurrent.ScheduledFuture;
  35 import java.util.concurrent.ScheduledThreadPoolExecutor;
  36 import java.util.concurrent.TimeUnit;
  37 import org.apache.commons.lang3.StringUtils;
  38 import org.apache.flink.api.java.tuple.Tuple2;
  39 import org.apache.flink.configuration.Configuration;
  40 import org.apache.flink.types.Row;
  41 import org.apache.flink.util.Preconditions;
  42 import org.apache.hadoop.hbase.AuthUtil;
  43 import org.apache.hadoop.hbase.ChoreService;
  44 import org.apache.hadoop.hbase.HBaseConfiguration;
  45 import org.apache.hadoop.hbase.ScheduledChore;
  46 import org.apache.hadoop.hbase.TableName;
  47 import org.apache.hadoop.hbase.client.Connection;
  48 import org.apache.hadoop.hbase.client.ConnectionFactory;
  49 import org.apache.hadoop.hbase.client.Put;
  50 import org.apache.hadoop.hbase.client.Table;
  51 import org.apache.hadoop.security.UserGroupInformation;
  52 import org.slf4j.Logger;
  53 import org.slf4j.LoggerFactory;
  54 
  55 
  56 /**
  57  * @author: jingzhen@dtstack.com
  58  * date: 2017-6-29
  59  */
  60 public class HbaseOutputFormat extends AbstractDtRichOutputFormat&lt;Tuple2&lt;Boolean, Row&gt;&gt; {
  61 
  62     private static final Logger LOG = LoggerFactory.getLogger(HbaseOutputFormat.class);
  63     private String host;
  64     private String zkParent;
  65     private String rowkey;
  66     private String tableName;
  67     private String[] columnNames;
  68     private Map&lt;String, String&gt; columnNameFamily;
  69     private boolean kerberosAuthEnable;
  70     private String regionserverKeytabFile;
  71     private String regionserverPrincipal;
  72     private String securityKrb5Conf;
  73     private String zookeeperSaslClient;
  74     private String clientPrincipal;
  75     private String clientKeytabFile;
  76     private String[] families;
  77     private String[] qualifiers;
  78     private transient org.apache.hadoop.conf.Configuration conf;
  79     private transient Connection conn;
  80     private transient Table table;
  81     private transient ChoreService choreService;
  82     private transient List&lt;Row&gt; records;
  83     private transient volatile boolean closed = false;
  84     /**
  85      * 批量写入的参数
  86      */
  87     private Integer batchSize;
  88     private Long batchWaitInterval;
  89     /**
  90      * 定时任务
  91      */
  92     private transient ScheduledExecutorService scheduler;
  93     private transient ScheduledFuture&lt;?&gt; scheduledFuture;
  94 
  95     /**
  96      * 脏数据管理
  97      */
  98     private DirtyDataManager dirtyDataManager;
  99 
 100     private HbaseOutputFormat() {
 101     }
 102 
 103     public static HbaseOutputFormatBuilder buildHbaseOutputFormat() {
 104         return new HbaseOutputFormatBuilder();
 105     }
 106 
 107     @Override
 108     public void configure(Configuration parameters) {
 109         // 这里不要做耗时较长的操作，否则会导致AKKA通信超时
 110         // DO NOTHING
 111     }
 112 
 113     @Override
 114     public void open(int taskNumber, int numTasks) throws IOException {
 115         LOG.warn(&quot;---open---&quot;);
 116         records = new ArrayList&lt;&gt;();
 117         conf = HBaseConfiguration.create();
 118         openConn();
 119         table = conn.getTable(TableName.valueOf(tableName));
 120         LOG.warn(&quot;---open end(get table from hbase) ---&quot;);
 121         initMetric();
 122     }
 123 
 124     private void openConn() {
 125         try {
 126             if (kerberosAuthEnable) {
 127                 LOG.info(&quot;open kerberos conn&quot;);
 128                 openKerberosConn();
 129             } else {
 130                 LOG.info(&quot;open conn&quot;);
 131                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 132                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 133                 conn = ConnectionFactory.createConnection(conf);
 134             }
 135         } catch (Exception e) {
 136             throw new RuntimeException(e);
 137         }
 138         initScheduledTask(batchWaitInterval);
 139     }
 140 
 141     /**
 142      * 初始化定时写入任务
 143      *
 144      * @param batchWaitInterval 定时任务时间
 145      */
 146     private void initScheduledTask(Long batchWaitInterval) {
 147         try {
 148             if (batchWaitInterval &gt; 0) {
 149                 this.scheduler = new ScheduledThreadPoolExecutor(
 150                         1,
 151                         new DTThreadFactory(&quot;hbase-batch-flusher&quot;)
 152                 );
 153 
 154                 this.scheduledFuture = this.scheduler.scheduleWithFixedDelay(
 155                         () -&gt; {
 156                             synchronized (HbaseOutputFormat.this) {
 157                                 if (!records.isEmpty()) {
 158                                     dealBatchOperation(records);
 159                                 }
 160                             }
 161                         }, batchWaitInterval, batchWaitInterval, TimeUnit.MILLISECONDS
 162                 );
 163             }
 164         } catch (Exception e) {
 165             LOG.error(&quot;init schedule task failed !&quot;);
 166             throw new RuntimeException(e);
 167         }
 168     }
 169 
 170     private void openKerberosConn() throws Exception {
 171         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 172         conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 173 
 174         LOG.info(&quot;kerberos config:{}&quot;, this.conf.toString());
 175         Preconditions.checkArgument(!StringUtils.isEmpty(clientPrincipal), &quot; clientPrincipal not null!&quot;);
<abbr title=" 176         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;);"> 176         Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;🔵</abbr>
 177 
 178         fillSyncKerberosConfig(conf, regionserverPrincipal, zookeeperSaslClient, securityKrb5Conf);
 179 
 180         clientKeytabFile = System.getProperty(&quot;user.dir&quot;) + File.separator + clientKeytabFile;
<abbr title=" 181         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal;"> 181         clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal🔵</abbr>
 182 
 183         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KEYTAB_FILE, clientKeytabFile);
 184         conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KERBEROS_PRINCIPAL, clientPrincipal);
 185 
<abbr title=" 186         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clientKeytabFile);"> 186         UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrinci🔵</abbr>
 187         org.apache.hadoop.conf.Configuration finalConf = conf;
 188         conn = userGroupInformation.doAs((PrivilegedAction&lt;Connection&gt;) () -&gt; {
 189             try {
 190                 ScheduledChore authChore = AuthUtil.getAuthChore(finalConf);
 191                 if (authChore != null) {
 192                     choreService = new ChoreService(&quot;hbaseKerberosSink&quot;);
 193                     choreService.scheduleChore(authChore);
 194                 }
 195 
 196                 return ConnectionFactory.createConnection(finalConf);
 197             } catch (IOException e) {
 198                 LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 199                 throw new RuntimeException(e);
 200             }
 201         });
 202     }
 203 
 204     @Override
 205     public void writeRecord(Tuple2&lt;Boolean, Row&gt; record) {
 206         if (record.f0) {
 207             if (this.batchSize &gt; 1) {
 208                 writeBatchRecord(record.f1);
 209             } else {
 210                 dealInsert(record.f1);
 211             }
 212         }
 213     }
 214 
 215     public void writeBatchRecord(Row row) {
 216         records.add(row);
 217         // 数据累计到batchSize之后开始处理
 218         if (records.size() == this.batchSize) {
 219             dealBatchOperation(records);
 220         }
 221     }
 222 
 223     protected synchronized void dealBatchOperation(List&lt;Row&gt; records) {
 224         // A null in the result array means that the call for that action failed, even after retries.
 225         Object[] results = null;
 226         try {
 227             List&lt;Put&gt; puts = new ArrayList&lt;&gt;();
 228             for (Row record : records) {
 229                 Put put = getPutByRow(record);
 230                 if (put == null || put.isEmpty()) {
 231 
 232 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 233                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 234                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 235                         record.toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 236                         &quot;HBase put is empty, check record please!&quot;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 237                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 238                     outDirtyRecords.inc();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 239 </span>
 240 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 241 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 241 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 242 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 243 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 244                     dealError(</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 245                         record,</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 246                         &quot;HBase put is empty, please check the record.&quot;);</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 247 </span>
 248 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 249                 } else {
 250                     puts.add(put);
 251                 }
 252             }
 253             results = new Object[puts.size()];
 254             table.batch(puts, results);
 255 
 256             // 打印结果
 257             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 258                 // 只打印最后一条数据
 259                 LOG.info(records.get(records.size() - 1).toString());
 260             }
 261         } catch (IOException | InterruptedException e) {
 262             // ignore exception
 263         } finally {
 264             // 判断数据是否插入成功
 265             for (int i = 0; i &lt; Objects.requireNonNull(results).length; i++) {
 266                 if (results[i] instanceof Exception) {
 267 
 268 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 269                     dirtyDataManager.execute();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 270                     // 脏数据记录</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 271                     dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 272                         records.get(i).toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 273                         ExceptionTrace.traceOriginalCause((Exception) results[i])</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 274                     );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 275                     outDirtyRecords.inc();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 276 </span>
 277 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 278 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 278 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 279 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 280 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 281                     dealError(records.get(i), ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 282 </span>
 283 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 284                 } else {
 285                     // 输出结果条数记录
 286                     outRecords.inc();
 287                 }
 288             }
 289             // 添加完数据之后数据清空records
 290             records.clear();
 291         }
 292     }
 293 
 294     protected void dealInsert(Row record) {
 295         Put put = getPutByRow(record);
 296         if (put == null || put.isEmpty()) {
 297             // 记录脏数据
 298             outDirtyRecords.inc();
 299             return;
 300         }
 301 
 302         try {
 303             table.put(put);
 304 
 305 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 306             if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 307                 LOG.info(record.toString());</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 308             }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 309         } catch (Exception e) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 310             dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 311                 record.toString(),</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 312                 ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 313             outDirtyRecords.inc();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 314 </span>
 315 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 316 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 316 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 317 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 318 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 319         } catch (Exception e) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 320             dealError(record, ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 321 </span>
 322 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 323         }
 324 
 325         outRecords.inc();
 326     }
 327 
 328     private void dealError(Row record, String cause) {
 329         if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {
 330             LOG.error(&quot;Get dirty data: {}&quot;, record.toString());
 331             LOG.error(&quot;Error cause: &quot; + cause);
 332         }
 333         outDirtyRecords.inc();
 334     }
 335 
 336     private Put getPutByRow(Row record) {
 337         String rowKey = buildRowKey(record);
 338         if (StringUtils.isEmpty(rowKey)) {
 339             return null;
 340         }
 341         Put put = new Put(rowKey.getBytes());
 342         for (int i = 0; i &lt; record.getArity(); ++i) {
 343             Object fieldVal = record.getField(i);
 344             if (fieldVal != null) {
 345                 byte[] val = fieldVal.toString().getBytes();
 346                 byte[] cf = families[i].getBytes();
 347                 byte[] qualifier = qualifiers[i].getBytes();
 348 
 349                 put.addColumn(cf, qualifier, val);
 350             }
 351         }
 352         return put;
 353     }
 354 
 355     private String buildRowKey(Row record) {
 356         String rowKeyValues = getRowKeyValues(record);
 357         // all rowkey not null
 358         if (StringUtils.isBlank(rowKeyValues)) {
 359             LOG.error(&quot;row key value must not null,record is ..{}&quot;, record);
 360             outDirtyRecords.inc();
 361             return &quot;&quot;;
 362         }
 363         return rowKeyValues;
 364     }
 365 
 366     private String getRowKeyValues(Row record) {
 367         Map&lt;String, Object&gt; row = rowConvertMap(record);
 368         RowKeyBuilder rowKeyBuilder = new RowKeyBuilder();
 369         rowKeyBuilder.init(rowkey);
 370         return rowKeyBuilder.getRowKey(row);
 371     }
 372 
 373     private Map&lt;String, Object&gt; rowConvertMap(Row record) {
 374         Map&lt;String, Object&gt; rowValue = Maps.newHashMap();
 375         for (int i = 0; i &lt; columnNames.length; i++) {
 376             rowValue.put(columnNames[i], record.getField(i));
 377         }
 378         return rowValue;
 379     }
 380 
 381     @Override
 382     public synchronized void close() throws IOException {
 383         if (closed) {
 384             return;
 385         }
 386 
 387         closed = true;
 388         if (!records.isEmpty()) {
 389             dealBatchOperation(records);
 390         }
 391 
 392         if (scheduledFuture != null) {
 393             scheduledFuture.cancel(false);
 394             if (scheduler != null) {
 395                 scheduler.shutdownNow();
 396             }
 397         }
 398 
 399         if (conn != null) {
 400             conn.close();
 401             conn = null;
 402         }
 403 
 404         if (dirtyDataManager != null) {
 405             dirtyDataManager.close();
 406         }
 407     }
 408 
 409     private void fillSyncKerberosConfig(org.apache.hadoop.conf.Configuration config,
 410                                         String regionserverPrincipal,
 411                                         String zookeeperSaslClient,
 412                                         String securityKrb5Conf) {
 413         if (StringUtils.isEmpty(regionserverPrincipal)) {
<abbr title=" 414             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos&quot;);"> 414             throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is🔵</abbr>
 415         }
 416         config.set(HbaseConfigUtils.KEY_HBASE_MASTER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 417         config.set(HbaseConfigUtils.KEY_HBASE_REGIONSERVER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 418         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHORIZATION, &quot;true&quot;);
 419         config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHENTICATION, &quot;kerberos&quot;);
 420 
 421 
 422         if (!StringUtils.isEmpty(zookeeperSaslClient)) {
 423             System.setProperty(HbaseConfigUtils.KEY_ZOOKEEPER_SASL_CLIENT, zookeeperSaslClient);
 424         }
 425 
 426         if (!StringUtils.isEmpty(securityKrb5Conf)) {
 427             String krb5ConfPath = System.getProperty(&quot;user.dir&quot;) + File.separator + securityKrb5Conf;
 428             LOG.info(&quot;krb5ConfPath:{}&quot;, krb5ConfPath);
 429             System.setProperty(HbaseConfigUtils.KEY_JAVA_SECURITY_KRB5_CONF, krb5ConfPath);
 430         }
 431     }
 432 
 433     @Override
 434     public String toString() {
 435         return &quot;HbaseOutputFormat kerberos{&quot; +
 436                 &quot;kerberosAuthEnable=&quot; + kerberosAuthEnable +
 437                 &quot;, regionserverKeytabFile=&#x27;&quot; + regionserverKeytabFile + &#x27;\&#x27;&#x27; +
 438                 &quot;, regionserverPrincipal=&#x27;&quot; + regionserverPrincipal + &#x27;\&#x27;&#x27; +
 439                 &quot;, securityKrb5Conf=&#x27;&quot; + securityKrb5Conf + &#x27;\&#x27;&#x27; +
 440                 &quot;, zookeeperSaslClient=&#x27;&quot; + zookeeperSaslClient + &#x27;\&#x27;&#x27; +
 441                 &quot;, clientPrincipal=&#x27;&quot; + clientPrincipal + &#x27;\&#x27;&#x27; +
 442                 &quot;, clientKeytabFile=&#x27;&quot; + clientKeytabFile + &#x27;\&#x27;&#x27; +
 443                 &quot;, batchSize=&#x27;&quot; + batchSize + &#x27;\&#x27;&#x27; +
 444                 &quot;, batchWaitInterval=&#x27;&quot; + batchWaitInterval + &#x27;\&#x27;&#x27; +
 445                 &#x27;}&#x27;;
 446     }
 447 
 448     public static class HbaseOutputFormatBuilder {
 449 
 450         private final HbaseOutputFormat format;
 451 
 452         private HbaseOutputFormatBuilder() {
 453             format = new HbaseOutputFormat();
 454         }
 455 
 456         public HbaseOutputFormatBuilder setHost(String host) {
 457             format.host = host;
 458             return this;
 459         }
 460 
 461         public HbaseOutputFormatBuilder setZkParent(String parent) {
 462             format.zkParent = parent;
 463             return this;
 464         }
 465 
 466 
 467         public HbaseOutputFormatBuilder setTable(String tableName) {
 468             format.tableName = tableName;
 469             return this;
 470         }
 471 
 472         public HbaseOutputFormatBuilder setRowkey(String rowkey) {
 473             format.rowkey = rowkey;
 474             return this;
 475         }
 476 
 477         public HbaseOutputFormatBuilder setColumnNames(String[] columnNames) {
 478             format.columnNames = columnNames;
 479             return this;
 480         }
 481 
 482         public HbaseOutputFormatBuilder setColumnNameFamily(Map&lt;String, String&gt; columnNameFamily) {
 483             format.columnNameFamily = columnNameFamily;
 484             return this;
 485         }
 486 
 487         public HbaseOutputFormatBuilder setKerberosAuthEnable(boolean kerberosAuthEnable) {
 488             format.kerberosAuthEnable = kerberosAuthEnable;
 489             return this;
 490         }
 491 
 492         public HbaseOutputFormatBuilder setRegionserverKeytabFile(String regionserverKeytabFile) {
 493             format.regionserverKeytabFile = regionserverKeytabFile;
 494             return this;
 495         }
 496 
 497         public HbaseOutputFormatBuilder setRegionserverPrincipal(String regionserverPrincipal) {
 498             format.regionserverPrincipal = regionserverPrincipal;
 499             return this;
 500         }
 501 
 502         public HbaseOutputFormatBuilder setSecurityKrb5Conf(String securityKrb5Conf) {
 503             format.securityKrb5Conf = securityKrb5Conf;
 504             return this;
 505         }
 506 
 507         public HbaseOutputFormatBuilder setZookeeperSaslClient(String zookeeperSaslClient) {
 508             format.zookeeperSaslClient = zookeeperSaslClient;
 509             return this;
 510         }
 511 
 512         public HbaseOutputFormatBuilder setClientPrincipal(String clientPrincipal) {
 513             format.clientPrincipal = clientPrincipal;
 514             return this;
 515         }
 516 
 517         public HbaseOutputFormatBuilder setClientKeytabFile(String clientKeytabFile) {
 518             format.clientKeytabFile = clientKeytabFile;
 519             return this;
 520         }
 521 
 522         public HbaseOutputFormatBuilder setDirtyManager(DirtyDataManager dirtyDataManager) {
 523             format.dirtyDataManager = dirtyDataManager;
 524             return this;
 525         }
 526 
 527         public HbaseOutputFormatBuilder setBatchSize(Integer batchSize) {
 528             format.batchSize = batchSize;
 529             return this;
 530         }
 531 
 532         public HbaseOutputFormatBuilder setBatchWaitInterval(Long batchWaitInterval) {
 533             format.batchWaitInterval = batchWaitInterval;
 534             return this;
 535         }
 536 
 537         public HbaseOutputFormat finish() {
 538             Preconditions.checkNotNull(format.host, &quot;zookeeperQuorum should be specified&quot;);
 539             Preconditions.checkNotNull(format.tableName, &quot;tableName should be specified&quot;);
 540             Preconditions.checkNotNull(format.columnNames, &quot;columnNames should be specified&quot;);
<abbr title=" 541             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be zero&quot;);"> 541             Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be🔵</abbr>
 542 
 543             String[] families = new String[format.columnNames.length];
 544             String[] qualifiers = new String[format.columnNames.length];
 545 
 546             if (format.columnNameFamily != null) {
 547                 List&lt;String&gt; keyList = new LinkedList&lt;&gt;(format.columnNameFamily.keySet());
 548                 String[] columns = keyList.toArray(new String[0]);
 549                 for (int i = 0; i &lt; columns.length; ++i) {
 550                     String col = columns[i];
 551                     String[] part = col.split(&quot;:&quot;);
 552                     families[i] = part[0];
 553                     qualifiers[i] = part[1];
 554                 }
 555             }
 556             format.families = families;
 557             format.qualifiers = qualifiers;
 558 
 559             return format;
 560         }
 561     }
 562 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.sink.hbase;
  21  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  22 +import com.dtstack.flink.sql.dirtyManager.manager.DirtyDataManager;</span>
  23  import com.dtstack.flink.sql.exception.ExceptionTrace;
  24  import com.dtstack.flink.sql.factory.DTThreadFactory;
  25  import com.dtstack.flink.sql.outputformat.AbstractDtRichOutputFormat;
  26  import com.google.common.collect.Maps;
  27  import org.apache.commons.lang3.StringUtils;
  28  import org.apache.flink.api.java.tuple.Tuple2;
  29  import org.apache.flink.configuration.Configuration;
  30  import org.apache.flink.types.Row;
  31  import org.apache.flink.util.Preconditions;
  32  import org.apache.hadoop.hbase.AuthUtil;
  33  import org.apache.hadoop.hbase.ChoreService;
  34  import org.apache.hadoop.hbase.HBaseConfiguration;
  35  import org.apache.hadoop.hbase.ScheduledChore;
  36  import org.apache.hadoop.hbase.TableName;
  37  import org.apache.hadoop.hbase.client.Connection;
  38  import org.apache.hadoop.hbase.client.ConnectionFactory;
  39  import org.apache.hadoop.hbase.client.Put;
  40  import org.apache.hadoop.hbase.client.Table;
  41  import org.apache.hadoop.security.UserGroupInformation;
  42  import org.slf4j.Logger;
  43  import org.slf4j.LoggerFactory;
  44  
  45  import java.io.File;
  46  import java.io.IOException;
  47  import java.security.PrivilegedAction;
  48  import java.util.ArrayList;
  49  import java.util.LinkedList;
  50  import java.util.List;
  51  import java.util.Map;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  52 +import java.util.Objects;</span>
  53  import java.util.concurrent.ScheduledExecutorService;
  54  import java.util.concurrent.ScheduledFuture;
  55  import java.util.concurrent.ScheduledThreadPoolExecutor;
  56  import java.util.concurrent.TimeUnit;
  57  
  58  /**
  59   * @author: jingzhen@dtstack.com
  60   * date: 2017-6-29
  61   */
  62  public class HbaseOutputFormat extends AbstractDtRichOutputFormat&lt;Tuple2&lt;Boolean, Row&gt;&gt; {
  63  
  64      private static final Logger LOG = LoggerFactory.getLogger(HbaseOutputFormat.class);
  65      private String host;
  66      private String zkParent;
  67      private String rowkey;
  68      private String tableName;
  69      private String[] columnNames;
  70      private Map&lt;String, String&gt; columnNameFamily;
  71      private boolean kerberosAuthEnable;
  72      private String regionserverKeytabFile;
  73      private String regionserverPrincipal;
  74      private String securityKrb5Conf;
  75      private String zookeeperSaslClient;
  76      private String clientPrincipal;
  77      private String clientKeytabFile;
  78      private String[] families;
  79      private String[] qualifiers;
  80      private transient org.apache.hadoop.conf.Configuration conf;
  81      private transient Connection conn;
  82      private transient Table table;
  83      private transient ChoreService choreService;
  84      private transient List&lt;Row&gt; records;
  85      private transient volatile boolean closed = false;
  86      /**
  87       * 批量写入的参数
  88       */
  89      private Integer batchSize;
  90      private Long batchWaitInterval;
  91      /**
  92       * 定时任务
  93       */
  94      private transient ScheduledExecutorService scheduler;
  95      private transient ScheduledFuture&lt;?&gt; scheduledFuture;
  96  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  97 +    /**</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  98 +     * 脏数据管理</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  99 +     */</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 100 +    private DirtyDataManager dirtyDataManager;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 101 +</span>
 102      private HbaseOutputFormat() {
 103      }
 104  
 105      public static HbaseOutputFormatBuilder buildHbaseOutputFormat() {
 106          return new HbaseOutputFormatBuilder();
 107      }
 108  
 109      @Override
 110      public void configure(Configuration parameters) {
 111          // 这里不要做耗时较长的操作，否则会导致AKKA通信超时
 112          // DO NOTHING
 113      }
 114  
 115      @Override
 116      public void open(int taskNumber, int numTasks) throws IOException {
 117          LOG.warn(&quot;---open---&quot;);
 118          records = new ArrayList&lt;&gt;();
 119          conf = HBaseConfiguration.create();
 120          openConn();
 121          table = conn.getTable(TableName.valueOf(tableName));
 122          LOG.warn(&quot;---open end(get table from hbase) ---&quot;);
 123          initMetric();
 124      }
 125  
 126      private void openConn() {
 127          try {
 128              if (kerberosAuthEnable) {
 129                  LOG.info(&quot;open kerberos conn&quot;);
 130                  openKerberosConn();
 131              } else {
 132                  LOG.info(&quot;open conn&quot;);
 133                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 134                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 135                  conn = ConnectionFactory.createConnection(conf);
 136              }
 137          } catch (Exception e) {
 138              throw new RuntimeException(e);
 139          }
 140          initScheduledTask(batchWaitInterval);
 141      }
 142  
 143      /**
 144       * 初始化定时写入任务
 145       *
 146       * @param batchWaitInterval 定时任务时间
 147       */
 148      private void initScheduledTask(Long batchWaitInterval) {
 149          try {
 150              if (batchWaitInterval &gt; 0) {
 151                  this.scheduler = new ScheduledThreadPoolExecutor(
 152                          1,
 153                          new DTThreadFactory(&quot;hbase-batch-flusher&quot;)
 154                  );
 155  
 156                  this.scheduledFuture = this.scheduler.scheduleWithFixedDelay(
 157                          () -&gt; {
 158                              synchronized (HbaseOutputFormat.this) {
 159                                  if (!records.isEmpty()) {
 160                                      dealBatchOperation(records);
 161                                  }
 162                              }
 163                          }, batchWaitInterval, batchWaitInterval, TimeUnit.MILLISECONDS
 164                  );
 165              }
 166          } catch (Exception e) {
 167              LOG.error(&quot;init schedule task failed !&quot;);
 168              throw new RuntimeException(e);
 169          }
 170      }
 171  
 172      private void openKerberosConn() throws Exception {
 173          conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 174          conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 175  
 176          LOG.info(&quot;kerberos config:{}&quot;, this.conf.toString());
 177          Preconditions.checkArgument(!StringUtils.isEmpty(clientPrincipal), &quot; clientPrincipal not null!&quot;);
 178          Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;);
 179  
 180          fillSyncKerberosConfig(conf, regionserverPrincipal, zookeeperSaslClient, securityKrb5Conf);
 181  
 182          clientKeytabFile = System.getProperty(&quot;user.dir&quot;) + File.separator + clientKeytabFile;
 183          clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal;
 184  
 185          conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KEYTAB_FILE, clientKeytabFile);
 186          conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KERBEROS_PRINCIPAL, clientPrincipal);
 187  
<abbr title=" 188          UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clientKeytabFile);"> 188          UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clie🔵</abbr>
 189          org.apache.hadoop.conf.Configuration finalConf = conf;
 190          conn = userGroupInformation.doAs((PrivilegedAction&lt;Connection&gt;) () -&gt; {
 191              try {
 192                  ScheduledChore authChore = AuthUtil.getAuthChore(finalConf);
 193                  if (authChore != null) {
 194                      choreService = new ChoreService(&quot;hbaseKerberosSink&quot;);
 195                      choreService.scheduleChore(authChore);
 196                  }
 197  
 198                  return ConnectionFactory.createConnection(finalConf);
 199              } catch (IOException e) {
 200                  LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 201                  throw new RuntimeException(e);
 202              }
 203          });
 204      }
 205  
 206      @Override
 207      public void writeRecord(Tuple2&lt;Boolean, Row&gt; record) {
 208          if (record.f0) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 209 -            if (this.batchSize != 0) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 210 +            if (this.batchSize &gt; 1) {</span>
 211                  writeBatchRecord(record.f1);
 212              } else {
 213                  dealInsert(record.f1);
 214              }
 215          }
 216      }
 217  
 218      public void writeBatchRecord(Row row) {
 219          records.add(row);
 220          // 数据累计到batchSize之后开始处理
 221          if (records.size() == this.batchSize) {
 222              dealBatchOperation(records);
 223          }
 224      }
 225  
 226      protected synchronized void dealBatchOperation(List&lt;Row&gt; records) {
 227          // A null in the result array means that the call for that action failed, even after retries.
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 228 -        Object[] results = new Object[records.size()];</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 229 +        Object[] results = null;</span>
 230          try {
 231              List&lt;Put&gt; puts = new ArrayList&lt;&gt;();
 232              for (Row record : records) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 233 -                puts.add(getPutByRow(record));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 234 -            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 235 +                Put put = getPutByRow(record);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 236 +                if (put == null || put.isEmpty()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 237 +                    dirtyDataManager.execute();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 238 +                    dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 239 +                        record.toString(),</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 240 +                        &quot;HBase put is empty, check record please!&quot;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 241 +                    );</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 242 +                    outDirtyRecords.inc();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 243 +                } else {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 244 +                    puts.add(put);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 245 +                }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 246 +            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 247 +            results = new Object[puts.size()];</span>
 248              table.batch(puts, results);
 249  
 250              // 打印结果
 251              if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 252                  // 只打印最后一条数据
 253                  LOG.info(records.get(records.size() - 1).toString());
 254              }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 255 -        } catch (IOException | InterruptedException ignored) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 256 +        } catch (IOException | InterruptedException e) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 257 +            // ignore exception</span>
 258          } finally {
 259              // 判断数据是否插入成功
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 260 -            for (int i = 0; i &lt; results.length; i++) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 261 +            for (int i = 0; i &lt; Objects.requireNonNull(results).length; i++) {</span>
 262                  if (results[i] instanceof Exception) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 263 -                    if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 264 -                        LOG.error(&quot;Get dirty data: {}&quot;, records.get(i).toString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 265 -                        LOG.error(&quot;Error cause: &quot; + ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 266 -                    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 267 +                    dirtyDataManager.execute();</span>
 268                      // 脏数据记录
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 269 +                    dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 270 +                        records.get(i).toString(),</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 271 +                        ExceptionTrace.traceOriginalCause((Exception) results[i])</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 272 +                    );</span>
 273                      outDirtyRecords.inc();

 274                  } else {
 275                      // 输出结果条数记录
 276                      outRecords.inc();
 277                  }
 278              }
 279              // 添加完数据之后数据清空records
 280              records.clear();
 281          }
 282      }
 283  
 284      protected void dealInsert(Row record) {
 285          Put put = getPutByRow(record);
 286          if (put == null || put.isEmpty()) {
 287              // 记录脏数据
 288              outDirtyRecords.inc();
 289              return;
 290          }
 291  
 292          try {
 293              table.put(put);
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 294 +            if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 295 +                LOG.info(record.toString());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 296 +            }</span>
 297          } catch (Exception e) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 298 -            if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 299 -                LOG.error(&quot;Get dirty data: {}&quot;, record.toString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 300 -                LOG.error(&quot;Error cause: &quot; + ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 301 -            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 302 +            dirtyDataManager.collectDirtyData(</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 303 +                record.toString(),</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 304 +                ExceptionTrace.traceOriginalCause(e));</span>
 305              outDirtyRecords.inc();

 306          }
 307  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 308 -        if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 309 -            LOG.info(record.toString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 310 -        }</span>
 311          outRecords.inc();








 312      }
 313  
 314      private Put getPutByRow(Row record) {
 315          String rowKey = buildRowKey(record);
 316          if (StringUtils.isEmpty(rowKey)) {
 317              return null;
 318          }
 319          Put put = new Put(rowKey.getBytes());
 320          for (int i = 0; i &lt; record.getArity(); ++i) {
 321              Object fieldVal = record.getField(i);
 322              if (fieldVal != null) {
 323                  byte[] val = fieldVal.toString().getBytes();
 324                  byte[] cf = families[i].getBytes();
 325                  byte[] qualifier = qualifiers[i].getBytes();
 326  
 327                  put.addColumn(cf, qualifier, val);
 328              }
 329          }
 330          return put;
 331      }
 332  
 333      private String buildRowKey(Row record) {
 334          String rowKeyValues = getRowKeyValues(record);
 335          // all rowkey not null
 336          if (StringUtils.isBlank(rowKeyValues)) {
 337              LOG.error(&quot;row key value must not null,record is ..{}&quot;, record);
 338              outDirtyRecords.inc();
 339              return &quot;&quot;;
 340          }
 341          return rowKeyValues;
 342      }
 343  
 344      private String getRowKeyValues(Row record) {
 345          Map&lt;String, Object&gt; row = rowConvertMap(record);
 346          RowKeyBuilder rowKeyBuilder = new RowKeyBuilder();
 347          rowKeyBuilder.init(rowkey);
 348          return rowKeyBuilder.getRowKey(row);
 349      }
 350  
 351      private Map&lt;String, Object&gt; rowConvertMap(Row record) {
 352          Map&lt;String, Object&gt; rowValue = Maps.newHashMap();
 353          for (int i = 0; i &lt; columnNames.length; i++) {
 354              rowValue.put(columnNames[i], record.getField(i));
 355          }
 356          return rowValue;
 357      }
 358  
 359      @Override
 360      public synchronized void close() throws IOException {
 361          if (closed) {
 362              return;
 363          }
 364  
 365          closed = true;
 366          if (!records.isEmpty()) {
 367              dealBatchOperation(records);
 368          }
 369  
 370          if (scheduledFuture != null) {
 371              scheduledFuture.cancel(false);
 372              if (scheduler != null) {
 373                  scheduler.shutdownNow();
 374              }
 375          }
 376  
 377          if (conn != null) {
 378              conn.close();
 379              conn = null;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 380 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 381 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 382 +        if (dirtyDataManager != null) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 383 +            dirtyDataManager.close();</span>
 384          }
 385      }
 386  
 387      private void fillSyncKerberosConfig(org.apache.hadoop.conf.Configuration config,
 388                                          String regionserverPrincipal,
 389                                          String zookeeperSaslClient,
 390                                          String securityKrb5Conf) {
 391          if (StringUtils.isEmpty(regionserverPrincipal)) {
<abbr title=" 392              throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos&quot;);"> 392              throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos🔵</abbr>
 393          }
 394          config.set(HbaseConfigUtils.KEY_HBASE_MASTER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 395          config.set(HbaseConfigUtils.KEY_HBASE_REGIONSERVER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 396          config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHORIZATION, &quot;true&quot;);
 397          config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHENTICATION, &quot;kerberos&quot;);
 398  
 399  
 400          if (!StringUtils.isEmpty(zookeeperSaslClient)) {
 401              System.setProperty(HbaseConfigUtils.KEY_ZOOKEEPER_SASL_CLIENT, zookeeperSaslClient);
 402          }
 403  
 404          if (!StringUtils.isEmpty(securityKrb5Conf)) {
 405              String krb5ConfPath = System.getProperty(&quot;user.dir&quot;) + File.separator + securityKrb5Conf;
 406              LOG.info(&quot;krb5ConfPath:{}&quot;, krb5ConfPath);
 407              System.setProperty(HbaseConfigUtils.KEY_JAVA_SECURITY_KRB5_CONF, krb5ConfPath);
 408          }
 409      }
 410  
 411      @Override
 412      public String toString() {
 413          return &quot;HbaseOutputFormat kerberos{&quot; +
 414                  &quot;kerberosAuthEnable=&quot; + kerberosAuthEnable +
 415                  &quot;, regionserverKeytabFile=&#x27;&quot; + regionserverKeytabFile + &#x27;\&#x27;&#x27; +
 416                  &quot;, regionserverPrincipal=&#x27;&quot; + regionserverPrincipal + &#x27;\&#x27;&#x27; +
 417                  &quot;, securityKrb5Conf=&#x27;&quot; + securityKrb5Conf + &#x27;\&#x27;&#x27; +
 418                  &quot;, zookeeperSaslClient=&#x27;&quot; + zookeeperSaslClient + &#x27;\&#x27;&#x27; +
 419                  &quot;, clientPrincipal=&#x27;&quot; + clientPrincipal + &#x27;\&#x27;&#x27; +
 420                  &quot;, clientKeytabFile=&#x27;&quot; + clientKeytabFile + &#x27;\&#x27;&#x27; +
 421                  &quot;, batchSize=&#x27;&quot; + batchSize + &#x27;\&#x27;&#x27; +
 422                  &quot;, batchWaitInterval=&#x27;&quot; + batchWaitInterval + &#x27;\&#x27;&#x27; +
 423                  &#x27;}&#x27;;
 424      }
 425  
 426      public static class HbaseOutputFormatBuilder {
 427  
 428          private final HbaseOutputFormat format;
 429  
 430          private HbaseOutputFormatBuilder() {
 431              format = new HbaseOutputFormat();
 432          }
 433  
 434          public HbaseOutputFormatBuilder setHost(String host) {
 435              format.host = host;
 436              return this;
 437          }
 438  
 439          public HbaseOutputFormatBuilder setZkParent(String parent) {
 440              format.zkParent = parent;
 441              return this;
 442          }
 443  
 444  
 445          public HbaseOutputFormatBuilder setTable(String tableName) {
 446              format.tableName = tableName;
 447              return this;
 448          }
 449  
 450          public HbaseOutputFormatBuilder setRowkey(String rowkey) {
 451              format.rowkey = rowkey;
 452              return this;
 453          }
 454  
 455          public HbaseOutputFormatBuilder setColumnNames(String[] columnNames) {
 456              format.columnNames = columnNames;
 457              return this;
 458          }
 459  
 460          public HbaseOutputFormatBuilder setColumnNameFamily(Map&lt;String, String&gt; columnNameFamily) {
 461              format.columnNameFamily = columnNameFamily;
 462              return this;
 463          }
 464  
 465          public HbaseOutputFormatBuilder setKerberosAuthEnable(boolean kerberosAuthEnable) {
 466              format.kerberosAuthEnable = kerberosAuthEnable;
 467              return this;
 468          }
 469  
 470          public HbaseOutputFormatBuilder setRegionserverKeytabFile(String regionserverKeytabFile) {
 471              format.regionserverKeytabFile = regionserverKeytabFile;
 472              return this;
 473          }
 474  
 475          public HbaseOutputFormatBuilder setRegionserverPrincipal(String regionserverPrincipal) {
 476              format.regionserverPrincipal = regionserverPrincipal;
 477              return this;
 478          }
 479  
 480          public HbaseOutputFormatBuilder setSecurityKrb5Conf(String securityKrb5Conf) {
 481              format.securityKrb5Conf = securityKrb5Conf;
 482              return this;
 483          }
 484  
 485          public HbaseOutputFormatBuilder setZookeeperSaslClient(String zookeeperSaslClient) {
 486              format.zookeeperSaslClient = zookeeperSaslClient;
 487              return this;
 488          }
 489  
 490          public HbaseOutputFormatBuilder setClientPrincipal(String clientPrincipal) {
 491              format.clientPrincipal = clientPrincipal;
 492              return this;
 493          }
 494  
 495          public HbaseOutputFormatBuilder setClientKeytabFile(String clientKeytabFile) {
 496              format.clientKeytabFile = clientKeytabFile;
 497              return this;
 498          }
 499  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 500 +        public HbaseOutputFormatBuilder setDirtyManager(DirtyDataManager dirtyDataManager) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 501 +            format.dirtyDataManager = dirtyDataManager;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 502 +            return this;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 503 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 504 +</span>
 505          public HbaseOutputFormatBuilder setBatchSize(Integer batchSize) {
 506              format.batchSize = batchSize;
 507              return this;
 508          }
 509  
 510          public HbaseOutputFormatBuilder setBatchWaitInterval(Long batchWaitInterval) {
 511              format.batchWaitInterval = batchWaitInterval;
 512              return this;
 513          }
 514  
 515          public HbaseOutputFormat finish() {
 516              Preconditions.checkNotNull(format.host, &quot;zookeeperQuorum should be specified&quot;);
 517              Preconditions.checkNotNull(format.tableName, &quot;tableName should be specified&quot;);
 518              Preconditions.checkNotNull(format.columnNames, &quot;columnNames should be specified&quot;);
 519              Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be zero&quot;);
 520  
 521              String[] families = new String[format.columnNames.length];
 522              String[] qualifiers = new String[format.columnNames.length];
 523  
 524              if (format.columnNameFamily != null) {
 525                  List&lt;String&gt; keyList = new LinkedList&lt;&gt;(format.columnNameFamily.keySet());
 526                  String[] columns = keyList.toArray(new String[0]);
 527                  for (int i = 0; i &lt; columns.length; ++i) {
 528                      String col = columns[i];
 529                      String[] part = col.split(&quot;:&quot;);
 530                      families[i] = part[0];
 531                      qualifiers[i] = part[1];
 532                  }
 533              }
 534              format.families = families;
 535              format.qualifiers = qualifiers;
 536  
 537              return format;
 538          }
 539      }
 540  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.sink.hbase;
  21  

  22  import com.dtstack.flink.sql.exception.ExceptionTrace;
  23  import com.dtstack.flink.sql.factory.DTThreadFactory;
  24  import com.dtstack.flink.sql.outputformat.AbstractDtRichOutputFormat;
  25  import com.google.common.collect.Maps;
  26  import org.apache.commons.lang3.StringUtils;
  27  import org.apache.flink.api.java.tuple.Tuple2;
  28  import org.apache.flink.configuration.Configuration;
  29  import org.apache.flink.types.Row;
  30  import org.apache.flink.util.Preconditions;
  31  import org.apache.hadoop.hbase.AuthUtil;
  32  import org.apache.hadoop.hbase.ChoreService;
  33  import org.apache.hadoop.hbase.HBaseConfiguration;
  34  import org.apache.hadoop.hbase.ScheduledChore;
  35  import org.apache.hadoop.hbase.TableName;
  36  import org.apache.hadoop.hbase.client.Connection;
  37  import org.apache.hadoop.hbase.client.ConnectionFactory;
  38  import org.apache.hadoop.hbase.client.Put;
  39  import org.apache.hadoop.hbase.client.Table;
  40  import org.apache.hadoop.security.UserGroupInformation;
  41  import org.slf4j.Logger;
  42  import org.slf4j.LoggerFactory;
  43  
  44  import java.io.File;
  45  import java.io.IOException;
  46  import java.security.PrivilegedAction;
  47  import java.util.ArrayList;
  48  import java.util.LinkedList;
  49  import java.util.List;
  50  import java.util.Map;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import java.util.Objects;</span>
  52  import java.util.concurrent.ScheduledExecutorService;
  53  import java.util.concurrent.ScheduledFuture;
  54  import java.util.concurrent.ScheduledThreadPoolExecutor;
  55  import java.util.concurrent.TimeUnit;
  56  
  57  /**
  58   * @author: jingzhen@dtstack.com
  59   * date: 2017-6-29
  60   */
  61  public class HbaseOutputFormat extends AbstractDtRichOutputFormat&lt;Tuple2&lt;Boolean, Row&gt;&gt; {
  62  
  63      private static final Logger LOG = LoggerFactory.getLogger(HbaseOutputFormat.class);
  64      private String host;
  65      private String zkParent;
  66      private String rowkey;
  67      private String tableName;
  68      private String[] columnNames;
  69      private Map&lt;String, String&gt; columnNameFamily;
  70      private boolean kerberosAuthEnable;
  71      private String regionserverKeytabFile;
  72      private String regionserverPrincipal;
  73      private String securityKrb5Conf;
  74      private String zookeeperSaslClient;
  75      private String clientPrincipal;
  76      private String clientKeytabFile;
  77      private String[] families;
  78      private String[] qualifiers;
  79      private transient org.apache.hadoop.conf.Configuration conf;
  80      private transient Connection conn;
  81      private transient Table table;
  82      private transient ChoreService choreService;
  83      private transient List&lt;Row&gt; records;
  84      private transient volatile boolean closed = false;
  85      /**
  86       * 批量写入的参数
  87       */
  88      private Integer batchSize;
  89      private Long batchWaitInterval;
  90      /**
  91       * 定时任务
  92       */
  93      private transient ScheduledExecutorService scheduler;
  94      private transient ScheduledFuture&lt;?&gt; scheduledFuture;
  95  





  96      private HbaseOutputFormat() {
  97      }
  98  
  99      public static HbaseOutputFormatBuilder buildHbaseOutputFormat() {
 100          return new HbaseOutputFormatBuilder();
 101      }
 102  
 103      @Override
 104      public void configure(Configuration parameters) {
 105          // 这里不要做耗时较长的操作，否则会导致AKKA通信超时
 106          // DO NOTHING
 107      }
 108  
 109      @Override
 110      public void open(int taskNumber, int numTasks) throws IOException {
 111          LOG.warn(&quot;---open---&quot;);
 112          records = new ArrayList&lt;&gt;();
 113          conf = HBaseConfiguration.create();
 114          openConn();
 115          table = conn.getTable(TableName.valueOf(tableName));
 116          LOG.warn(&quot;---open end(get table from hbase) ---&quot;);
 117          initMetric();
 118      }
 119  
 120      private void openConn() {
 121          try {
 122              if (kerberosAuthEnable) {
 123                  LOG.info(&quot;open kerberos conn&quot;);
 124                  openKerberosConn();
 125              } else {
 126                  LOG.info(&quot;open conn&quot;);
 127                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 128                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 129                  conn = ConnectionFactory.createConnection(conf);
 130              }
 131          } catch (Exception e) {
 132              throw new RuntimeException(e);
 133          }
 134          initScheduledTask(batchWaitInterval);
 135      }
 136  
 137      /**
 138       * 初始化定时写入任务
 139       *
 140       * @param batchWaitInterval 定时任务时间
 141       */
 142      private void initScheduledTask(Long batchWaitInterval) {
 143          try {
 144              if (batchWaitInterval &gt; 0) {
 145                  this.scheduler = new ScheduledThreadPoolExecutor(
 146                          1,
 147                          new DTThreadFactory(&quot;hbase-batch-flusher&quot;)
 148                  );
 149  
 150                  this.scheduledFuture = this.scheduler.scheduleWithFixedDelay(
 151                          () -&gt; {
 152                              synchronized (HbaseOutputFormat.this) {
 153                                  if (!records.isEmpty()) {
 154                                      dealBatchOperation(records);
 155                                  }
 156                              }
 157                          }, batchWaitInterval, batchWaitInterval, TimeUnit.MILLISECONDS
 158                  );
 159              }
 160          } catch (Exception e) {
 161              LOG.error(&quot;init schedule task failed !&quot;);
 162              throw new RuntimeException(e);
 163          }
 164      }
 165  
 166      private void openKerberosConn() throws Exception {
 167          conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, host);
 168          conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, zkParent);
 169  
 170          LOG.info(&quot;kerberos config:{}&quot;, this.conf.toString());
 171          Preconditions.checkArgument(!StringUtils.isEmpty(clientPrincipal), &quot; clientPrincipal not null!&quot;);
 172          Preconditions.checkArgument(!StringUtils.isEmpty(clientKeytabFile), &quot; clientKeytabFile not null!&quot;);
 173  
 174          fillSyncKerberosConfig(conf, regionserverPrincipal, zookeeperSaslClient, securityKrb5Conf);
 175  
 176          clientKeytabFile = System.getProperty(&quot;user.dir&quot;) + File.separator + clientKeytabFile;
 177          clientPrincipal = !StringUtils.isEmpty(clientPrincipal) ? clientPrincipal : regionserverPrincipal;
 178  
 179          conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KEYTAB_FILE, clientKeytabFile);
 180          conf.set(HbaseConfigUtils.KEY_HBASE_CLIENT_KERBEROS_PRINCIPAL, clientPrincipal);
 181  
<abbr title=" 182          UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clientKeytabFile);"> 182          UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, clientPrincipal, clie🔵</abbr>
 183          org.apache.hadoop.conf.Configuration finalConf = conf;
 184          conn = userGroupInformation.doAs((PrivilegedAction&lt;Connection&gt;) () -&gt; {
 185              try {
 186                  ScheduledChore authChore = AuthUtil.getAuthChore(finalConf);
 187                  if (authChore != null) {
 188                      choreService = new ChoreService(&quot;hbaseKerberosSink&quot;);
 189                      choreService.scheduleChore(authChore);
 190                  }
 191  
 192                  return ConnectionFactory.createConnection(finalConf);
 193              } catch (IOException e) {
 194                  LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 195                  throw new RuntimeException(e);
 196              }
 197          });
 198      }
 199  
 200      @Override
 201      public void writeRecord(Tuple2&lt;Boolean, Row&gt; record) {
 202          if (record.f0) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 203 -            if (this.batchSize != 0) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 204 +            if (this.batchSize &gt; 1) {</span>
 205                  writeBatchRecord(record.f1);
 206              } else {
 207                  dealInsert(record.f1);
 208              }
 209          }
 210      }
 211  
 212      public void writeBatchRecord(Row row) {
 213          records.add(row);
 214          // 数据累计到batchSize之后开始处理
 215          if (records.size() == this.batchSize) {
 216              dealBatchOperation(records);
 217          }
 218      }
 219  
 220      protected synchronized void dealBatchOperation(List&lt;Row&gt; records) {
 221          // A null in the result array means that the call for that action failed, even after retries.
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 222 -        Object[] results = new Object[records.size()];</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 223 +        Object[] results = null;</span>
 224          try {
 225              List&lt;Put&gt; puts = new ArrayList&lt;&gt;();
 226              for (Row record : records) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 227 -                puts.add(getPutByRow(record));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 228 -            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 229 +                Put put = getPutByRow(record);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 230 +                if (put == null || put.isEmpty()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 231 +                    dealError(</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 232 +                        record,</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 233 +                        &quot;HBase put is empty, please check the record.&quot;);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 234 +                } else {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 235 +                    puts.add(put);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 236 +                }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 237 +            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 238 +            results = new Object[puts.size()];</span>



 239              table.batch(puts, results);
 240  
 241              // 打印结果
 242              if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 243                  // 只打印最后一条数据
 244                  LOG.info(records.get(records.size() - 1).toString());
 245              }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 246 -        } catch (IOException | InterruptedException ignored) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 247 +        } catch (IOException | InterruptedException e) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 248 +            // ignore exception</span>
 249          } finally {
 250              // 判断数据是否插入成功
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 251 -            for (int i = 0; i &lt; results.length; i++) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 252 +            for (int i = 0; i &lt; Objects.requireNonNull(results).length; i++) {</span>
 253                  if (results[i] instanceof Exception) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 254 -                    if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 255 -                        LOG.error(&quot;Get dirty data: {}&quot;, records.get(i).toString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 256 -                        LOG.error(&quot;Error cause: &quot; + ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 257 -                    }</span>

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 258 -                    // 脏数据记录</span>




<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 259 -                    outDirtyRecords.inc();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 260 +                    dealError(records.get(i), ExceptionTrace.traceOriginalCause((Exception) results[i]));</span>
 261                  } else {
 262                      // 输出结果条数记录
 263                      outRecords.inc();
 264                  }
 265              }
 266              // 添加完数据之后数据清空records
 267              records.clear();
 268          }
 269      }
 270  
 271      protected void dealInsert(Row record) {
 272          Put put = getPutByRow(record);
 273          if (put == null || put.isEmpty()) {
 274              // 记录脏数据
 275              outDirtyRecords.inc();
 276              return;
 277          }
 278  
 279          try {
 280              table.put(put);



 281          } catch (Exception e) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 282 -            if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 283 -                LOG.error(&quot;Get dirty data: {}&quot;, record.toString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 284 -                LOG.error(&quot;Error cause: &quot; + ExceptionTrace.traceOriginalCause(e));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 285 -            }</span>



<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 286 -            outDirtyRecords.inc();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 287 +            dealError(record, ExceptionTrace.traceOriginalCause(e));</span>
 288          }
 289  
 290          if (outRecords.getCount() % ROW_PRINT_FREQUENCY == 0) {
 291              LOG.info(record.toString());
 292          }
 293          outRecords.inc();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 294 +    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 295 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 296 +    private void dealError(Row record, String cause) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 297 +        if (outDirtyRecords.getCount() % DIRTY_PRINT_FREQUENCY == 0 || LOG.isDebugEnabled()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 298 +            LOG.error(&quot;Get dirty data: {}&quot;, record.toString());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 299 +            LOG.error(&quot;Error cause: &quot; + cause);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 300 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 301 +        outDirtyRecords.inc();</span>
 302      }
 303  
 304      private Put getPutByRow(Row record) {
 305          String rowKey = buildRowKey(record);
 306          if (StringUtils.isEmpty(rowKey)) {
 307              return null;
 308          }
 309          Put put = new Put(rowKey.getBytes());
 310          for (int i = 0; i &lt; record.getArity(); ++i) {
 311              Object fieldVal = record.getField(i);
 312              if (fieldVal != null) {
 313                  byte[] val = fieldVal.toString().getBytes();
 314                  byte[] cf = families[i].getBytes();
 315                  byte[] qualifier = qualifiers[i].getBytes();
 316  
 317                  put.addColumn(cf, qualifier, val);
 318              }
 319          }
 320          return put;
 321      }
 322  
 323      private String buildRowKey(Row record) {
 324          String rowKeyValues = getRowKeyValues(record);
 325          // all rowkey not null
 326          if (StringUtils.isBlank(rowKeyValues)) {
 327              LOG.error(&quot;row key value must not null,record is ..{}&quot;, record);
 328              outDirtyRecords.inc();
 329              return &quot;&quot;;
 330          }
 331          return rowKeyValues;
 332      }
 333  
 334      private String getRowKeyValues(Row record) {
 335          Map&lt;String, Object&gt; row = rowConvertMap(record);
 336          RowKeyBuilder rowKeyBuilder = new RowKeyBuilder();
 337          rowKeyBuilder.init(rowkey);
 338          return rowKeyBuilder.getRowKey(row);
 339      }
 340  
 341      private Map&lt;String, Object&gt; rowConvertMap(Row record) {
 342          Map&lt;String, Object&gt; rowValue = Maps.newHashMap();
 343          for (int i = 0; i &lt; columnNames.length; i++) {
 344              rowValue.put(columnNames[i], record.getField(i));
 345          }
 346          return rowValue;
 347      }
 348  
 349      @Override
 350      public synchronized void close() throws IOException {
 351          if (closed) {
 352              return;
 353          }
 354  
 355          closed = true;
 356          if (!records.isEmpty()) {
 357              dealBatchOperation(records);
 358          }
 359  
 360          if (scheduledFuture != null) {
 361              scheduledFuture.cancel(false);
 362              if (scheduler != null) {
 363                  scheduler.shutdownNow();
 364              }
 365          }
 366  
 367          if (conn != null) {
 368              conn.close();
 369              conn = null;




 370          }
 371      }
 372  
 373      private void fillSyncKerberosConfig(org.apache.hadoop.conf.Configuration config,
 374                                          String regionserverPrincipal,
 375                                          String zookeeperSaslClient,
 376                                          String securityKrb5Conf) {
 377          if (StringUtils.isEmpty(regionserverPrincipal)) {
<abbr title=" 378              throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos&quot;);"> 378              throw new IllegalArgumentException(&quot;Must provide regionserverPrincipal when authentication is Kerberos🔵</abbr>
 379          }
 380          config.set(HbaseConfigUtils.KEY_HBASE_MASTER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 381          config.set(HbaseConfigUtils.KEY_HBASE_REGIONSERVER_KERBEROS_PRINCIPAL, regionserverPrincipal);
 382          config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHORIZATION, &quot;true&quot;);
 383          config.set(HbaseConfigUtils.KEY_HBASE_SECURITY_AUTHENTICATION, &quot;kerberos&quot;);
 384  
 385  
 386          if (!StringUtils.isEmpty(zookeeperSaslClient)) {
 387              System.setProperty(HbaseConfigUtils.KEY_ZOOKEEPER_SASL_CLIENT, zookeeperSaslClient);
 388          }
 389  
 390          if (!StringUtils.isEmpty(securityKrb5Conf)) {
 391              String krb5ConfPath = System.getProperty(&quot;user.dir&quot;) + File.separator + securityKrb5Conf;
 392              LOG.info(&quot;krb5ConfPath:{}&quot;, krb5ConfPath);
 393              System.setProperty(HbaseConfigUtils.KEY_JAVA_SECURITY_KRB5_CONF, krb5ConfPath);
 394          }
 395      }
 396  
 397      @Override
 398      public String toString() {
 399          return &quot;HbaseOutputFormat kerberos{&quot; +
 400                  &quot;kerberosAuthEnable=&quot; + kerberosAuthEnable +
 401                  &quot;, regionserverKeytabFile=&#x27;&quot; + regionserverKeytabFile + &#x27;\&#x27;&#x27; +
 402                  &quot;, regionserverPrincipal=&#x27;&quot; + regionserverPrincipal + &#x27;\&#x27;&#x27; +
 403                  &quot;, securityKrb5Conf=&#x27;&quot; + securityKrb5Conf + &#x27;\&#x27;&#x27; +
 404                  &quot;, zookeeperSaslClient=&#x27;&quot; + zookeeperSaslClient + &#x27;\&#x27;&#x27; +
 405                  &quot;, clientPrincipal=&#x27;&quot; + clientPrincipal + &#x27;\&#x27;&#x27; +
 406                  &quot;, clientKeytabFile=&#x27;&quot; + clientKeytabFile + &#x27;\&#x27;&#x27; +
 407                  &quot;, batchSize=&#x27;&quot; + batchSize + &#x27;\&#x27;&#x27; +
 408                  &quot;, batchWaitInterval=&#x27;&quot; + batchWaitInterval + &#x27;\&#x27;&#x27; +
 409                  &#x27;}&#x27;;
 410      }
 411  
 412      public static class HbaseOutputFormatBuilder {
 413  
 414          private final HbaseOutputFormat format;
 415  
 416          private HbaseOutputFormatBuilder() {
 417              format = new HbaseOutputFormat();
 418          }
 419  
 420          public HbaseOutputFormatBuilder setHost(String host) {
 421              format.host = host;
 422              return this;
 423          }
 424  
 425          public HbaseOutputFormatBuilder setZkParent(String parent) {
 426              format.zkParent = parent;
 427              return this;
 428          }
 429  
 430  
 431          public HbaseOutputFormatBuilder setTable(String tableName) {
 432              format.tableName = tableName;
 433              return this;
 434          }
 435  
 436          public HbaseOutputFormatBuilder setRowkey(String rowkey) {
 437              format.rowkey = rowkey;
 438              return this;
 439          }
 440  
 441          public HbaseOutputFormatBuilder setColumnNames(String[] columnNames) {
 442              format.columnNames = columnNames;
 443              return this;
 444          }
 445  
 446          public HbaseOutputFormatBuilder setColumnNameFamily(Map&lt;String, String&gt; columnNameFamily) {
 447              format.columnNameFamily = columnNameFamily;
 448              return this;
 449          }
 450  
 451          public HbaseOutputFormatBuilder setKerberosAuthEnable(boolean kerberosAuthEnable) {
 452              format.kerberosAuthEnable = kerberosAuthEnable;
 453              return this;
 454          }
 455  
 456          public HbaseOutputFormatBuilder setRegionserverKeytabFile(String regionserverKeytabFile) {
 457              format.regionserverKeytabFile = regionserverKeytabFile;
 458              return this;
 459          }
 460  
 461          public HbaseOutputFormatBuilder setRegionserverPrincipal(String regionserverPrincipal) {
 462              format.regionserverPrincipal = regionserverPrincipal;
 463              return this;
 464          }
 465  
 466          public HbaseOutputFormatBuilder setSecurityKrb5Conf(String securityKrb5Conf) {
 467              format.securityKrb5Conf = securityKrb5Conf;
 468              return this;
 469          }
 470  
 471          public HbaseOutputFormatBuilder setZookeeperSaslClient(String zookeeperSaslClient) {
 472              format.zookeeperSaslClient = zookeeperSaslClient;
 473              return this;
 474          }
 475  
 476          public HbaseOutputFormatBuilder setClientPrincipal(String clientPrincipal) {
 477              format.clientPrincipal = clientPrincipal;
 478              return this;
 479          }
 480  
 481          public HbaseOutputFormatBuilder setClientKeytabFile(String clientKeytabFile) {
 482              format.clientKeytabFile = clientKeytabFile;
 483              return this;
 484          }
 485  





 486          public HbaseOutputFormatBuilder setBatchSize(Integer batchSize) {
 487              format.batchSize = batchSize;
 488              return this;
 489          }
 490  
 491          public HbaseOutputFormatBuilder setBatchWaitInterval(Long batchWaitInterval) {
 492              format.batchWaitInterval = batchWaitInterval;
 493              return this;
 494          }
 495  
 496          public HbaseOutputFormat finish() {
 497              Preconditions.checkNotNull(format.host, &quot;zookeeperQuorum should be specified&quot;);
 498              Preconditions.checkNotNull(format.tableName, &quot;tableName should be specified&quot;);
 499              Preconditions.checkNotNull(format.columnNames, &quot;columnNames should be specified&quot;);
 500              Preconditions.checkArgument(format.columnNames.length != 0, &quot;columnNames length should not be zero&quot;);
 501  
 502              String[] families = new String[format.columnNames.length];
 503              String[] qualifiers = new String[format.columnNames.length];
 504  
 505              if (format.columnNameFamily != null) {
 506                  List&lt;String&gt; keyList = new LinkedList&lt;&gt;(format.columnNameFamily.keySet());
 507                  String[] columns = keyList.toArray(new String[0]);
 508                  for (int i = 0; i &lt; columns.length; ++i) {
 509                      String col = columns[i];
 510                      String[] part = col.split(&quot;:&quot;);
 511                      families[i] = part[0];
 512                      qualifiers[i] = part[1];
 513                  }
 514              }
 515              format.families = families;
 516              format.qualifiers = qualifiers;
 517  
 518              return format;
 519          }
 520      }
 521  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            