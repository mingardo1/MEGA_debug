<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>452</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    452
                    <a href="451.html">prev</a>
                    <a href="453.html">next</a>
                    <a href="452_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_5553ee5c6410a412ab4ed61d9499805adee8995a_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e0a10435dcb243a911c0405daebc6aa667d5119d:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[bj]], subset: [[bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import com.dtstack.flink.sql.util.RowDataComplete;
  30 import org.apache.calcite.sql.JoinType;
  31 import org.apache.commons.collections.map.HashedMap;
  32 import org.apache.flink.api.java.tuple.Tuple2;
  33 import org.apache.commons.lang.StringUtils;
  34 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  35 import com.google.common.collect.Maps;
  36 import org.apache.flink.table.dataformat.BaseRow;
  37 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  38 import org.apache.flink.types.Row;
  39 import org.apache.flink.util.Collector;
  40 import org.apache.hadoop.conf.Configuration;
  41 import org.apache.hadoop.hbase.Cell;
  42 import org.apache.hadoop.hbase.CellUtil;
  43 import org.apache.hadoop.hbase.HBaseConfiguration;
  44 import org.apache.hadoop.hbase.TableName;
  45 import org.apache.hadoop.hbase.client.Connection;
  46 import org.apache.hadoop.hbase.client.ConnectionFactory;
  47 import org.apache.hadoop.hbase.client.Result;
  48 import org.apache.hadoop.hbase.client.ResultScanner;
  49 import org.apache.hadoop.hbase.client.Scan;
  50 import org.apache.hadoop.hbase.client.Table;
  51 import org.apache.hadoop.hbase.util.Bytes;
  52 import org.apache.hadoop.security.UserGroupInformation;
  53 import org.slf4j.Logger;
  54 import org.slf4j.LoggerFactory;
  55 
  56 import java.io.File;
  57 import java.io.IOException;
  58 
  59 import java.security.PrivilegedAction;
  60 import java.sql.SQLException;
  61 import java.sql.Timestamp;
  62 import java.time.LocalDateTime;
  63 import java.util.Calendar;
  64 import java.util.HashMap;
  65 import java.util.List;
  66 import java.util.Map;
  67 import java.util.concurrent.atomic.AtomicReference;
  68 
  69 public class HbaseAllReqRow extends BaseAllReqRow {
  70 
  71     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  72 
  73     private String tableName;
  74 
  75     private Map&lt;String, String&gt; aliasNameInversion;
  76 
  77     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  78     private Connection conn = null;
  79     private Table table = null;
  80     private ResultScanner resultScanner = null;
  81     private Configuration conf = null;
  82 
<abbr title="  83     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  83     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  84         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  85         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  86 
  87         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  88         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  89         aliasNameInversion = new HashMap&lt;&gt;();
  90         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  91             aliasNameInversion.put(entry.getValue(), entry.getKey());
  92         }
  93     }
  94 
  95     @Override
  96     public Row fillData(Row input, Object sideInput) {
  97         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  98         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  99         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 100             Object obj = input.getField(entry.getValue());
<abbr title=" 101             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 101             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
 102 
<abbr title=" 103             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 103             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 104 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 105             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 106                 obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 107 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 108             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 109                 obj = ((Timestamp)obj).getTime();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 110             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 111             row.setField(entry.getKey(), obj);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 112         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 113 </span>
 114 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 115             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 116                 //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 117                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());"> 117                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime())🔵</abbr></span>
 118 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 119             }
 120 
 121             row.setField(entry.getKey(), obj);
 122         }
 123 
 124         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 125             if(sideInputList == null){
 126                 row.setField(entry.getKey(), null);
 127             }else{
 128                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 129                 key = aliasNameInversion.get(key);
 130                 row.setField(entry.getKey(), sideInputList.get(key));
 131             }
 132         }
 133         return row;
 134     }
 135 
 136     @Override
 137     protected void initCache() throws SQLException {
 138         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 139         cacheRef.set(newCache);
 140         loadData(newCache);
 141     }
 142 
 143     @Override
 144     protected void reloadCache() {
 145         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 146         try {
 147             loadData(newCache);
 148         } catch (SQLException e) {
 149             LOG.error(&quot;&quot;, e);
 150         }
 151 
 152         cacheRef.set(newCache);
 153         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 154     }
 155 
 156     @Override
 157     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 158         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 159         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 160             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 161             Object equalObj = input.getField(conValIndex);
 162             if (equalObj == null) {
 163                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 164                     Row data = fillData(input, null);
 165                     RowDataComplete.collectRow(out, data);
 166                 }
 167                 return;
 168             }
 169             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 170         }
 171 
 172         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 173 
 174         Map&lt;String, Object&gt; cacheList = null;
 175 
 176         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 177         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 178         if (hbaseSideTableInfo.isPreRowKey()) {
 179             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 180                 if (entry.getKey().startsWith(rowKeyStr)) {
 181                     cacheList = cacheRef.get().get(entry.getKey());
 182                     Row row = fillData(input, cacheList);
 183                     RowDataComplete.collectRow(out, row);
 184                 }
 185             }
 186         } else {
 187             cacheList = cacheRef.get().get(rowKeyStr);
 188             Row row = fillData(input, cacheList);
 189             RowDataComplete.collectRow(out, row);
 190         }
 191 
 192     }
 193 
 194     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 195         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 196         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 197         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 198         int loadDataCount = 0;
 199         try {
 200             if (openKerberos) {
 201                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 202                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 204                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 205                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 206 
<abbr title=" 207                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 207                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 208                 Configuration finalConf = conf;
 209                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 210                     @Override
 211                     public Connection run() {
 212                         try {
 213                             return ConnectionFactory.createConnection(finalConf);
 214                         } catch (IOException e) {
 215                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 216                             throw new RuntimeException(e);
 217                         }
 218                     }
 219                 });
 220 
 221             } else {
 222                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 223                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 224                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 224                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 225                 conn = ConnectionFactory.createConnection(conf);
 226             }
 227 
 228             table = conn.getTable(TableName.valueOf(tableName));
 229             resultScanner = table.getScanner(new Scan());
 230             for (Result r : resultScanner) {
 231                 Map&lt;String, Object&gt; kv = new HashedMap();
 232                 for (Cell cell : r.listCells())
 233                 {
 234                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 235                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 236                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 237                     StringBuilder key = new StringBuilder();
 238                     key.append(family).append(&quot;:&quot;).append(qualifier);
 239 
 240                     kv.put(aliasNameInversion.get(key.toString()), value);
 241                 }
 242                 loadDataCount++;
 243                 tmpCache.put(new String(r.getRow()), kv);
 244             }
 245         } catch (IOException e) {
 246             throw new RuntimeException(e);
 247         } finally {
 248             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 249             try {
 250                 if (null != conn) {
 251                     conn.close();
 252                 }
 253 
 254                 if (null != table) {
 255                     table.close();
 256                 }
 257 
 258                 if (null != resultScanner) {
 259                     resultScanner.close();
 260                 }
 261             } catch (IOException e) {
 262                 LOG.error(&quot;&quot;, e);
 263             }
 264         }
 265     }
 266 
 267 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import com.dtstack.flink.sql.util.RowDataComplete;
  30 import org.apache.calcite.sql.JoinType;
  31 import org.apache.commons.collections.map.HashedMap;
  32 import org.apache.flink.api.java.tuple.Tuple2;
  33 import org.apache.commons.lang.StringUtils;
  34 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  35 import com.google.common.collect.Maps;
  36 import org.apache.flink.table.dataformat.BaseRow;
  37 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  38 import org.apache.flink.types.Row;
  39 import org.apache.flink.util.Collector;
  40 import org.apache.hadoop.conf.Configuration;
  41 import org.apache.hadoop.hbase.Cell;
  42 import org.apache.hadoop.hbase.CellUtil;
  43 import org.apache.hadoop.hbase.HBaseConfiguration;
  44 import org.apache.hadoop.hbase.TableName;
  45 import org.apache.hadoop.hbase.client.Connection;
  46 import org.apache.hadoop.hbase.client.ConnectionFactory;
  47 import org.apache.hadoop.hbase.client.Result;
  48 import org.apache.hadoop.hbase.client.ResultScanner;
  49 import org.apache.hadoop.hbase.client.Scan;
  50 import org.apache.hadoop.hbase.client.Table;
  51 import org.apache.hadoop.hbase.util.Bytes;
  52 import org.apache.hadoop.security.UserGroupInformation;
  53 import org.slf4j.Logger;
  54 import org.slf4j.LoggerFactory;
  55 
  56 import java.io.File;
  57 import java.io.IOException;
  58 
  59 import java.security.PrivilegedAction;
  60 import java.sql.SQLException;
  61 import java.sql.Timestamp;
  62 import java.time.LocalDateTime;
  63 import java.util.Calendar;
  64 import java.util.HashMap;
  65 import java.util.List;
  66 import java.util.Map;
  67 import java.util.concurrent.atomic.AtomicReference;
  68 
  69 public class HbaseAllReqRow extends BaseAllReqRow {
  70 
  71     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  72 
  73     private String tableName;
  74 
  75     private Map&lt;String, String&gt; aliasNameInversion;
  76 
  77     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  78     private Connection conn = null;
  79     private Table table = null;
  80     private ResultScanner resultScanner = null;
  81     private Configuration conf = null;
  82 
<abbr title="  83     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  83     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  84         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  85         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  86 
  87         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  88         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  89         aliasNameInversion = new HashMap&lt;&gt;();
  90         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  91             aliasNameInversion.put(entry.getValue(), entry.getKey());
  92         }
  93     }
  94 
  95     @Override
  96     public Row fillData(Row input, Object sideInput) {
  97         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  98         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  99         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 100             Object obj = input.getField(entry.getValue());
<abbr title=" 101             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 101             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
 102 
<abbr title=" 103             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 103             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 104 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 105             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 106                 obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 107 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 108             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 109                 obj = ((Timestamp)obj).getTime();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 110             }</span>
 111 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 112             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 113                 //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 114                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());"> 114                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime())🔵</abbr></span>
 115 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 116             }
 117 
 118             row.setField(entry.getKey(), obj);
 119         }
 120 
 121         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 122             if(sideInputList == null){
 123                 row.setField(entry.getKey(), null);
 124             }else{
 125                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 126                 key = aliasNameInversion.get(key);
 127                 row.setField(entry.getKey(), sideInputList.get(key));
 128             }
 129         }
 130         return row;
 131     }
 132 
 133     @Override
 134     protected void initCache() throws SQLException {
 135         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 136         cacheRef.set(newCache);
 137         loadData(newCache);
 138     }
 139 
 140     @Override
 141     protected void reloadCache() {
 142         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 143         try {
 144             loadData(newCache);
 145         } catch (SQLException e) {
 146             LOG.error(&quot;&quot;, e);
 147         }
 148 
 149         cacheRef.set(newCache);
 150         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 151     }
 152 
 153     @Override
 154     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 155         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 156         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 157             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 158             Object equalObj = input.getField(conValIndex);
 159             if (equalObj == null) {
 160                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 161                     Row data = fillData(input, null);
 162                     RowDataComplete.collectRow(out, data);
 163                 }
 164                 return;
 165             }
 166             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 167         }
 168 
 169         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 170 
 171         Map&lt;String, Object&gt; cacheList = null;
 172 
 173         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 174         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 175         if (hbaseSideTableInfo.isPreRowKey()) {
 176             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 177                 if (entry.getKey().startsWith(rowKeyStr)) {
 178                     cacheList = cacheRef.get().get(entry.getKey());
 179                     Row row = fillData(input, cacheList);
 180                     RowDataComplete.collectRow(out, row);
 181                 }
 182             }
 183         } else {
 184             cacheList = cacheRef.get().get(rowKeyStr);
 185             Row row = fillData(input, cacheList);
 186             RowDataComplete.collectRow(out, row);
 187         }
 188 
 189     }
 190 
 191     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 192         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 193         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 194         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 195         int loadDataCount = 0;
 196         try {
 197             if (openKerberos) {
 198                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 199                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 200                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 200                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 201                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 202                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 203 
<abbr title=" 204                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 204                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 205                 Configuration finalConf = conf;
 206                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 207                     @Override
 208                     public Connection run() {
 209                         try {
 210                             return ConnectionFactory.createConnection(finalConf);
 211                         } catch (IOException e) {
 212                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 213                             throw new RuntimeException(e);
 214                         }
 215                     }
 216                 });
 217 
 218             } else {
 219                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 220                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 221                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 221                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 222                 conn = ConnectionFactory.createConnection(conf);
 223             }
 224 
 225             table = conn.getTable(TableName.valueOf(tableName));
 226             resultScanner = table.getScanner(new Scan());
 227             for (Result r : resultScanner) {
 228                 Map&lt;String, Object&gt; kv = new HashedMap();
 229                 for (Cell cell : r.listCells())
 230                 {
 231                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 232                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 233                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 234                     StringBuilder key = new StringBuilder();
 235                     key.append(family).append(&quot;:&quot;).append(qualifier);
 236 
 237                     kv.put(aliasNameInversion.get(key.toString()), value);
 238                 }
 239                 loadDataCount++;
 240                 tmpCache.put(new String(r.getRow()), kv);
 241             }
 242         } catch (IOException e) {
 243             throw new RuntimeException(e);
 244         } finally {
 245             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 246             try {
 247                 if (null != conn) {
 248                     conn.close();
 249                 }
 250 
 251                 if (null != table) {
 252                     table.close();
 253                 }
 254 
 255                 if (null != resultScanner) {
 256                     resultScanner.close();
 257                 }
 258             } catch (IOException e) {
 259                 LOG.error(&quot;&quot;, e);
 260             }
 261         }
 262     }
 263 
 264 }
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  26 import com.dtstack.flink.sql.util.RowDataComplete;
  27 import com.google.common.collect.Maps;
  28 import java.io.File;
  29 import java.io.IOException;
  30 import java.security.PrivilegedAction;
  31 import java.sql.SQLException;
  32 import java.sql.Timestamp;
  33 import java.time.LocalDateTime;
  34 import java.util.Calendar;
  35 import java.util.HashMap;
  36 import java.util.List;
  37 import java.util.Map;
  38 import java.util.concurrent.atomic.AtomicReference;
  39 import org.apache.calcite.sql.JoinType;
  40 import org.apache.commons.collections.map.HashedMap;
  41 import org.apache.commons.lang.StringUtils;
  42 import org.apache.flink.api.java.tuple.Tuple2;
  43 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  44 import org.apache.flink.table.dataformat.BaseRow;
  45 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  46 import org.apache.flink.types.Row;
  47 import org.apache.flink.util.Collector;
  48 import org.apache.hadoop.conf.Configuration;
  49 import org.apache.hadoop.hbase.Cell;
  50 import org.apache.hadoop.hbase.CellUtil;
  51 import org.apache.hadoop.hbase.HBaseConfiguration;
  52 import org.apache.hadoop.hbase.TableName;
  53 import org.apache.hadoop.hbase.client.Connection;
  54 import org.apache.hadoop.hbase.client.ConnectionFactory;
  55 import org.apache.hadoop.hbase.client.Result;
  56 import org.apache.hadoop.hbase.client.ResultScanner;
  57 import org.apache.hadoop.hbase.client.Scan;
  58 import org.apache.hadoop.hbase.client.Table;
  59 import org.apache.hadoop.hbase.util.Bytes;
  60 import org.apache.hadoop.security.UserGroupInformation;
  61 import org.slf4j.Logger;
  62 import org.slf4j.LoggerFactory;
  63 
  64 
  65 public class HbaseAllReqRow extends BaseAllReqRow {
  66     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  67 
  68     private String tableName;
  69 
  70     private Map&lt;String, String&gt; aliasNameInversion;
  71 
  72     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73 
  74     private Connection conn = null;
  75 
  76     private Table table = null;
  77 
  78     private ResultScanner resultScanner = null;
  79 
  80     private Configuration conf = null;
  81 
<abbr title="  82     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  82     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  83         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  84         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  85         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  86         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  87         aliasNameInversion = new HashMap&lt;&gt;();
  88         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  89             aliasNameInversion.put(entry.getValue(), entry.getKey());
  90         }
  91     }
  92 
  93     @Override
  94     public Row fillData(Row input, Object sideInput) {
  95         Map&lt;String, Object&gt; sideInputList = ((Map&lt;String, Object&gt;) (sideInput));
  96         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  97         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
  98             Object obj = input.getField(entry.getValue());
<abbr title="  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
<abbr title=" 100             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 100             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 101             if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
 102                 //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响
<abbr title=" 103                 obj = ((Timestamp) (obj)).getTime() + ((long) (LOCAL_TZ.getOffset(Timestamp.valueOf(((LocalDateTime) (obj))))));"> 103                 obj = ((Timestamp) (obj)).getTime() + ((long) (LOCAL_TZ.getOffset(Timestamp.valueOf(((Loc🔵</abbr>
 104             }
 105             row.setField(entry.getKey(), obj);
 106         }
 107         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 108             if (sideInputList == null) {
 109                 row.setField(entry.getKey(), null);
 110             } else {
 111                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 112                 key = aliasNameInversion.get(key);
 113                 row.setField(entry.getKey(), sideInputList.get(key));
 114             }
 115         }
 116         return row;
 117     }
 118 
 119     @Override
 120     protected void initCache() throws SQLException {
 121         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 122         cacheRef.set(newCache);
 123         loadData(newCache);
 124     }
 125 
 126     @Override
 127     protected void reloadCache() {
 128         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 129         try {
 130             loadData(newCache);
 131         } catch (SQLException e) {
 132             LOG.error(&quot;&quot;, e);
 133         }
 134 
 135         cacheRef.set(newCache);
 136         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 137     }
 138 
 139     @Override
 140     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 141         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 142         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 143             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 144             Object equalObj = input.getField(conValIndex);
 145             if (equalObj == null) {
 146                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 147                     Row data = fillData(input, null);
 148                     RowDataComplete.collectRow(out, data);
 149                 }
 150                 return;
 151             }
 152             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 153         }
 154         String rowKeyStr = ((HbaseAllSideInfo) (sideInfo)).getRowKeyBuilder().getRowKey(refData);
 155         Map&lt;String, Object&gt; cacheList = null;
 156         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 157         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 158         if (hbaseSideTableInfo.isPreRowKey()) {
 159             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 160                 if (entry.getKey().startsWith(rowKeyStr)) {
 161                     cacheList = cacheRef.get().get(entry.getKey());
 162                     Row row = fillData(input, cacheList);
 163                     RowDataComplete.collectRow(out, row);
 164                 }
 165             }
 166         } else {
 167             cacheList = cacheRef.get().get(rowKeyStr);
 168             Row row = fillData(input, cacheList);
 169             RowDataComplete.collectRow(out, row);
 170         }
 171     }
 172 
 173     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 174         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 175         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 176         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 177         int loadDataCount = 0;
 178         try {
 179             if (openKerberos) {
 180                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 181                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 182                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 182                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 183                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 184                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 185 
<abbr title=" 186                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 186                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 187                 Configuration finalConf = conf;
 188                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 189                     @Override
 190                     public Connection run() {
 191                         try {
 192                             return ConnectionFactory.createConnection(finalConf);
 193                         } catch (IOException e) {
 194                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 195                             throw new RuntimeException(e);
 196                         }
 197                     }
 198                 });
 199 
 200             } else {
 201                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 202                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 204                 conn = ConnectionFactory.createConnection(conf);
 205             }
 206 
 207             table = conn.getTable(TableName.valueOf(tableName));
 208             resultScanner = table.getScanner(new Scan());
 209             for (Result r : resultScanner) {
 210                 Map&lt;String, Object&gt; kv = new HashedMap();
 211                 for (Cell cell : r.listCells())
 212                 {
 213                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 214                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 215                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 216                     StringBuilder key = new StringBuilder();
 217                     key.append(family).append(&quot;:&quot;).append(qualifier);
 218 
 219                     kv.put(aliasNameInversion.get(key.toString()), value);
 220                 }
 221                 loadDataCount++;
 222                 tmpCache.put(new String(r.getRow()), kv);
 223             }
 224         } catch (IOException e) {
 225             throw new RuntimeException(e);
 226         } finally {
 227             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 228             try {
 229                 if (null != conn) {
 230                     conn.close();
 231                 }
 232 
 233                 if (null != table) {
 234                     table.close();
 235                 }
 236 
 237                 if (null != resultScanner) {
 238                     resultScanner.close();
 239                 }
 240             } catch (IOException e) {
 241                 LOG.error(&quot;&quot;, e);
 242             }
 243         }
 244     }
 245 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import com.dtstack.flink.sql.util.RowDataComplete;</span>
  30  import org.apache.calcite.sql.JoinType;
  31  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  32 +import org.apache.flink.api.java.tuple.Tuple2;</span>
  33  import org.apache.commons.lang.StringUtils;
  34  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  35  import com.google.common.collect.Maps;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  36 -import org.apache.flink.table.runtime.types.CRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  37 +import org.apache.flink.table.dataformat.BaseRow;</span>
  38  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  39  import org.apache.flink.types.Row;
  40  import org.apache.flink.util.Collector;
  41  import org.apache.hadoop.conf.Configuration;
  42  import org.apache.hadoop.hbase.Cell;
  43  import org.apache.hadoop.hbase.CellUtil;
  44  import org.apache.hadoop.hbase.HBaseConfiguration;
  45  import org.apache.hadoop.hbase.TableName;
  46  import org.apache.hadoop.hbase.client.Connection;
  47  import org.apache.hadoop.hbase.client.ConnectionFactory;
  48  import org.apache.hadoop.hbase.client.Result;
  49  import org.apache.hadoop.hbase.client.ResultScanner;
  50  import org.apache.hadoop.hbase.client.Scan;
  51  import org.apache.hadoop.hbase.client.Table;
  52  import org.apache.hadoop.hbase.util.Bytes;
  53  import org.apache.hadoop.security.UserGroupInformation;
  54  import org.slf4j.Logger;
  55  import org.slf4j.LoggerFactory;
  56  
  57  import java.io.File;
  58  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  59 +</span>
  60  import java.security.PrivilegedAction;
  61  import java.sql.SQLException;
  62  import java.sql.Timestamp;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  63 +import java.time.LocalDateTime;</span>
  64  import java.util.Calendar;
  65  import java.util.HashMap;
  66  import java.util.List;
  67  import java.util.Map;
  68  import java.util.concurrent.atomic.AtomicReference;
  69  
  70  public class HbaseAllReqRow extends BaseAllReqRow {
  71  
  72      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  73  
  74      private String tableName;
  75  
  76      private Map&lt;String, String&gt; aliasNameInversion;
  77  
  78      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  79      private Connection conn = null;
  80      private Table table = null;
  81      private ResultScanner resultScanner = null;
  82      private Configuration conf = null;
  83  
<abbr title="  84      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  84      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  85          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  86          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  87  
  88          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  89          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  90          aliasNameInversion = new HashMap&lt;&gt;();
  91          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  92              aliasNameInversion.put(entry.getValue(), entry.getKey());
  93          }
  94      }
  95  
  96      @Override
  97      public Row fillData(Row input, Object sideInput) {
  98          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  99          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 100          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 101              Object obj = input.getField(entry.getValue());
<abbr title=" 102              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 102              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 103  
<abbr title=" 104              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 104              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 105 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 106 -                obj = ((Timestamp)obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 107 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 108 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 109              }




 110              row.setField(entry.getKey(), obj);
 111          }
 112  
 113          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 114              if(sideInputList == null){
 115                  row.setField(entry.getKey(), null);
 116              }else{
 117                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 118 +                key = aliasNameInversion.get(key);</span>
 119                  row.setField(entry.getKey(), sideInputList.get(key));
 120              }
 121          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 122 -</span>
 123          return row;
 124      }
 125  
 126      @Override
 127      protected void initCache() throws SQLException {
 128          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 129          cacheRef.set(newCache);
 130          loadData(newCache);
 131      }
 132  
 133      @Override
 134      protected void reloadCache() {
 135          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 136          try {
 137              loadData(newCache);
 138          } catch (SQLException e) {
 139              LOG.error(&quot;&quot;, e);
 140          }
 141  
 142          cacheRef.set(newCache);
 143          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 144      }
 145  
 146      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 147 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 148 +    public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {</span>
 149          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 150          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 151              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 152 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 153 +            Object equalObj = input.getField(conValIndex);</span>
 154              if (equalObj == null) {
 155                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 156 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 157 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 158 +                    Row data = fillData(input, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 159 +                    RowDataComplete.collectRow(out, data);</span>
 160                  }
 161                  return;
 162              }
 163              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 164          }
 165  
 166          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 167  
 168          Map&lt;String, Object&gt; cacheList = null;
 169  
 170          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 171          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 172          if (hbaseSideTableInfo.isPreRowKey()) {
 173              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 174                  if (entry.getKey().startsWith(rowKeyStr)) {
 175                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 176 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 177 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 178 +                    Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 179 +                    RowDataComplete.collectRow(out, row);</span>
 180                  }
 181              }
 182          } else {
 183              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 184 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 185 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 186 +            Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 187 +            RowDataComplete.collectRow(out, row);</span>
 188          }
 189  
 190      }
 191  
 192      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 193          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 194          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 195          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 196          int loadDataCount = 0;
 197          try {
 198              if (openKerberos) {
 199                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 200                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 201                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 202                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 203                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 204  
<abbr title=" 205                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 205                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 206                  Configuration finalConf = conf;
 207                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 208                      @Override
 209                      public Connection run() {
 210                          try {
 211                              return ConnectionFactory.createConnection(finalConf);
 212                          } catch (IOException e) {
 213                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 214                              throw new RuntimeException(e);
 215                          }
 216                      }
 217                  });
 218  
 219              } else {
 220                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 221                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 222                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 223                  conn = ConnectionFactory.createConnection(conf);
 224              }
 225  
 226              table = conn.getTable(TableName.valueOf(tableName));
 227              resultScanner = table.getScanner(new Scan());
 228              for (Result r : resultScanner) {
 229                  Map&lt;String, Object&gt; kv = new HashedMap();
 230                  for (Cell cell : r.listCells())
 231                  {
 232                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 233                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 234                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 235                      StringBuilder key = new StringBuilder();
 236                      key.append(family).append(&quot;:&quot;).append(qualifier);
 237  
 238                      kv.put(aliasNameInversion.get(key.toString()), value);
 239                  }
 240                  loadDataCount++;
 241                  tmpCache.put(new String(r.getRow()), kv);
 242              }
 243          } catch (IOException e) {
 244              throw new RuntimeException(e);
 245          } finally {
 246              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 247              try {
 248                  if (null != conn) {
 249                      conn.close();
 250                  }
 251  
 252                  if (null != table) {
 253                      table.close();
 254                  }
 255  
 256                  if (null != resultScanner) {
 257                      resultScanner.close();
 258                  }
 259              } catch (IOException e) {
 260                  LOG.error(&quot;&quot;, e);
 261              }
 262          }
 263      }
 264  
 265  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;

  29  import org.apache.calcite.sql.JoinType;
  30  import org.apache.commons.collections.map.HashedMap;

  31  import org.apache.commons.lang.StringUtils;
  32  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  33  import com.google.common.collect.Maps;
  34  import org.apache.flink.table.runtime.types.CRow;

  35  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  36  import org.apache.flink.types.Row;
  37  import org.apache.flink.util.Collector;
  38  import org.apache.hadoop.conf.Configuration;
  39  import org.apache.hadoop.hbase.Cell;
  40  import org.apache.hadoop.hbase.CellUtil;
  41  import org.apache.hadoop.hbase.HBaseConfiguration;
  42  import org.apache.hadoop.hbase.TableName;
  43  import org.apache.hadoop.hbase.client.Connection;
  44  import org.apache.hadoop.hbase.client.ConnectionFactory;
  45  import org.apache.hadoop.hbase.client.Result;
  46  import org.apache.hadoop.hbase.client.ResultScanner;
  47  import org.apache.hadoop.hbase.client.Scan;
  48  import org.apache.hadoop.hbase.client.Table;
  49  import org.apache.hadoop.hbase.util.Bytes;
  50  import org.apache.hadoop.security.UserGroupInformation;
  51  import org.slf4j.Logger;
  52  import org.slf4j.LoggerFactory;
  53  
  54  import java.io.File;
  55  import java.io.IOException;

  56  import java.security.PrivilegedAction;
  57  import java.sql.SQLException;
  58  import java.sql.Timestamp;

  59  import java.util.Calendar;
  60  import java.util.HashMap;
  61  import java.util.List;
  62  import java.util.Map;
  63  import java.util.concurrent.atomic.AtomicReference;
  64  
  65  public class HbaseAllReqRow extends BaseAllReqRow {
  66  
  67      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  68  
  69      private String tableName;
  70  
  71      private Map&lt;String, String&gt; aliasNameInversion;
  72  
  73      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  74      private Connection conn = null;
  75      private Table table = null;
  76      private ResultScanner resultScanner = null;
  77      private Configuration conf = null;
  78  
<abbr title="  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  80          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  81          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  82  
  83          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  84          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  85          aliasNameInversion = new HashMap&lt;&gt;();
  86          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  87              aliasNameInversion.put(entry.getValue(), entry.getKey());
  88          }
  89      }
  90  
  91      @Override
  92      public Row fillData(Row input, Object sideInput) {
  93          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  94          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  95          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  96              Object obj = input.getField(entry.getValue());
<abbr title="  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
  98  
<abbr title="  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
 100              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 101 -                obj = ((Timestamp)obj).getTime();</span>


<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 102 -            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 103 +                //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 104 +                obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 105 +            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 106 +</span>
 107              row.setField(entry.getKey(), obj);
 108          }
 109  
 110          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 111              if(sideInputList == null){
 112                  row.setField(entry.getKey(), null);
 113              }else{
 114                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());

 115                  row.setField(entry.getKey(), sideInputList.get(key));
 116              }
 117          }
 118  
 119          return row;
 120      }
 121  
 122      @Override
 123      protected void initCache() throws SQLException {
 124          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 125          cacheRef.set(newCache);
 126          loadData(newCache);
 127      }
 128  
 129      @Override
 130      protected void reloadCache() {
 131          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 132          try {
 133              loadData(newCache);
 134          } catch (SQLException e) {
 135              LOG.error(&quot;&quot;, e);
 136          }
 137  
 138          cacheRef.set(newCache);
 139          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 140      }
 141  
 142      @Override
 143      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {

 144          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 145          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 146              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 147              Object equalObj = input.row().getField(conValIndex);

 148              if (equalObj == null) {
 149                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 150                      Row data = fillData(input.row(), null);
 151                      out.collect(new CRow(data, input.change()));


 152                  }
 153                  return;
 154              }
 155              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 156          }
 157  
 158          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 159  
 160          Map&lt;String, Object&gt; cacheList = null;
 161  
 162          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 163          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 164          if (hbaseSideTableInfo.isPreRowKey()) {
 165              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 166                  if (entry.getKey().startsWith(rowKeyStr)) {
 167                      cacheList = cacheRef.get().get(entry.getKey());
 168                      Row row = fillData(input.row(), cacheList);
 169                      out.collect(new CRow(row, input.change()));


 170                  }
 171              }
 172          } else {
 173              cacheList = cacheRef.get().get(rowKeyStr);
 174              Row row = fillData(input.row(), cacheList);
 175              out.collect(new CRow(row, input.change()));


 176          }
 177  
 178      }
 179  
 180      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 181          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 182          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 183          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 184          int loadDataCount = 0;
 185          try {
 186              if (openKerberos) {
 187                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 188                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 189                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 190                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 191                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 192  
<abbr title=" 193                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 193                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 194                  Configuration finalConf = conf;
 195                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 196                      @Override
 197                      public Connection run() {
 198                          try {
 199                              return ConnectionFactory.createConnection(finalConf);
 200                          } catch (IOException e) {
 201                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 202                              throw new RuntimeException(e);
 203                          }
 204                      }
 205                  });
 206  
 207              } else {
 208                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 209                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 210                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 211                  conn = ConnectionFactory.createConnection(conf);
 212              }
 213  
 214              table = conn.getTable(TableName.valueOf(tableName));
 215              resultScanner = table.getScanner(new Scan());
 216              for (Result r : resultScanner) {
 217                  Map&lt;String, Object&gt; kv = new HashedMap();
 218                  for (Cell cell : r.listCells())
 219                  {
 220                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 221                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 222                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 223                      StringBuilder key = new StringBuilder();
 224                      key.append(family).append(&quot;:&quot;).append(qualifier);
 225  
 226                      kv.put(aliasNameInversion.get(key.toString()), value);
 227                  }
 228                  loadDataCount++;
 229                  tmpCache.put(new String(r.getRow()), kv);
 230              }
 231          } catch (IOException e) {
 232              throw new RuntimeException(e);
 233          } finally {
 234              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 235              try {
 236                  if (null != conn) {
 237                      conn.close();
 238                  }
 239  
 240                  if (null != table) {
 241                      table.close();
 242                  }
 243  
 244                  if (null != resultScanner) {
 245                      resultScanner.close();
 246                  }
 247              } catch (IOException e) {
 248                  LOG.error(&quot;&quot;, e);
 249              }
 250          }
 251      }
 252  
 253  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            