<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>553 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                           &#x27;\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                           &#x27;\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;protected SinkFunction&lt;Row&gt; kafkaProducer010;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;protected RichSinkFunction&lt;CRow&gt; &#x27;
                           &#x27;kafkaProducer010;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;
                           &#x27;                .setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;mapDataStream.addSink(kafkaProducer010).name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;SinkFunction\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\nRichSinkFunction\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;Row\n&#x27;, &#x27;CHUNK_THEIRS&#x27;: &#x27;\nCRow\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                           &#x27;\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                           &#x27;\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        kafkaProducer010 = new &#x27;
                         &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties,\n&#x27;
                         &#x27;                Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka10SinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        kafkaProducer010 = new &#x27;
                           &#x27;KafkaProducer010Factory().createKafkaProducer(kafka10SinkTableInfo,\n&#x27;
                           &#x27;                typeInformation, properties,\n&#x27;
                           &#x27;                Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;()), partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;Row\n&#x27;, &#x27;CHUNK_THEIRS&#x27;: &#x27;\nCRow\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;spork&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;protected SinkFunction&lt;Row&gt; kafkaProducer010;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;protected RichSinkFunction&lt;CRow&gt; &#x27;
                           &#x27;kafkaProducer010;\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;SinkFunction\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\nRichSinkFunction\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;
                           &#x27;                .setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;mapDataStream.addSink(kafkaProducer010).name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        