<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>588 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;/*\n&#x27;
                         &#x27; * Licensed to the Apache Software Foundation (ASF) &#x27;
                         &#x27;under one\n&#x27;
                         &#x27; * or more contributor license agreements.  See the &#x27;
                         &#x27;NOTICE file\n&#x27;
                         &#x27; * distributed with this work for additional &#x27;
                         &#x27;information\n&#x27;
                         &#x27; * regarding copyright ownership.  The ASF licenses &#x27;
                         &#x27;this file\n&#x27;
                         &#x27; * to you under the Apache License, Version 2.0 &#x27;
                         &#x27;(the\n&#x27;
                         &#x27; * &quot;License&quot;); you may not use this file except in &#x27;
                         &#x27;compliance\n&#x27;
                         &#x27; * with the License.  You may obtain a copy of the &#x27;
                         &#x27;License at\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; *     http://www.apache.org/licenses/LICENSE-2.0\n&#x27;
                         &#x27; *\n&#x27;
                         &#x27; * Unless required by applicable law or agreed to in &#x27;
                         &#x27;writing, software\n&#x27;
                         &#x27; * distributed under the License is distributed on &#x27;
                         &#x27;an &quot;AS IS&quot; BASIS,\n&#x27;
                         &#x27; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, &#x27;
                         &#x27;either express or implied.\n&#x27;
                         &#x27; * See the License for the specific language &#x27;
                         &#x27;governing permissions and\n&#x27;
                         &#x27; * limitations under the License.\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;package com.dtstack.flink.sql.source.kafka;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.AbsDeserialization;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.source.JsonDataParser;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;com.dtstack.flink.sql.source.kafka.metric.KafkaTopicPartitionLagMetric;\n&#x27;
                         &#x27;import com.dtstack.flink.sql.table.TableInfo;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.api.common.typeinfo.TypeInformation;\n&#x27;
                         &#x27;import org.apache.flink.metrics.MetricGroup;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;\n&#x27;
                         &#x27;import org.apache.flink.types.Row;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.KafkaConsumer;\n&#x27;
                         &#x27;import &#x27;
                         &#x27;org.apache.kafka.clients.consumer.internals.SubscriptionState;\n&#x27;
                         &#x27;import org.apache.kafka.common.TopicPartition;\n&#x27;
                         &#x27;import org.slf4j.Logger;\n&#x27;
                         &#x27;import org.slf4j.LoggerFactory;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import java.io.IOException;\n&#x27;
                         &#x27;import java.lang.reflect.Field;\n&#x27;
                         &#x27;import java.util.List;\n&#x27;
                         &#x27;import java.util.Map;\n&#x27;
                         &#x27;import java.util.Set;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;\n&#x27;
                         &#x27;import static &#x27;
                         &#x27;com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;/**\n&#x27;
                         &#x27; * json string parsing custom\n&#x27;
                         &#x27; * Date: 2018/09/18\n&#x27;
                         &#x27; * Company: www.dtstack.com\n&#x27;
                         &#x27; * @author sishu.yss\n&#x27;
                         &#x27; */\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;public class CustomerJsonDeserialization extends &#x27;
                         &#x27;AbsDeserialization&lt;Row&gt; {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final Logger LOG = &#x27;
                         &#x27;LoggerFactory.getLogger(CustomerJsonDeserialization.class);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static final long serialVersionUID = &#x27;
                         &#x27;2385115520960444192L;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private AbstractFetcher&lt;Row, ?&gt; fetcher;\n&#x27;
                         &#x27;    private TypeInformation&lt;Row&gt; typeInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private boolean firstMsg = true;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public &#x27;
                         &#x27;CustomerJsonDeserialization(TypeInformation&lt;Row&gt; &#x27;
                         &#x27;typeInfo, Map&lt;String, String&gt; rowAndFieldMapping, &#x27;
                         &#x27;List&lt;TableInfo.FieldExtraInfo&gt; fieldExtraInfos) {\n&#x27;
                         &#x27;        this.typeInfo = typeInfo;\n&#x27;
                         &#x27;        this.jsonDataParser = new &#x27;
                         &#x27;JsonDataParser(typeInfo, rowAndFieldMapping, &#x27;
                         &#x27;fieldExtraInfos);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public Row deserialize(byte[] message) throws &#x27;
                         &#x27;IOException {\n&#x27;
                         &#x27;        if(firstMsg){\n&#x27;
                         &#x27;            try {\n&#x27;
                         &#x27;                registerPtMetric(fetcher);\n&#x27;
                         &#x27;            } catch (Exception e) {\n&#x27;
                         &#x27;                LOG.error(&quot;register topic partition &#x27;
                         &#x27;metric error.&quot;, e);\n&#x27;
                         &#x27;            }\n&#x27;
                         &#x27;            firstMsg = false;\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;        Row row = parseSourceData(message);\n&#x27;
                         &#x27;        return row;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    protected void &#x27;
                         &#x27;registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) &#x27;
                         &#x27;throws Exception {\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerThreadField = &#x27;
                         &#x27;fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);\n&#x27;
                         &#x27;        consumerThreadField.setAccessible(true);\n&#x27;
                         &#x27;        KafkaConsumerThread consumerThread = &#x27;
                         &#x27;(KafkaConsumerThread) &#x27;
                         &#x27;consumerThreadField.get(fetcher);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field hasAssignedPartitionsField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);\n&#x27;
                         &#x27;        &#x27;
                         &#x27;hasAssignedPartitionsField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //wait until assignedPartitions\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        boolean hasAssignedPartitions = (boolean) &#x27;
                         &#x27;hasAssignedPartitionsField.get(consumerThread);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        if(!hasAssignedPartitions){\n&#x27;
                         &#x27;            throw new RuntimeException(&quot;wait 50 &#x27;
                         &#x27;secs, but not assignedPartitions&quot;);\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Field consumerField = &#x27;
                         &#x27;consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);\n&#x27;
                         &#x27;        consumerField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        KafkaConsumer kafkaConsumer = &#x27;
                         &#x27;(KafkaConsumer) consumerField.get(consumerThread);\n&#x27;
                         &#x27;        Field subscriptionStateField = &#x27;
                         &#x27;kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);\n&#x27;
                         &#x27;        subscriptionStateField.setAccessible(true);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        //topic partitions lag\n&#x27;
                         &#x27;        SubscriptionState subscriptionState = &#x27;
                         &#x27;(SubscriptionState) &#x27;
                         &#x27;subscriptionStateField.get(kafkaConsumer);\n&#x27;
                         &#x27;        Set&lt;TopicPartition&gt; assignedPartitions = &#x27;
                         &#x27;subscriptionState.assignedPartitions();\n&#x27;
                         &#x27;        for(TopicPartition topicPartition : &#x27;
                         &#x27;assignedPartitions){\n&#x27;
                         &#x27;            MetricGroup metricGroup = &#x27;
                         &#x27;getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, &#x27;
                         &#x27;topicPartition.topic())\n&#x27;
                         &#x27;                    .addGroup(DT_PARTITION_GROUP, &#x27;
                         &#x27;topicPartition.partition() + &quot;&quot;);\n&#x27;
                         &#x27;            &#x27;
                         &#x27;metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new &#x27;
                         &#x27;KafkaTopicPartitionLagMetric(subscriptionState, &#x27;
                         &#x27;topicPartition));\n&#x27;
                         &#x27;        }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    private static String &#x27;
                         &#x27;partitionLagMetricName(TopicPartition tp) {\n&#x27;
                         &#x27;        return tp + &quot;.records-lag&quot;;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getProducedType() {\n&#x27;
                         &#x27;        return typeInfo;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; &#x27;
                         &#x27;fetcher) {\n&#x27;
                         &#x27;        this.fetcher = fetcher;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;}\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        