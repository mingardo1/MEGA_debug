<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>492</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    492
                    <a href="491.html">prev</a>
                    <a href="493.html">next</a>
                    <a href="492_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_e346a804d69c8cd0124b4eb3d35156cfb5cd0779_kafka-base/kafka-base-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaDeserializationMetricWrapper.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779:kafka-base/kafka-base-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaDeserializationMetricWrapper.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779^1:kafka-base/kafka-base-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaDeserializationMetricWrapper.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779^2:kafka-base/kafka-base-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaDeserializationMetricWrapper.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;6e351a99f6e8449c76ad55e517a5da6cbb108379:kafka-base/kafka-base-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaDeserializationMetricWrapper.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b]], subset: [[b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.source.kafka;
  20 
  21 import com.dtstack.flink.sql.format.DeserializationMetricWrapper;
  22 import org.apache.flink.api.common.serialization.DeserializationSchema;
  23 import org.apache.flink.api.common.typeinfo.TypeInformation;
  24 import org.apache.flink.metrics.Gauge;
  25 import org.apache.flink.metrics.MetricGroup;
  26 import org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;
  27 import org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;
  28 import org.apache.flink.types.Row;
  29 import org.apache.kafka.clients.consumer.KafkaConsumer;
  30 import org.apache.kafka.clients.consumer.internals.SubscriptionState;
  31 import org.apache.kafka.common.TopicPartition;
  32 import org.slf4j.Logger;
  33 import org.slf4j.LoggerFactory;
  34 
  35 import java.io.IOException;
  36 import java.lang.reflect.Field;
  37 import java.util.Set;
  38 import java.util.concurrent.atomic.AtomicBoolean;
  39 
  40 import static com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;
  41 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;
  42 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;
  43 
  44 /**
  45  * add metric for source
  46  * &lt;p&gt;
  47  * company: www.dtstack.com
  48  * @author: toutian
  49  * create: 2019/12/24
  50  */
  51 public class KafkaDeserializationMetricWrapper extends DeserializationMetricWrapper {
  52 
  53     private static final Logger LOG = LoggerFactory.getLogger(KafkaDeserializationMetricWrapper.class);
  54 
  55     private AbstractFetcher&lt;Row, ?&gt; fetcher;
  56     private TypeInformation&lt;Row&gt; typeInfo;
  57 
  58     private AtomicBoolean firstMsg = new AtomicBoolean(true);
  59 
  60     private Calculate calculate;
  61 
<abbr title="  62     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializationSchema, Calculate calculate) {">  62     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deðŸ”µ</abbr>
  63         super(typeInfo, deserializationSchema);
  64         this.calculate = calculate;
  65     }
  66 
  67     @Override
  68     protected void beforeDeserialize() throws IOException {
  69         super.beforeDeserialize();
  70         if (firstMsg.compareAndSet(true, false)) {
  71             try {
  72                 registerPtMetric(fetcher);
  73             } catch (Exception e) {
  74                 LOG.error(&quot;register topic partition metric error.&quot;, e);
  75             }
  76         }
  77     }
  78 
  79     protected void registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) throws Exception {
  80         Field consumerThreadField = getConsumerThreadField(fetcher);
  81         consumerThreadField.setAccessible(true);
  82         KafkaConsumerThread consumerThread = (KafkaConsumerThread) consumerThreadField.get(fetcher);
  83 
<abbr title="  84         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);">  84         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitiðŸ”µ</abbr>
  85         hasAssignedPartitionsField.setAccessible(true);
  86 
  87         //wait until assignedPartitions
  88 
  89         boolean hasAssignedPartitions = (boolean) hasAssignedPartitionsField.get(consumerThread);
  90 
  91         if (!hasAssignedPartitions) {
  92             throw new RuntimeException(&quot;wait 50 secs, but not assignedPartitions&quot;);
  93         }
  94 
  95         Field consumerField = consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);
  96         consumerField.setAccessible(true);
  97 
  98         KafkaConsumer kafkaConsumer = (KafkaConsumer) consumerField.get(consumerThread);
  99         Field subscriptionStateField = kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);
 100         subscriptionStateField.setAccessible(true);
 101 
 102         //topic partitions lag
<abbr title=" 103         SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumer);"> 103         SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumeðŸ”µ</abbr>
 104         Set&lt;TopicPartition&gt; assignedPartitions = subscriptionState.assignedPartitions();
 105 
 106         for (TopicPartition topicPartition : assignedPartitions) {
<abbr title=" 107             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartition.topic())"> 107             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicðŸ”µ</abbr>
 108                     .addGroup(DT_PARTITION_GROUP, topicPartition.partition() + &quot;&quot;);
 109             metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new Gauge&lt;Long&gt;() {
 110                 @Override
 111                 public Long getValue() {
 112                     return calculate.calc(subscriptionState, topicPartition);
 113                 }
 114             });
 115         }
 116     }
 117 
 118     public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {
 119         this.fetcher = fetcher;
 120     }
 121 
 122     private Field getConsumerThreadField(AbstractFetcher fetcher) throws NoSuchFieldException {
 123         try {
 124             return fetcher.getClass().getDeclaredField(&quot;consumerThread&quot;);
 125         } catch (Exception e) {
 126             return fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);
 127         }
 128     }
 129 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 130 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 131     public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 132         this.fetcher = fetcher;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 133     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 134 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 135     @Override</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 136     public TypeInformation&lt;Row&gt; getProducedType() {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 137         return typeInfo;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 138     }</span>
 139 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 140     public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 141         this.fetcher = fetcher;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 142     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 143 }</span>
 144 =======
 145 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 146 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.source.kafka;
  20 
  21 import com.dtstack.flink.sql.format.DeserializationMetricWrapper;
  22 import org.apache.flink.api.common.serialization.DeserializationSchema;
  23 import org.apache.flink.api.common.typeinfo.TypeInformation;
  24 import org.apache.flink.metrics.Gauge;
  25 import org.apache.flink.metrics.MetricGroup;
  26 import org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;
  27 import org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;
  28 import org.apache.flink.types.Row;
  29 import org.apache.kafka.clients.consumer.KafkaConsumer;
  30 import org.apache.kafka.clients.consumer.internals.SubscriptionState;
  31 import org.apache.kafka.common.TopicPartition;
  32 import org.slf4j.Logger;
  33 import org.slf4j.LoggerFactory;
  34 
  35 import java.io.IOException;
  36 import java.lang.reflect.Field;
  37 import java.util.Set;
  38 import java.util.concurrent.atomic.AtomicBoolean;
  39 
  40 import static com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;
  41 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;
  42 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;
  43 
  44 /**
  45  * add metric for source
  46  * &lt;p&gt;
  47  * company: www.dtstack.com
  48  * @author: toutian
  49  * create: 2019/12/24
  50  */
  51 public class KafkaDeserializationMetricWrapper extends DeserializationMetricWrapper {
  52 
  53     private static final Logger LOG = LoggerFactory.getLogger(KafkaDeserializationMetricWrapper.class);
  54 
  55     private AbstractFetcher&lt;Row, ?&gt; fetcher;
  56     private TypeInformation&lt;Row&gt; typeInfo;
  57 
  58     private AtomicBoolean firstMsg = new AtomicBoolean(true);
  59 
  60     private Calculate calculate;
  61 
<abbr title="  62     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializationSchema, Calculate calculate) {">  62     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deðŸ”µ</abbr>
  63         super(typeInfo, deserializationSchema);
  64         this.calculate = calculate;
  65     }
  66 
  67     @Override
  68     protected void beforeDeserialize() throws IOException {
  69         super.beforeDeserialize();
  70         if (firstMsg.compareAndSet(true, false)) {
  71             try {
  72                 registerPtMetric(fetcher);
  73             } catch (Exception e) {
  74                 LOG.error(&quot;register topic partition metric error.&quot;, e);
  75             }
  76         }
  77     }
  78 
  79     protected void registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) throws Exception {
  80         Field consumerThreadField = getConsumerThreadField(fetcher);
  81         consumerThreadField.setAccessible(true);
  82         KafkaConsumerThread consumerThread = (KafkaConsumerThread) consumerThreadField.get(fetcher);
  83 
<abbr title="  84         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);">  84         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitiðŸ”µ</abbr>
  85         hasAssignedPartitionsField.setAccessible(true);
  86 
  87         //wait until assignedPartitions
  88 
  89         boolean hasAssignedPartitions = (boolean) hasAssignedPartitionsField.get(consumerThread);
  90 
  91         if (!hasAssignedPartitions) {
  92             throw new RuntimeException(&quot;wait 50 secs, but not assignedPartitions&quot;);
  93         }
  94 
  95         Field consumerField = consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);
  96         consumerField.setAccessible(true);
  97 
  98         KafkaConsumer kafkaConsumer = (KafkaConsumer) consumerField.get(consumerThread);
  99         Field subscriptionStateField = kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);
 100         subscriptionStateField.setAccessible(true);
 101 
 102         //topic partitions lag
<abbr title=" 103         SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumer);"> 103         SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumeðŸ”µ</abbr>
 104         Set&lt;TopicPartition&gt; assignedPartitions = subscriptionState.assignedPartitions();
 105 
 106         for (TopicPartition topicPartition : assignedPartitions) {
<abbr title=" 107             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartition.topic())"> 107             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicðŸ”µ</abbr>
 108                     .addGroup(DT_PARTITION_GROUP, topicPartition.partition() + &quot;&quot;);
 109             metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new Gauge&lt;Long&gt;() {
 110                 @Override
 111                 public Long getValue() {
 112                     return calculate.calc(subscriptionState, topicPartition);
 113                 }
 114             });
 115         }
 116     }
 117 
 118     private Field getConsumerThreadField(AbstractFetcher fetcher) throws NoSuchFieldException {
 119         try {
 120             return fetcher.getClass().getDeclaredField(&quot;consumerThread&quot;);
 121         } catch (Exception e) {
 122             return fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);
 123         }
 124     }
 125 
 126     public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {
 127         this.fetcher = fetcher;
 128     }
 129 
 130     @Override
 131     public TypeInformation&lt;Row&gt; getProducedType() {
 132         return typeInfo;
 133     }
 134 }
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.source.kafka;
  19 
  20 import com.dtstack.flink.sql.format.DeserializationMetricWrapper;
  21 import java.io.IOException;
  22 import java.lang.reflect.Field;
  23 import java.util.Set;
  24 import java.util.concurrent.atomic.AtomicBoolean;
  25 import org.apache.flink.api.common.serialization.DeserializationSchema;
  26 import org.apache.flink.api.common.typeinfo.TypeInformation;
  27 import org.apache.flink.metrics.Gauge;
  28 import org.apache.flink.metrics.MetricGroup;
  29 import org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;
  30 import org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;
  31 import org.apache.flink.types.Row;
  32 import org.apache.kafka.clients.consumer.KafkaConsumer;
  33 import org.apache.kafka.clients.consumer.internals.SubscriptionState;
  34 import org.apache.kafka.common.TopicPartition;
  35 import org.slf4j.Logger;
  36 import org.slf4j.LoggerFactory;
  37 import static com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;
  38 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;
  39 import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;
  40 
  41 
  42 /**
  43  * add metric for source
  44  * &lt;p&gt;
  45  * company: www.dtstack.com
  46  * @author: toutian
  47  * create: 2019/12/24
  48  */
  49 public class KafkaDeserializationMetricWrapper extends DeserializationMetricWrapper {
  50     private static final Logger LOG = LoggerFactory.getLogger(KafkaDeserializationMetricWrapper.class);
  51 
  52     private AbstractFetcher&lt;Row, ?&gt; fetcher;
  53 
  54     private TypeInformation&lt;Row&gt; typeInfo;
  55 
  56     private AtomicBoolean firstMsg = new AtomicBoolean(true);
  57 
  58     private Calculate calculate;
  59 
<abbr title="  60     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializationSchema, Calculate calculate) {">  60     public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deðŸ”µ</abbr>
  61         super(typeInfo, deserializationSchema);
  62         this.calculate = calculate;
  63     }
  64 
  65     @Override
  66     protected void beforeDeserialize() throws IOException {
  67         super.beforeDeserialize();
  68         if (firstMsg.compareAndSet(true, false)) {
  69             try {
  70                 registerPtMetric(fetcher);
  71             } catch (Exception e) {
  72                 LOG.error(&quot;register topic partition metric error.&quot;, e);
  73             }
  74         }
  75     }
  76 
  77     protected void registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) throws Exception {
  78         Field consumerThreadField = getConsumerThreadField(fetcher);
  79         consumerThreadField.setAccessible(true);
  80         KafkaConsumerThread consumerThread = ((KafkaConsumerThread) (consumerThreadField.get(fetcher)));
<abbr title="  81         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);">  81         Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitiðŸ”µ</abbr>
  82         hasAssignedPartitionsField.setAccessible(true);
  83         // wait until assignedPartitions
  84         boolean hasAssignedPartitions = ((boolean) (hasAssignedPartitionsField.get(consumerThread)));
  85         if (!hasAssignedPartitions) {
  86             throw new RuntimeException(&quot;wait 50 secs, but not assignedPartitions&quot;);
  87         }
  88         Field consumerField = consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);
  89         consumerField.setAccessible(true);
  90         KafkaConsumer kafkaConsumer = ((KafkaConsumer) (consumerField.get(consumerThread)));
  91         Field subscriptionStateField = kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);
  92         subscriptionStateField.setAccessible(true);
  93         // topic partitions lag
<abbr title="  94         SubscriptionState subscriptionState = ((SubscriptionState) (subscriptionStateField.get(kafkaConsumer)));">  94         SubscriptionState subscriptionState = ((SubscriptionState) (subscriptionStateField.get(kafkaConsuðŸ”µ</abbr>
  95         Set&lt;TopicPartition&gt; assignedPartitions = subscriptionState.assignedPartitions();
  96         for (TopicPartition topicPartition : assignedPartitions) {
<abbr title="  97             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartition.topic()).addGroup(DT_PARTITION_GROUP, topicPartition.partition() + &quot;&quot;);">  97             MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicðŸ”µ</abbr>
  98             metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new Gauge&lt;Long&gt;() {
  99                 @Override
 100                 public Long getValue() {
 101                     return calculate.calc(subscriptionState, topicPartition);
 102                 }
 103             });
 104         }
 105     }
 106 
 107     public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {
 108         this.fetcher = fetcher;
 109     }
 110 
 111     @Override
 112     public TypeInformation&lt;Row&gt; getProducedType() {
 113         return typeInfo;
 114     }
 115 
 116     private Field getConsumerThreadField(AbstractFetcher fetcher) throws NoSuchFieldException {
 117         try {
 118             return fetcher.getClass().getDeclaredField(&quot;consumerThread&quot;);
 119         } catch (java.lang.Exception e) {
 120             return fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);
 121         }
 122     }
 123 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.source.kafka;
  20  
  21  import com.dtstack.flink.sql.format.DeserializationMetricWrapper;
  22  import org.apache.flink.api.common.serialization.DeserializationSchema;
  23  import org.apache.flink.api.common.typeinfo.TypeInformation;
  24  import org.apache.flink.metrics.Gauge;
  25  import org.apache.flink.metrics.MetricGroup;
  26  import org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;
  27  import org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;
  28  import org.apache.flink.types.Row;
  29  import org.apache.kafka.clients.consumer.KafkaConsumer;
  30  import org.apache.kafka.clients.consumer.internals.SubscriptionState;
  31  import org.apache.kafka.common.TopicPartition;
  32  import org.slf4j.Logger;
  33  import org.slf4j.LoggerFactory;
  34  
  35  import java.io.IOException;
  36  import java.lang.reflect.Field;
  37  import java.util.Set;
  38  import java.util.concurrent.atomic.AtomicBoolean;
  39  
  40  import static com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;
  41  import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;
  42  import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;
  43  
  44  /**
  45   * add metric for source
  46   * &lt;p&gt;
  47   * company: www.dtstack.com
  48   * @author: toutian
  49   * create: 2019/12/24
  50   */
  51  public class KafkaDeserializationMetricWrapper extends DeserializationMetricWrapper {
  52  
  53      private static final Logger LOG = LoggerFactory.getLogger(KafkaDeserializationMetricWrapper.class);
  54  
  55      private AbstractFetcher&lt;Row, ?&gt; fetcher;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  56 +    private TypeInformation&lt;Row&gt; typeInfo;</span>
  57  
  58      private AtomicBoolean firstMsg = new AtomicBoolean(true);
  59  
  60      private Calculate calculate;
  61  
<abbr title="  62      public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializationSchema, Calculate calculate) {">  62      public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializaðŸ”µ</abbr>
  63          super(typeInfo, deserializationSchema);
  64          this.calculate = calculate;
  65      }
  66  
  67      @Override
  68      protected void beforeDeserialize() throws IOException {
  69          super.beforeDeserialize();
  70          if (firstMsg.compareAndSet(true, false)) {
  71              try {
  72                  registerPtMetric(fetcher);
  73              } catch (Exception e) {
  74                  LOG.error(&quot;register topic partition metric error.&quot;, e);
  75              }
  76          }
  77      }
  78  
  79      protected void registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) throws Exception {
  80  
  81          Field consumerThreadField = getConsumerThreadField(fetcher);
  82          consumerThreadField.setAccessible(true);
  83          KafkaConsumerThread consumerThread = (KafkaConsumerThread) consumerThreadField.get(fetcher);
  84  
  85          Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);
  86          hasAssignedPartitionsField.setAccessible(true);
  87  
  88          //wait until assignedPartitions
  89  
  90          boolean hasAssignedPartitions = (boolean) hasAssignedPartitionsField.get(consumerThread);
  91  
  92          if (!hasAssignedPartitions) {
  93              throw new RuntimeException(&quot;wait 50 secs, but not assignedPartitions&quot;);
  94          }
  95  
  96          Field consumerField = consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);
  97          consumerField.setAccessible(true);
  98  
  99          KafkaConsumer kafkaConsumer = (KafkaConsumer) consumerField.get(consumerThread);
 100          Field subscriptionStateField = kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);
 101          subscriptionStateField.setAccessible(true);
 102  
 103          //topic partitions lag
 104          SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumer);
 105          Set&lt;TopicPartition&gt; assignedPartitions = subscriptionState.assignedPartitions();
 106  
 107          for (TopicPartition topicPartition : assignedPartitions) {
<abbr title=" 108              MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartition.topic())"> 108              MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartitionðŸ”µ</abbr>
 109                      .addGroup(DT_PARTITION_GROUP, topicPartition.partition() + &quot;&quot;);
 110              metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new Gauge&lt;Long&gt;() {
 111                  @Override
 112                  public Long getValue() {
 113                      return calculate.calc(subscriptionState, topicPartition);
 114                  }
 115              });
 116          }
 117      }
 118  
 119      private Field getConsumerThreadField(AbstractFetcher&lt;Row, ?&gt; fetcher) throws NoSuchFieldException {





 120          try {
 121              return fetcher.getClass().getDeclaredField(&quot;consumerThread&quot;);
 122          } catch (Exception e) {
 123              return fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);
 124          }
 125      }
 126  
 127      public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {
 128          this.fetcher = fetcher;
 129      }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 130 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 131 +    @Override</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 132 +    public TypeInformation&lt;Row&gt; getProducedType() {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 133 +        return typeInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 134 +    }</span>
 135  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.source.kafka;
  20  
  21  import com.dtstack.flink.sql.format.DeserializationMetricWrapper;
  22  import org.apache.flink.api.common.serialization.DeserializationSchema;
  23  import org.apache.flink.api.common.typeinfo.TypeInformation;
  24  import org.apache.flink.metrics.Gauge;
  25  import org.apache.flink.metrics.MetricGroup;
  26  import org.apache.flink.streaming.connectors.kafka.internal.KafkaConsumerThread;
  27  import org.apache.flink.streaming.connectors.kafka.internals.AbstractFetcher;
  28  import org.apache.flink.types.Row;
  29  import org.apache.kafka.clients.consumer.KafkaConsumer;
  30  import org.apache.kafka.clients.consumer.internals.SubscriptionState;
  31  import org.apache.kafka.common.TopicPartition;
  32  import org.slf4j.Logger;
  33  import org.slf4j.LoggerFactory;
  34  
  35  import java.io.IOException;
  36  import java.lang.reflect.Field;
  37  import java.util.Set;
  38  import java.util.concurrent.atomic.AtomicBoolean;
  39  
  40  import static com.dtstack.flink.sql.metric.MetricConstant.DT_PARTITION_GROUP;
  41  import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_GROUP;
  42  import static com.dtstack.flink.sql.metric.MetricConstant.DT_TOPIC_PARTITION_LAG_GAUGE;
  43  
  44  /**
  45   * add metric for source
  46   * &lt;p&gt;
  47   * company: www.dtstack.com
  48   * @author: toutian
  49   * create: 2019/12/24
  50   */
  51  public class KafkaDeserializationMetricWrapper extends DeserializationMetricWrapper {
  52  
  53      private static final Logger LOG = LoggerFactory.getLogger(KafkaDeserializationMetricWrapper.class);
  54  
  55      private AbstractFetcher&lt;Row, ?&gt; fetcher;

  56  
  57      private AtomicBoolean firstMsg = new AtomicBoolean(true);
  58  
  59      private Calculate calculate;
  60  
<abbr title="  61      public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializationSchema, Calculate calculate) {">  61      public KafkaDeserializationMetricWrapper(TypeInformation&lt;Row&gt; typeInfo, DeserializationSchema&lt;Row&gt; deserializaðŸ”µ</abbr>
  62          super(typeInfo, deserializationSchema);
  63          this.calculate = calculate;
  64      }
  65  
  66      @Override
  67      protected void beforeDeserialize() throws IOException {
  68          super.beforeDeserialize();
  69          if (firstMsg.compareAndSet(true, false)) {
  70              try {
  71                  registerPtMetric(fetcher);
  72              } catch (Exception e) {
  73                  LOG.error(&quot;register topic partition metric error.&quot;, e);
  74              }
  75          }
  76      }
  77  
  78      protected void registerPtMetric(AbstractFetcher&lt;Row, ?&gt; fetcher) throws Exception {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  79 -</span>
  80          Field consumerThreadField = getConsumerThreadField(fetcher);
  81          consumerThreadField.setAccessible(true);
  82          KafkaConsumerThread consumerThread = (KafkaConsumerThread) consumerThreadField.get(fetcher);
  83  
  84          Field hasAssignedPartitionsField = consumerThread.getClass().getDeclaredField(&quot;hasAssignedPartitions&quot;);
  85          hasAssignedPartitionsField.setAccessible(true);
  86  
  87          //wait until assignedPartitions
  88  
  89          boolean hasAssignedPartitions = (boolean) hasAssignedPartitionsField.get(consumerThread);
  90  
  91          if (!hasAssignedPartitions) {
  92              throw new RuntimeException(&quot;wait 50 secs, but not assignedPartitions&quot;);
  93          }
  94  
  95          Field consumerField = consumerThread.getClass().getDeclaredField(&quot;consumer&quot;);
  96          consumerField.setAccessible(true);
  97  
  98          KafkaConsumer kafkaConsumer = (KafkaConsumer) consumerField.get(consumerThread);
  99          Field subscriptionStateField = kafkaConsumer.getClass().getDeclaredField(&quot;subscriptions&quot;);
 100          subscriptionStateField.setAccessible(true);
 101  
 102          //topic partitions lag
 103          SubscriptionState subscriptionState = (SubscriptionState) subscriptionStateField.get(kafkaConsumer);
 104          Set&lt;TopicPartition&gt; assignedPartitions = subscriptionState.assignedPartitions();
 105  
 106          for (TopicPartition topicPartition : assignedPartitions) {
<abbr title=" 107              MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartition.topic())"> 107              MetricGroup metricGroup = getRuntimeContext().getMetricGroup().addGroup(DT_TOPIC_GROUP, topicPartitionðŸ”µ</abbr>
 108                      .addGroup(DT_PARTITION_GROUP, topicPartition.partition() + &quot;&quot;);
 109              metricGroup.gauge(DT_TOPIC_PARTITION_LAG_GAUGE, new Gauge&lt;Long&gt;() {
 110                  @Override
 111                  public Long getValue() {
 112                      return calculate.calc(subscriptionState, topicPartition);
 113                  }
 114              });
 115          }
 116      }
 117  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 118 -    private Field getConsumerThreadField(AbstractFetcher&lt;Row, ?&gt; fetcher) throws NoSuchFieldException {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 119 +    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 120 +        this.fetcher = fetcher;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 121 +    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 122 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 123 +    private Field getConsumerThreadField(AbstractFetcher fetcher) throws NoSuchFieldException {</span>
 124          try {
 125              return fetcher.getClass().getDeclaredField(&quot;consumerThread&quot;);
 126          } catch (Exception e) {
 127              return fetcher.getClass().getSuperclass().getDeclaredField(&quot;consumerThread&quot;);
 128          }
 129      }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 130 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 131 -    public void setFetcher(AbstractFetcher&lt;Row, ?&gt; fetcher) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 132 -        this.fetcher = fetcher;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 133 -    }</span>





 134  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            