<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>395</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    395
                    <a href="394.html">prev</a>
                    <a href="396.html">next</a>
                    <a href="395_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_525f07e4c1a4304fab84614e5693bf3a6bfc4246_rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;525f07e4c1a4304fab84614e5693bf3a6bfc4246:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;525f07e4c1a4304fab84614e5693bf3a6bfc4246^1:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;525f07e4c1a4304fab84614e5693bf3a6bfc4246^2:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;f063639d1975f59523e41f325d59d2fcf27a9f34:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [b], [j]], subset: [[bj], [b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.api.java.tuple.Tuple2;
  23 import org.apache.flink.configuration.Configuration;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 
  27 
  28 import com.dtstack.flink.sql.side.BaseAllReqRow;
  29 import com.dtstack.flink.sql.side.BaseSideInfo;
  30 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  31 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  32 import com.google.common.collect.Lists;
  33 import com.google.common.collect.Maps;
  34 import org.apache.calcite.sql.JoinType;
  35 import org.apache.commons.collections.CollectionUtils;
  36 import org.apache.commons.lang3.StringUtils;
  37 import org.apache.flink.util.Collector;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 import java.time.LocalDateTime;
  48 import java.util.Calendar;
  49 import java.util.List;
  50 import java.util.Map;
  51 import java.util.concurrent.atomic.AtomicReference;
  52 import java.util.stream.Collectors;
  53 
  54 /**
  55  * side operator with cache for all(period reload)
  56  * Date: 2018/11/26
  57  * Company: www.dtstack.com
  58  *
  59  * @author maqi
  60  */
  61 
  62 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  63 
  64     private static final long serialVersionUID = 2098635140857937718L;
  65 
  66     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  67 
  68     private static final int CONN_RETRY_NUM = 3;
  69 
  70     private static final int DEFAULT_FETCH_SIZE = 1000;
  71 
  72     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73 
  74     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  75         super(sideInfo);
  76     }
  77 
  78     @Override
  79     public void open(Configuration parameters) throws Exception {
  80         super.open(parameters);
  81         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  82         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  83     }
  84 
  85 
  86     @Override
  87     protected void initCache() throws SQLException {
  88         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  89         cacheRef.set(newCache);
  90         loadData(newCache);
  91     }
  92 
  93     @Override
  94     protected void reloadCache() {
  95         //reload cacheRef and replace to old cacheRef
  96         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  97         try {
  98             loadData(newCache);
  99         } catch (SQLException e) {
 100             throw new RuntimeException(e);
 101         }
 102         cacheRef.set(newCache);
 103         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 104     }
 105 
 106     @Override
 107     public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 108         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 109         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 110                 .map(value.f1::getField)
 111                 .filter(object -&gt; null != object)
 112                 .collect(Collectors.toCollection(ArrayList::new));
 113 
 114         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 115             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 116             return;
 117         }
 118 
 119         String cacheKey = inputParams.stream()
 120                 .map(Object::toString)
 121                 .collect(Collectors.joining(&quot;_&quot;));
 122 
 123         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 124         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 125 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 126             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
 127 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 128             out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 129         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 130 </span>
 131 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 132             out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 133         } else if (!CollectionUtils.isEmpty(cacheList)) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 134             cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 135 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 136         }
 137 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 138 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 139         cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 140 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 141 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 142         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 143 =======
 144 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 145     }
 146 
 147     @Override
 148     public Row fillData(Row input, Object sideInput) {
 149         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 150         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 151 
 152         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 153             // origin value
 154             Object obj = input.getField(entry.getValue());
<abbr title=" 155             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 155             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 156             row.setField(entry.getKey(), obj);
 157         }
 158 
 159         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 160             if (cacheInfo == null) {
 161                 row.setField(entry.getKey(), null);
 162             } else {
 163                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 164             }
 165 
 166         }
 167         return row;
 168     }
 169 
 170     /**
 171      * covert flink time attribute.Type information for indicating event or processing time.
 172      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 173      *
 174      * @param entry
 175      * @param obj
 176      * @return
 177      */
 178     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 179         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 180         if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 181             obj = Timestamp.valueOf(((LocalDateTime) obj));
 182         }
 183         return obj;
 184     }
 185 
 186     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 187         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 188         Connection connection = null;
 189 
 190         try {
 191             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 192                 try {
<abbr title=" 193                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 193                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 194                     break;
 195                 } catch (Exception e) {
 196                     if (i == CONN_RETRY_NUM - 1) {
 197                         throw new RuntimeException(&quot;&quot;, e);
 198                     }
 199                     try {
<abbr title=" 200                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 200                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 201                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 202                         Thread.sleep(5 * 1000);
 203                     } catch (InterruptedException e1) {
 204                         LOG.error(&quot;&quot;, e1);
 205                     }
 206                 }
 207             }
 208             queryAndFillData(tmpCache, connection);
 209         } catch (Exception e) {
 210             LOG.error(&quot;&quot;, e);
 211             throw new SQLException(e);
 212         } finally {
 213             if (connection != null) {
 214                 connection.close();
 215             }
 216         }
 217     }
 218 
<abbr title=" 219     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 219     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 220         //load data from table
 221         String sql = sideInfo.getSqlCondition();
 222         Statement statement = connection.createStatement();
 223         statement.setFetchSize(getFetchSize());
 224         ResultSet resultSet = statement.executeQuery(sql);
 225 
 226         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 227         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 228         while (resultSet.next()) {
 229             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 230             for (String fieldName : sideFieldNames) {
 231                 Object object = resultSet.getObject(fieldName.trim());
 232                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 233                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 234                 oneRow.put(fieldName.trim(), object);
 235             }
 236 
 237             String cacheKey = sideInfo.getEqualFieldList().stream()
 238                     .map(equalField -&gt; oneRow.get(equalField))
 239                     .map(Object::toString)
 240                     .collect(Collectors.joining(&quot;_&quot;));
 241 
 242             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 243                     .add(oneRow);
 244         }
 245     }
 246 
 247     public int getFetchSize() {
 248         return DEFAULT_FETCH_SIZE;
 249     }
 250 
 251     /**
 252      * get jdbc connection
 253      *
 254      * @param dbURL
 255      * @param userName
 256      * @param password
 257      * @return
 258      */
 259     public abstract Connection getConn(String dbURL, String userName, String password);
 260 
 261 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.api.java.tuple.Tuple2;
  23 import org.apache.flink.configuration.Configuration;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 import org.apache.flink.util.Collector;
  27 
  28 
  29 import com.dtstack.flink.sql.side.BaseAllReqRow;
  30 import com.dtstack.flink.sql.side.BaseSideInfo;
  31 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33 import com.google.common.collect.Lists;
  34 import com.google.common.collect.Maps;
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.CollectionUtils;
  37 import org.apache.commons.lang3.StringUtils;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 import java.time.LocalDateTime;
  48 import java.util.List;
  49 import java.util.Map;
  50 import java.util.Calendar;
  51 import java.util.concurrent.atomic.AtomicReference;
  52 import java.util.stream.Collectors;
  53 
  54 /**
  55  * side operator with cache for all(period reload)
  56  * Date: 2018/11/26
  57  * Company: www.dtstack.com
  58  *
  59  * @author maqi
  60  */
  61 
  62 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  63 
  64     private static final long serialVersionUID = 2098635140857937718L;
  65 
  66     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  67 
  68     private static final int CONN_RETRY_NUM = 3;
  69 
  70     private static final int DEFAULT_FETCH_SIZE = 1000;
  71 
  72     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73 
  74     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  75         super(sideInfo);
  76     }
  77 
  78     @Override
  79     public void open(Configuration parameters) throws Exception {
  80         super.open(parameters);
  81         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  82         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  83     }
  84 
  85 
  86     @Override
  87     protected void initCache() throws SQLException {
  88         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  89         cacheRef.set(newCache);
  90         loadData(newCache);
  91     }
  92 
  93     @Override
  94     protected void reloadCache() {
  95         //reload cacheRef and replace to old cacheRef
  96         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  97         try {
  98             loadData(newCache);
  99         } catch (SQLException e) {
 100             throw new RuntimeException(e);
 101         }
 102         cacheRef.set(newCache);
 103         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 104     }
 105 
 106     @Override
 107     public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 108         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 109         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 110                 .map(value.f1::getField)
 111                 .filter(object -&gt; null != object)
 112                 .collect(Collectors.toCollection(ArrayList::new));
 113 
 114         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 115             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 116             return;
 117         }
 118 
 119         String cacheKey = inputParams.stream()
 120                 .map(Object::toString)
 121                 .collect(Collectors.joining(&quot;_&quot;));
 122 
 123         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 124         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 125 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 126             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 127         }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 128 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 129         cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 130 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 131             out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 132         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 133 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 134         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 135 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 136             out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 137         } else if (!CollectionUtils.isEmpty(cacheList)) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 138             cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 139 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 140     }
 141     }
 142 
 143     @Override
 144     public Row fillData(Row input, Object sideInput) {
 145         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 146         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 147 
 148         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 149             // origin value
 150             Object obj = input.getField(entry.getValue());
<abbr title=" 151             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 151             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 152             row.setField(entry.getKey(), obj);
 153         }
 154 
 155         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 156             if (cacheInfo == null) {
 157                 row.setField(entry.getKey(), null);
 158             } else {
 159                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 160             }
 161 
 162         }
 163         return row;
 164     }
 165 
 166     /**
 167      * covert flink time attribute.Type information for indicating event or processing time.
 168      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 169      *
 170      * @param entry
 171      * @param obj
 172      * @return
 173      */
 174     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 175         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 176         if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 177             obj = Timestamp.valueOf(((LocalDateTime) obj));
 178         }
 179         return obj;
 180     }
 181 
 182     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 183         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 184         Connection connection = null;
 185 
 186         try {
 187             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 188                 try {
<abbr title=" 189                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 189                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 190                     break;
 191                 } catch (Exception e) {
 192                     if (i == CONN_RETRY_NUM - 1) {
 193                         throw new RuntimeException(&quot;&quot;, e);
 194                     }
 195                     try {
<abbr title=" 196                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 196                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 197                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 198                         Thread.sleep(5 * 1000);
 199                     } catch (InterruptedException e1) {
 200                         LOG.error(&quot;&quot;, e1);
 201                     }
 202                 }
 203             }
 204             queryAndFillData(tmpCache, connection);
 205         } catch (Exception e) {
 206             LOG.error(&quot;&quot;, e);
 207             throw new SQLException(e);
 208         } finally {
 209             if (connection != null) {
 210                 connection.close();
 211             }
 212         }
 213     }
 214 
<abbr title=" 215     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 215     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 216         //load data from table
 217         String sql = sideInfo.getSqlCondition();
 218         Statement statement = connection.createStatement();
 219         statement.setFetchSize(getFetchSize());
 220         ResultSet resultSet = statement.executeQuery(sql);
 221 
 222         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 223         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 224         while (resultSet.next()) {
 225             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 226             for (String fieldName : sideFieldNames) {
 227                 Object object = resultSet.getObject(fieldName.trim());
 228                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 229                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 230                 oneRow.put(fieldName.trim(), object);
 231             }
 232 
 233             String cacheKey = sideInfo.getEqualFieldList().stream()
 234                     .map(equalField -&gt; oneRow.get(equalField))
 235                     .map(Object::toString)
 236                     .collect(Collectors.joining(&quot;_&quot;));
 237 
 238             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 239                     .add(oneRow);
 240         }
 241     }
 242 
 243     public int getFetchSize() {
 244         return DEFAULT_FETCH_SIZE;
 245     }
 246 
 247     /**
 248      * get jdbc connection
 249      *
 250      * @param dbURL
 251      * @param userName
 252      * @param password
 253      * @return
 254      */
 255     public abstract Connection getConn(String dbURL, String userName, String password);
 256 
 257 }
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.rdb.all;
  19 
  20 import com.dtstack.flink.sql.side.BaseAllReqRow;
  21 import com.dtstack.flink.sql.side.BaseSideInfo;
  22 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  23 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  24 import com.google.common.collect.Lists;
  25 import com.google.common.collect.Maps;
  26 import java.sql.Connection;
  27 import java.sql.ResultSet;
  28 import java.sql.SQLException;
  29 import java.sql.Statement;
  30 import java.sql.Timestamp;
  31 import java.time.LocalDateTime;
  32 import java.util.ArrayList;
  33 import java.util.Calendar;
  34 import java.util.List;
  35 import java.util.Map;
  36 import java.util.concurrent.atomic.AtomicReference;
  37 import java.util.stream.Collectors;
  38 import org.apache.calcite.sql.JoinType;
  39 import org.apache.commons.collections.CollectionUtils;
  40 import org.apache.commons.lang3.StringUtils;
  41 import org.apache.flink.api.common.typeinfo.TypeInformation;
  42 import org.apache.flink.api.java.tuple.Tuple2;
  43 import org.apache.flink.configuration.Configuration;
  44 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  45 import org.apache.flink.types.Row;
  46 import org.apache.flink.util.Collector;
  47 import org.slf4j.Logger;
  48 import org.slf4j.LoggerFactory;
  49 
  50 
  51 /**
  52  * side operator with cache for all(period reload)
  53  * Date: 2018/11/26
  54  * Company: www.dtstack.com
  55  *
  56  * @author maqi
  57  */
  58 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  59     private static final long serialVersionUID = 2098635140857937718L;
  60 
  61     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  62 
  63     private static final int CONN_RETRY_NUM = 3;
  64 
  65     private static final int DEFAULT_FETCH_SIZE = 1000;
  66 
  67     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  68 
  69     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  70         super(sideInfo);
  71     }
  72 
  73     @Override
  74     public void open(Configuration parameters) throws Exception {
  75         super.open(parameters);
  76         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  77         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  78     }
  79 
  80     @Override
  81     protected void initCache() throws SQLException {
  82         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  83         cacheRef.set(newCache);
  84         loadData(newCache);
  85     }
  86 
  87     @Override
  88     protected void reloadCache() {
  89         // reload cacheRef and replace to old cacheRef
  90         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  91         try {
  92             loadData(newCache);
  93         } catch (SQLException e) {
  94             throw new RuntimeException(e);
  95         }
  96         cacheRef.set(newCache);
  97         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
  98     }
  99 
 100     @Override
<abbr title=" 101     public void flatMap(Tuple2&lt;Boolean, Row&gt; value, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception {"> 101     public void flatMap(Tuple2&lt;Boolean, Row&gt; value, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception🔵</abbr>
 102         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
<abbr title=" 103         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.f1::getField).filter(( object) -&gt; null != object).collect(Collectors.toCollection(ArrayList::new));"> 103         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.f1::getField).filter(( object) -🔵</abbr>
 104         if ((inputParams.size() != equalValIndex.size()) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 105             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 106             return;
 107         }
 108         String cacheKey = inputParams.stream().map(Object::toString).collect(Collectors.joining(&quot;_&quot;));
 109         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 110         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 111             out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));
 112         } else if (!CollectionUtils.isEmpty(cacheList)) {
<abbr title=" 113             cacheList.stream().forEach(( one) -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));"> 113             cacheList.stream().forEach(( one) -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null)🔵</abbr>
 114         }
 115     }
 116 
 117     @Override
 118     public Row fillData(Row input, Object sideInput) {
 119         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 120         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 121 
 122         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 123             // origin value
 124             Object obj = input.getField(entry.getValue());
<abbr title=" 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),🔵</abbr>
 126             row.setField(entry.getKey(), obj);
 127         }
 128 
 129         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 130             if (cacheInfo == null) {
 131                 row.setField(entry.getKey(), null);
 132             } else {
 133                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 134             }
 135 
 136         }
 137         return row;
 138     }
 139 
 140     /**
 141      * covert flink time attribute.Type information for indicating event or processing time.
 142      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 143      *
 144      * @param entry
 145      *
 146      * @param obj
 147      *
 148      * @return
 149      */
 150     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 151         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 152         if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
 153             obj = Timestamp.valueOf(((LocalDateTime) (obj)));
 154         }
 155         return obj;
 156     }
 157 
 158     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 159         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 160         Connection connection = null;
 161 
 162         try {
 163             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 164                 try {
<abbr title=" 165                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 165                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswo🔵</abbr>
 166                     break;
 167                 } catch (Exception e) {
 168                     if (i == CONN_RETRY_NUM - 1) {
 169                         throw new RuntimeException(&quot;&quot;, e);
 170                     }
 171                     try {
<abbr title=" 172                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 172                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserN🔵</abbr>
 173                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 174                         Thread.sleep(5 * 1000);
 175                     } catch (InterruptedException e1) {
 176                         LOG.error(&quot;&quot;, e1);
 177                     }
 178                 }
 179             }
 180             queryAndFillData(tmpCache, connection);
 181         } catch (Exception e) {
 182             LOG.error(&quot;&quot;, e);
 183             throw new SQLException(e);
 184         } finally {
 185             if (connection != null) {
 186                 connection.close();
 187             }
 188         }
 189     }
 190 
<abbr title=" 191     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 191     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)🔵</abbr>
 192         // load data from table
 193         String sql = sideInfo.getSqlCondition();
 194         Statement statement = connection.createStatement();
 195         statement.setFetchSize(getFetchSize());
 196         ResultSet resultSet = statement.executeQuery(sql);
 197         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 198         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 199         while (resultSet.next()) {
 200             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 201             for (String fieldName : sideFieldNames) {
 202                 Object object = resultSet.getObject(fieldName.trim());
 203                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 204                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 205                 oneRow.put(fieldName.trim(), object);
 206             }
<abbr title=" 207             String cacheKey = sideInfo.getEqualFieldList().stream().map(( equalField) -&gt; oneRow.get(equalField)).map(Object::toString).collect(Collectors.joining(&quot;_&quot;));"> 207             String cacheKey = sideInfo.getEqualFieldList().stream().map(( equalField) -&gt; oneRow.get(equal🔵</abbr>
 208             tmpCache.computeIfAbsent(cacheKey, ( key) -&gt; Lists.newArrayList()).add(oneRow);
 209         }
 210     }
 211 
 212     public int getFetchSize() {
 213         return DEFAULT_FETCH_SIZE;
 214     }
 215 
 216     /**
 217      *  get jdbc connection
 218      * @param dbURL
 219      * @param userName
 220      * @param password
 221      * @return
 222      */
 223     public abstract Connection getConn(String dbURL, String userName, String password);
 224 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  22 +import org.apache.flink.api.java.tuple.Tuple2;</span>
  23  import org.apache.flink.configuration.Configuration;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import org.apache.flink.table.runtime.types.CRow;</span>
  25  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  26  import org.apache.flink.types.Row;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  27 -import org.apache.flink.util.Collector;</span>
  28  
  29  
  30  import com.dtstack.flink.sql.side.BaseAllReqRow;
  31  import com.dtstack.flink.sql.side.BaseSideInfo;
  32  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  33  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  34  import com.google.common.collect.Lists;
  35  import com.google.common.collect.Maps;
  36  import org.apache.calcite.sql.JoinType;
  37  import org.apache.commons.collections.CollectionUtils;
  38  import org.apache.commons.lang3.StringUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  39 +import org.apache.flink.util.Collector;</span>
  40  import org.slf4j.Logger;
  41  import org.slf4j.LoggerFactory;
  42  
  43  import java.sql.Connection;
  44  import java.sql.ResultSet;
  45  import java.sql.SQLException;
  46  import java.sql.Statement;
  47  import java.sql.Timestamp;
  48  import java.util.ArrayList;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  49 +import java.time.LocalDateTime;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import java.util.Calendar;</span>
  51  import java.util.List;
  52  import java.util.Map;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  53 -import java.util.Objects;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  54 -import java.util.Calendar;</span>
  55  import java.util.concurrent.atomic.AtomicReference;
  56  import java.util.stream.Collectors;
  57  
  58  /**
  59   * side operator with cache for all(period reload)
  60   * Date: 2018/11/26
  61   * Company: www.dtstack.com
  62   *
  63   * @author maqi
  64   */
  65  
  66  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  67  
  68      private static final long serialVersionUID = 2098635140857937718L;
  69  
  70      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  71  
  72      private static final int CONN_RETRY_NUM = 3;
  73  
  74      private static final int DEFAULT_FETCH_SIZE = 1000;
  75  
  76      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  77  
  78      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  79          super(sideInfo);
  80      }
  81  
  82      @Override
  83      public void open(Configuration parameters) throws Exception {
  84          super.open(parameters);
  85          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  86          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  87      }
  88  
  89  
  90      @Override
  91      protected void initCache() throws SQLException {
  92          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  93          cacheRef.set(newCache);
  94          loadData(newCache);
  95      }
  96  
  97      @Override
  98      protected void reloadCache() {
  99          //reload cacheRef and replace to old cacheRef
 100          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
 101          cacheRef.set(newCache);
 102          try {
 103              loadData(newCache);
 104          } catch (SQLException e) {
 105              throw new RuntimeException(e);
 106          }

 107          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 108      }
 109  
 110      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 111 -    public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 112 +    public void flatMap(Tuple2&lt;Boolean,Row&gt; value, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {</span>
 113          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 114          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 115 -                .map(value.row()::getField)</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 116 -                .filter(Objects::nonNull)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 117 +                .map(value.f1::getField)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 118 +                .filter(object -&gt; null != object)</span>
 119                  .collect(Collectors.toCollection(ArrayList::new));
 120  
 121          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 122 -            out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 123 +            out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
 124              return;
 125          }
 126  
 127          String cacheKey = inputParams.stream()
 128                  .map(Object::toString)
 129                  .collect(Collectors.joining(&quot;_&quot;));
 130  
 131          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 132          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 133 -            out.collect(new CRow(fillData(value.row(), null), value.change()));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 134 -        }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 135 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 136 -        cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 137 +            out.collect(Tuple2.of(value.f0, fillData(value.f1, null)));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 138 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 139 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 140 +        cacheList.stream().forEach(one -&gt; out.collect(Tuple2.of(value.f0, fillData(value.f1, null))));</span>
 141      }
 142  
 143      @Override
 144      public Row fillData(Row input, Object sideInput) {
 145          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 146          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 147  
 148          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 149              // origin value
 150              Object obj = input.getField(entry.getValue());
 151              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 152              row.setField(entry.getKey(), obj);
 153          }
 154  
 155          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 156              if (cacheInfo == null) {
 157                  row.setField(entry.getKey(), null);
 158              } else {
 159                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 160              }
 161  
 162          }
 163          return row;
 164      }
 165  
 166      /**
 167       *  covert flink time attribute.Type information for indicating event or processing time.
 168       *  However, it behaves like a regular SQL timestamp but is serialized as Long.


 169       *
 170       * @param entry
 171       * @param obj
 172       * @return
 173       */
 174      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 175          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 176 -        if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 177 -            obj = ((Timestamp) obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 178 +        if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 179 +            obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 180          }
 181          return obj;
 182      }
 183  
 184      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 185          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 186          Connection connection = null;
 187  
 188          try {
 189              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 190                  try {
 191                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 192                      break;
 193                  } catch (Exception e) {
 194                      if (i == CONN_RETRY_NUM - 1) {
 195                          throw new RuntimeException(&quot;&quot;, e);
 196                      }
 197                      try {
<abbr title=" 198                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 198                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;🔵</abbr>
 199                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 200                          Thread.sleep(5 * 1000);
 201                      } catch (InterruptedException e1) {
 202                          LOG.error(&quot;&quot;, e1);
 203                      }
 204                  }
 205              }
 206              queryAndFillData(tmpCache, connection);
 207          } catch (Exception e) {
 208              LOG.error(&quot;&quot;, e);
 209              throw new SQLException(e);
 210          } finally {
 211              if (connection != null) {
 212                  connection.close();
 213              }
 214          }
 215      }
 216  
<abbr title=" 217      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 217      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws S🔵</abbr>
 218          //load data from table
 219          String sql = sideInfo.getSqlCondition();
 220          Statement statement = connection.createStatement();
 221          statement.setFetchSize(getFetchSize());
 222          ResultSet resultSet = statement.executeQuery(sql);
 223  
 224          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 225          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 226          while (resultSet.next()) {
 227              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 228              for (String fieldName : sideFieldNames) {
 229                  Object object = resultSet.getObject(fieldName.trim());
 230                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 231                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 232                  oneRow.put(fieldName.trim(), object);
 233              }
 234  
 235              String cacheKey = sideInfo.getEqualFieldList().stream()
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 236 -                    .map(oneRow::get)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 237 +                    .map(equalField -&gt; oneRow.get(equalField))</span>
 238                      .map(Object::toString)
 239                      .collect(Collectors.joining(&quot;_&quot;));
 240  
 241              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 242                      .add(oneRow);
 243          }
 244      }
 245  
 246      public int getFetchSize() {
 247          return DEFAULT_FETCH_SIZE;
 248      }
 249  
 250      /**
 251       *  get jdbc connection


 252       * @param dbURL
 253       * @param userName
 254       * @param password
 255       * @return
 256       */
 257      public abstract Connection getConn(String dbURL, String userName, String password);
 258  
 259  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;

  22  import org.apache.flink.configuration.Configuration;
  23  import org.apache.flink.table.runtime.types.CRow;
  24  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25  import org.apache.flink.types.Row;
  26  import org.apache.flink.util.Collector;
  27  
  28  
  29  import com.dtstack.flink.sql.side.BaseAllReqRow;
  30  import com.dtstack.flink.sql.side.BaseSideInfo;
  31  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33  import com.google.common.collect.Lists;
  34  import com.google.common.collect.Maps;
  35  import org.apache.calcite.sql.JoinType;
  36  import org.apache.commons.collections.CollectionUtils;
  37  import org.apache.commons.lang3.StringUtils;

  38  import org.slf4j.Logger;
  39  import org.slf4j.LoggerFactory;
  40  
  41  import java.sql.Connection;
  42  import java.sql.ResultSet;
  43  import java.sql.SQLException;
  44  import java.sql.Statement;
  45  import java.sql.Timestamp;
  46  import java.util.ArrayList;


  47  import java.util.List;
  48  import java.util.Map;
  49  import java.util.Objects;
  50  import java.util.Calendar;
  51  import java.util.concurrent.atomic.AtomicReference;
  52  import java.util.stream.Collectors;
  53  
  54  /**
  55   * side operator with cache for all(period reload)
  56   * Date: 2018/11/26
  57   * Company: www.dtstack.com
  58   *
  59   * @author maqi
  60   */
  61  
  62  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  63  
  64      private static final long serialVersionUID = 2098635140857937718L;
  65  
  66      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  67  
  68      private static final int CONN_RETRY_NUM = 3;
  69  
  70      private static final int DEFAULT_FETCH_SIZE = 1000;
  71  
  72      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73  
  74      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  75          super(sideInfo);
  76      }
  77  
  78      @Override
  79      public void open(Configuration parameters) throws Exception {
  80          super.open(parameters);
  81          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  82          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  83      }
  84  
  85  
  86      @Override
  87      protected void initCache() throws SQLException {
  88          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  89          cacheRef.set(newCache);
  90          loadData(newCache);
  91      }
  92  
  93      @Override
  94      protected void reloadCache() {
  95          //reload cacheRef and replace to old cacheRef
  96          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  97 -        cacheRef.set(newCache);</span>
  98          try {
  99              loadData(newCache);
 100          } catch (SQLException e) {
 101              throw new RuntimeException(e);
 102          }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 103 +        cacheRef.set(newCache);</span>
 104          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 105      }
 106  
 107      @Override
 108      public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {

 109          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 110          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 111                  .map(value.row()::getField)
 112                  .filter(Objects::nonNull)


 113                  .collect(Collectors.toCollection(ArrayList::new));
 114  
 115          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 116              out.collect(new CRow(fillData(value.row(), null), value.change()));

 117              return;
 118          }
 119  
 120          String cacheKey = inputParams.stream()
 121                  .map(Object::toString)
 122                  .collect(Collectors.joining(&quot;_&quot;));
 123  
 124          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 125          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 126              out.collect(new CRow(fillData(value.row(), null), value.change()));
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 127 -        }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 128 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 129 -        cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 130 +        } else if (!CollectionUtils.isEmpty(cacheList)) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 131 +            cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 132 +        }</span>

 133      }
 134  
 135      @Override
 136      public Row fillData(Row input, Object sideInput) {
 137          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 138          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 139  
 140          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 141              // origin value
 142              Object obj = input.getField(entry.getValue());
 143              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 144              row.setField(entry.getKey(), obj);
 145          }
 146  
 147          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 148              if (cacheInfo == null) {
 149                  row.setField(entry.getKey(), null);
 150              } else {
 151                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 152              }
 153  
 154          }
 155          return row;
 156      }
 157  
 158      /**
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 159 -     *  covert flink time attribute.Type information for indicating event or processing time.</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 160 -     *  However, it behaves like a regular SQL timestamp but is serialized as Long.</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 161 +     * covert flink time attribute.Type information for indicating event or processing time.</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 162 +     * However, it behaves like a regular SQL timestamp but is serialized as Long.</span>
 163       *
 164       * @param entry
 165       * @param obj
 166       * @return
 167       */
 168      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 169          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 170          if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 171              obj = ((Timestamp) obj).getTime();


 172          }
 173          return obj;
 174      }
 175  
 176      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 177          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 178          Connection connection = null;
 179  
 180          try {
 181              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 182                  try {
 183                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 184                      break;
 185                  } catch (Exception e) {
 186                      if (i == CONN_RETRY_NUM - 1) {
 187                          throw new RuntimeException(&quot;&quot;, e);
 188                      }
 189                      try {
<abbr title=" 190                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 190                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;🔵</abbr>
 191                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 192                          Thread.sleep(5 * 1000);
 193                      } catch (InterruptedException e1) {
 194                          LOG.error(&quot;&quot;, e1);
 195                      }
 196                  }
 197              }
 198              queryAndFillData(tmpCache, connection);
 199          } catch (Exception e) {
 200              LOG.error(&quot;&quot;, e);
 201              throw new SQLException(e);
 202          } finally {
 203              if (connection != null) {
 204                  connection.close();
 205              }
 206          }
 207      }
 208  
<abbr title=" 209      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 209      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws S🔵</abbr>
 210          //load data from table
 211          String sql = sideInfo.getSqlCondition();
 212          Statement statement = connection.createStatement();
 213          statement.setFetchSize(getFetchSize());
 214          ResultSet resultSet = statement.executeQuery(sql);
 215  
 216          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 217          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 218          while (resultSet.next()) {
 219              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 220              for (String fieldName : sideFieldNames) {
 221                  Object object = resultSet.getObject(fieldName.trim());
 222                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 223                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 224                  oneRow.put(fieldName.trim(), object);
 225              }
 226  
 227              String cacheKey = sideInfo.getEqualFieldList().stream()
 228                      .map(oneRow::get)

 229                      .map(Object::toString)
 230                      .collect(Collectors.joining(&quot;_&quot;));
 231  
 232              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 233                      .add(oneRow);
 234          }
 235      }
 236  
 237      public int getFetchSize() {
 238          return DEFAULT_FETCH_SIZE;
 239      }
 240  
 241      /**
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 242 -     *  get jdbc connection</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 243 +     * get jdbc connection</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 244 +     *</span>
 245       * @param dbURL
 246       * @param userName
 247       * @param password
 248       * @return
 249       */
 250      public abstract Connection getConn(String dbURL, String userName, String password);
 251  
 252  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            