<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>354</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    354
                    <a href="353.html">prev</a>
                    <a href="355.html">next</a>
                    <a href="354_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_20e23caf71608de9de1a43e207cd97e0cca164d2_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;20e23caf71608de9de1a43e207cd97e0cca164d2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;20e23caf71608de9de1a43e207cd97e0cca164d2^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;20e23caf71608de9de1a43e207cd97e0cca164d2^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;0ff459b1686a683bac5ef7bffcb5eb694dcc7123:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [b]], subset: [[b], [b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  30 import com.dtstack.flink.sql.util.RowDataComplete;</span>
  31 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  32 import org.apache.calcite.sql.JoinType;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  33 import org.apache.commons.collections.map.HashedMap;</span>
  34 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  35 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  36 import com.google.common.collect.Maps;</span>
  37 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  38 import org.apache.calcite.sql.JoinType;
  39 import org.apache.commons.collections.map.HashedMap;
  40 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  41 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  42 import com.google.common.collect.Maps;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  43 import org.apache.flink.table.dataformat.BaseRow;</span>
  44 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  45 import com.google.common.collect.Maps;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  46 import org.apache.flink.table.runtime.types.CRow;</span>
  47 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  48 import org.apache.flink.table.runtime.types.CRow;</span>
  49 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  50 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  51 import org.apache.flink.types.Row;
  52 import org.apache.flink.util.Collector;
  53 import org.apache.hadoop.conf.Configuration;
  54 import org.apache.hadoop.hbase.Cell;
  55 import org.apache.hadoop.hbase.CellUtil;
  56 import org.apache.hadoop.hbase.TableName;
  57 import org.apache.hadoop.hbase.client.*;
  58 import org.apache.hadoop.hbase.util.Bytes;
  59 import org.apache.hadoop.security.UserGroupInformation;
  60 import org.slf4j.Logger;
  61 import org.slf4j.LoggerFactory;
  62 
  63 import java.io.IOException;
  64 
  65 import java.security.PrivilegedAction;
  66 import java.sql.SQLException;
  67 import java.sql.Timestamp;
  68 import java.time.LocalDateTime;
  69 import java.util.Calendar;
  70 import java.util.HashMap;
  71 import java.util.List;
  72 import java.util.Map;
  73 import java.util.concurrent.atomic.AtomicReference;
  74 
  75 public class HbaseAllReqRow extends BaseAllReqRow {
  76 
  77     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  78 
  79     private String tableName;
  80 
  81     private Map&lt;String, String&gt; aliasNameInversion;
  82 
  83     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  84     private Connection conn = null;
  85     private Table table = null;
  86     private ResultScanner resultScanner = null;
  87     private Configuration conf = null;
  88 
<abbr title="  89     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  89     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  90         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  91         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  92 
  93         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  94         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  95         aliasNameInversion = new HashMap&lt;&gt;();
  96         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  97             aliasNameInversion.put(entry.getValue(), entry.getKey());
  98         }
  99     }
 100 
 101     @Override
 102     public Row fillData(Row input, Object sideInput) {
 103         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
 104         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 105         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 106             Object obj = input.getField(entry.getValue());
<abbr title=" 107             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 107             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
 108 
<abbr title=" 109             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 109             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 110             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 111                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 112             }
 113             row.setField(entry.getKey(), obj);
 114         }
 115 
 116         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 117             if(sideInputList == null){
 118                 row.setField(entry.getKey(), null);
 119             }else{
 120                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 121                 key = aliasNameInversion.get(key);
 122                 row.setField(entry.getKey(), sideInputList.get(key));
 123             }
 124         }
 125         return row;
 126     }
 127 
 128     @Override
 129     protected void initCache() throws SQLException {
 130         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 131         cacheRef.set(newCache);
 132         loadData(newCache);
 133     }
 134 
 135     @Override
 136     protected void reloadCache() {
 137         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 138         try {
 139             loadData(newCache);
 140         } catch (SQLException e) {
 141             LOG.error(&quot;&quot;, e);
 142         }
 143 
 144         cacheRef.set(newCache);
 145         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 146     }
 147 
 148     @Override
 149     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 150         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 151         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 152             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 153             Object equalObj = input.getField(conValIndex);
 154             if (equalObj == null) {
 155                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 156                     Row data = fillData(input, null);
 157                     RowDataComplete.collectRow(out, data);
 158                 }
 159                 return;
 160             }
 161             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 162         }
 163 
 164         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 165 
 166         Map&lt;String, Object&gt; cacheList = null;
 167 
 168         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 169         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 170         if (hbaseSideTableInfo.isPreRowKey()) {
 171             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 172                 if (entry.getKey().startsWith(rowKeyStr)) {
 173                     cacheList = cacheRef.get().get(entry.getKey());
 174                     Row row = fillData(input, cacheList);
 175                     RowDataComplete.collectRow(out, row);
 176                 }
 177             }
 178         } else {
 179             cacheList = cacheRef.get().get(rowKeyStr);
 180             Row row = fillData(input, cacheList);
 181             RowDataComplete.collectRow(out, row);
 182         }
 183 
 184     }
 185 
 186     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 187         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 188         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 189         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 190         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 191         int loadDataCount = 0;
 192         try {
 193             if (openKerberos) {
 194                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 195                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 196                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 196                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 197                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 198                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 199 
<abbr title=" 200                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 200                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 201                 Configuration finalConf = conf;
 202                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 203                     @Override
 204                     public Connection run() {
 205                         try {
 206                             return ConnectionFactory.createConnection(finalConf);
 207                         } catch (IOException e) {
 208                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 209                             throw new RuntimeException(e);
 210                         }
 211                     }
 212                 });
 213 
 214             } else {
 215                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 216                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 217                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 217                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 218                 conn = ConnectionFactory.createConnection(conf);
 219             }
 220 
 221             table = conn.getTable(TableName.valueOf(tableName));
 222             resultScanner = table.getScanner(new Scan());
 223             for (Result r : resultScanner) {
 224                 Map&lt;String, Object&gt; kv = new HashedMap();
 225                 for (Cell cell : r.listCells()) {
 226                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 227                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 228                     StringBuilder key = new StringBuilder();
 229                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 230                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 230                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 231                     kv.put(aliasNameInversion.get(key.toString()), value);
 232                 }
 233                 loadDataCount++;
 234                 tmpCache.put(new String(r.getRow()), kv);
 235             }
 236         } catch (IOException e) {
 237             throw new RuntimeException(e);
 238         } finally {
 239             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 240             try {
 241                 if (null != conn) {
 242                     conn.close();
 243                 }
 244 
 245                 if (null != table) {
 246                     table.close();
 247                 }
 248 
 249                 if (null != resultScanner) {
 250                     resultScanner.close();
 251                 }
 252             } catch (IOException e) {
 253                 LOG.error(&quot;&quot;, e);
 254             }
 255         }
 256     }
 257 
 258 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import com.dtstack.flink.sql.util.RowDataComplete;
  30 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  31 import com.google.common.collect.Maps;
  32 import org.apache.flink.table.dataformat.BaseRow;
  33 import org.apache.calcite.sql.JoinType;
  34 import org.apache.commons.collections.map.HashedMap;
  35 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  36 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  37 import org.apache.flink.types.Row;
  38 import org.apache.flink.util.Collector;
  39 import org.apache.hadoop.conf.Configuration;
  40 import org.apache.hadoop.hbase.Cell;
  41 import org.apache.hadoop.hbase.CellUtil;
  42 import org.apache.hadoop.hbase.TableName;
  43 import org.apache.hadoop.hbase.client.*;
  44 import org.apache.hadoop.hbase.util.Bytes;
  45 import org.apache.hadoop.security.UserGroupInformation;
  46 import org.slf4j.Logger;
  47 import org.slf4j.LoggerFactory;
  48 
  49 import java.io.IOException;
  50 
  51 import java.security.PrivilegedAction;
  52 import java.sql.SQLException;
  53 import java.sql.Timestamp;
  54 import java.time.LocalDateTime;
  55 import java.util.Calendar;
  56 import java.util.HashMap;
  57 import java.util.List;
  58 import java.util.Map;
  59 import java.util.concurrent.atomic.AtomicReference;
  60 
  61 public class HbaseAllReqRow extends BaseAllReqRow {
  62 
  63     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  64 
  65     private String tableName;
  66 
  67     private Map&lt;String, String&gt; aliasNameInversion;
  68 
  69     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  70     private Connection conn = null;
  71     private Table table = null;
  72     private ResultScanner resultScanner = null;
  73     private Configuration conf = null;
  74 
<abbr title="  75     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  75     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  76         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  77         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  78 
  79         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  80         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  81         aliasNameInversion = new HashMap&lt;&gt;();
  82         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  83             aliasNameInversion.put(entry.getValue(), entry.getKey());
  84         }
  85     }
  86 
  87     @Override
  88     public Row fillData(Row input, Object sideInput) {
  89         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  90         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  91         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  92             Object obj = input.getField(entry.getValue());
<abbr title="  93             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  93             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
  94 
<abbr title="  95             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  95             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
  96             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
  97                 obj = Timestamp.valueOf(((LocalDateTime) obj));
  98             }
  99             row.setField(entry.getKey(), obj);
 100         }
 101 
 102         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 103             if(sideInputList == null){
 104                 row.setField(entry.getKey(), null);
 105             }else{
 106                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 107                 key = aliasNameInversion.get(key);
 108                 row.setField(entry.getKey(), sideInputList.get(key));
 109             }
 110         }
 111         return row;
 112     }
 113 
 114     @Override
 115     protected void initCache() throws SQLException {
 116         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 117         cacheRef.set(newCache);
 118         loadData(newCache);
 119     }
 120 
 121     @Override
 122     protected void reloadCache() {
 123         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 124         try {
 125             loadData(newCache);
 126         } catch (SQLException e) {
 127             LOG.error(&quot;&quot;, e);
 128         }
 129 
 130         cacheRef.set(newCache);
 131         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 132     }
 133 
 134     @Override
 135     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 136         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 137         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 138             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 139             Object equalObj = input.getField(conValIndex);
 140             if (equalObj == null) {
 141                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 142                     Row data = fillData(input, null);
 143                     RowDataComplete.collectRow(out, data);
 144                 }
 145                 return;
 146             }
 147             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 148         }
 149 
 150         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 151 
 152         Map&lt;String, Object&gt; cacheList = null;
 153 
 154         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 155         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 156         if (hbaseSideTableInfo.isPreRowKey()) {
 157             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 158                 if (entry.getKey().startsWith(rowKeyStr)) {
 159                     cacheList = cacheRef.get().get(entry.getKey());
 160                     Row row = fillData(input, cacheList);
 161                     RowDataComplete.collectRow(out, row);
 162                 }
 163             }
 164         } else {
 165             cacheList = cacheRef.get().get(rowKeyStr);
 166             Row row = fillData(input, cacheList);
 167             RowDataComplete.collectRow(out, row);
 168         }
 169 
 170     }
 171 
 172     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 173         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 174         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 175         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 176         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 177         int loadDataCount = 0;
 178         try {
 179             if (openKerberos) {
 180                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 181                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 182                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 182                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 183                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 184                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 185 
<abbr title=" 186                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 186                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 187                 Configuration finalConf = conf;
 188                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 189                     @Override
 190                     public Connection run() {
 191                         try {
 192                             return ConnectionFactory.createConnection(finalConf);
 193                         } catch (IOException e) {
 194                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 195                             throw new RuntimeException(e);
 196                         }
 197                     }
 198                 });
 199 
 200             } else {
 201                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 202                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 203                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 204                 conn = ConnectionFactory.createConnection(conf);
 205             }
 206 
 207             table = conn.getTable(TableName.valueOf(tableName));
 208             resultScanner = table.getScanner(new Scan());
 209             for (Result r : resultScanner) {
 210                 Map&lt;String, Object&gt; kv = new HashedMap();
 211                 for (Cell cell : r.listCells()) {
 212                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 213                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 214                     StringBuilder key = new StringBuilder();
 215                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 216                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 216                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 217                     kv.put(aliasNameInversion.get(key.toString()), value);
 218                 }
 219                 loadDataCount++;
 220                 tmpCache.put(new String(r.getRow()), kv);
 221             }
 222         } catch (IOException e) {
 223             throw new RuntimeException(e);
 224         } finally {
 225             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 226             try {
 227                 if (null != conn) {
 228                     conn.close();
 229                 }
 230 
 231                 if (null != table) {
 232                     table.close();
 233                 }
 234 
 235                 if (null != resultScanner) {
 236                     resultScanner.close();
 237                 }
 238             } catch (IOException e) {
 239                 LOG.error(&quot;&quot;, e);
 240             }
 241         }
 242     }
 243 
 244 }
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  26 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  27 import com.dtstack.flink.sql.util.RowDataComplete;
  28 import com.google.common.collect.Maps;
  29 import java.io.IOException;
  30 import java.security.PrivilegedAction;
  31 import java.sql.SQLException;
  32 import java.sql.Timestamp;
  33 import java.time.LocalDateTime;
  34 import java.util.Calendar;
  35 import java.util.HashMap;
  36 import java.util.List;
  37 import java.util.Map;
  38 import java.util.concurrent.atomic.AtomicReference;
  39 import org.apache.calcite.sql.JoinType;
  40 import org.apache.commons.collections.map.HashedMap;
  41 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  42 import org.apache.flink.table.dataformat.BaseRow;
  43 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  44 import org.apache.flink.types.Row;
  45 import org.apache.flink.util.Collector;
  46 import org.apache.hadoop.conf.Configuration;
  47 import org.apache.hadoop.hbase.Cell;
  48 import org.apache.hadoop.hbase.CellUtil;
  49 import org.apache.hadoop.hbase.TableName;
  50 import org.apache.hadoop.hbase.client.*;
  51 import org.apache.hadoop.hbase.util.Bytes;
  52 import org.apache.hadoop.security.UserGroupInformation;
  53 import org.slf4j.Logger;
  54 import org.slf4j.LoggerFactory;
  55 
  56 
  57 public class HbaseAllReqRow extends BaseAllReqRow {
  58     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  59 
  60     private String tableName;
  61 
  62     private Map&lt;String, String&gt; aliasNameInversion;
  63 
  64     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  65 
  66     private Connection conn = null;
  67 
  68     private Table table = null;
  69 
  70     private ResultScanner resultScanner = null;
  71 
  72     private Configuration conf = null;
  73 
<abbr title="  74     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  74     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  75         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  76         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  77         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  78         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  79         aliasNameInversion = new HashMap&lt;&gt;();
  80         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  81             aliasNameInversion.put(entry.getValue(), entry.getKey());
  82         }
  83     }
  84 
  85     @Override
  86     public Row fillData(Row input, Object sideInput) {
  87         Map&lt;String, Object&gt; sideInputList = ((Map&lt;String, Object&gt;) (sideInput));
  88         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  89         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
  90             Object obj = input.getField(entry.getValue());
<abbr title="  91             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  91             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
<abbr title="  92             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  92             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
  93             if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
  94                 obj = Timestamp.valueOf(((LocalDateTime) (obj)));
  95             }
  96             row.setField(entry.getKey(), obj);
  97         }
  98         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
  99             if (sideInputList == null) {
 100                 row.setField(entry.getKey(), null);
 101             } else {
 102                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 103                 key = aliasNameInversion.get(key);
 104                 row.setField(entry.getKey(), sideInputList.get(key));
 105             }
 106         }
 107         return row;
 108     }
 109 
 110     @Override
 111     protected void initCache() throws SQLException {
 112         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 113         cacheRef.set(newCache);
 114         loadData(newCache);
 115     }
 116 
 117     @Override
 118     protected void reloadCache() {
 119         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 120         try {
 121             loadData(newCache);
 122         } catch (SQLException e) {
 123             LOG.error(&quot;&quot;, e);
 124         }
 125 
 126         cacheRef.set(newCache);
 127         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 128     }
 129 
 130     @Override
 131     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 132         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 133         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 134             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 135             Object equalObj = input.getField(conValIndex);
 136             if (equalObj == null) {
 137                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 138                     Row data = fillData(input, null);
 139                     RowDataComplete.collectRow(out, data);
 140                 }
 141                 return;
 142             }
 143             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 144         }
 145         String rowKeyStr = ((HbaseAllSideInfo) (sideInfo)).getRowKeyBuilder().getRowKey(refData);
 146         Map&lt;String, Object&gt; cacheList = null;
 147         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 148         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 149         if (hbaseSideTableInfo.isPreRowKey()) {
 150             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 151                 if (entry.getKey().startsWith(rowKeyStr)) {
 152                     cacheList = cacheRef.get().get(entry.getKey());
 153                     Row row = fillData(input, cacheList);
 154                     RowDataComplete.collectRow(out, row);
 155                 }
 156             }
 157         } else {
 158             cacheList = cacheRef.get().get(rowKeyStr);
 159             Row row = fillData(input, cacheList);
 160             RowDataComplete.collectRow(out, row);
 161         }
 162     }
 163 
 164     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 165         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 166         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo) (sideInfo)).getColRefType();
 167         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 168         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 169         int loadDataCount = 0;
 170         try {
 171             if (openKerberos) {
 172                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 173                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 174                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 174                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 175                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 176                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
<abbr title=" 177                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 177                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 178                 Configuration finalConf = conf;
 179                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 180                     @Override
 181                     public Connection run() {
 182                         try {
 183                             return ConnectionFactory.createConnection(finalConf);
 184                         } catch (IOException e) {
 185                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 186                             throw new RuntimeException(e);
 187                         }
 188                     }
 189                 });
 190             } else {
 191                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 192                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 193                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 193                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 194                 conn = ConnectionFactory.createConnection(conf);
 195             }
 196             table = conn.getTable(TableName.valueOf(tableName));
 197             resultScanner = table.getScanner(new Scan());
 198             for (Result r : resultScanner) {
 199                 Map&lt;String, Object&gt; kv = new HashedMap();
 200                 for (Cell cell : r.listCells()) {
 201                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 202                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 203                     StringBuilder key = new StringBuilder();
 204                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 205                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 205                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 206                     kv.put(aliasNameInversion.get(key.toString()), value);
 207                 }
 208                 loadDataCount++;
 209                 tmpCache.put(new String(r.getRow()), kv);
 210             }
 211         } catch (IOException e) {
 212             throw new RuntimeException(e);
 213         } finally {
 214             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 215             try {
 216                 if (null != conn) {
 217                     conn.close();
 218                 }
 219                 if (null != table) {
 220                     table.close();
 221                 }
 222                 if (null != resultScanner) {
 223                     resultScanner.close();
 224                 }
 225             } catch (IOException e) {
 226                 LOG.error(&quot;&quot;, e);
 227             }
 228         }
 229     }
 230 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import com.dtstack.flink.sql.util.RowDataComplete;</span>

  30  import org.apache.calcite.sql.JoinType;
  31  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  32 -import org.apache.commons.lang.StringUtils;</span>
  33  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  34  import com.google.common.collect.Maps;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  35 -import org.apache.flink.table.runtime.types.CRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  36 +import org.apache.flink.table.dataformat.BaseRow;</span>
  37  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  38  import org.apache.flink.types.Row;
  39  import org.apache.flink.util.Collector;
  40  import org.apache.hadoop.conf.Configuration;
  41  import org.apache.hadoop.hbase.Cell;
  42  import org.apache.hadoop.hbase.CellUtil;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  43 -import org.apache.hadoop.hbase.HBaseConfiguration;</span>
  44  import org.apache.hadoop.hbase.TableName;
  45  import org.apache.hadoop.hbase.client.Connection;
  46  import org.apache.hadoop.hbase.client.ConnectionFactory;
  47  import org.apache.hadoop.hbase.client.Result;
  48  import org.apache.hadoop.hbase.client.ResultScanner;
  49  import org.apache.hadoop.hbase.client.Scan;
  50  import org.apache.hadoop.hbase.client.Table;

  51  import org.apache.hadoop.hbase.util.Bytes;
  52  import org.apache.hadoop.security.UserGroupInformation;
  53  import org.slf4j.Logger;
  54  import org.slf4j.LoggerFactory;
  55  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  56 -import java.io.File;</span>
  57  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +</span>
  59  import java.security.PrivilegedAction;
  60  import java.sql.SQLException;
  61  import java.sql.Timestamp;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  62 +import java.time.LocalDateTime;</span>
  63  import java.util.Calendar;
  64  import java.util.HashMap;
  65  import java.util.List;
  66  import java.util.Map;
  67  import java.util.concurrent.atomic.AtomicReference;
  68  
  69  public class HbaseAllReqRow extends BaseAllReqRow {
  70  
  71      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  72  
  73      private String tableName;
  74  
  75      private Map&lt;String, String&gt; aliasNameInversion;
  76  
  77      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  78      private Connection conn = null;
  79      private Table table = null;
  80      private ResultScanner resultScanner = null;
  81      private Configuration conf = null;
  82  
<abbr title="  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  84          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  85          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  86  
  87          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  88          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  89          aliasNameInversion = new HashMap&lt;&gt;();
  90          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  91              aliasNameInversion.put(entry.getValue(), entry.getKey());
  92          }
  93      }
  94  
  95      @Override
  96      public Row fillData(Row input, Object sideInput) {
  97          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  98          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  99          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 100              Object obj = input.getField(entry.getValue());
<abbr title=" 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 102  
<abbr title=" 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 104 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 105 -                //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 106 -                obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 107 -            }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 108 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 109 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 110 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 111 +            }</span>
 112              row.setField(entry.getKey(), obj);
 113          }
 114  
 115          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 116              if(sideInputList == null){
 117                  row.setField(entry.getKey(), null);
 118              }else{
 119                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 120 +                key = aliasNameInversion.get(key);</span>
 121                  row.setField(entry.getKey(), sideInputList.get(key));
 122              }
 123          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 124 -</span>
 125          return row;
 126      }
 127  
 128      @Override
 129      protected void initCache() throws SQLException {
 130          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 131          cacheRef.set(newCache);
 132          loadData(newCache);
 133      }
 134  
 135      @Override
 136      protected void reloadCache() {
 137          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 138          try {
 139              loadData(newCache);
 140          } catch (SQLException e) {
 141              LOG.error(&quot;&quot;, e);
 142          }
 143  
 144          cacheRef.set(newCache);
 145          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 146      }
 147  
 148      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 149 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 150 +    public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {</span>
 151          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 152          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 153              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 154 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 155 +            Object equalObj = input.getField(conValIndex);</span>
 156              if (equalObj == null) {
 157                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 158 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 159 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 160 +                    Row data = fillData(input, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 161 +                    RowDataComplete.collectRow(out, data);</span>
 162                  }
 163                  return;
 164              }
 165              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 166          }
 167  
 168          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 169  
 170          Map&lt;String, Object&gt; cacheList = null;
 171  
 172          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 173          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 174          if (hbaseSideTableInfo.isPreRowKey()) {
 175              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 176                  if (entry.getKey().startsWith(rowKeyStr)) {
 177                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 178 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 179 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 180 +                    Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 181 +                    RowDataComplete.collectRow(out, row);</span>
 182                  }
 183              }
 184          } else {
 185              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 186 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 187 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 188 +            Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 189 +            RowDataComplete.collectRow(out, row);</span>
 190          }
 191  
 192      }
 193  
 194      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 195          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();

 196          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 197          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 198          int loadDataCount = 0;
 199          try {
 200              if (openKerberos) {
 201                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 202                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 203                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 204                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 205                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 206  
<abbr title=" 207                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 207                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 208                  Configuration finalConf = conf;
 209                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 210                      @Override
 211                      public Connection run() {
 212                          try {
 213                              return ConnectionFactory.createConnection(finalConf);
 214                          } catch (IOException e) {
 215                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 216                              throw new RuntimeException(e);
 217                          }
 218                      }
 219                  });
 220  
 221              } else {
 222                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 223                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 224                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 225                  conn = ConnectionFactory.createConnection(conf);
 226              }
 227  
 228              table = conn.getTable(TableName.valueOf(tableName));
 229              resultScanner = table.getScanner(new Scan());
 230              for (Result r : resultScanner) {
 231                  Map&lt;String, Object&gt; kv = new HashedMap();
 232                  for (Cell cell : r.listCells())
 233                  {

 234                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 235                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 236                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 237                      StringBuilder key = new StringBuilder();
 238                      key.append(family).append(&quot;:&quot;).append(qualifier);
 239  

 240                      kv.put(aliasNameInversion.get(key.toString()), value);
 241                  }
 242                  loadDataCount++;
 243                  tmpCache.put(new String(r.getRow()), kv);
 244              }
 245          } catch (IOException e) {
 246              throw new RuntimeException(e);
 247          } finally {
 248              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 249              try {
 250                  if (null != conn) {
 251                      conn.close();
 252                  }
 253  
 254                  if (null != table) {
 255                      table.close();
 256                  }
 257  
 258                  if (null != resultScanner) {
 259                      resultScanner.close();
 260                  }
 261              } catch (IOException e) {
 262                  LOG.error(&quot;&quot;, e);
 263              }
 264          }
 265      }
 266  
 267  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  30 +import com.google.common.collect.Maps;</span>
  31  import org.apache.calcite.sql.JoinType;
  32  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  33 -import org.apache.commons.lang.StringUtils;</span>
  34  import org.apache.flink.api.java.typeutils.RowTypeInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  35 -import com.google.common.collect.Maps;</span>
  36  import org.apache.flink.table.runtime.types.CRow;

  37  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  38  import org.apache.flink.types.Row;
  39  import org.apache.flink.util.Collector;
  40  import org.apache.hadoop.conf.Configuration;
  41  import org.apache.hadoop.hbase.Cell;
  42  import org.apache.hadoop.hbase.CellUtil;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  43 -import org.apache.hadoop.hbase.HBaseConfiguration;</span>
  44  import org.apache.hadoop.hbase.TableName;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  45 -import org.apache.hadoop.hbase.client.Connection;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  46 -import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  47 -import org.apache.hadoop.hbase.client.Result;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  48 -import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  49 -import org.apache.hadoop.hbase.client.Scan;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  50 -import org.apache.hadoop.hbase.client.Table;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import org.apache.hadoop.hbase.client.*;</span>
  52  import org.apache.hadoop.hbase.util.Bytes;
  53  import org.apache.hadoop.security.UserGroupInformation;
  54  import org.slf4j.Logger;
  55  import org.slf4j.LoggerFactory;
  56  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  57 -import java.io.File;</span>
  58  import java.io.IOException;

  59  import java.security.PrivilegedAction;
  60  import java.sql.SQLException;
  61  import java.sql.Timestamp;

  62  import java.util.Calendar;
  63  import java.util.HashMap;
  64  import java.util.List;
  65  import java.util.Map;
  66  import java.util.concurrent.atomic.AtomicReference;
  67  
  68  public class HbaseAllReqRow extends BaseAllReqRow {
  69  
  70      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  71  
  72      private String tableName;
  73  
  74      private Map&lt;String, String&gt; aliasNameInversion;
  75  
  76      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  77      private Connection conn = null;
  78      private Table table = null;
  79      private ResultScanner resultScanner = null;
  80      private Configuration conf = null;
  81  
<abbr title="  82      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  82      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  83          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  84          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  85  
  86          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  87          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  88          aliasNameInversion = new HashMap&lt;&gt;();
  89          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  90              aliasNameInversion.put(entry.getValue(), entry.getKey());
  91          }
  92      }
  93  
  94      @Override
  95      public Row fillData(Row input, Object sideInput) {
  96          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  97          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  98          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  99              Object obj = input.getField(entry.getValue());
<abbr title=" 100              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 100              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 101  
<abbr title=" 102              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 102              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
 103              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 104                  //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响
 105                  obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());
 106              }
 107  



 108              row.setField(entry.getKey(), obj);
 109          }
 110  
 111          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 112              if(sideInputList == null){
 113                  row.setField(entry.getKey(), null);
 114              }else{
 115                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());

 116                  row.setField(entry.getKey(), sideInputList.get(key));
 117              }
 118          }
 119  
 120          return row;
 121      }
 122  
 123      @Override
 124      protected void initCache() throws SQLException {
 125          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 126          cacheRef.set(newCache);
 127          loadData(newCache);
 128      }
 129  
 130      @Override
 131      protected void reloadCache() {
 132          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 133          try {
 134              loadData(newCache);
 135          } catch (SQLException e) {
 136              LOG.error(&quot;&quot;, e);
 137          }
 138  
 139          cacheRef.set(newCache);
 140          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 141      }
 142  
 143      @Override
 144      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {

 145          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 146          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 147              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 148              Object equalObj = input.row().getField(conValIndex);

 149              if (equalObj == null) {
 150                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 151                      Row data = fillData(input.row(), null);
 152                      out.collect(new CRow(data, input.change()));


 153                  }
 154                  return;
 155              }
 156              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 157          }
 158  
 159          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 160  
 161          Map&lt;String, Object&gt; cacheList = null;
 162  
 163          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 164          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 165          if (hbaseSideTableInfo.isPreRowKey()) {
 166              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 167                  if (entry.getKey().startsWith(rowKeyStr)) {
 168                      cacheList = cacheRef.get().get(entry.getKey());
 169                      Row row = fillData(input.row(), cacheList);
 170                      out.collect(new CRow(row, input.change()));


 171                  }
 172              }
 173          } else {
 174              cacheList = cacheRef.get().get(rowKeyStr);
 175              Row row = fillData(input.row(), cacheList);
 176              out.collect(new CRow(row, input.change()));


 177          }
 178  
 179      }
 180  
 181      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 182          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 183 +        Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();</span>
 184          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 185          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 186          int loadDataCount = 0;
 187          try {
 188              if (openKerberos) {
 189                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 190                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 191                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 192                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 193                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 194  
<abbr title=" 195                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 195                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 196                  Configuration finalConf = conf;
 197                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 198                      @Override
 199                      public Connection run() {
 200                          try {
 201                              return ConnectionFactory.createConnection(finalConf);
 202                          } catch (IOException e) {
 203                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 204                              throw new RuntimeException(e);
 205                          }
 206                      }
 207                  });
 208  
 209              } else {
 210                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 211                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 212                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 213                  conn = ConnectionFactory.createConnection(conf);
 214              }
 215  
 216              table = conn.getTable(TableName.valueOf(tableName));
 217              resultScanner = table.getScanner(new Scan());
 218              for (Result r : resultScanner) {
 219                  Map&lt;String, Object&gt; kv = new HashedMap();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 220 -                for (Cell cell : r.listCells())</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 221 -                {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 222 +                for (Cell cell : r.listCells()) {</span>
 223                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 224                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 225 -                    String value = Bytes.toString(CellUtil.cloneValue(cell));</span>
 226                      StringBuilder key = new StringBuilder();
 227                      key.append(family).append(&quot;:&quot;).append(qualifier);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 228 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 229 +                    Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 229 +                    Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()🔵</abbr></span>
 230                      kv.put(aliasNameInversion.get(key.toString()), value);
 231                  }
 232                  loadDataCount++;
 233                  tmpCache.put(new String(r.getRow()), kv);
 234              }
 235          } catch (IOException e) {
 236              throw new RuntimeException(e);
 237          } finally {
 238              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 239              try {
 240                  if (null != conn) {
 241                      conn.close();
 242                  }
 243  
 244                  if (null != table) {
 245                      table.close();
 246                  }
 247  
 248                  if (null != resultScanner) {
 249                      resultScanner.close();
 250                  }
 251              } catch (IOException e) {
 252                  LOG.error(&quot;&quot;, e);
 253              }
 254          }
 255      }
 256  
 257  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            