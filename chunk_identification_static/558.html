<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>558</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    558
                    <a href="557.html">prev</a>
                    <a href="559.html">next</a>
                    <a href="558_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_7302b163e73618ae14d90bd0ad9b64f1caf7c884_kafka10/kafka10-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaSource.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7302b163e73618ae14d90bd0ad9b64f1caf7c884:kafka10/kafka10-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaSource.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7302b163e73618ae14d90bd0ad9b64f1caf7c884^1:kafka10/kafka10-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaSource.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7302b163e73618ae14d90bd0ad9b64f1caf7c884^2:kafka10/kafka10-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaSource.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b259aa5e9ca64e4d07266783ec504a1f5fd6d5ec:kafka10/kafka10-source/src/main/java/com/dtstack/flink/sql/source/kafka/KafkaSource.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[bj]], subset: [[bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.source.kafka;
  21 
  22 import com.dtstack.flink.sql.source.IStreamSourceGener;
  23 import com.dtstack.flink.sql.source.kafka.table.KafkaSourceTableInfo;
  24 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  25 import com.dtstack.flink.sql.util.DtStringUtil;
  26 import com.dtstack.flink.sql.util.PluginUtil;
  27 import org.apache.commons.lang3.StringUtils;
  28 import org.apache.flink.api.common.typeinfo.TypeInformation;
  29 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  30 import org.apache.flink.streaming.api.datastream.DataStreamSource;
  31 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  32 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;
  33 import org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition;
  34 import org.apache.flink.table.api.Table;
  35 import org.apache.flink.table.api.java.StreamTableEnvironment;
  36 import org.apache.flink.types.Row;
  37 
  38 import java.util.HashMap;
  39 import java.util.Map;
  40 import java.util.Properties;
  41 
  42 /**
  43  * If eventtime field is specified, the default time field rowtime
  44  * Date: 2018/09/18
  45  * Company: www.dtstack.com
  46  *
  47  * @author sishu.yss
  48  */
  49 
  50 public class KafkaSource implements IStreamSourceGener&lt;Table&gt; {
  51 
  52 	private static final String SOURCE_OPERATOR_NAME_TPL = &quot;${topic}_${table}&quot;;
  53 
  54 	/**
  55 	 * Get kafka data source, you need to provide the data field names, data types
  56 	 * If you do not specify auto.offset.reset, the default use groupoffset
  57 	 *
  58 	 * @param sourceTableInfo
  59 	 * @return
  60 	 */
  61 	@SuppressWarnings(&quot;rawtypes&quot;)
  62 	@Override
<abbr title="  63 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  63 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StðŸ”µ</abbr>
  64 
  65 		KafkaSourceTableInfo kafkaSourceTableInfo = (KafkaSourceTableInfo) sourceTableInfo;
  66 		String topicName = kafkaSourceTableInfo.getTopic();
  67 
  68 		Properties props = new Properties();
  69 		for (String key : kafkaSourceTableInfo.getKafkaParamKeys()) {
  70 			props.setProperty(key, kafkaSourceTableInfo.getKafkaParam(key));
  71 		}
  72 		props.setProperty(&quot;bootstrap.servers&quot;, kafkaSourceTableInfo.getBootstrapServers());
  73 		if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())){
  74 			props.setProperty(&quot;auto.offset.reset&quot;, &quot;none&quot;);
  75 		} else {
  76 			props.setProperty(&quot;auto.offset.reset&quot;, kafkaSourceTableInfo.getOffsetReset());
  77 		}
  78 		if (StringUtils.isNotBlank(kafkaSourceTableInfo.getGroupId())){
  79 			props.setProperty(&quot;group.id&quot;, kafkaSourceTableInfo.getGroupId());
  80 		}
  81 
  82 		TypeInformation[] types = new TypeInformation[kafkaSourceTableInfo.getFields().length];
  83 		for (int i = 0; i &lt; kafkaSourceTableInfo.getFieldClasses().length; i++) {
  84 			types[i] = TypeInformation.of(kafkaSourceTableInfo.getFieldClasses()[i]);
  85 		}
  86 
  87 		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafkaSourceTableInfo.getFields());
  88 
<abbr title="  89         FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().createKafkaTableSource(kafkaSourceTableInfo, typeInformation, props);">  89         FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().ðŸ”µ</abbr>
  90 
  91 		//earliest,latest
  92 		if (&quot;earliest&quot;.equalsIgnoreCase(kafkaSourceTableInfo.getOffsetReset())) {
  93 			kafkaSrc.setStartFromEarliest();
<abbr title="  94 		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}">  94 		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:123ðŸ”µ</abbr>
  95 			try {
<abbr title="  96 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.class);">  96 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.ðŸ”µ</abbr>
  97 				Map&lt;String, Object&gt; offsetMap = PluginUtil.objectToMap(properties);
  98 				Map&lt;KafkaTopicPartition, Long&gt; specificStartupOffsets = new HashMap&lt;&gt;();
  99 				for (Map.Entry&lt;String, Object&gt; entry : offsetMap.entrySet()) {
<abbr title=" 100 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(entry.getValue().toString()));"> 100 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), LongðŸ”µ</abbr>
 101 				}
 102 				kafkaSrc.setStartFromSpecificOffsets(specificStartupOffsets);
 103 			} catch (Exception e) {
 104 				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafkaSourceTableInfo.getOffsetReset());
 105 			}
 106 		} else {
 107 			kafkaSrc.setStartFromLatest();
 108 		}
 109 
 110 		String fields = StringUtils.join(kafkaSourceTableInfo.getFields(), &quot;,&quot;);
<abbr title=" 111 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 111 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;,ðŸ”µ</abbr>
 112 
 113 		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);
 114 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 115 		Integer parallelism = kafka010SourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 116 		if (parallelism &gt; 0) {</span>
 117 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 118 			} catch (Exception e) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 119 				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafka010SourceTableInfo.getOffsetReset());"> 119 				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafka010SourceTableInfo.getOffsetReset()ðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 120 			}</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 121 		} else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 122 			kafkaSrc.setStartFromLatest();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 123 		}</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 124 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 125 		String fields = StringUtils.join(kafka010SourceTableInfo.getFields(), &quot;,&quot;);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 126 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 126 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;,ðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 127 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 128 		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 129 		Integer parallelism = kafka010SourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 130 		if (parallelism != null) {</span>
 131 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 132 		Integer parallelism = kafkaSourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 133 		if (parallelism != null) {</span>
 134 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 135 			kafkaSource.setParallelism(parallelism);
 136 		}
 137 		return tableEnv.fromDataStream(kafkaSource, fields);
 138 	}
 139 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.source.kafka;
  21 
  22 import com.dtstack.flink.sql.source.IStreamSourceGener;
  23 import com.dtstack.flink.sql.source.kafka.table.KafkaSourceTableInfo;
  24 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  25 import com.dtstack.flink.sql.util.DtStringUtil;
  26 import com.dtstack.flink.sql.util.PluginUtil;
  27 import org.apache.commons.lang3.StringUtils;
  28 import org.apache.flink.api.common.typeinfo.TypeInformation;
  29 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  30 import org.apache.flink.streaming.api.datastream.DataStreamSource;
  31 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  32 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;
  33 import org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition;
  34 import org.apache.flink.table.api.Table;
  35 import org.apache.flink.table.api.java.StreamTableEnvironment;
  36 import org.apache.flink.types.Row;
  37 
  38 import java.util.HashMap;
  39 import java.util.Map;
  40 import java.util.Properties;
  41 
  42 /**
  43  * If eventtime field is specified, the default time field rowtime
  44  * Date: 2018/09/18
  45  * Company: www.dtstack.com
  46  *
  47  * @author sishu.yss
  48  */
  49 
  50 public class KafkaSource implements IStreamSourceGener&lt;Table&gt; {
  51 
  52 	private static final String SOURCE_OPERATOR_NAME_TPL = &quot;${topic}_${table}&quot;;
  53 
  54 	/**
  55 	 * Get kafka data source, you need to provide the data field names, data types
  56 	 * If you do not specify auto.offset.reset, the default use groupoffset
  57 	 *
  58 	 * @param sourceTableInfo
  59 	 * @return
  60 	 */
  61 	@SuppressWarnings(&quot;rawtypes&quot;)
  62 	@Override
<abbr title="  63 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  63 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StðŸ”µ</abbr>
  64 
  65 		KafkaSourceTableInfo kafkaSourceTableInfo = (KafkaSourceTableInfo) sourceTableInfo;
  66 		String topicName = kafkaSourceTableInfo.getTopic();
  67 
  68 		Properties props = new Properties();
  69 		for (String key : kafkaSourceTableInfo.getKafkaParamKeys()) {
  70 			props.setProperty(key, kafkaSourceTableInfo.getKafkaParam(key));
  71 		}
  72 		props.setProperty(&quot;bootstrap.servers&quot;, kafkaSourceTableInfo.getBootstrapServers());
  73 		if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())){
  74 			props.setProperty(&quot;auto.offset.reset&quot;, &quot;none&quot;);
  75 		} else {
  76 			props.setProperty(&quot;auto.offset.reset&quot;, kafkaSourceTableInfo.getOffsetReset());
  77 		}
  78 		if (StringUtils.isNotBlank(kafkaSourceTableInfo.getGroupId())){
  79 			props.setProperty(&quot;group.id&quot;, kafkaSourceTableInfo.getGroupId());
  80 		}
  81 
  82 		TypeInformation[] types = new TypeInformation[kafkaSourceTableInfo.getFields().length];
  83 		for (int i = 0; i &lt; kafkaSourceTableInfo.getFieldClasses().length; i++) {
  84 			types[i] = TypeInformation.of(kafkaSourceTableInfo.getFieldClasses()[i]);
  85 		}
  86 
  87 		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafkaSourceTableInfo.getFields());
  88 
<abbr title="  89         FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().createKafkaTableSource(kafkaSourceTableInfo, typeInformation, props);">  89         FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().ðŸ”µ</abbr>
  90 
  91 		//earliest,latest
  92 		if (&quot;earliest&quot;.equalsIgnoreCase(kafkaSourceTableInfo.getOffsetReset())) {
  93 			kafkaSrc.setStartFromEarliest();
<abbr title="  94 		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}">  94 		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:123ðŸ”µ</abbr>
  95 			try {
<abbr title="  96 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.class);">  96 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.ðŸ”µ</abbr>
  97 				Map&lt;String, Object&gt; offsetMap = PluginUtil.objectToMap(properties);
  98 				Map&lt;KafkaTopicPartition, Long&gt; specificStartupOffsets = new HashMap&lt;&gt;();
  99 				for (Map.Entry&lt;String, Object&gt; entry : offsetMap.entrySet()) {
<abbr title=" 100 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(entry.getValue().toString()));"> 100 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), LongðŸ”µ</abbr>
 101 				}
 102 				kafkaSrc.setStartFromSpecificOffsets(specificStartupOffsets);
 103 			} catch (Exception e) {
 104 				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafkaSourceTableInfo.getOffsetReset());
 105 			}
 106 		} else {
 107 			kafkaSrc.setStartFromLatest();
 108 		}
 109 
 110 		String fields = StringUtils.join(kafkaSourceTableInfo.getFields(), &quot;,&quot;);
<abbr title=" 111 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 111 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;,ðŸ”µ</abbr>
 112 
 113 		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);
 114 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 115 		Integer parallelism = kafka010SourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 116 		if (parallelism &gt; 0) {</span>
 117 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 118 			}</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 119 		} else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 120 			kafkaSrc.setStartFromLatest();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 121 		}</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 122 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 123 		String fields = StringUtils.join(kafka010SourceTableInfo.getFields(), &quot;,&quot;);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 124 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 124 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;,ðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 125 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 126 		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 127 		Integer parallelism = kafka010SourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 128 		if (parallelism != null) {</span>
 129 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 130 		Integer parallelism = kafkaSourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 131 		if (parallelism != null) {</span>
 132 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 133 			kafkaSource.setParallelism(parallelism);
 134 		}
 135 		return tableEnv.fromDataStream(kafkaSource, fields);
 136 	}
 137 }
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.source.kafka;
  19 
  20 import com.dtstack.flink.sql.source.IStreamSourceGener;
  21 import com.dtstack.flink.sql.source.kafka.table.KafkaSourceTableInfo;
  22 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  23 import com.dtstack.flink.sql.util.DtStringUtil;
  24 import com.dtstack.flink.sql.util.PluginUtil;
  25 import java.util.HashMap;
  26 import java.util.Map;
  27 import java.util.Properties;
  28 import org.apache.commons.lang3.StringUtils;
  29 import org.apache.flink.api.common.typeinfo.TypeInformation;
  30 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  31 import org.apache.flink.streaming.api.datastream.DataStreamSource;
  32 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  33 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;
  34 import org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition;
  35 import org.apache.flink.table.api.Table;
  36 import org.apache.flink.table.api.java.StreamTableEnvironment;
  37 import org.apache.flink.types.Row;
  38 
  39 
  40 /**
  41  * If eventtime field is specified, the default time field rowtime
  42  * Date: 2018/09/18
  43  * Company: www.dtstack.com
  44  *
  45  * @author sishu.yss
  46  */
  47 public class KafkaSource implements IStreamSourceGener&lt;Table&gt; {
  48 	private static final String SOURCE_OPERATOR_NAME_TPL = &quot;${topic}_${table}&quot;;
  49 
  50 	/**
  51 	 * Get kafka data source, you need to provide the data field names, data types
  52 	 * If you do not specify auto.offset.reset, the default use groupoffset
  53 	 *
  54 	 * @param sourceTableInfo
  55 	 * @return
  56 	 */
  57 	@SuppressWarnings(&quot;rawtypes&quot;)
  58 	@Override
<abbr title="  59 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  59 	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StðŸ”µ</abbr>
  60 		KafkaSourceTableInfo kafkaSourceTableInfo = ((KafkaSourceTableInfo) (sourceTableInfo));
  61 		String topicName = kafkaSourceTableInfo.getTopic();
  62 		Properties props = new Properties();
  63 		for (String key : kafkaSourceTableInfo.getKafkaParamKeys()) {
  64 			props.setProperty(key, kafkaSourceTableInfo.getKafkaParam(key));
  65 		}
  66 		props.setProperty(&quot;bootstrap.servers&quot;, kafkaSourceTableInfo.getBootstrapServers());
  67 		if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {
  68 			props.setProperty(&quot;auto.offset.reset&quot;, &quot;none&quot;);
  69 		} else {
  70 			props.setProperty(&quot;auto.offset.reset&quot;, kafkaSourceTableInfo.getOffsetReset());
  71 		}
  72 		if (StringUtils.isNotBlank(kafkaSourceTableInfo.getGroupId())) {
  73 			props.setProperty(&quot;group.id&quot;, kafkaSourceTableInfo.getGroupId());
  74 		}
  75 		TypeInformation[] types = new TypeInformation[kafkaSourceTableInfo.getFields().length];
  76 		for (int i = 0; i &lt; kafkaSourceTableInfo.getFieldClasses().length; i++) {
  77 			types[i] = TypeInformation.of(kafkaSourceTableInfo.getFieldClasses()[i]);
  78 		}
  79 		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafkaSourceTableInfo.getFields());
<abbr title="  80 		FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = ((FlinkKafkaConsumer010&lt;Row&gt;) (new KafkaConsumer010Factory().createKafkaTableSource(kafkaSourceTableInfo, typeInformation, props)));">  80 		FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = ((FlinkKafkaConsumer010&lt;Row&gt;) (new KafkaConsumer010Factory().creaðŸ”µ</abbr>
  81 		//earliest,latest
  82 		if (&quot;earliest&quot;.equalsIgnoreCase(kafkaSourceTableInfo.getOffsetReset())) {
  83 			kafkaSrc.setStartFromEarliest();
  84 		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {
  85 		// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}
  86 			try {
<abbr title="  87 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.class);">  87 				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.ðŸ”µ</abbr>
  88 				Map&lt;String, Object&gt; offsetMap = PluginUtil.objectToMap(properties);
  89 				Map&lt;KafkaTopicPartition, Long&gt; specificStartupOffsets = new HashMap&lt;&gt;();
  90 				for (Map.Entry&lt;String, Object&gt; entry : offsetMap.entrySet()) {
<abbr title="  91 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(entry.getValue().toString()));">  91 					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), LongðŸ”µ</abbr>
  92 				}
  93 				kafkaSrc.setStartFromSpecificOffsets(specificStartupOffsets);
  94 			} catch (java.lang.Exception e) {
  95 				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafkaSourceTableInfo.getOffsetReset());
  96 			}
  97 		} else {
  98 			kafkaSrc.setStartFromLatest();
  99 		}
 100 		String fields = StringUtils.join(kafkaSourceTableInfo.getFields(), &quot;,&quot;);
<abbr title=" 101 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 101 		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;,ðŸ”µ</abbr>
 102 		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);
 103 		Integer parallelism = kafkaSourceTableInfo.getParallelism();
 104 		if (parallelism &gt; 0) {
 105 			kafkaSource.setParallelism(parallelism);
 106 		}
 107 		return tableEnv.fromDataStream(kafkaSource, fields);
 108 	}
 109 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.source.kafka;
  21  
  22  import com.dtstack.flink.sql.source.IStreamSourceGener;
  23  import com.dtstack.flink.sql.source.kafka.table.KafkaSourceTableInfo;
  24  import com.dtstack.flink.sql.table.SourceTableInfo;

  25  import com.dtstack.flink.sql.util.DtStringUtil;
  26  import com.dtstack.flink.sql.util.PluginUtil;
  27  import org.apache.commons.lang3.BooleanUtils;
  28  import org.apache.commons.lang3.StringUtils;
  29  import org.apache.flink.api.common.typeinfo.TypeInformation;
  30  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  31  import org.apache.flink.streaming.api.datastream.DataStreamSource;
  32  import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  33  import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;
  34  import org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition;
  35  import org.apache.flink.table.api.Table;
  36  import org.apache.flink.table.api.java.StreamTableEnvironment;
  37  import org.apache.flink.types.Row;
  38  
  39  import java.util.HashMap;
  40  import java.util.Map;
  41  import java.util.Properties;
  42  import java.util.regex.Pattern;
  43  
  44  /**
  45   * If eventtime field is specified, the default time field rowtime
  46   * Date: 2018/09/18
  47   * Company: www.dtstack.com
  48   *
  49   * @author sishu.yss
  50   */
  51  
  52  public class KafkaSource implements IStreamSourceGener&lt;Table&gt; {
  53  
  54  	private static final String SOURCE_OPERATOR_NAME_TPL = &quot;${topic}_${table}&quot;;
  55  
  56  	/**
  57  	 * Get kafka data source, you need to provide the data field names, data types
  58  	 * If you do not specify auto.offset.reset, the default use groupoffset
  59  	 *
  60  	 * @param sourceTableInfo
  61  	 * @return
  62  	 */
  63  	@SuppressWarnings(&quot;rawtypes&quot;)
  64  	@Override
<abbr title="  65  	public Table genStreamSource(SourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  65  	public Table genStreamSource(SourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironmðŸ”µ</abbr>

  66  
  67  		KafkaSourceTableInfo kafka010SourceTableInfo = (KafkaSourceTableInfo) sourceTableInfo;
  68  		String topicName = kafka010SourceTableInfo.getTopic();


  69  
  70  		Properties props = new Properties();
  71  		for (String key : kafka010SourceTableInfo.getKafkaParamKeys()) {
  72  			props.setProperty(key, kafka010SourceTableInfo.getKafkaParam(key));


  73  		}
  74  		props.setProperty(&quot;bootstrap.servers&quot;, kafka010SourceTableInfo.getBootstrapServers());
  75  		if (DtStringUtil.isJosn(kafka010SourceTableInfo.getOffsetReset())){


  76  			props.setProperty(&quot;auto.offset.reset&quot;, &quot;none&quot;);
  77  		} else {
  78  			props.setProperty(&quot;auto.offset.reset&quot;, kafka010SourceTableInfo.getOffsetReset());

  79  		}
  80  		if (StringUtils.isNotBlank(kafka010SourceTableInfo.getGroupId())){
  81  			props.setProperty(&quot;group.id&quot;, kafka010SourceTableInfo.getGroupId());
  82  		}
  83  		// only required for Kafka 0.8
  84  		//TODO props.setProperty(&quot;zookeeper.connect&quot;, kafka09SourceTableInfo.)
  85  
  86  		TypeInformation[] types = new TypeInformation[kafka010SourceTableInfo.getFields().length];
  87  		for (int i = 0; i &lt; kafka010SourceTableInfo.getFieldClasses().length; i++) {
  88  			types[i] = TypeInformation.of(kafka010SourceTableInfo.getFieldClasses()[i]);


  89  		}
  90  
  91  		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafka010SourceTableInfo.getFields());
  92  
  93  		FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc;
  94  		if (BooleanUtils.isTrue(kafka010SourceTableInfo.getTopicIsPattern())) {
  95  			kafkaSrc = new CustomerKafka010Consumer(Pattern.compile(topicName),
<abbr title="  96  					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTableInfo.getFieldExtraInfoList()), props);">  96  					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTðŸ”µ</abbr>
  97  		} else {
  98  			kafkaSrc = new CustomerKafka010Consumer(topicName,
<abbr title="  99  					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTableInfo.getFieldExtraInfoList()), props);">  99  					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTðŸ”µ</abbr>



 100  		}
 101  




 102  		//earliest,latest
 103  		if (&quot;earliest&quot;.equalsIgnoreCase(kafka010SourceTableInfo.getOffsetReset())) {

 104  			kafkaSrc.setStartFromEarliest();
 105  		} else if (DtStringUtil.isJosn(kafka010SourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}

 106  			try {
<abbr title=" 107  				Properties properties = PluginUtil.jsonStrToObject(kafka010SourceTableInfo.getOffsetReset(), Properties.class);"> 107  				Properties properties = PluginUtil.jsonStrToObject(kafka010SourceTableInfo.getOffsetReset(), Properties.class)ðŸ”µ</abbr>
 108  				Map&lt;String, Object&gt; offsetMap = PluginUtil.ObjectToMap(properties);


 109  				Map&lt;KafkaTopicPartition, Long&gt; specificStartupOffsets = new HashMap&lt;&gt;();
 110  				for (Map.Entry&lt;String, Object&gt; entry : offsetMap.entrySet()) {
<abbr title=" 111  					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(entry.getValue().toString()));"> 111  					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(ðŸ”µ</abbr>
 112  				}
 113  				kafkaSrc.setStartFromSpecificOffsets(specificStartupOffsets);
 114  			} catch (Exception e) {
 115  				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafka010SourceTableInfo.getOffsetReset());

 116  			}
 117  		} else {
 118  			kafkaSrc.setStartFromLatest();
 119  		}
 120  
 121  		String fields = StringUtils.join(kafka010SourceTableInfo.getFields(), &quot;,&quot;);

<abbr title=" 122  		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 122  		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTaðŸ”µ</abbr>
 123  
 124  		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);
 125  		Integer parallelism = kafka010SourceTableInfo.getParallelism();

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 126 -		if (parallelism != null) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 127 +		if (parallelism &gt; 0) {</span>
 128  			kafkaSource.setParallelism(parallelism);
 129  		}
 130  		return tableEnv.fromDataStream(kafkaSource, fields);
 131  	}
 132  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.source.kafka;
  21  
  22  import com.dtstack.flink.sql.source.IStreamSourceGener;
  23  import com.dtstack.flink.sql.source.kafka.table.KafkaSourceTableInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import com.dtstack.flink.sql.table.SourceTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  25 +import com.dtstack.flink.sql.table.AbstractSourceTableInfo;</span>
  26  import com.dtstack.flink.sql.util.DtStringUtil;
  27  import com.dtstack.flink.sql.util.PluginUtil;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  28 -import org.apache.commons.lang3.BooleanUtils;</span>
  29  import org.apache.commons.lang3.StringUtils;
  30  import org.apache.flink.api.common.typeinfo.TypeInformation;
  31  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32  import org.apache.flink.streaming.api.datastream.DataStreamSource;
  33  import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  34  import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;
  35  import org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition;
  36  import org.apache.flink.table.api.Table;
  37  import org.apache.flink.table.api.java.StreamTableEnvironment;
  38  import org.apache.flink.types.Row;
  39  
  40  import java.util.HashMap;
  41  import java.util.Map;
  42  import java.util.Properties;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  43 -import java.util.regex.Pattern;</span>
  44  
  45  /**
  46   * If eventtime field is specified, the default time field rowtime
  47   * Date: 2018/09/18
  48   * Company: www.dtstack.com
  49   *
  50   * @author sishu.yss
  51   */
  52  
  53  public class KafkaSource implements IStreamSourceGener&lt;Table&gt; {
  54  
  55  	private static final String SOURCE_OPERATOR_NAME_TPL = &quot;${topic}_${table}&quot;;
  56  
  57  	/**
  58  	 * Get kafka data source, you need to provide the data field names, data types
  59  	 * If you do not specify auto.offset.reset, the default use groupoffset
  60  	 *
  61  	 * @param sourceTableInfo
  62  	 * @return
  63  	 */
  64  	@SuppressWarnings(&quot;rawtypes&quot;)
  65  	@Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title="  66 -	public Table genStreamSource(SourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  66 -	public Table genStreamSource(SourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironmðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  67 +	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv) {">  67 +	public Table genStreamSource(AbstractSourceTableInfo sourceTableInfo, StreamExecutionEnvironment env, StreamTableðŸ”µ</abbr></span>
  68  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  69 -		KafkaSourceTableInfo kafka010SourceTableInfo = (KafkaSourceTableInfo) sourceTableInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  70 -		String topicName = kafka010SourceTableInfo.getTopic();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  71 +		KafkaSourceTableInfo kafkaSourceTableInfo = (KafkaSourceTableInfo) sourceTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  72 +		String topicName = kafkaSourceTableInfo.getTopic();</span>
  73  
  74  		Properties props = new Properties();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  75 -		for (String key : kafka010SourceTableInfo.getKafkaParamKeys()) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  76 -			props.setProperty(key, kafka010SourceTableInfo.getKafkaParam(key));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  77 +		for (String key : kafkaSourceTableInfo.getKafkaParamKeys()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  78 +			props.setProperty(key, kafkaSourceTableInfo.getKafkaParam(key));</span>
  79  		}
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  80 -		props.setProperty(&quot;bootstrap.servers&quot;, kafka010SourceTableInfo.getBootstrapServers());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  81 -		if (DtStringUtil.isJosn(kafka010SourceTableInfo.getOffsetReset())){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  82 +		props.setProperty(&quot;bootstrap.servers&quot;, kafkaSourceTableInfo.getBootstrapServers());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  83 +		if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())){</span>
  84  			props.setProperty(&quot;auto.offset.reset&quot;, &quot;none&quot;);
  85  		} else {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  86 -			props.setProperty(&quot;auto.offset.reset&quot;, kafka010SourceTableInfo.getOffsetReset());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  87 +			props.setProperty(&quot;auto.offset.reset&quot;, kafkaSourceTableInfo.getOffsetReset());</span>
  88  		}
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  89 -		if (StringUtils.isNotBlank(kafka010SourceTableInfo.getGroupId())){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  90 -			props.setProperty(&quot;group.id&quot;, kafka010SourceTableInfo.getGroupId());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  91 -		}</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  92 -		// only required for Kafka 0.8</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  93 -		//TODO props.setProperty(&quot;zookeeper.connect&quot;, kafka09SourceTableInfo.)</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  94 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  95 -		TypeInformation[] types = new TypeInformation[kafka010SourceTableInfo.getFields().length];</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  96 -		for (int i = 0; i &lt; kafka010SourceTableInfo.getFieldClasses().length; i++) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  97 -			types[i] = TypeInformation.of(kafka010SourceTableInfo.getFieldClasses()[i]);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  98 +		if (StringUtils.isNotBlank(kafkaSourceTableInfo.getGroupId())){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  99 +			props.setProperty(&quot;group.id&quot;, kafkaSourceTableInfo.getGroupId());</span>
 100  		}
 101  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 102 -		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafka010SourceTableInfo.getFields());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 103 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 104 -		FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 105 -		if (BooleanUtils.isTrue(kafka010SourceTableInfo.getTopicIsPattern())) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 106 -			kafkaSrc = new CustomerKafka010Consumer(Pattern.compile(topicName),</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 107 -					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTableInfo.getFieldExtraInfoList()), props);"> 107 -					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTðŸ”µ</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 108 -		} else {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 109 -			kafkaSrc = new CustomerKafka010Consumer(topicName,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 110 -					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTableInfo.getFieldExtraInfoList()), props);"> 110 -					new CustomerJsonDeserialization(typeInformation, kafka010SourceTableInfo.getPhysicalFields(), kafka010SourceTðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 111 +		TypeInformation[] types = new TypeInformation[kafkaSourceTableInfo.getFields().length];</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 112 +		for (int i = 0; i &lt; kafkaSourceTableInfo.getFieldClasses().length; i++) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 113 +			types[i] = TypeInformation.of(kafkaSourceTableInfo.getFieldClasses()[i]);</span>
 114  		}
 115  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 116 +		TypeInformation&lt;Row&gt; typeInformation = new RowTypeInfo(types, kafkaSourceTableInfo.getFields());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 117 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 118 +        FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().createKafkaTableSource(kafkaSourceTableInfo, typeInformation, props);"> 118 +        FlinkKafkaConsumer010&lt;Row&gt; kafkaSrc = (FlinkKafkaConsumer010&lt;Row&gt;) new KafkaConsumer010Factory().createKafðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 119 +</span>
 120  		//earliest,latest
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 121 -		if (&quot;earliest&quot;.equalsIgnoreCase(kafka010SourceTableInfo.getOffsetReset())) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 122 +		if (&quot;earliest&quot;.equalsIgnoreCase(kafkaSourceTableInfo.getOffsetReset())) {</span>
 123  			kafkaSrc.setStartFromEarliest();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 124 -		} else if (DtStringUtil.isJosn(kafka010SourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 125 +		} else if (DtStringUtil.isJosn(kafkaSourceTableInfo.getOffsetReset())) {// {&quot;0&quot;:12312,&quot;1&quot;:12321,&quot;2&quot;:12312}</span>
 126  			try {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 127 -				Properties properties = PluginUtil.jsonStrToObject(kafka010SourceTableInfo.getOffsetReset(), Properties.class);"> 127 -				Properties properties = PluginUtil.jsonStrToObject(kafka010SourceTableInfo.getOffsetReset(), Properties.class)ðŸ”µ</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 128 -				Map&lt;String, Object&gt; offsetMap = PluginUtil.ObjectToMap(properties);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 129 +				Properties properties = PluginUtil.jsonStrToObject(kafkaSourceTableInfo.getOffsetReset(), Properties.class);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 130 +				Map&lt;String, Object&gt; offsetMap = PluginUtil.objectToMap(properties);</span>
 131  				Map&lt;KafkaTopicPartition, Long&gt; specificStartupOffsets = new HashMap&lt;&gt;();
 132  				for (Map.Entry&lt;String, Object&gt; entry : offsetMap.entrySet()) {
<abbr title=" 133  					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(entry.getValue().toString()));"> 133  					specificStartupOffsets.put(new KafkaTopicPartition(topicName, Integer.valueOf(entry.getKey())), Long.valueOf(ðŸ”µ</abbr>
 134  				}
 135  				kafkaSrc.setStartFromSpecificOffsets(specificStartupOffsets);
 136  			} catch (Exception e) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 137 -				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafka010SourceTableInfo.getOffsetReset());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 138 +				throw new RuntimeException(&quot;not support offsetReset type:&quot; + kafkaSourceTableInfo.getOffsetReset());</span>
 139  			}
 140  		} else {
 141  			kafkaSrc.setStartFromLatest();
 142  		}
 143  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 144 -		String fields = StringUtils.join(kafka010SourceTableInfo.getFields(), &quot;,&quot;);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 145 +		String fields = StringUtils.join(kafkaSourceTableInfo.getFields(), &quot;,&quot;);</span>
<abbr title=" 146  		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTableInfo.getName());"> 146  		String sourceOperatorName = SOURCE_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, topicName).replace(&quot;${table}&quot;, sourceTaðŸ”µ</abbr>
 147  
 148  		DataStreamSource kafkaSource = env.addSource(kafkaSrc, sourceOperatorName, typeInformation);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 149 -		Integer parallelism = kafka010SourceTableInfo.getParallelism();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 150 +		Integer parallelism = kafkaSourceTableInfo.getParallelism();</span>
 151  		if (parallelism != null) {

 152  			kafkaSource.setParallelism(parallelism);
 153  		}
 154  		return tableEnv.fromDataStream(kafkaSource, fields);
 155  	}
 156  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            