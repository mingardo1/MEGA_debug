<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>551 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    protected FlinkKafkaProducer09&lt;Row&gt; &#x27;
                         &#x27;kafkaProducer09;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\tprotected FlinkKafkaProducer09&lt;CRow&gt; &#x27;
                           &#x27;kafkaProducer09;\n&#x27;
                           &#x27;\tprotected CRowTypeInfo typeInformation;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    /** Partitioner to select Kafka partition for &#x27;
                         &#x27;each item. */\n&#x27;
                         &#x27;    protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; &#x27;
                         &#x27;partitioner;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t/** Partitioner to select Kafka partition for &#x27;
                           &#x27;each item. */\n&#x27;
                           &#x27;\tprotected Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; &#x27;
                           &#x27;partitioner;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer09 = &#x27;
                         &#x27;(FlinkKafkaProducer09&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducer09Factory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\ttypeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;\t\tthis.kafkaProducer09 = &#x27;
                           &#x27;(FlinkKafkaProducer09&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducer09Factory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                         &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                         &#x27;fieldNames);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public void &#x27;
                         &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;
                         &#x27;                .setParallelism(parallelism);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic void &#x27;
                           &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;dataStream) {\n&#x27;
                           &#x27;\t\tDataStream&lt;CRow&gt; mapDataStream = dataStream\n&#x27;
                           &#x27;\t\t\t\t.map((Tuple2&lt;Boolean, Row&gt; record) -&gt; new &#x27;
                           &#x27;CRow(record.f1, record.f0))\n&#x27;
                           &#x27;\t\t\t\t.returns(typeInformation)\n&#x27;
                           &#x27;\t\t\t\t.setParallelism(parallelism);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer09 = &#x27;
                         &#x27;(FlinkKafkaProducer09&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducer09Factory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka09SinkTableInfo.getName());\n&#x27;
                         &#x27;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\ttypeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;\t\tthis.kafkaProducer09 = &#x27;
                           &#x27;(FlinkKafkaProducer09&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducer09Factory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\tDataStream&lt;CRow&gt; mapDataStream = dataStream\n&#x27;
                           &#x27;\t\t\t\t.map((Tuple2&lt;Boolean, Row&gt; record) -&gt; new &#x27;
                           &#x27;CRow(record.f1, record.f0))\n&#x27;
                           &#x27;\t\t\t\t.returns(typeInformation)\n&#x27;
                           &#x27;\t\t\t\t.setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tmapDataStream.addSink(kafkaProducer09)\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;import &#x27;
                         &#x27;org.apache.flink.streaming.api.datastream.DataStreamSink;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;import &#x27;
                           &#x27;org.apache.flink.streaming.api.functions.sink.RichSinkFunction;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    protected FlinkKafkaProducer09&lt;Row&gt; &#x27;
                         &#x27;kafkaProducer09;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\tprotected FlinkKafkaProducer09&lt;CRow&gt; &#x27;
                           &#x27;kafkaProducer09;\n&#x27;
                           &#x27;\tprotected CRowTypeInfo typeInformation;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;    /** Partitioner to select Kafka partition for &#x27;
                         &#x27;each item. */\n&#x27;
                         &#x27;    protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; &#x27;
                         &#x27;partitioner;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t/** Partitioner to select Kafka partition for &#x27;
                           &#x27;each item. */\n&#x27;
                           &#x27;\tprotected Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; &#x27;
                           &#x27;partitioner;\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer09 = &#x27;
                         &#x27;(FlinkKafkaProducer09&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducer09Factory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\ttypeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;\t\tthis.kafkaProducer09 = &#x27;
                           &#x27;(FlinkKafkaProducer09&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducer09Factory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public TypeInformation&lt;Row&gt; getRecordType() {\n&#x27;
                         &#x27;        return new RowTypeInfo(fieldTypes, &#x27;
                         &#x27;fieldNames);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public void &#x27;
                         &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;
                         &#x27;                .setParallelism(parallelism);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic void &#x27;
                           &#x27;emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                           &#x27;dataStream) {\n&#x27;
                           &#x27;\t\tDataStream&lt;CRow&gt; mapDataStream = dataStream\n&#x27;
                           &#x27;\t\t\t\t.map((Tuple2&lt;Boolean, Row&gt; record) -&gt; new &#x27;
                           &#x27;CRow(record.f1, record.f0))\n&#x27;
                           &#x27;\t\t\t\t.returns(typeInformation)\n&#x27;
                           &#x27;\t\t\t\t.setParallelism(parallelism);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer09 = &#x27;
                         &#x27;(FlinkKafkaProducer09&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducer09Factory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafka09SinkTableInfo.getName());\n&#x27;
                         &#x27;\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\ttypeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;\t\tthis.kafkaProducer09 = &#x27;
                           &#x27;(FlinkKafkaProducer09&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducer09Factory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\tDataStream&lt;CRow&gt; mapDataStream = dataStream\n&#x27;
                           &#x27;\t\t\t\t.map((Tuple2&lt;Boolean, Row&gt; record) -&gt; new &#x27;
                           &#x27;CRow(record.f1, record.f0))\n&#x27;
                           &#x27;\t\t\t\t.returns(typeInformation)\n&#x27;
                           &#x27;\t\t\t\t.setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tmapDataStream.addSink(kafkaProducer09)\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        