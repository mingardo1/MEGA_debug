<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>499</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    499
                    <a href="498.html">prev</a>
                    <a href="500.html">next</a>
                    <a href="499_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_b33108525150e417d003328be87242cc626fe203_kafka-base/kafka-base-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/AbstractKafkaProducerFactory.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b33108525150e417d003328be87242cc626fe203:kafka-base/kafka-base-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/AbstractKafkaProducerFactory.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b33108525150e417d003328be87242cc626fe203^1:kafka-base/kafka-base-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/AbstractKafkaProducerFactory.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b33108525150e417d003328be87242cc626fe203^2:kafka-base/kafka-base-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/AbstractKafkaProducerFactory.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b59ef71c4aa3401fd523d61328334a6bac817e1c:kafka-base/kafka-base-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/AbstractKafkaProducerFactory.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [bj], [bj], [s]], subset: [[b], [sbj], [bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.sink.kafka;
  19 
  20 import com.dtstack.flink.sql.format.FormatType;
  21 import com.dtstack.flink.sql.format.SerializationMetricWrapper;
  22 import com.dtstack.flink.sql.sink.kafka.serialization.AvroCRowSerializationSchema;
  23 import com.dtstack.flink.sql.sink.kafka.serialization.CsvCRowSerializationSchema;
  24 import com.dtstack.flink.sql.sink.kafka.serialization.JsonCRowSerializationSchema;
  25 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  26 import org.apache.commons.lang3.StringUtils;
  27 import org.apache.flink.api.common.serialization.SerializationSchema;
  28 import org.apache.flink.api.common.typeinfo.TypeInformation;
  29 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
  30 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  31 import org.apache.flink.formats.avro.AvroRowSerializationSchema;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  32 import org.apache.flink.formats.csv.CsvRowSerializationSchema;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  33 import org.apache.flink.formats.json.JsonRowSerializationSchema;</span>
  34 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  35 import org.apache.flink.formats.avro.AvroRowSerializationSchema;</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  36 import org.apache.flink.formats.csv.CsvRowSerializationSchema;</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  37 import org.apache.flink.formats.json.DTJsonRowSerializationSchema;</span>
  38 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  39 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
  40 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  41 import org.apache.flink.table.runtime.types.CRow;
  42 
  43 import java.util.Optional;
  44 import java.util.Properties;
  45 
  46 /**
  47  * ÊäΩË±°ÁöÑkafka producer ÁöÑÂ∑•ÂéÇÁ±ª
  48  * ÂåÖÊã¨Â∫èÁªü‰∏ÄÁöÑÂ∫èÂàóÂåñÂ∑•ÂÖ∑ÁöÑÊûÑÈÄ†
  49  * company: www.dtstack.com
  50  * @author: toutian
  51  * create: 2019/12/26
  52  */
  53 public abstract class AbstractKafkaProducerFactory {
  54 
  55     /**
  56      *  Ëé∑ÂèñÂÖ∑‰ΩìÁöÑKafkaProducer
  57      * eg create KafkaProducer010
  58      * @param kafkaSinkTableInfo
  59      * @param typeInformation
  60      * @param properties
  61      * @param partitioner
  62      * @return
  63      */
<abbr title="  64     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; partitioner, String[] partitionKeys);">  64     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, Typüîµ</abbr>
  65 
<abbr title="  66     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  66     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTabüîµ</abbr>
<abbr title="  67         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typeInformation);">  67         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typüîµ</abbr>
  68         return new SerializationMetricWrapper(serializationSchema);
  69     }
  70 
<abbr title="  71     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  71     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, Tyüîµ</abbr>
  72         SerializationSchema&lt;CRow&gt; serializationSchema = null;
  73         if (FormatType.JSON.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  74             if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {
  75 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title="  76                 serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());">  76                 serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(üîµ</abbr></span>
  77 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title="  78                 serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());">  78                 serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString()üîµ</abbr></span>
  79 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title="  80                 serializationSchema = new DTJsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());">  80                 serializationSchema = new DTJsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaStringüîµ</abbr></span>
  81 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  82             } else if (typeInformation != null &amp;&amp; typeInformation.getArity() != 0) {
  83 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title="  84                 serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfo.getUpdateMode());">  84                 serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfoüîµ</abbr></span>
  85 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  86                 serializationSchema = new JsonRowSerializationSchema(typeInformation);</span>
  87 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  88                 serializationSchema = new DTJsonRowSerializationSchema(typeInformation);</span>
  89 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  90             } else {
<abbr title="  91                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStringÔºàJSON SchemaÔºâor TypeInformation&lt;Row&gt;&quot;);">  91                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set üîµ</abbr>
  92             }
  93         } else if (FormatType.CSV.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  94             if (StringUtils.isBlank(kafkaSinkTableInfo.getFieldDelimiter())) {
<abbr title="  95                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimiter&quot;);">  95                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set füîµ</abbr>
  96             }
<abbr title="  97             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Builder(typeInformation);">  97             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Buüîµ</abbr>
  98             serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);
  99             serSchemaBuilder.setUpdateMode(kafkaSinkTableInfo.getUpdateMode());
 100 
 101             serializationSchema = serSchemaBuilder.build();
 102         } else if (FormatType.AVRO.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
 103             if (StringUtils.isBlank(kafkaSinkTableInfo.getSchemaString())) {
<abbr title=" 104                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaString&quot;);"> 104                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set üîµ</abbr>
 105             }
<abbr title=" 106             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());"> 106             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), küîµ</abbr>
 107         }
 108 
 109         if (null == serializationSchema) {
<abbr title=" 110             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType());"> 110             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType())üîµ</abbr>
 111         }
 112 
 113         return serializationSchema;
 114     }
 115 
 116 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.sink.kafka;
  19 
  20 import com.dtstack.flink.sql.format.FormatType;
  21 import com.dtstack.flink.sql.format.SerializationMetricWrapper;
  22 import com.dtstack.flink.sql.sink.kafka.serialization.AvroCRowSerializationSchema;
  23 import com.dtstack.flink.sql.sink.kafka.serialization.CsvCRowSerializationSchema;
  24 import com.dtstack.flink.sql.sink.kafka.serialization.JsonCRowSerializationSchema;
  25 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  26 import org.apache.commons.lang3.StringUtils;
  27 import org.apache.flink.api.common.serialization.SerializationSchema;
  28 import org.apache.flink.api.common.typeinfo.TypeInformation;
  29 import org.apache.flink.formats.json.DTJsonRowSerializationSchema;
  30 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
  31 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  32 import org.apache.flink.table.runtime.types.CRow;
  33 
  34 import java.util.Optional;
  35 import java.util.Properties;
  36 
  37 /**
  38  * ÊäΩË±°ÁöÑkafka producer ÁöÑÂ∑•ÂéÇÁ±ª
  39  * ÂåÖÊã¨Â∫èÁªü‰∏ÄÁöÑÂ∫èÂàóÂåñÂ∑•ÂÖ∑ÁöÑÊûÑÈÄ†
  40  * company: www.dtstack.com
  41  * @author: toutian
  42  * create: 2019/12/26
  43  */
  44 public abstract class AbstractKafkaProducerFactory {
  45 
  46     /**
  47      *  Ëé∑ÂèñÂÖ∑‰ΩìÁöÑKafkaProducer
  48      * eg create KafkaProducer010
  49      * @param kafkaSinkTableInfo
  50      * @param typeInformation
  51      * @param properties
  52      * @param partitioner
  53      * @return
  54      */
<abbr title="  55     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; partitioner, String[] partitionKeys);">  55     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, Typüîµ</abbr>
  56 
<abbr title="  57     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  57     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTabüîµ</abbr>
<abbr title="  58         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typeInformation);">  58         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typüîµ</abbr>
  59         return new SerializationMetricWrapper(serializationSchema);
  60     }
  61 
<abbr title="  62     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  62     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, Tyüîµ</abbr>
  63         SerializationSchema&lt;CRow&gt; serializationSchema = null;
  64         if (FormatType.JSON.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  65             if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {
  66 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title="  67                 serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());">  67                 serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(üîµ</abbr></span>
  68 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  69             if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title="  70                 serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());">  70                 serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString()üîµ</abbr></span>
  71 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title="  72                 serializationSchema = new DTJsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());">  72                 serializationSchema = new DTJsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaStringüîµ</abbr></span>
  73 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
  74             } else if (typeInformation != null &amp;&amp; typeInformation.getArity() != 0) {
  75 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title="  76                 serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfo.getUpdateMode());">  76                 serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfoüîµ</abbr></span>
  77 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  78             } else if (typeInformation != null &amp;&amp; typeInformation.getArity() != 0) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  79                 serializationSchema = new JsonRowSerializationSchema(typeInformation);</span>
  80 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  81                 serializationSchema = new DTJsonRowSerializationSchema(typeInformation);</span>
  82 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
  83             } else {
<abbr title="  84                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStringÔºàJSON SchemaÔºâor TypeInformation&lt;Row&gt;&quot;);">  84                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set üîµ</abbr>
  85             }
  86         } else if (FormatType.CSV.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  87             if (StringUtils.isBlank(kafkaSinkTableInfo.getFieldDelimiter())) {
<abbr title="  88                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimiter&quot;);">  88                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set füîµ</abbr>
  89             }
<abbr title="  90             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Builder(typeInformation);">  90             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Buüîµ</abbr>
  91             serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);
  92             serSchemaBuilder.setUpdateMode(kafkaSinkTableInfo.getUpdateMode());
  93 
  94             serializationSchema = serSchemaBuilder.build();
  95         } else if (FormatType.AVRO.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  96             if (StringUtils.isBlank(kafkaSinkTableInfo.getSchemaString())) {
<abbr title="  97                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaString&quot;);">  97                 throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set üîµ</abbr>
  98             }
<abbr title="  99             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());">  99             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), küîµ</abbr>
 100         }
 101 
 102         if (null == serializationSchema) {
<abbr title=" 103             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType());"> 103             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType())üîµ</abbr>
 104         }
 105 
 106         return serializationSchema;
 107     }
 108 
 109 }
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.sink.kafka;
  19 
  20 import com.dtstack.flink.sql.format.FormatType;
  21 import com.dtstack.flink.sql.format.SerializationMetricWrapper;
  22 import com.dtstack.flink.sql.sink.kafka.serialization.AvroCRowSerializationSchema;
  23 import com.dtstack.flink.sql.sink.kafka.serialization.CsvCRowSerializationSchema;
  24 import com.dtstack.flink.sql.sink.kafka.serialization.JsonCRowSerializationSchema;
  25 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  26 import java.util.Optional;
  27 import java.util.Properties;
  28 import org.apache.commons.lang3.StringUtils;
  29 import org.apache.flink.api.common.serialization.SerializationSchema;
  30 import org.apache.flink.api.common.typeinfo.TypeInformation;
  31 import org.apache.flink.formats.json.DTJsonRowSerializationSchema;
  32 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
  33 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  34 import org.apache.flink.table.runtime.types.CRow;
  35 
  36 
  37 /**
  38  * ÊäΩË±°ÁöÑkafka producer ÁöÑÂ∑•ÂéÇÁ±ª
  39  * ÂåÖÊã¨Â∫èÁªü‰∏ÄÁöÑÂ∫èÂàóÂåñÂ∑•ÂÖ∑ÁöÑÊûÑÈÄ†
  40  * company: www.dtstack.com
  41  * @author: toutian
  42  * create: 2019/12/26
  43  */
  44 public abstract class AbstractKafkaProducerFactory {
  45     /**
  46      *  Ëé∑ÂèñÂÖ∑‰ΩìÁöÑKafkaProducer
  47      * eg create KafkaProducer010
  48      * @param kafkaSinkTableInfo
  49      * @param typeInformation
  50      * @param properties
  51      * @param partitioner
  52      * @return
  53      */
<abbr title="  54     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; partitioner, String[] partitionKeys);">  54     public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, Typüîµ</abbr>
  55 
<abbr title="  56     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  56     protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTabüîµ</abbr>
<abbr title="  57         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typeInformation);">  57         SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typüîµ</abbr>
  58         return new SerializationMetricWrapper(serializationSchema);
  59     }
  60 
<abbr title="  61     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  61     private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, Tyüîµ</abbr>
  62         SerializationSchema&lt;CRow&gt; serializationSchema = null;
  63         if (FormatType.JSON.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  64             if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {
  65                 serializationSchema = new
  66 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  67 JsonCRowSerializationSchema</span>
  68 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title="  69 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/">  69 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwüîµ</abbr></span>
  70 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  71 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  72 DTJsonRowSerializationSchema</span>
  73 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
  74                 (kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());
  75             } else if ((typeInformation != null) &amp;&amp; (typeInformation.getArity() != 0)) {
  76                 serializationSchema = new
  77 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  78 JsonCRowSerializationSchema</span>
  79 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title="  80 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/">  80 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwüîµ</abbr></span>
  81 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  82 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  83 DTJsonRowSerializationSchema</span>
  84 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
  85                 (typeInformation, kafkaSinkTableInfo.getUpdateMode());
  86             } else {
<abbr title="  87                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.JSON.name()) + &quot; must set schemaStringÔºàJSON SchemaÔºâor TypeInformation&lt;Row&gt;&quot;);">  87                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.JSON.name()) + &quot; must seüîµ</abbr>
  88             }
  89         } else if (FormatType.CSV.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  90             if (StringUtils.isBlank(kafkaSinkTableInfo.getFieldDelimiter())) {
<abbr title="  91                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.CSV.name()) + &quot; must set fieldDelimiter&quot;);">  91                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.CSV.name()) + &quot; must setüîµ</abbr>
  92             }
<abbr title="  93             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Builder(typeInformation);">  93             final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Buüîµ</abbr>
  94             serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);
  95             serSchemaBuilder.setUpdateMode(kafkaSinkTableInfo.getUpdateMode());
  96             serializationSchema = serSchemaBuilder.build();
  97         } else if (FormatType.AVRO.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  98             if (StringUtils.isBlank(kafkaSinkTableInfo.getSchemaString())) {
<abbr title="  99                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.AVRO.name()) + &quot; must set schemaString&quot;);">  99                 throw new IllegalArgumentException((&quot;sinkDataType:&quot; + FormatType.AVRO.name()) + &quot; must seüîµ</abbr>
 100             }
<abbr title=" 101             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());"> 101             serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), küîµ</abbr>
 102         }
 103         if (null == serializationSchema) {
<abbr title=" 104             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType());"> 104             throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType())üîµ</abbr>
 105         }
 106         return serializationSchema;
 107     }
 108 }
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  package com.dtstack.flink.sql.sink.kafka;
  19  
  20  import com.dtstack.flink.sql.format.FormatType;
  21  import com.dtstack.flink.sql.format.SerializationMetricWrapper;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  22 +import com.dtstack.flink.sql.sink.kafka.serialization.AvroCRowSerializationSchema;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  23 +import com.dtstack.flink.sql.sink.kafka.serialization.CsvCRowSerializationSchema;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  24 +import com.dtstack.flink.sql.sink.kafka.serialization.JsonCRowSerializationSchema;</span>
  25  import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  26  import org.apache.commons.lang3.StringUtils;
  27  import org.apache.flink.api.common.serialization.SerializationSchema;
  28  import org.apache.flink.api.common.typeinfo.TypeInformation;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  29 -import org.apache.flink.formats.avro.AvroRowSerializationSchema;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  30 -import org.apache.flink.formats.csv.CsvRowSerializationSchema;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  31 -import org.apache.flink.formats.json.JsonRowSerializationSchema;</span>

  32  import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
  33  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  34 -import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  35 +import org.apache.flink.table.runtime.types.CRow;</span>
  36  
  37  import java.util.Optional;
  38  import java.util.Properties;
  39  
  40  /**
  41   * ÊäΩË±°ÁöÑkafka producer ÁöÑÂ∑•ÂéÇÁ±ª
  42   * ÂåÖÊã¨Â∫èÁªü‰∏ÄÁöÑÂ∫èÂàóÂåñÂ∑•ÂÖ∑ÁöÑÊûÑÈÄ†
  43   * company: www.dtstack.com
  44   * @author: toutian
  45   * create: 2019/12/26
  46   */
  47  public abstract class AbstractKafkaProducerFactory {
  48  
  49      /**
  50       *  Ëé∑ÂèñÂÖ∑‰ΩìÁöÑKafkaProducer
  51       * eg create KafkaProducer010
  52       * @param kafkaSinkTableInfo
  53       * @param typeInformation
  54       * @param properties
  55       * @param partitioner
  56       * @return
  57       */
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title="  58 -    public abstract RichSinkFunction&lt;Row&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner, String[] partitionKeys);">  58 -    public abstract RichSinkFunction&lt;Row&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformatiüîµ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  59 +    public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;CRow&gt;&gt; partitioner, String[] partitionKeys);">  59 +    public abstract RichSinkFunction&lt;CRow&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformatüîµ</abbr></span>
  60  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title="  61 -    protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation) {">  61 -    protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, Tüîµ</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  62 -        return new SerializationMetricWrapper(createSerializationSchema(kafkaSinkTableInfo, typeInformation));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  63 +    protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  63 +    protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, Tüîµ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  64 +        SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typeInformation);">  64 +        SerializationSchema&lt;CRow&gt; serializationSchema = createSerializationSchema(kafkaSinkTableInfo, typeInformatüîµ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  65 +        return new SerializationMetricWrapper(serializationSchema);</span>
  66      }
  67  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title="  68 -    private SerializationSchema&lt;Row&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation) {">  68 -    private SerializationSchema&lt;Row&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformatüîµ</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  69 -        SerializationSchema&lt;Row&gt; serializationSchema = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  70 +    private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;CRow&gt; typeInformation) {">  70 +    private SerializationSchema&lt;CRow&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformaüîµ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  71 +        SerializationSchema&lt;CRow&gt; serializationSchema = null;</span>
  72          if (FormatType.JSON.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  73 -</span>
  74              if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  75 -                serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  76 +                serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());">  76 +                serializationSchema = new JsonCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSüîµ</abbr></span>
  77              } else if (typeInformation != null &amp;&amp; typeInformation.getArity() != 0) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  78 -                serializationSchema = new JsonRowSerializationSchema(typeInformation);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  79 +                serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfo.getUpdateMode());">  79 +                serializationSchema = new JsonCRowSerializationSchema(typeInformation, kafkaSinkTableInfo.getUpdatüîµ</abbr></span>
  80              } else {
<abbr title="  81                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStringÔºàJSON SchemaÔºâor TypeInformation&lt;Row&gt;&quot;);">  81                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStrüîµ</abbr>
  82              }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  83 -</span>
  84          } else if (FormatType.CSV.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  85 -</span>
  86              if (StringUtils.isBlank(kafkaSinkTableInfo.getFieldDelimiter())) {
<abbr title="  87                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimiter&quot;);">  87                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimüîµ</abbr>
  88              }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title="  89 +            final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Builder(typeInformation);">  89 +            final CsvCRowSerializationSchema.Builder serSchemaBuilder = new CsvCRowSerializationSchema.Builder(typüîµ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  90 +            serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  91 +            serSchemaBuilder.setUpdateMode(kafkaSinkTableInfo.getUpdateMode());</span>
  92  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title="  93 -            final CsvRowSerializationSchema.Builder serSchemaBuilder = new CsvRowSerializationSchema.Builder(typeInformation);">  93 -            final CsvRowSerializationSchema.Builder serSchemaBuilder = new CsvRowSerializationSchema.Builder(typeIüîµ</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  94 -            serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);</span>
  95              serializationSchema = serSchemaBuilder.build();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  96 -</span>
  97          } else if (FormatType.AVRO.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  98 -</span>
  99              if (StringUtils.isBlank(kafkaSinkTableInfo.getSchemaString())) {
<abbr title=" 100                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaString&quot;);"> 100                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaStrüîµ</abbr>
 101              }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 102 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 103 -            serializationSchema = new AvroRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 104 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 105 +            serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTableInfo.getUpdateMode());"> 105 +            serializationSchema = new AvroCRowSerializationSchema(kafkaSinkTableInfo.getSchemaString(), kafkaSinkTüîµ</abbr></span>
 106          }
 107  
 108          if (null == serializationSchema) {
 109              throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType());
 110          }
 111  
 112          return serializationSchema;
 113      }
 114  
 115  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  package com.dtstack.flink.sql.sink.kafka;
  19  
  20  import com.dtstack.flink.sql.format.FormatType;
  21  import com.dtstack.flink.sql.format.SerializationMetricWrapper;



  22  import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  23  import org.apache.commons.lang3.StringUtils;
  24  import org.apache.flink.api.common.serialization.SerializationSchema;
  25  import org.apache.flink.api.common.typeinfo.TypeInformation;
  26  import org.apache.flink.formats.avro.AvroRowSerializationSchema;
  27  import org.apache.flink.formats.csv.CsvRowSerializationSchema;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  28 -import org.apache.flink.formats.json.JsonRowSerializationSchema;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import org.apache.flink.formats.json.DTJsonRowSerializationSchema;</span>
  30  import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
  31  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  32  import org.apache.flink.types.Row;

  33  
  34  import java.util.Optional;
  35  import java.util.Properties;
  36  
  37  /**
  38   * ÊäΩË±°ÁöÑkafka producer ÁöÑÂ∑•ÂéÇÁ±ª
  39   * ÂåÖÊã¨Â∫èÁªü‰∏ÄÁöÑÂ∫èÂàóÂåñÂ∑•ÂÖ∑ÁöÑÊûÑÈÄ†
  40   * company: www.dtstack.com
  41   * @author: toutian
  42   * create: 2019/12/26
  43   */
  44  public abstract class AbstractKafkaProducerFactory {
  45  
  46      /**
  47       *  Ëé∑ÂèñÂÖ∑‰ΩìÁöÑKafkaProducer
  48       * eg create KafkaProducer010
  49       * @param kafkaSinkTableInfo
  50       * @param typeInformation
  51       * @param properties
  52       * @param partitioner
  53       * @return
  54       */
<abbr title="  55      public abstract RichSinkFunction&lt;Row&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation, Properties properties, Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner, String[] partitionKeys);">  55      public abstract RichSinkFunction&lt;Row&gt; createKafkaProducer(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformatiüîµ</abbr>

  56  
<abbr title="  57      protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation) {">  57      protected SerializationMetricWrapper createSerializationMetricWrapper(KafkaSinkTableInfo kafkaSinkTableInfo, Tüîµ</abbr>
  58          return new SerializationMetricWrapper(createSerializationSchema(kafkaSinkTableInfo, typeInformation));



  59      }
  60  
<abbr title="  61      private SerializationSchema&lt;Row&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformation&lt;Row&gt; typeInformation) {">  61      private SerializationSchema&lt;Row&gt; createSerializationSchema(KafkaSinkTableInfo kafkaSinkTableInfo, TypeInformatüîµ</abbr>
  62          SerializationSchema&lt;Row&gt; serializationSchema = null;


  63          if (FormatType.JSON.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  64  
  65              if (StringUtils.isNotBlank(kafkaSinkTableInfo.getSchemaString())) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  66 -                serializationSchema = new JsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  67 +                serializationSchema = new DTJsonRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());</span>
  68              } else if (typeInformation != null &amp;&amp; typeInformation.getArity() != 0) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  69 -                serializationSchema = new JsonRowSerializationSchema(typeInformation);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  70 +                serializationSchema = new DTJsonRowSerializationSchema(typeInformation);</span>
  71              } else {
<abbr title="  72                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStringÔºàJSON SchemaÔºâor TypeInformation&lt;Row&gt;&quot;);">  72                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.JSON.name() + &quot; must set schemaStrüîµ</abbr>
  73              }
  74  
  75          } else if (FormatType.CSV.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  76  
  77              if (StringUtils.isBlank(kafkaSinkTableInfo.getFieldDelimiter())) {
<abbr title="  78                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimiter&quot;);">  78                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.CSV.name() + &quot; must set fieldDelimüîµ</abbr>
  79              }



  80  
<abbr title="  81              final CsvRowSerializationSchema.Builder serSchemaBuilder = new CsvRowSerializationSchema.Builder(typeInformation);">  81              final CsvRowSerializationSchema.Builder serSchemaBuilder = new CsvRowSerializationSchema.Builder(typeIüîµ</abbr>
  82              serSchemaBuilder.setFieldDelimiter(kafkaSinkTableInfo.getFieldDelimiter().toCharArray()[0]);
  83              serializationSchema = serSchemaBuilder.build();
  84  
  85          } else if (FormatType.AVRO.name().equalsIgnoreCase(kafkaSinkTableInfo.getSinkDataType())) {
  86  
  87              if (StringUtils.isBlank(kafkaSinkTableInfo.getSchemaString())) {
<abbr title="  88                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaString&quot;);">  88                  throw new IllegalArgumentException(&quot;sinkDataType:&quot; + FormatType.AVRO.name() + &quot; must set schemaStrüîµ</abbr>
  89              }
  90  
  91              serializationSchema = new AvroRowSerializationSchema(kafkaSinkTableInfo.getSchemaString());
  92  

  93          }
  94  
  95          if (null == serializationSchema) {
  96              throw new UnsupportedOperationException(&quot;FormatType:&quot; + kafkaSinkTableInfo.getSinkDataType());
  97          }
  98  
  99          return serializationSchema;
 100      }
 101  
 102  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            