<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>544 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink {\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public KafkaSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;
                         &#x27;        KafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                         &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Properties kafkaProperties = &#x27;
                         &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.tableName = &#x27;
                         &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                         &#x27;        this.topic = &#x27;
                         &#x27;kafka09SinkTableInfo.getTopic();\n&#x27;
                         &#x27;        this.partitioner = Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                         &#x27;        this.partitionKeys = &#x27;
                         &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.fieldNames = &#x27;
                         &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                         &#x27;        this.fieldTypes = &#x27;
                         &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.schema = buildTableSchema(fieldNames, &#x27;
                         &#x27;fieldTypes);\n&#x27;
                         &#x27;        this.parallelism = &#x27;
                         &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                         &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink{\n&#x27;
                           &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic KafkaSink &#x27;
                           &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                           &#x27;targetTableInfo) {\n&#x27;
                           &#x27;\t\tKafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                           &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tProperties kafkaProperties = &#x27;
                           &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.tableName = &#x27;
                           &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                           &#x27;\t\tthis.topic = kafka09SinkTableInfo.getTopic();\n&#x27;
                           &#x27;\t\tthis.partitioner = Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                           &#x27;\t\tthis.partitionKeys = &#x27;
                           &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.fieldNames = &#x27;
                           &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                           &#x27;\t\tthis.fieldTypes = &#x27;
                           &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.schema = buildTableSchema(fieldNames, &#x27;
                           &#x27;fieldTypes);\n&#x27;
                           &#x27;\t\tthis.parallelism = &#x27;
                           &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                           &#x27;\t\tthis.sinkOperatorName = &#x27;
                           &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                           &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                           &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink {\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public KafkaSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;
                         &#x27;        KafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                         &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Properties kafkaProperties = &#x27;
                         &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.tableName = &#x27;
                         &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                         &#x27;        this.topic = &#x27;
                         &#x27;kafka09SinkTableInfo.getTopic();\n&#x27;
                         &#x27;        this.partitioner = Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                         &#x27;        this.partitionKeys = &#x27;
                         &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.fieldNames = &#x27;
                         &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                         &#x27;        this.fieldTypes = &#x27;
                         &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.schema = buildTableSchema(fieldNames, &#x27;
                         &#x27;fieldTypes);\n&#x27;
                         &#x27;        this.parallelism = &#x27;
                         &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                         &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;public class KafkaSink extends AbstractKafkaSink{\n&#x27;
                           &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic KafkaSink &#x27;
                           &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                           &#x27;targetTableInfo) {\n&#x27;
                           &#x27;\t\tKafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                           &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tProperties kafkaProperties = &#x27;
                           &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.tableName = &#x27;
                           &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                           &#x27;\t\tthis.topic = kafka09SinkTableInfo.getTopic();\n&#x27;
                           &#x27;\t\tthis.partitioner = Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                           &#x27;\t\tthis.partitionKeys = &#x27;
                           &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.fieldNames = &#x27;
                           &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                           &#x27;\t\tthis.fieldTypes = &#x27;
                           &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.schema = buildTableSchema(fieldNames, &#x27;
                           &#x27;fieldTypes);\n&#x27;
                           &#x27;\t\tthis.parallelism = &#x27;
                           &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                           &#x27;\t\tthis.sinkOperatorName = &#x27;
                           &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                           &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                           &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;spork&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink {\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public KafkaSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;
                         &#x27;        KafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                         &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Properties kafkaProperties = &#x27;
                         &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.tableName = &#x27;
                         &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                         &#x27;        this.topic = &#x27;
                         &#x27;kafka09SinkTableInfo.getTopic();\n&#x27;
                         &#x27;        this.partitioner = Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                         &#x27;        this.partitionKeys = &#x27;
                         &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.fieldNames = &#x27;
                         &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                         &#x27;        this.fieldTypes = &#x27;
                         &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.schema = buildTableSchema(fieldNames, &#x27;
                         &#x27;fieldTypes);\n&#x27;
                         &#x27;        this.parallelism = &#x27;
                         &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                         &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink{\n&#x27;
                           &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic KafkaSink &#x27;
                           &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                           &#x27;targetTableInfo) {\n&#x27;
                           &#x27;\t\tKafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                           &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tProperties kafkaProperties = &#x27;
                           &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.tableName = &#x27;
                           &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                           &#x27;\t\tthis.topic = kafka09SinkTableInfo.getTopic();\n&#x27;
                           &#x27;\t\tthis.partitioner = Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                           &#x27;\t\tthis.partitionKeys = &#x27;
                           &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.fieldNames = &#x27;
                           &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                           &#x27;\t\tthis.fieldTypes = &#x27;
                           &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.schema = buildTableSchema(fieldNames, &#x27;
                           &#x27;fieldTypes);\n&#x27;
                           &#x27;\t\tthis.parallelism = &#x27;
                           &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                           &#x27;\t\tthis.sinkOperatorName = &#x27;
                           &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                           &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                           &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;public class KafkaSink extends AbstractKafkaSink {\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public KafkaSink &#x27;
                         &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                         &#x27;targetTableInfo) {\n&#x27;
                         &#x27;        KafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                         &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        Properties kafkaProperties = &#x27;
                         &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.tableName = &#x27;
                         &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                         &#x27;        this.topic = &#x27;
                         &#x27;kafka09SinkTableInfo.getTopic();\n&#x27;
                         &#x27;        this.partitioner = Optional.of(new &#x27;
                         &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                         &#x27;        this.partitionKeys = &#x27;
                         &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.fieldNames = &#x27;
                         &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                         &#x27;        this.fieldTypes = &#x27;
                         &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                         &#x27;        this.schema = buildTableSchema(fieldNames, &#x27;
                         &#x27;fieldTypes);\n&#x27;
                         &#x27;        this.parallelism = &#x27;
                         &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                         &#x27;        this.kafkaProducer011 = new &#x27;
                         &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                         &#x27;getOutputType(), kafkaProperties, partitioner, &#x27;
                         &#x27;partitionKeys);\n&#x27;
                         &#x27;        return this;\n&#x27;
                         &#x27;    }\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;\n&#x27;
                           &#x27;public class KafkaSink extends AbstractKafkaSink{\n&#x27;
                           &#x27;\t@Override\n&#x27;
                           &#x27;\tpublic KafkaSink &#x27;
                           &#x27;genStreamSink(AbstractTargetTableInfo &#x27;
                           &#x27;targetTableInfo) {\n&#x27;
                           &#x27;\t\tKafkaSinkTableInfo kafka09SinkTableInfo = &#x27;
                           &#x27;(KafkaSinkTableInfo) targetTableInfo;\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;\t\tProperties kafkaProperties = &#x27;
                           &#x27;getKafkaProperties(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.tableName = &#x27;
                           &#x27;kafka09SinkTableInfo.getName();\n&#x27;
                           &#x27;\t\tthis.topic = kafka09SinkTableInfo.getTopic();\n&#x27;
                           &#x27;\t\tthis.partitioner = Optional.of(new &#x27;
                           &#x27;CustomerFlinkPartition&lt;&gt;());\n&#x27;
                           &#x27;\t\tthis.partitionKeys = &#x27;
                           &#x27;getPartitionKeys(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.fieldNames = &#x27;
                           &#x27;kafka09SinkTableInfo.getFields();\n&#x27;
                           &#x27;\t\tthis.fieldTypes = &#x27;
                           &#x27;getTypeInformations(kafka09SinkTableInfo);\n&#x27;
                           &#x27;\t\tthis.schema = buildTableSchema(fieldNames, &#x27;
                           &#x27;fieldTypes);\n&#x27;
                           &#x27;\t\tthis.parallelism = &#x27;
                           &#x27;kafka09SinkTableInfo.getParallelism();\n&#x27;
                           &#x27;\t\tthis.sinkOperatorName = &#x27;
                           &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                           &#x27;topic).replace(&quot;${table}&quot;, tableName);\n&#x27;
                           &#x27;\t\tthis.kafkaProducer = new &#x27;
                           &#x27;KafkaProducer09Factory().createKafkaProducer(kafka09SinkTableInfo, &#x27;
                           &#x27;getRowTypeInfo(), kafkaProperties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;
                           &#x27;\t\treturn this;\n&#x27;
                           &#x27;\t}\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;spork&#x27;, &#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        