<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>574</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    574
                    <a href="573.html">prev</a>
                    <a href="575.html">next</a>
                    <a href="574_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_3f89d1e66187447b56be7b8b76e9b09af9b9850d_kafka11/kafka11-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/KafkaSink.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;3f89d1e66187447b56be7b8b76e9b09af9b9850d:kafka11/kafka11-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/KafkaSink.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;3f89d1e66187447b56be7b8b76e9b09af9b9850d^1:kafka11/kafka11-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/KafkaSink.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;3f89d1e66187447b56be7b8b76e9b09af9b9850d^2:kafka11/kafka11-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/KafkaSink.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;b2e4085e6d35798d51707eb23aa215e0e694591e:kafka11/kafka11-sink/src/main/java/com/dtstack/flink/sql/sink/kafka/KafkaSink.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [bs], [bs], [j]], subset: [[b], [bs], [bs], [j]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.sink.kafka;
  20 
  21 import com.dtstack.flink.sql.sink.IStreamSinkGener;
  22 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  23 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  24 import org.apache.commons.lang3.StringUtils;
  25 import org.apache.flink.api.common.typeinfo.TypeInformation;
  26 import org.apache.flink.api.java.tuple.Tuple2;
  27 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  28 import org.apache.flink.api.java.typeutils.TupleTypeInfo;
  29 import org.apache.flink.streaming.api.datastream.DataStream;
  30 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  31 import org.apache.flink.streaming.api.datastream.DataStreamSink;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  32 import org.apache.flink.streaming.connectors.kafka.KafkaTableSinkBase;</span>
  33 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  34 import org.apache.flink.streaming.connectors.kafka.KafkaTableSinkBase;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  35 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;</span>
  36 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  37 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011;</span>
  38 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  39 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;
  40 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  41 import org.apache.flink.table.api.TableSchema;
  42 import org.apache.flink.table.sinks.RetractStreamTableSink;
  43 import org.apache.flink.table.sinks.TableSink;
  44 import org.apache.flink.table.utils.TableConnectorUtils;
  45 import org.apache.flink.types.Row;
  46 
  47 import java.util.Optional;
  48 import java.util.Properties;
  49 
  50 /**
  51  * kafka result table
  52  * Date: 2018/12/18
  53  * Company: www.dtstack.com
  54  *
  55  * @author DocLi
  56  *
  57  * @modifyer maqi
  58  *
  59  */
  60 public class KafkaSink  implements RetractStreamTableSink&lt;Row&gt;, IStreamSinkGener&lt;KafkaSink&gt; {
  61 
  62     protected String[] fieldNames;
  63 
  64     protected TypeInformation&lt;?&gt;[] fieldTypes;
  65 
  66     protected String topic;
  67 
  68     protected int parallelism;
  69 
  70     protected Properties properties;
  71 
  72     protected FlinkKafkaProducer011&lt;Row&gt; kafkaProducer011;
  73 
  74     /** The schema of the table. */
  75     private TableSchema schema;
  76 
  77     /** Partitioner to select Kafka partition for each item. */
  78     protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner;
  79     private String[] partitionKeys;
  80 
  81 
  82     @Override
  83     public KafkaSink genStreamSink(AbstractTargetTableInfo targetTableInfo) {
  84         KafkaSinkTableInfo kafka11SinkTableInfo = (KafkaSinkTableInfo) targetTableInfo;
  85         this.topic = kafka11SinkTableInfo.getTopic();
  86 
  87         properties = new Properties();
  88         properties.setProperty(&quot;bootstrap.servers&quot;, kafka11SinkTableInfo.getBootstrapServers());
  89 
  90         for (String key : kafka11SinkTableInfo.getKafkaParamKeys()) {
  91             properties.setProperty(key, kafka11SinkTableInfo.getKafkaParam(key));
  92         }
  93         this.partitioner = Optional.of(new CustomerFlinkPartition&lt;&gt;());
  94         this.partitionKeys = getPartitionKeys(kafka11SinkTableInfo);
  95         this.fieldNames = kafka11SinkTableInfo.getFields();
  96         TypeInformation[] types = new TypeInformation[kafka11SinkTableInfo.getFields().length];
  97         for (int i = 0; i &lt; kafka11SinkTableInfo.getFieldClasses().length; i++) {
  98             types[i] = TypeInformation.of(kafka11SinkTableInfo.getFieldClasses()[i]);
  99         }
 100         this.fieldTypes = types;
 101 
 102         TableSchema.Builder schemaBuilder = TableSchema.builder();
 103         for (int i=0;i&lt;fieldNames.length;i++) {
 104             schemaBuilder.field(fieldNames[i], fieldTypes[i]);
 105         }
 106         this.schema = schemaBuilder.build();
 107 
 108         Integer parallelism = kafka11SinkTableInfo.getParallelism();
 109         if (parallelism != null) {
 110             this.parallelism = parallelism;
 111         }
 112 
 113         this.kafkaProducer011 = (FlinkKafkaProducer011&lt;Row&gt;) new KafkaProducer011Factory()
<abbr title=" 114                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partitioner, partitionKeys);"> 114                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partðŸ”µ</abbr>
 115         return this;
 116     }
 117 
 118     @Override
 119     public TypeInformation&lt;Row&gt; getRecordType() {
 120         return new RowTypeInfo(fieldTypes, fieldNames);
 121     }
 122 
 123     @Override
 124     public void emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {
 125 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 126         consumeDataStream(dataStream);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 127     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 128 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 129     @Override</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 130     public DataStreamSink&lt;Row&gt; consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 131         KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 132                 schema,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 133                 topic,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 134                 properties,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 135                 partitioner,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 136                 serializationSchema</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 137         );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 138 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 139         DataStream&lt;Row&gt; ds = dataStream</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 140                 .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 141                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})</span>
 142 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 143                 schema,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 144                 topic,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 145                 properties,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 146                 partitioner,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 147                 serializationSchema</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 148         );</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 149 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 150         DataStream&lt;Row&gt; ds = dataStream</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 151                 .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 152                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 153                 .returns(getOutputType().getTypeAt(1))</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 154                 .setParallelism(parallelism);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 155 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 156         kafkaTableSink.emitDataStream(ds);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 157     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 158 </span>
 159 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 160         DataStream&lt;Row&gt; mapDataStream = dataStream.filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 161                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f1)</span>
 162 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 163                 .returns(getOutputType().getTypeAt(1))
 164                 .setParallelism(parallelism);
 165 
 166 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 167         DataStreamSink&lt;Row&gt; dataStreamSink = (DataStreamSink&lt;Row&gt;) kafkaTableSink.consumeDataStream(ds);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 168         return dataStreamSink;</span>
 169 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 170         DataStream&lt;Row&gt; ds = dataStream</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 171                 .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 172                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 173                 .returns(getOutputType().getTypeAt(1))</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 174                 .setParallelism(parallelism);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 175 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 176         kafkaTableSink.emitDataStream(ds);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 177     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 178 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 179     @Override</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 180     public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 181         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 181         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, ðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 182     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 183 </span>
 184 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 185         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFieldNames()));"> 185         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClasðŸ”µ</abbr></span>
 186 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 187     }
 188 
 189     @Override
 190     public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {
<abbr title=" 191         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 191         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, ðŸ”µ</abbr>
 192     }
 193 
 194     @Override
 195     public String[] getFieldNames() {
 196         return fieldNames;
 197     }
 198 
 199     @Override
 200     public TypeInformation&lt;?&gt;[] getFieldTypes() {
 201         return fieldTypes;
 202     }
 203 
 204     @Override
<abbr title=" 205     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes) {"> 205     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes)ðŸ”µ</abbr>
 206         this.fieldNames = fieldNames;
 207         this.fieldTypes = fieldTypes;
 208         return this;
 209     }
 210 
 211     private String[] getPartitionKeys(KafkaSinkTableInfo kafkaSinkTableInfo){
 212         if(StringUtils.isNotBlank(kafkaSinkTableInfo.getPartitionKeys())){
 213             return StringUtils.split(kafkaSinkTableInfo.getPartitionKeys(), &#x27;,&#x27;);
 214         }
 215         return null;
 216     }
 217 
 218 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.sink.kafka;
  20 
  21 import com.dtstack.flink.sql.sink.IStreamSinkGener;
  22 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  23 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  24 import org.apache.commons.lang3.StringUtils;
  25 import org.apache.flink.api.common.typeinfo.TypeInformation;
  26 import org.apache.flink.api.java.tuple.Tuple2;
  27 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  28 import org.apache.flink.api.java.typeutils.TupleTypeInfo;
  29 import org.apache.flink.streaming.api.datastream.DataStream;
  30 import org.apache.flink.streaming.api.datastream.DataStreamSink;
  31 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011;
  32 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;
  33 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  34 import org.apache.flink.table.api.TableSchema;
  35 import org.apache.flink.table.sinks.RetractStreamTableSink;
  36 import org.apache.flink.table.sinks.TableSink;
  37 import org.apache.flink.table.utils.TableConnectorUtils;
  38 import org.apache.flink.types.Row;
  39 
  40 import java.util.Optional;
  41 import java.util.Properties;
  42 
  43 /**
  44  * kafka result table
  45  * Date: 2018/12/18
  46  * Company: www.dtstack.com
  47  *
  48  * @author DocLi
  49  *
  50  * @modifyer maqi
  51  *
  52  */
  53 public class KafkaSink  implements RetractStreamTableSink&lt;Row&gt;, IStreamSinkGener&lt;KafkaSink&gt; {
  54 
  55     protected String[] fieldNames;
  56 
  57     protected TypeInformation&lt;?&gt;[] fieldTypes;
  58 
  59     protected String topic;
  60 
  61     protected int parallelism;
  62 
  63     protected Properties properties;
  64 
  65     protected FlinkKafkaProducer011&lt;Row&gt; kafkaProducer011;
  66 
  67     /** The schema of the table. */
  68     private TableSchema schema;
  69 
  70     /** Partitioner to select Kafka partition for each item. */
  71     protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner;
  72 
  73 
  74     @Override
  75     public KafkaSink genStreamSink(AbstractTargetTableInfo targetTableInfo) {
  76         KafkaSinkTableInfo kafka11SinkTableInfo = (KafkaSinkTableInfo) targetTableInfo;
  77         this.topic = kafka11SinkTableInfo.getTopic();
  78 
  79         properties = new Properties();
  80         properties.setProperty(&quot;bootstrap.servers&quot;, kafka11SinkTableInfo.getBootstrapServers());
  81 
  82         for (String key : kafka11SinkTableInfo.getKafkaParamKeys()) {
  83             properties.setProperty(key, kafka11SinkTableInfo.getKafkaParam(key));
  84         }
  85         this.partitioner = Optional.of(new CustomerFlinkPartition&lt;&gt;());
  86         this.partitionKeys = getPartitionKeys(kafka11SinkTableInfo);
  87         this.fieldNames = kafka11SinkTableInfo.getFields();
  88         TypeInformation[] types = new TypeInformation[kafka11SinkTableInfo.getFields().length];
  89         for (int i = 0; i &lt; kafka11SinkTableInfo.getFieldClasses().length; i++) {
  90             types[i] = TypeInformation.of(kafka11SinkTableInfo.getFieldClasses()[i]);
  91         }
  92         this.fieldTypes = types;
  93 
  94         TableSchema.Builder schemaBuilder = TableSchema.builder();
  95         for (int i=0;i&lt;fieldNames.length;i++) {
  96             schemaBuilder.field(fieldNames[i], fieldTypes[i]);
  97         }
  98         this.schema = schemaBuilder.build();
  99 
 100         Integer parallelism = kafka11SinkTableInfo.getParallelism();
 101         if (parallelism != null) {
 102             this.parallelism = parallelism;
 103         }
 104 
 105         this.kafkaProducer011 = (FlinkKafkaProducer011&lt;Row&gt;) new KafkaProducer011Factory()
<abbr title=" 106                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partitioner, partitionKeys);"> 106                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partðŸ”µ</abbr>
 107         return this;
 108     }
 109     private String[] partitionKeys;
 110 
 111     @Override
 112     public TypeInformation&lt;Row&gt; getRecordType() {
 113         return new RowTypeInfo(fieldTypes, fieldNames);
 114     }
 115 
 116     @Override
 117     public void emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {
 118 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 119         consumeDataStream(dataStream);</span>
 120 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 121         KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 122                 schema,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 123                 topic,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 124                 properties,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 125                 partitioner,</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 126                 serializationSchema</span>
 127 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 128         DataStream&lt;Row&gt; mapDataStream = dataStream.filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 129                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f1)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 130                 .returns(getOutputType().getTypeAt(1))</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 131                 .setParallelism(parallelism);</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 132 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 133         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFieldNames()));"> 133         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClasðŸ”µ</abbr></span>
 134 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 135     }
 136 
 137     @Override
 138     public DataStreamSink&lt;Row&gt; consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {
 139         KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(
 140                 schema,
 141                 topic,
 142                 properties,
 143                 partitioner,
 144                 serializationSchema
 145         );
 146 
 147         DataStream&lt;Row&gt; ds = dataStream
 148                 .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)
 149                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})
 150                 .returns(getOutputType().getTypeAt(1))
 151                 .setParallelism(parallelism);
 152 
 153         DataStreamSink&lt;Row&gt; dataStreamSink = (DataStreamSink&lt;Row&gt;) kafkaTableSink.consumeDataStream(ds);
 154         return dataStreamSink;
 155     }
 156 
 157     @Override
 158     public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {
<abbr title=" 159         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 159         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, ðŸ”µ</abbr>
 160     }
 161 
 162     @Override
 163     public String[] getFieldNames() {
 164         return fieldNames;
 165     }
 166 
 167     @Override
 168     public TypeInformation&lt;?&gt;[] getFieldTypes() {
 169         return fieldTypes;
 170     }
 171 
 172     @Override
<abbr title=" 173     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes) {"> 173     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes)ðŸ”µ</abbr>
 174         this.fieldNames = fieldNames;
 175         this.fieldTypes = fieldTypes;
 176         return this;
 177     }
 178 
 179     private String[] getPartitionKeys(KafkaSinkTableInfo kafkaSinkTableInfo){
 180         if(StringUtils.isNotBlank(kafkaSinkTableInfo.getPartitionKeys())){
 181             return StringUtils.split(kafkaSinkTableInfo.getPartitionKeys(), &#x27;,&#x27;);
 182         }
 183         return null;
 184     }
 185 
 186 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.sink.kafka;
  19 
  20 import com.dtstack.flink.sql.sink.IStreamSinkGener;
  21 import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  22 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  23 import java.util.Optional;
  24 import java.util.Properties;
  25 import org.apache.commons.lang3.StringUtils;
  26 import org.apache.flink.api.common.typeinfo.TypeInformation;
  27 import org.apache.flink.api.java.tuple.Tuple2;
  28 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  29 import org.apache.flink.api.java.typeutils.TupleTypeInfo;
  30 import org.apache.flink.streaming.api.datastream.DataStream;
  31 import org.apache.flink.streaming.api.datastream.DataStreamSink;
  32 import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011;
  33 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;
  34 import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  35 import org.apache.flink.table.api.TableSchema;
  36 import org.apache.flink.table.sinks.RetractStreamTableSink;
  37 import org.apache.flink.table.sinks.TableSink;
  38 import org.apache.flink.table.utils.TableConnectorUtils;
  39 import org.apache.flink.types.Row;
  40 
  41 
  42 /**
  43  * kafka result table
  44  * Date: 2018/12/18
  45  * Company: www.dtstack.com
  46  *
  47  * @author DocLi
  48  *
  49  * @modifyer maqi
  50  *
  51  */
  52 public class KafkaSink  implements RetractStreamTableSink&lt;Row&gt;, IStreamSinkGener&lt;KafkaSink&gt; {
  53 
  54     protected String[] fieldNames;
  55 
  56     protected TypeInformation&lt;?&gt;[] fieldTypes;
  57 
  58     protected String topic;
  59 
  60     protected int parallelism;
  61 
  62     protected Properties properties;
  63 
  64     protected FlinkKafkaProducer011&lt;Row&gt; kafkaProducer011;
  65 
  66     /** The schema of the table. */
  67     private TableSchema schema;
  68 
  69     /** Partitioner to select Kafka partition for each item. */
  70     protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner;
  71     private String[] partitionKeys;
  72 
  73 
  74     @Override
  75     public KafkaSink genStreamSink(AbstractTargetTableInfo targetTableInfo) {
  76         KafkaSinkTableInfo kafka11SinkTableInfo = (KafkaSinkTableInfo) targetTableInfo;
  77         this.topic = kafka11SinkTableInfo.getTopic();
  78 
  79         properties = new Properties();
  80         properties.setProperty(&quot;bootstrap.servers&quot;, kafka11SinkTableInfo.getBootstrapServers());
  81 
  82         for (String key : kafka11SinkTableInfo.getKafkaParamKeys()) {
  83             properties.setProperty(key, kafka11SinkTableInfo.getKafkaParam(key));
  84         }
  85         this.partitioner = Optional.of(new CustomerFlinkPartition&lt;&gt;());
  86         this.partitionKeys = getPartitionKeys(kafka11SinkTableInfo);
  87         this.fieldNames = kafka11SinkTableInfo.getFields();
  88         TypeInformation[] types = new TypeInformation[kafka11SinkTableInfo.getFields().length];
  89         for (int i = 0; i &lt; kafka11SinkTableInfo.getFieldClasses().length; i++) {
  90             types[i] = TypeInformation.of(kafka11SinkTableInfo.getFieldClasses()[i]);
  91         }
  92         this.fieldTypes = types;
  93 
  94         TableSchema.Builder schemaBuilder = TableSchema.builder();
  95         for (int i=0;i&lt;fieldNames.length;i++) {
  96             schemaBuilder.field(fieldNames[i], fieldTypes[i]);
  97         }
  98         this.schema = schemaBuilder.build();
  99 
 100         Integer parallelism = kafka11SinkTableInfo.getParallelism();
 101         if (parallelism != null) {
 102             this.parallelism = parallelism;
 103         }
 104 
 105         this.kafkaProducer011 = (FlinkKafkaProducer011&lt;Row&gt;) new KafkaProducer011Factory()
<abbr title=" 106                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partitioner, partitionKeys);"> 106                 .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partðŸ”µ</abbr>
 107         return this;
 108     }
 109 
 110     @Override
 111     public TypeInformation&lt;Row&gt; getRecordType() {
 112         return new RowTypeInfo(fieldTypes, fieldNames);
 113     }
 114 
 115     @Override
 116     public void emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {
 117 
 118 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 119         consumeDataStream(dataStream);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 120     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 121 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 122     @Override</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 123     public DataStreamSink&lt;Row&gt; consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 124         KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 125                 schema,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 126                 topic,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 127                 properties,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 128                 partitioner,</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 129                 serializationSchema</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 130         );</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 131 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 132         DataStream&lt;Row&gt; ds = dataStream</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 133                 .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 134                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 135 </span>
 136 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 137 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 137 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwðŸ”µ</abbr></span>
 138 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 139 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 140         DataStream&lt;Row&gt; mapDataStream = dataStream.filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 141                 .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f1)</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 142 </span>
 143 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 144                 .returns(getOutputType().getTypeAt(1))
 145                 .setParallelism(parallelism);
 146 
 147 
 148 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 149         DataStreamSink&lt;Row&gt; dataStreamSink = (DataStreamSink&lt;Row&gt;) kafkaTableSink.consumeDataStream(ds);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 150         return dataStreamSink;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 151 </span>
 152 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 153 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 153 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwðŸ”µ</abbr></span>
 154 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 155 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 156         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFieldNames()));"> 156         mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClasðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 157 </span>
 158 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 159     }
 160 
 161     @Override
 162     public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {
<abbr title=" 163         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 163         return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, ðŸ”µ</abbr>
 164     }
 165 
 166     @Override
 167     public String[] getFieldNames() {
 168         return fieldNames;
 169     }
 170 
 171     @Override
 172     public TypeInformation&lt;?&gt;[] getFieldTypes() {
 173         return fieldTypes;
 174     }
 175 
 176     @Override
<abbr title=" 177     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes) {"> 177     public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes)ðŸ”µ</abbr>
 178         this.fieldNames = fieldNames;
 179         this.fieldTypes = fieldTypes;
 180         return this;
 181     }
 182 
 183     private String[] getPartitionKeys(KafkaSinkTableInfo kafkaSinkTableInfo){
 184         if(StringUtils.isNotBlank(kafkaSinkTableInfo.getPartitionKeys())){
 185             return StringUtils.split(kafkaSinkTableInfo.getPartitionKeys(), &#x27;,&#x27;);
 186         }
 187         return null;
 188     }
 189 
 190 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.sink.kafka;
  20  
  21  import com.dtstack.flink.sql.sink.IStreamSinkGener;
  22  import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
  23  import com.dtstack.flink.sql.table.TargetTableInfo;
  24  import org.apache.flink.api.common.serialization.SerializationSchema;


  25  import org.apache.flink.api.common.typeinfo.TypeInformation;
  26  import org.apache.flink.api.java.tuple.Tuple2;
  27  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  28  import org.apache.flink.api.java.typeutils.TupleTypeInfo;
  29  import org.apache.flink.streaming.api.datastream.DataStream;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  30 +import org.apache.flink.streaming.api.datastream.DataStreamSink;</span>
  31  import org.apache.flink.streaming.connectors.kafka.KafkaTableSinkBase;

  32  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;
  33  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  34  import org.apache.flink.table.api.TableSchema;
  35  import org.apache.flink.table.sinks.RetractStreamTableSink;
  36  import org.apache.flink.table.sinks.TableSink;

  37  import org.apache.flink.types.Row;
  38  
  39  import java.util.Optional;
  40  import java.util.Properties;
  41  
  42  /**
  43   * kafka result table
  44   * Date: 2018/12/18
  45   * Company: www.dtstack.com
  46   *
  47   * @author DocLi
  48   *
  49   * @modifyer maqi
  50   *
  51   */
  52  public class KafkaSink  implements RetractStreamTableSink&lt;Row&gt;, IStreamSinkGener&lt;KafkaSink&gt; {
  53  
  54      protected String[] fieldNames;
  55  
  56      protected TypeInformation&lt;?&gt;[] fieldTypes;
  57  
  58      protected String topic;
  59  
  60      protected int parallelism;
  61  
  62      protected Properties properties;
  63  
  64      /** Serialization schema for encoding records to Kafka. */
  65      protected SerializationSchema serializationSchema;

  66  
  67      /** The schema of the table. */
  68      private TableSchema schema;
  69  
  70      /** Partitioner to select Kafka partition for each item. */
  71      protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner;

  72  
  73  
  74      @Override
  75      public KafkaSink genStreamSink(TargetTableInfo targetTableInfo) {

  76          KafkaSinkTableInfo kafka11SinkTableInfo = (KafkaSinkTableInfo) targetTableInfo;
  77          this.topic = kafka11SinkTableInfo.getTopic();
  78  
  79          properties = new Properties();
  80          properties.setProperty(&quot;bootstrap.servers&quot;, kafka11SinkTableInfo.getBootstrapServers());
  81  
  82          for (String key : kafka11SinkTableInfo.getKafkaParamKeys()) {
  83              properties.setProperty(key, kafka11SinkTableInfo.getKafkaParam(key));
  84          }
  85          this.partitioner = Optional.of(new FlinkFixedPartitioner&lt;&gt;());


  86          this.fieldNames = kafka11SinkTableInfo.getFields();
  87          TypeInformation[] types = new TypeInformation[kafka11SinkTableInfo.getFields().length];
  88          for (int i = 0; i &lt; kafka11SinkTableInfo.getFieldClasses().length; i++) {
  89              types[i] = TypeInformation.of(kafka11SinkTableInfo.getFieldClasses()[i]);
  90          }
  91          this.fieldTypes = types;
  92  
  93          TableSchema.Builder schemaBuilder = TableSchema.builder();
  94          for (int i=0;i&lt;fieldNames.length;i++) {
  95              schemaBuilder.field(fieldNames[i], fieldTypes[i]);
  96          }
  97          this.schema = schemaBuilder.build();
  98  
  99          Integer parallelism = kafka11SinkTableInfo.getParallelism();
 100          if (parallelism != null) {
 101              this.parallelism = parallelism;
 102          }
 103  
 104          this.serializationSchema = new CustomerJsonRowSerializationSchema(getOutputType().getTypeAt(1));


 105          return this;
 106      }
 107  
 108      @Override
 109      public TypeInformation&lt;Row&gt; getRecordType() {
 110          return new RowTypeInfo(fieldTypes, fieldNames);
 111      }
 112  
 113      @Override
 114      public void emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 115 +        consumeDataStream(dataStream);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 116 +    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 117 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 118 +    @Override</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 119 +    public DataStreamSink&lt;Row&gt; consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {</span>
 120          KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(
 121                  schema,
 122                  topic,
 123                  properties,
 124                  partitioner,
 125                  serializationSchema
 126          );
 127  
 128          DataStream&lt;Row&gt; ds = dataStream
 129                  .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)
 130                  .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})


 131                  .returns(getOutputType().getTypeAt(1))
 132                  .setParallelism(parallelism);
 133  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 134 -        kafkaTableSink.emitDataStream(ds);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 135 +        DataStreamSink&lt;Row&gt; dataStreamSink = (DataStreamSink&lt;Row&gt;) kafkaTableSink.consumeDataStream(ds);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 136 +        return dataStreamSink;</span>
 137      }
 138  
 139      @Override
 140      public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {
<abbr title=" 141          return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 141          return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNameðŸ”µ</abbr>
 142      }
 143  
 144      @Override
 145      public String[] getFieldNames() {
 146          return fieldNames;
 147      }
 148  
 149      @Override
 150      public TypeInformation&lt;?&gt;[] getFieldTypes() {
 151          return fieldTypes;
 152      }
 153  
 154      @Override
 155      public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes) {
 156          this.fieldNames = fieldNames;
 157          this.fieldTypes = fieldTypes;
 158          return this;
 159      }








 160  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.sink.kafka;
  20  
  21  import com.dtstack.flink.sql.sink.IStreamSinkGener;
  22  import com.dtstack.flink.sql.sink.kafka.table.KafkaSinkTableInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  23 -import com.dtstack.flink.sql.table.TargetTableInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import org.apache.flink.api.common.serialization.SerializationSchema;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  25 +import com.dtstack.flink.sql.table.AbstractTargetTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  26 +import org.apache.commons.lang3.StringUtils;</span>
  27  import org.apache.flink.api.common.typeinfo.TypeInformation;
  28  import org.apache.flink.api.java.tuple.Tuple2;
  29  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  30  import org.apache.flink.api.java.typeutils.TupleTypeInfo;
  31  import org.apache.flink.streaming.api.datastream.DataStream;

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  32 -import org.apache.flink.streaming.connectors.kafka.KafkaTableSinkBase;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  33 +import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011;</span>
  34  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkFixedPartitioner;
  35  import org.apache.flink.streaming.connectors.kafka.partitioner.FlinkKafkaPartitioner;
  36  import org.apache.flink.table.api.TableSchema;
  37  import org.apache.flink.table.sinks.RetractStreamTableSink;
  38  import org.apache.flink.table.sinks.TableSink;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  39 +import org.apache.flink.table.utils.TableConnectorUtils;</span>
  40  import org.apache.flink.types.Row;
  41  
  42  import java.util.Optional;
  43  import java.util.Properties;
  44  
  45  /**
  46   * kafka result table
  47   * Date: 2018/12/18
  48   * Company: www.dtstack.com
  49   *
  50   * @author DocLi
  51   *
  52   * @modifyer maqi
  53   *
  54   */
  55  public class KafkaSink  implements RetractStreamTableSink&lt;Row&gt;, IStreamSinkGener&lt;KafkaSink&gt; {
  56  
  57      protected String[] fieldNames;
  58  
  59      protected TypeInformation&lt;?&gt;[] fieldTypes;
  60  
  61      protected String topic;
  62  
  63      protected int parallelism;
  64  
  65      protected Properties properties;
  66  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  67 -    /** Serialization schema for encoding records to Kafka. */</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  68 -    protected SerializationSchema serializationSchema;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  69 +    protected FlinkKafkaProducer011&lt;Row&gt; kafkaProducer011;</span>
  70  
  71      /** The schema of the table. */
  72      private TableSchema schema;
  73  
  74      /** Partitioner to select Kafka partition for each item. */
  75      protected Optional&lt;FlinkKafkaPartitioner&lt;Row&gt;&gt; partitioner;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  76 +    private String[] partitionKeys;</span>
  77  
  78  
  79      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  80 -    public KafkaSink genStreamSink(TargetTableInfo targetTableInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  81 +    public KafkaSink genStreamSink(AbstractTargetTableInfo targetTableInfo) {</span>
  82          KafkaSinkTableInfo kafka11SinkTableInfo = (KafkaSinkTableInfo) targetTableInfo;
  83          this.topic = kafka11SinkTableInfo.getTopic();
  84  
  85          properties = new Properties();
  86          properties.setProperty(&quot;bootstrap.servers&quot;, kafka11SinkTableInfo.getBootstrapServers());
  87  
  88          for (String key : kafka11SinkTableInfo.getKafkaParamKeys()) {
  89              properties.setProperty(key, kafka11SinkTableInfo.getKafkaParam(key));
  90          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  91 -        this.partitioner = Optional.of(new FlinkFixedPartitioner&lt;&gt;());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  92 +        this.partitioner = Optional.of(new CustomerFlinkPartition&lt;&gt;());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  93 +        this.partitionKeys = getPartitionKeys(kafka11SinkTableInfo);</span>
  94          this.fieldNames = kafka11SinkTableInfo.getFields();
  95          TypeInformation[] types = new TypeInformation[kafka11SinkTableInfo.getFields().length];
  96          for (int i = 0; i &lt; kafka11SinkTableInfo.getFieldClasses().length; i++) {
  97              types[i] = TypeInformation.of(kafka11SinkTableInfo.getFieldClasses()[i]);
  98          }
  99          this.fieldTypes = types;
 100  
 101          TableSchema.Builder schemaBuilder = TableSchema.builder();
 102          for (int i=0;i&lt;fieldNames.length;i++) {
 103              schemaBuilder.field(fieldNames[i], fieldTypes[i]);
 104          }
 105          this.schema = schemaBuilder.build();
 106  
 107          Integer parallelism = kafka11SinkTableInfo.getParallelism();
 108          if (parallelism != null) {
 109              this.parallelism = parallelism;
 110          }
 111  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 112 -        this.serializationSchema = new CustomerJsonRowSerializationSchema(getOutputType().getTypeAt(1));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 113 +        this.kafkaProducer011 = (FlinkKafkaProducer011&lt;Row&gt;) new KafkaProducer011Factory()</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 114 +                .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partitioner, partitionKeys);"> 114 +                .createKafkaProducer(kafka11SinkTableInfo, getOutputType().getTypeAt(1), properties, partitioner, ðŸ”µ</abbr></span>
 115          return this;
 116      }
 117  
 118      @Override
 119      public TypeInformation&lt;Row&gt; getRecordType() {
 120          return new RowTypeInfo(fieldTypes, fieldNames);
 121      }
 122  
 123      @Override
 124      public void emitDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; dataStream) {





<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 125 -        KafkaTableSinkBase kafkaTableSink = new CustomerKafka11JsonTableSink(</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 126 -                schema,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 127 -                topic,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 128 -                properties,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 129 -                partitioner,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 130 -                serializationSchema</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 131 -        );</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 132 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 133 -        DataStream&lt;Row&gt; ds = dataStream</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 134 -                .filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 135 -                .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; {return record.f1;})</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 136 +        DataStream&lt;Row&gt; mapDataStream = dataStream.filter((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f0)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 137 +                .map((Tuple2&lt;Boolean, Row&gt; record) -&gt; record.f1)</span>
 138                  .returns(getOutputType().getTypeAt(1))
 139                  .setParallelism(parallelism);
 140  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 141 -        kafkaTableSink.emitDataStream(ds);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 142 +        mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFieldNames()));"> 142 +        mapDataStream.addSink(kafkaProducer011).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFðŸ”µ</abbr></span>

 143      }
 144  
 145      @Override
 146      public TupleTypeInfo&lt;Tuple2&lt;Boolean, Row&gt;&gt; getOutputType() {
<abbr title=" 147          return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNames));"> 147          return new TupleTypeInfo(org.apache.flink.table.api.Types.BOOLEAN(), new RowTypeInfo(fieldTypes, fieldNameðŸ”µ</abbr>
 148      }
 149  
 150      @Override
 151      public String[] getFieldNames() {
 152          return fieldNames;
 153      }
 154  
 155      @Override
 156      public TypeInformation&lt;?&gt;[] getFieldTypes() {
 157          return fieldTypes;
 158      }
 159  
 160      @Override
 161      public TableSink&lt;Tuple2&lt;Boolean, Row&gt;&gt;configure(String[] fieldNames, TypeInformation&lt;?&gt;[] fieldTypes) {
 162          this.fieldNames = fieldNames;
 163          this.fieldTypes = fieldTypes;
 164          return this;
 165      }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 166 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 167 +    private String[] getPartitionKeys(KafkaSinkTableInfo kafkaSinkTableInfo){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 168 +        if(StringUtils.isNotBlank(kafkaSinkTableInfo.getPartitionKeys())){</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 169 +            return StringUtils.split(kafkaSinkTableInfo.getPartitionKeys(), &#x27;,&#x27;);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 170 +        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 171 +        return null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 172 +    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 173 +</span>
 174  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            