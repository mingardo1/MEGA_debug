<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>516</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    516
                    <a href="515.html">prev</a>
                    <a href="517.html">next</a>
                    <a href="516_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e83f8c3a3cbab21ecd8ceab223b0f3539be4b5fd^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;55715c184d537500eff25ccea853833950100929:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b]], subset: [[b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import org.apache.calcite.sql.JoinType;
  29 import org.apache.commons.collections.map.HashedMap;
  30 import org.apache.flink.api.java.tuple.Tuple2;
  31 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32 import com.google.common.collect.Maps;
  33 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  34 import org.apache.flink.types.Row;
  35 import org.apache.flink.util.Collector;
  36 import org.apache.hadoop.conf.Configuration;
  37 import org.apache.hadoop.hbase.Cell;
  38 import org.apache.hadoop.hbase.CellUtil;
  39 import org.apache.hadoop.hbase.TableName;
  40 import org.apache.hadoop.hbase.client.Connection;
  41 import org.apache.hadoop.hbase.client.ConnectionFactory;
  42 import org.apache.hadoop.hbase.client.Result;
  43 import org.apache.hadoop.hbase.client.ResultScanner;
  44 import org.apache.hadoop.hbase.client.Scan;
  45 import org.apache.hadoop.hbase.client.Table;
  46 import org.apache.hadoop.hbase.util.Bytes;
  47 import org.slf4j.Logger;
  48 import org.slf4j.LoggerFactory;
  49 
  50 import java.io.IOException;
  51 
  52 import java.sql.SQLException;
  53 import java.sql.Timestamp;
  54 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  55 import java.time.LocalDateTime;</span>
  56 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  57 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  58     private String tableName;</span>
  59 =======
  60 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  61 import java.util.Calendar;
  62 import java.util.HashMap;
  63 import java.util.List;
  64 import java.util.Map;
  65 import java.util.concurrent.atomic.AtomicReference;
  66 
  67 public class HbaseAllReqRow extends BaseAllReqRow {
  68 
  69     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  70 
  71     private String tableName;
  72 
  73     private Map&lt;String, String&gt; aliasNameInversion;
  74 
  75     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  76 
<abbr title="  77     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  77     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  78         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  79         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  80 
  81         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  82         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  83         aliasNameInversion = new HashMap&lt;&gt;();
  84         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  85             aliasNameInversion.put(entry.getValue(), entry.getKey());
  86         }
  87     }
  88 
  89     @Override
  90     public Row fillData(Row input, Object sideInput) {
  91         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  92         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  93         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  94             Object obj = input.getField(entry.getValue());
<abbr title="  95             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  95             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
  96 
<abbr title="  97             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  97             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
  98             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
  99                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 100             }
 101             row.setField(entry.getKey(), obj);
 102         }
 103 
 104         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 105             if(sideInputList == null){
 106                 row.setField(entry.getKey(), null);
 107             }else{
 108                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 109                 row.setField(entry.getKey(), sideInputList.get(key));
 110             }
 111         }
 112 
 113         return row;
 114     }
 115 
 116     @Override
 117     protected void initCache() throws SQLException {
 118         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 119         cacheRef.set(newCache);
 120         loadData(newCache);
 121     }
 122 
 123     @Override
 124     protected void reloadCache() {
 125         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 126         try {
 127             loadData(newCache);
 128         } catch (SQLException e) {
 129             LOG.error(&quot;&quot;, e);
 130         }
 131 
 132         cacheRef.set(newCache);
 133         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 134     }
 135 
 136     @Override
 137     public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 138         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 139         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 140             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 141             Object equalObj = input.f1.getField(conValIndex);
 142             if (equalObj == null) {
 143                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 144                     Row data = fillData(input.f1, null);
 145                     out.collect(Tuple2.of(input.f0, data));
 146                 }
 147                 return;
 148             }
 149             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 150         }
 151 
 152         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 153 
 154         Map&lt;String, Object&gt; cacheList = null;
 155 
 156         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 157         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 158         if (hbaseSideTableInfo.isPreRowKey()) {
 159             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 160                 if (entry.getKey().startsWith(rowKeyStr)) {
 161                     cacheList = cacheRef.get().get(entry.getKey());
 162                     Row row = fillData(input.f1, cacheList);
 163                     out.collect(Tuple2.of(input.f0, row));
 164                 }
 165             }
 166         } else {
 167             cacheList = cacheRef.get().get(rowKeyStr);
 168             Row row = fillData(input.f1, cacheList);
 169             out.collect(Tuple2.of(input.f0, row));
 170         }
 171 
 172     }
 173 
 174     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 175         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 176         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 177         Configuration conf = new Configuration();
 178         conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 179         Connection conn = null;
 180         Table table = null;
 181         ResultScanner resultScanner = null;
 182         try {
 183             conn = ConnectionFactory.createConnection(conf);
 184             table = conn.getTable(TableName.valueOf(tableName));
 185             resultScanner = table.getScanner(new Scan());
 186             for (Result r : resultScanner) {
 187                 Map&lt;String, Object&gt; kv = new HashedMap();
 188                 for (Cell cell : r.listCells())
 189                 {
 190                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 191                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 192                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 193                     StringBuilder key = new StringBuilder();
 194                     key.append(family).append(&quot;:&quot;).append(qualifier);
 195 
 196                     kv.put(aliasNameInversion.get(key.toString()), value);
 197                 }
 198                 tmpCache.put(new String(r.getRow()), kv);
 199             }
 200         } catch (IOException e) {
 201             LOG.error(&quot;&quot;, e);
 202         } finally {
 203             try {
 204                 if (null != conn &amp;&amp; !conn.isClosed()) {
 205                     conn.close();
 206                 }
 207 
 208                 if (null != table) {
 209                     table.close();
 210                 }
 211 
 212                 if (null != resultScanner) {
 213                     resultScanner.close();
 214                 }
 215             } catch (IOException e) {
 216                 LOG.error(&quot;&quot;, e);
 217             }
 218         }
 219     }
 220 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import org.apache.calcite.sql.JoinType;
  29 import org.apache.commons.collections.map.HashedMap;
  30 import org.apache.flink.api.java.tuple.Tuple2;
  31 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32 import com.google.common.collect.Maps;
  33 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  34 import org.apache.flink.types.Row;
  35 import org.apache.flink.util.Collector;
  36 import org.apache.hadoop.conf.Configuration;
  37 import org.apache.hadoop.hbase.Cell;
  38 import org.apache.hadoop.hbase.CellUtil;
  39 import org.apache.hadoop.hbase.TableName;
  40 import org.apache.hadoop.hbase.client.Connection;
  41 import org.apache.hadoop.hbase.client.ConnectionFactory;
  42 import org.apache.hadoop.hbase.client.Result;
  43 import org.apache.hadoop.hbase.client.ResultScanner;
  44 import org.apache.hadoop.hbase.client.Scan;
  45 import org.apache.hadoop.hbase.client.Table;
  46 import org.apache.hadoop.hbase.util.Bytes;
  47 import org.slf4j.Logger;
  48 import org.slf4j.LoggerFactory;
  49 
  50 import java.io.IOException;
  51 
  52 import java.sql.SQLException;
  53 import java.sql.Timestamp;
  54 import java.time.LocalDateTime;
  55 import java.util.Calendar;
  56 import java.util.HashMap;
  57 import java.util.List;
  58 import java.util.Map;
  59 import java.util.concurrent.atomic.AtomicReference;
  60 
  61 public class HbaseAllReqRow extends BaseAllReqRow {
  62 
  63     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  64 
  65     private String tableName;
  66 
  67     private Map&lt;String, String&gt; aliasNameInversion;
  68 
  69     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  70 
<abbr title="  71     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  71     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  72         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  73         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  74 
  75         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  76         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  77         aliasNameInversion = new HashMap&lt;&gt;();
  78         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  79             aliasNameInversion.put(entry.getValue(), entry.getKey());
  80         }
  81     }
  82 
  83     @Override
  84     public Row fillData(Row input, Object sideInput) {
  85         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  86         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  87         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  88             Object obj = input.getField(entry.getValue());
<abbr title="  89             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  89             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
  90 
<abbr title="  91             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  91             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
  92             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
  93                 obj = Timestamp.valueOf(((LocalDateTime) obj));
  94             }
  95             row.setField(entry.getKey(), obj);
  96         }
  97 
  98         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
  99             if(sideInputList == null){
 100                 row.setField(entry.getKey(), null);
 101             }else{
 102                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 103                 row.setField(entry.getKey(), sideInputList.get(key));
 104             }
 105         }
 106 
 107         return row;
 108     }
 109 
 110     @Override
 111     protected void initCache() throws SQLException {
 112         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 113         cacheRef.set(newCache);
 114         loadData(newCache);
 115     }
 116 
 117     @Override
 118     protected void reloadCache() {
 119         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 120         try {
 121             loadData(newCache);
 122         } catch (SQLException e) {
 123             LOG.error(&quot;&quot;, e);
 124         }
 125 
 126         cacheRef.set(newCache);
 127         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 128     }
 129 
 130     @Override
 131     public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {
 132         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 133         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 134             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 135             Object equalObj = input.f1.getField(conValIndex);
 136             if (equalObj == null) {
 137                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 138                     Row data = fillData(input.f1, null);
 139                     out.collect(Tuple2.of(input.f0, data));
 140                 }
 141                 return;
 142             }
 143             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 144         }
 145 
 146         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 147 
 148         Map&lt;String, Object&gt; cacheList = null;
 149 
 150         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 151         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 152         if (hbaseSideTableInfo.isPreRowKey()) {
 153             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 154                 if (entry.getKey().startsWith(rowKeyStr)) {
 155                     cacheList = cacheRef.get().get(entry.getKey());
 156                     Row row = fillData(input.f1, cacheList);
 157                     out.collect(Tuple2.of(input.f0, row));
 158                 }
 159             }
 160         } else {
 161             cacheList = cacheRef.get().get(rowKeyStr);
 162             Row row = fillData(input.f1, cacheList);
 163             out.collect(Tuple2.of(input.f0, row));
 164         }
 165 
 166     }
 167 
 168     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 169         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 170         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 171         Configuration conf = new Configuration();
 172         conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 173         Connection conn = null;
 174         Table table = null;
 175         ResultScanner resultScanner = null;
 176         try {
 177             conn = ConnectionFactory.createConnection(conf);
 178             table = conn.getTable(TableName.valueOf(tableName));
 179             resultScanner = table.getScanner(new Scan());
 180             for (Result r : resultScanner) {
 181                 Map&lt;String, Object&gt; kv = new HashedMap();
 182                 for (Cell cell : r.listCells())
 183                 {
 184                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 185                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 186                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 187                     StringBuilder key = new StringBuilder();
 188                     key.append(family).append(&quot;:&quot;).append(qualifier);
 189 
 190                     kv.put(aliasNameInversion.get(key.toString()), value);
 191                 }
 192                 tmpCache.put(new String(r.getRow()), kv);
 193             }
 194         } catch (IOException e) {
 195             LOG.error(&quot;&quot;, e);
 196         } finally {
 197             try {
 198                 if (null != conn &amp;&amp; !conn.isClosed()) {
 199                     conn.close();
 200                 }
 201 
 202                 if (null != table) {
 203                     table.close();
 204                 }
 205 
 206                 if (null != resultScanner) {
 207                     resultScanner.close();
 208                 }
 209             } catch (IOException e) {
 210                 LOG.error(&quot;&quot;, e);
 211             }
 212         }
 213     }
 214 }
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.google.common.collect.Maps;
  26 import java.io.IOException;
  27 import java.sql.SQLException;
  28 import java.sql.Timestamp;
  29 import java.time.LocalDateTime;
  30 import java.util.Calendar;
  31 import java.util.HashMap;
  32 import java.util.List;
  33 import java.util.Map;
  34 import java.util.concurrent.atomic.AtomicReference;
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.map.HashedMap;
  37 import org.apache.flink.api.java.tuple.Tuple2;
  38 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  39 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  40 import org.apache.flink.types.Row;
  41 import org.apache.flink.util.Collector;
  42 import org.apache.hadoop.conf.Configuration;
  43 import org.apache.hadoop.hbase.Cell;
  44 import org.apache.hadoop.hbase.CellUtil;
  45 import org.apache.hadoop.hbase.TableName;
  46 import org.apache.hadoop.hbase.client.Connection;
  47 import org.apache.hadoop.hbase.client.ConnectionFactory;
  48 import org.apache.hadoop.hbase.client.Result;
  49 import org.apache.hadoop.hbase.client.ResultScanner;
  50 import org.apache.hadoop.hbase.client.Scan;
  51 import org.apache.hadoop.hbase.client.Table;
  52 import org.apache.hadoop.hbase.util.Bytes;
  53 import org.slf4j.Logger;
  54 import org.slf4j.LoggerFactory;
  55 
  56 
  57 public class HbaseAllReqRow extends BaseAllReqRow {
  58     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  59 
  60     private String tableName;
  61 
  62     private Map&lt;String, String&gt; aliasNameInversion;
  63 
  64     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  65 
<abbr title="  66     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  66     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  67         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  68         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  69         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  70         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  71         aliasNameInversion = new HashMap&lt;&gt;();
  72         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  73             aliasNameInversion.put(entry.getValue(), entry.getKey());
  74         }
  75     }
  76 
  77     @Override
  78     public Row fillData(Row input, Object sideInput) {
  79         Map&lt;String, Object&gt; sideInputList = ((Map&lt;String, Object&gt;) (sideInput));
  80         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  81         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
  82             Object obj = input.getField(entry.getValue());
<abbr title="  83             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  83             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
<abbr title="  84             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  84             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
  85             if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
  86                 obj = Timestamp.valueOf(((LocalDateTime) (obj)));
  87             }
  88             row.setField(entry.getKey(), obj);
  89         }
  90         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
  91             if (sideInputList == null) {
  92                 row.setField(entry.getKey(), null);
  93             } else {
  94                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
  95                 row.setField(entry.getKey(), sideInputList.get(key));
  96             }
  97         }
  98         return row;
  99     }
 100 
 101     @Override
 102     protected void initCache() throws SQLException {
 103         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 104         cacheRef.set(newCache);
 105         loadData(newCache);
 106     }
 107 
 108     @Override
 109     protected void reloadCache() {
 110         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 111         try {
 112             loadData(newCache);
 113         } catch (SQLException e) {
 114             LOG.error(&quot;&quot;, e);
 115         }
 116 
 117         cacheRef.set(newCache);
 118         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 119     }
 120 
 121     @Override
<abbr title=" 122     public void flatMap(Tuple2&lt;Boolean, Row&gt; input, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws Exception {"> 122     public void flatMap(Tuple2&lt;Boolean, Row&gt; input, Collector&lt;Tuple2&lt;Boolean, Row&gt;&gt; out) throws ExceptionðŸ”µ</abbr>
 123         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 124         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 125             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 126             Object equalObj = input.f1.getField(conValIndex);
 127             if (equalObj == null) {
 128                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 129                     Row data = fillData(input.f1, null);
 130                     out.collect(Tuple2.of(input.f0, data));
 131                 }
 132                 return;
 133             }
 134             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 135         }
 136         String rowKeyStr = ((HbaseAllSideInfo) (sideInfo)).getRowKeyBuilder().getRowKey(refData);
 137         Map&lt;String, Object&gt; cacheList = null;
 138         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 139         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 140         if (hbaseSideTableInfo.isPreRowKey()) {
 141             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 142                 if (entry.getKey().startsWith(rowKeyStr)) {
 143                     cacheList = cacheRef.get().get(entry.getKey());
 144                     Row row = fillData(input.f1, cacheList);
 145                     out.collect(Tuple2.of(input.f0, row));
 146                 }
 147             }
 148         } else {
 149             cacheList = cacheRef.get().get(rowKeyStr);
 150             Row row = fillData(input.f1, cacheList);
 151             out.collect(Tuple2.of(input.f0, row));
 152         }
 153     }
 154 
 155     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 156         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 157         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 158         Configuration conf = new Configuration();
 159         conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 160         Connection conn = null;
 161         Table table = null;
 162         ResultScanner resultScanner = null;
 163         try {
 164             conn = ConnectionFactory.createConnection(conf);
 165             table = conn.getTable(TableName.valueOf(tableName));
 166             resultScanner = table.getScanner(new Scan());
 167             for (Result r : resultScanner) {
 168                 Map&lt;String, Object&gt; kv = new HashedMap();
 169                 for (Cell cell : r.listCells()) {
 170                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 171                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 172                     String value = Bytes.toString(CellUtil.cloneValue(cell));
 173                     StringBuilder key = new StringBuilder();
 174                     key.append(family).append(&quot;:&quot;).append(qualifier);
 175                     kv.put(aliasNameInversion.get(key.toString()), value);
 176                 }
 177                 tmpCache.put(new String(r.getRow()), kv);
 178             }
 179         } catch (IOException e) {
 180             LOG.error(&quot;&quot;, e);
 181         } finally {
 182             try {
 183                 if ((null != conn) &amp;&amp; (!conn.isClosed())) {
 184                     conn.close();
 185                 }
 186                 if (null != table) {
 187                     table.close();
 188                 }
 189                 if (null != resultScanner) {
 190                     resultScanner.close();
 191                 }
 192             } catch (IOException e) {
 193                 LOG.error(&quot;&quot;, e);
 194             }
 195         }
 196     }
 197 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.*;




  24  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25  import org.apache.calcite.sql.JoinType;
  26  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  27 +import org.apache.flink.api.java.tuple.Tuple2;</span>
  28  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  29  import com.google.common.collect.Maps;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  30 -import org.apache.flink.table.runtime.types.CRow;</span>
  31  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  32  import org.apache.flink.types.Row;
  33  import org.apache.flink.util.Collector;
  34  import org.apache.hadoop.conf.Configuration;
  35  import org.apache.hadoop.hbase.Cell;
  36  import org.apache.hadoop.hbase.CellUtil;
  37  import org.apache.hadoop.hbase.TableName;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  38 -import org.apache.hadoop.hbase.client.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  39 +import org.apache.hadoop.hbase.client.Connection;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  40 +import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  41 +import org.apache.hadoop.hbase.client.Result;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  42 +import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  43 +import org.apache.hadoop.hbase.client.Scan;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  44 +import org.apache.hadoop.hbase.client.Table;</span>
  45  import org.apache.hadoop.hbase.util.Bytes;
  46  import org.slf4j.Logger;
  47  import org.slf4j.LoggerFactory;
  48  
  49  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +</span>
  51  import java.sql.SQLException;
  52  import java.sql.Timestamp;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  53 -import java.util.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  54 +import java.time.LocalDateTime;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  55 +import java.util.Calendar;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  56 +import java.util.HashMap;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  57 +import java.util.List;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +import java.util.Map;</span>
  59  import java.util.concurrent.atomic.AtomicReference;
  60  
  61  public class HbaseAllReqRow extends BaseAllReqRow {
  62  
  63      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  64  
  65      private String tableName;
  66  
  67      private Map&lt;String, String&gt; aliasNameInversion;
  68  
  69      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  70  
<abbr title="  71      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  71      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  72          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  73          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  74  
  75          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  76          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  77          aliasNameInversion = new HashMap&lt;&gt;();
  78          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  79              aliasNameInversion.put(entry.getValue(), entry.getKey());
  80          }
  81      }
  82  
  83      @Override
  84      public Row fillData(Row input, Object sideInput) {
  85          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  86          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  87          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  88              Object obj = input.getField(entry.getValue());
<abbr title="  89              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  89              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  90  
<abbr title="  91              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  91              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  92 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  93 -                obj = ((Timestamp)obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  94 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  95 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
  96              }
  97              row.setField(entry.getKey(), obj);
  98          }
  99  
 100          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 101              if(sideInputList == null){
 102                  row.setField(entry.getKey(), null);
 103              }else{
 104                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 105                  row.setField(entry.getKey(), sideInputList.get(key));
 106              }
 107          }
 108  
 109          return row;
 110      }
 111  
 112      @Override
 113      protected void initCache() throws SQLException {
 114          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 115          cacheRef.set(newCache);
 116          loadData(newCache);
 117      }
 118  
 119      @Override
 120      protected void reloadCache() {
 121          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 122          try {
 123              loadData(newCache);
 124          } catch (SQLException e) {
 125              LOG.error(&quot;&quot;, e);
 126          }
 127  
 128          cacheRef.set(newCache);
 129          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 130      }
 131  
 132      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 133 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 134 +    public void flatMap(Tuple2&lt;Boolean,Row&gt; input, Collector&lt;Tuple2&lt;Boolean,Row&gt;&gt; out) throws Exception {</span>
 135          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 136          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 137              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 138 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 139 +            Object equalObj = input.f1.getField(conValIndex);</span>
 140              if (equalObj == null) {
 141                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 142 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 143 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 144 +                    Row data = fillData(input.f1, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 145 +                    out.collect(Tuple2.of(input.f0, data));</span>
 146                  }
 147                  return;
 148              }
 149              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 150          }
 151  
 152          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 153  
 154          Map&lt;String, Object&gt; cacheList = null;
 155  
 156          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 157          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 158          if (hbaseSideTableInfo.isPreRowKey()) {
 159              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 160                  if (entry.getKey().startsWith(rowKeyStr)) {
 161                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 162 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 163 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 164 +                    Row row = fillData(input.f1, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 165 +                    out.collect(Tuple2.of(input.f0, row));</span>
 166                  }
 167              }
 168          } else {
 169              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 170 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 171 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 172 +            Row row = fillData(input.f1, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 173 +            out.collect(Tuple2.of(input.f0, row));</span>
 174          }
 175  
 176      }
 177  
 178      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 179          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 180          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 181          Configuration conf = new Configuration();
 182          conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 183          Connection conn = null;
 184          Table table = null;
 185          ResultScanner resultScanner = null;
 186          try {
 187              conn = ConnectionFactory.createConnection(conf);
 188              table = conn.getTable(TableName.valueOf(tableName));
 189              resultScanner = table.getScanner(new Scan());
 190              for (Result r : resultScanner) {
 191                  Map&lt;String, Object&gt; kv = new HashedMap();
 192                  for (Cell cell : r.listCells())
 193                  {
 194                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 195                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 196                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 197                      StringBuilder key = new StringBuilder();
 198                      key.append(family).append(&quot;:&quot;).append(qualifier);
 199  
 200                      kv.put(aliasNameInversion.get(key.toString()), value);
 201                  }
 202                  tmpCache.put(new String(r.getRow()), kv);
 203              }
 204          } catch (IOException e) {
 205              LOG.error(&quot;&quot;, e);
 206          } finally {
 207              try {
 208                  if (null != conn &amp;&amp; !conn.isClosed()) {
 209                      conn.close();
 210                  }
 211  
 212                  if (null != table) {
 213                      table.close();
 214                  }
 215  
 216                  if (null != resultScanner) {
 217                      resultScanner.close();
 218                  }
 219              } catch (IOException e) {
 220                  LOG.error(&quot;&quot;, e);
 221              }
 222          }
 223      }
 224  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  23 -import com.dtstack.flink.sql.side.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  24 +import com.dtstack.flink.sql.side.AbstractSideTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  25 +import com.dtstack.flink.sql.side.BaseAllReqRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  26 +import com.dtstack.flink.sql.side.FieldInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  27 +import com.dtstack.flink.sql.side.JoinInfo;</span>
  28  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  29  import org.apache.calcite.sql.JoinType;
  30  import org.apache.commons.collections.map.HashedMap;

  31  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32  import com.google.common.collect.Maps;
  33  import org.apache.flink.table.runtime.types.CRow;
  34  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  35  import org.apache.flink.types.Row;
  36  import org.apache.flink.util.Collector;
  37  import org.apache.hadoop.conf.Configuration;
  38  import org.apache.hadoop.hbase.Cell;
  39  import org.apache.hadoop.hbase.CellUtil;
  40  import org.apache.hadoop.hbase.TableName;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  41 -import org.apache.hadoop.hbase.client.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  42 +import org.apache.hadoop.hbase.client.Connection;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  43 +import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  44 +import org.apache.hadoop.hbase.client.Result;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  45 +import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  46 +import org.apache.hadoop.hbase.client.Scan;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  47 +import org.apache.hadoop.hbase.client.Table;</span>
  48  import org.apache.hadoop.hbase.util.Bytes;
  49  import org.slf4j.Logger;
  50  import org.slf4j.LoggerFactory;
  51  
  52  import java.io.IOException;

  53  import java.sql.SQLException;
  54  import java.sql.Timestamp;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  55 -import java.util.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  56 +import java.util.Calendar;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  57 +import java.util.HashMap;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +import java.util.List;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  59 +import java.util.Map;</span>

  60  import java.util.concurrent.atomic.AtomicReference;
  61  
  62  public class HbaseAllReqRow extends BaseAllReqRow {
  63  
  64      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  65  
  66      private String tableName;
  67  
  68      private Map&lt;String, String&gt; aliasNameInversion;
  69  
  70      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  71  
<abbr title="  72      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  72      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  73          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  74          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  75  
  76          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  77          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  78          aliasNameInversion = new HashMap&lt;&gt;();
  79          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  80              aliasNameInversion.put(entry.getValue(), entry.getKey());
  81          }
  82      }
  83  
  84      @Override
  85      public Row fillData(Row input, Object sideInput) {
  86          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  87          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  88          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  89              Object obj = input.getField(entry.getValue());
<abbr title="  90              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  90              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  91  
<abbr title="  92              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  92              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
  93              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
  94                  obj = ((Timestamp)obj).getTime();


  95              }
  96              row.setField(entry.getKey(), obj);
  97          }
  98  
  99          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 100              if(sideInputList == null){
 101                  row.setField(entry.getKey(), null);
 102              }else{
 103                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 104                  row.setField(entry.getKey(), sideInputList.get(key));
 105              }
 106          }
 107  
 108          return row;
 109      }
 110  
 111      @Override
 112      protected void initCache() throws SQLException {
 113          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 114          cacheRef.set(newCache);
 115          loadData(newCache);
 116      }
 117  
 118      @Override
 119      protected void reloadCache() {
 120          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 121          try {
 122              loadData(newCache);
 123          } catch (SQLException e) {
 124              LOG.error(&quot;&quot;, e);
 125          }
 126  
 127          cacheRef.set(newCache);
 128          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 129      }
 130  
 131      @Override
 132      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {

 133          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 134          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 135              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 136              Object equalObj = input.row().getField(conValIndex);

 137              if (equalObj == null) {
 138                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 139                      Row data = fillData(input.row(), null);
 140                      out.collect(new CRow(data, input.change()));


 141                  }
 142                  return;
 143              }
 144              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 145          }
 146  
 147          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 148  
 149          Map&lt;String, Object&gt; cacheList = null;
 150  
 151          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 152          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 153          if (hbaseSideTableInfo.isPreRowKey()) {
 154              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 155                  if (entry.getKey().startsWith(rowKeyStr)) {
 156                      cacheList = cacheRef.get().get(entry.getKey());
 157                      Row row = fillData(input.row(), cacheList);
 158                      out.collect(new CRow(row, input.change()));


 159                  }
 160              }
 161          } else {
 162              cacheList = cacheRef.get().get(rowKeyStr);
 163              Row row = fillData(input.row(), cacheList);
 164              out.collect(new CRow(row, input.change()));


 165          }
 166  
 167      }
 168  
 169      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 170          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 171          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 172          Configuration conf = new Configuration();
 173          conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 174          Connection conn = null;
 175          Table table = null;
 176          ResultScanner resultScanner = null;
 177          try {
 178              conn = ConnectionFactory.createConnection(conf);
 179              table = conn.getTable(TableName.valueOf(tableName));
 180              resultScanner = table.getScanner(new Scan());
 181              for (Result r : resultScanner) {
 182                  Map&lt;String, Object&gt; kv = new HashedMap();
 183                  for (Cell cell : r.listCells())
 184                  {
 185                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 186                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 187                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 188                      StringBuilder key = new StringBuilder();
 189                      key.append(family).append(&quot;:&quot;).append(qualifier);
 190  
 191                      kv.put(aliasNameInversion.get(key.toString()), value);
 192                  }
 193                  tmpCache.put(new String(r.getRow()), kv);
 194              }
 195          } catch (IOException e) {
 196              LOG.error(&quot;&quot;, e);
 197          } finally {
 198              try {
 199                  if (null != conn &amp;&amp; !conn.isClosed()) {
 200                      conn.close();
 201                  }
 202  
 203                  if (null != table) {
 204                      table.close();
 205                  }
 206  
 207                  if (null != resultScanner) {
 208                      resultScanner.close();
 209                  }
 210              } catch (IOException e) {
 211                  LOG.error(&quot;&quot;, e);
 212              }
 213          }
 214      }
 215  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            