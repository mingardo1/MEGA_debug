<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>491</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    491
                    <a href="490.html">prev</a>
                    <a href="492.html">next</a>
                    <a href="491_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_e346a804d69c8cd0124b4eb3d35156cfb5cd0779_core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779^1:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e346a804d69c8cd0124b4eb3d35156cfb5cd0779^2:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;6e351a99f6e8449c76ad55e517a5da6cbb108379:core/src/main/java/com/dtstack/flink/sql/exec/ExecuteProcessHelper.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [sbj], [sbj], [sbj], [sbj], [bs]], subset: [[b], [sbj], [sbj], [sbj], [sbj], [bs]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.exec;
  20 
  21 import com.dtstack.flink.sql.parser.CreateFuncParser;
  22 import com.dtstack.flink.sql.parser.CreateTmpTableParser;
  23 import com.dtstack.flink.sql.parser.FlinkPlanner;
  24 import com.dtstack.flink.sql.parser.InsertSqlParser;
  25 import com.dtstack.flink.sql.parser.SqlParser;
  26 import com.dtstack.flink.sql.parser.SqlTree;
  27 import org.apache.flink.api.common.typeinfo.TypeInformation;
  28 import org.apache.flink.api.java.tuple.Tuple2;
  29 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  30 import org.apache.flink.streaming.api.datastream.DataStream;
  31 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  32 import org.apache.flink.table.api.StreamQueryConfig;
  33 import org.apache.flink.table.api.Table;
  34 import org.apache.flink.table.api.TableEnvironment;
  35 import org.apache.flink.table.api.java.StreamTableEnvironment;
  36 import org.apache.flink.table.calcite.FlinkPlannerImpl;
  37 import org.apache.flink.table.sinks.TableSink;
  38 import org.apache.flink.types.Row;
  39 
  40 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  41 import com.dtstack.flink.sql.constrant.ConfigConstrant;
  42 import com.dtstack.flink.sql.enums.ClusterMode;
  43 import com.dtstack.flink.sql.enums.ECacheType;
  44 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  45 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  46 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  47 import com.dtstack.flink.sql.function.FunctionManager;
  48 import com.dtstack.flink.sql.option.OptionParser;
  49 import com.dtstack.flink.sql.option.Options;
  50 import com.dtstack.flink.sql.side.SideSqlExec;
  51 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  52 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  53 import com.dtstack.flink.sql.source.StreamSourceFactory;
  54 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  55 import com.dtstack.flink.sql.table.AbstractTableInfo;
  56 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  57 import com.dtstack.flink.sql.util.DtStringUtil;
  58 import com.dtstack.flink.sql.util.PluginUtil;
  59 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  60 import com.fasterxml.jackson.databind.ObjectMapper;
  61 import com.google.common.base.Preconditions;
  62 import com.google.common.base.Strings;
  63 import com.google.common.collect.Lists;
  64 import com.google.common.collect.Maps;
  65 import com.google.common.collect.Sets;
  66 import org.apache.calcite.sql.SqlInsert;
  67 import org.apache.calcite.sql.SqlNode;
  68 import org.apache.commons.io.Charsets;
  69 import org.apache.commons.lang3.StringUtils;
  70 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  71 import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  72 import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  73 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  74 import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  75 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  76 import org.apache.flink.table.api.EnvironmentSettings;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  77 import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  78 import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  79 import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  80 import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  81 import org.apache.flink.types.Row;</span>
  82 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  83 import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  84 import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  85 import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  86 import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  87 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  88 import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  89 import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  90 import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  91 import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  92 import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  93 import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  94 import org.slf4j.Logger;</span>
  95 =======
  96 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  97 import org.slf4j.Logger;
  98 import org.slf4j.LoggerFactory;
  99 
 100 import java.io.File;
 101 import java.lang.reflect.InvocationTargetException;
 102 import java.net.URL;
 103 import java.net.URLClassLoader;
 104 import java.net.URLDecoder;
 105 import java.util.Arrays;
 106 import java.util.List;
 107 import java.util.Map;
 108 import java.util.Properties;
 109 import java.util.Set;
 110 
 111 /**
 112  *  任务执行时的流程方法
 113  * Date: 2020/2/17
 114  * Company: www.dtstack.com
 115  * @author maqi
 116  */
 117 public class ExecuteProcessHelper {
 118 
 119     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
 120     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
 121     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
 122 
 123 
 124     public static ParamsInfo parseParams(String[] args) throws Exception {
 125         LOG.info(&quot;------------program params-------------------------&quot;);
 126         Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 127         LOG.info(&quot;-------------------------------------------&quot;);
 128 
 129         OptionParser optionParser = new OptionParser(args);
 130         Options options = optionParser.getOptions();
 131 
 132         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 133         String name = options.getName();
 134         String localSqlPluginPath = options.getLocalSqlPluginPath();
 135         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 136         String pluginLoadMode = options.getPluginLoadMode();
 137         String deployMode = options.getMode();
 138         String logLevel = options.getLogLevel();
 139 
<abbr title=" 140         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),"> 140         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 141                 &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 142         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 143         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 144 
 145         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 146 
 147         return ParamsInfo.builder()
 148                 .setSql(sql)
 149                 .setName(name)
 150                 .setLocalSqlPluginPath(localSqlPluginPath)
 151                 .setRemoteSqlPluginPath(remoteSqlPluginPath)
 152                 .setPluginLoadMode(pluginLoadMode)
 153                 .setDeployMode(deployMode)
 154                 .setConfProp(confProperties)
 155                 .setJarUrlList(jarUrlList)
 156                 .build();
 157 
 158     }
 159 
 160     /**
 161      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 162      * @param remoteSqlPluginPath
 163      * @param deployMode
 164      * @param pluginLoadMode
 165      * @return
 166      */
<abbr title=" 167     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 167     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 168         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 169             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 170                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 171         }
 172         return true;
 173     }
 174 
 175 
 176     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 177         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 177         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 178 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 179         StreamTableEnvironment tableEnv = getStreamTableEnv(env,paramsInfo.getConfProp());</span>
 180 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 181         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 182         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 182         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 183 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 184         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 185         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());</span>
 186 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 187         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 188         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 188         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 189         // init global flinkPlanner</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 190         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.getTypeFactory());"> 190         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.ge🔵</abbr></span>
 191 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 192 
 193         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 194         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 195 
 196         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 197         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 198 
 199         //register udf
 200         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 201         //register table schema
<abbr title=" 202         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 202         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
<abbr title=" 203                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 203                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, regist🔵</abbr>
 204         // cache classPathSets
 205         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 206 
<abbr title=" 207         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache);"> 207         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 208 
 209         if (env instanceof MyLocalStreamEnvironment) {
 210             ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 211         }
 212         return env;
 213     }
 214 
 215 
 216     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 217         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 218         if (Strings.isNullOrEmpty(addJarListStr)) {
 219             return jarUrlList;
 220         }
 221 
<abbr title=" 222         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 222         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 223         //Get External jar to load
 224         for (String addJarPath : addJarFileList) {
 225             jarUrlList.add(new File(addJarPath).toURI().toURL());
 226         }
 227         return jarUrlList;
 228     }
 229 
 230     private static void sqlTranslation(String localSqlPluginPath,
 231                                        StreamTableEnvironment tableEnv,
 232                                        SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 233                                        Map&lt;String, Table&gt; registerTableCache) throws Exception {
 234 
 235         SideSqlExec sideSqlExec = new SideSqlExec();
 236         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 237 
 238         int scope = 0;
 239         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
 240 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 241             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, result);</span>
 242 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 243         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 244         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 245             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 245             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 247 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 248         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 249             if (LOG.isInfoEnabled()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 250                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 251             }</span>
 252 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 253             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result, scope + &quot;&quot;);"> 253             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 254             scope++;</span>
 255 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 256         }
 257 
 258         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 259             if (LOG.isInfoEnabled()) {
 260                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 261             }
 262 
 263             boolean isSide = false;
 264             for (String tableName : result.getTargetTableList()) {
 265                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 266                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 267                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 268 
 269                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 270                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 271                     String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 272                     tmp.setExecSql(tmpSql);
 273 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 274                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, tmp);</span>
 275 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 276                     tmp.setExecSql(tmpSql);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 277                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 277                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 278                 } else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 279                     for (String sourceTable : result.getSourceTableList()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 280                         if (sideTableMap.containsKey(sourceTable)) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 281                             isSide = true;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 282                             break;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 283                         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 284                     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 285                     if (isSide) {</span>
 286 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 287                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp, scope + &quot;&quot;);"> 287                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr></span>
 288 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 289                 } else {
 290                     for (String sourceTable : result.getSourceTableList()) {
 291                         if (sideTableMap.containsKey(sourceTable)) {
 292                             isSide = true;
 293                             break;
 294                         }
 295                     }
 296                     if (isSide) {
 297                         //sql-dimensional table contains the dimension table of execution
 298 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title=" 299                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, null);"> 299                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
 300 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 301                         //sql-dimensional table contains the dimension table of execution</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 302                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 302                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 303                     } else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 304                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 305                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 305                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 306                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 307                         if (LOG.isInfoEnabled()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 308                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 309                         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 310                     }</span>
 311 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 312                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null, null);"> 312                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
 313 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 314                     } else {
 315                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 316                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 316                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 317                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql());
 318                         if (LOG.isInfoEnabled()) {
 319                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 320                         }
 321                     }
 322                 }
 323 
 324                 scope++;
 325             }
 326         }
 327     }
 328 
<abbr title=" 329     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 329     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 330             throws IllegalAccessException, InvocationTargetException {
 331         // udf和tableEnv须由同一个类加载器加载
 332         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 333         URLClassLoader classLoader = null;
 334         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 335         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 336             //classloader
 337             if (classLoader == null) {
<abbr title=" 338                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);"> 338                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoad🔵</abbr>
 339             }
<abbr title=" 340             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 340             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 341         }
 342     }
 343 
 344     /**
 345      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 346      * @param sqlTree
 347      * @param env
 348      * @param tableEnv
 349      * @param localSqlPluginPath
 350      * @param remoteSqlPluginPath
 351      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 352      * @param sideTableMap
 353      * @param registerTableCache
 354      * @return
 355      * @throws Exception
 356      */
<abbr title=" 357     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 357     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
<abbr title=" 358                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 358                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, A🔵</abbr>
 359         Set&lt;URL&gt; pluginClassPathSets = Sets.newHashSet();
 360         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 361         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 362 
 363             if (tableInfo instanceof AbstractSourceTableInfo) {
 364 
 365                 AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 366                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 366                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 367                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 368                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 368                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 369                 //Create table in which the function is arranged only need adaptation sql
 370                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 371                 Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 372 
<abbr title=" 373                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 373                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
 374                 DataStream adaptStream = tableEnv.toAppendStream(adaptTable, typeInfo);
 375 
 376                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 377 
 378                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 379                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 379                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 380                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 381                 } else {
 382                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 383                 }
 384 
 385                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 386                 tableEnv.registerTable(tableInfo.getName(), regTable);
 387                 if (LOG.isInfoEnabled()) {
 388                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 389                 }
 390                 registerTableCache.put(tableInfo.getName(), regTable);
 391 
<abbr title=" 392                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 392                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 393                 pluginClassPathSets.add(sourceTablePathUrl);
 394             } else if (tableInfo instanceof AbstractTargetTableInfo) {
 395 
<abbr title=" 396                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 396                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo,🔵</abbr>
<abbr title=" 397                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 397                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 398                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 398                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
 399 
<abbr title=" 400                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 400                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 401                 pluginClassPathSets.add(sinkTablePathUrl);
 402             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 403                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 403                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).ge🔵</abbr>
 404                 sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 405 
<abbr title=" 406                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 406                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 407                 pluginClassPathSets.add(sideTablePathUrl);
 408             } else {
 409                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 410             }
 411         }
 412         return pluginClassPathSets;
 413     }
 414 
 415     /**
 416      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 417      * @param env
 418      * @param classPathSet
 419      */
<abbr title=" 420     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 420     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 421         int i = 0;
 422         for (URL url : classPathSet) {
 423             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 424             env.registerCachedFile(url.getPath(), classFileName, true);
 425             i++;
 426         }
 427     }
 428 
<abbr title=" 429     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 429     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 430         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 431                 StreamExecutionEnvironment.getExecutionEnvironment() :
 432                 new MyLocalStreamEnvironment();
 433 
 434         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 435         return env;
 436     }
 437 
 438 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title=" 439     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties confProperties) {"> 439     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties co🔵</abbr></span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 440         // use blink and streammode</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 441         EnvironmentSettings settings = EnvironmentSettings.newInstance()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 442                 .useBlinkPlanner()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 443                 .inStreamingMode()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 444                 .build();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 445 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 446         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 447         StreamEnvConfigManager.streamTableEnvironmentStateTTLConfig(tableEnv, confProperties);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 448         return tableEnv;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 449     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 450 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 451 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 452     public static void setLogLevel(ParamsInfo paramsInfo){</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 453         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 454         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 455             return;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 456         }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 457         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 458         logLevelProcess.process(logLevel);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 459     }</span>
 460 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 461 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 462         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 463         return env;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 464     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 465 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 466 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 467     public static void setLogLevel(ParamsInfo paramsInfo){</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 468         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 469         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 470             return;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 471         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 472         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 473         logLevelProcess.process(logLevel);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 474     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 475 }</span>
 476 =======
 477 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 478 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.exec;
  20 
  21 import com.dtstack.flink.sql.parser.CreateFuncParser;
  22 import com.dtstack.flink.sql.parser.CreateTmpTableParser;
  23 import com.dtstack.flink.sql.parser.FlinkPlanner;
  24 import com.dtstack.flink.sql.parser.InsertSqlParser;
  25 import com.dtstack.flink.sql.parser.SqlParser;
  26 import com.dtstack.flink.sql.parser.SqlTree;
  27 import org.apache.flink.api.common.typeinfo.TypeInformation;
  28 import org.apache.flink.api.java.tuple.Tuple2;
  29 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  30 import org.apache.flink.streaming.api.datastream.DataStream;
  31 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  32 import org.apache.flink.table.api.EnvironmentSettings;
  33 import org.apache.flink.table.api.Table;
  34 import org.apache.flink.table.api.TableEnvironment;
  35 import org.apache.flink.table.api.java.StreamTableEnvironment;
  36 import org.apache.flink.table.calcite.FlinkPlannerImpl;
  37 import org.apache.flink.table.sinks.TableSink;
  38 import org.apache.flink.types.Row;
  39 
  40 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  41 import com.dtstack.flink.sql.constrant.ConfigConstrant;
  42 import com.dtstack.flink.sql.enums.ClusterMode;
  43 import com.dtstack.flink.sql.enums.ECacheType;
  44 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  45 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  46 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  47 import com.dtstack.flink.sql.function.FunctionManager;
  48 import com.dtstack.flink.sql.option.OptionParser;
  49 import com.dtstack.flink.sql.option.Options;
  50 import com.dtstack.flink.sql.side.SideSqlExec;
  51 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  52 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  53 import com.dtstack.flink.sql.source.StreamSourceFactory;
  54 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  55 import com.dtstack.flink.sql.table.AbstractTableInfo;
  56 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  57 import com.dtstack.flink.sql.util.DtStringUtil;
  58 import com.dtstack.flink.sql.util.PluginUtil;
  59 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  60 import com.fasterxml.jackson.databind.ObjectMapper;
  61 import com.google.common.base.Preconditions;
  62 import com.google.common.base.Strings;
  63 import com.google.common.collect.Lists;
  64 import com.google.common.collect.Maps;
  65 import com.google.common.collect.Sets;
  66 import org.apache.calcite.sql.SqlInsert;
  67 import org.apache.calcite.sql.SqlNode;
  68 import org.apache.commons.io.Charsets;
  69 import org.apache.commons.lang3.StringUtils;
  70 import org.slf4j.Logger;
  71 import org.slf4j.LoggerFactory;
  72 
  73 import java.io.File;
  74 import java.lang.reflect.InvocationTargetException;
  75 import java.net.URL;
  76 import java.net.URLClassLoader;
  77 import java.net.URLDecoder;
  78 import java.util.Arrays;
  79 import java.util.List;
  80 import java.util.Map;
  81 import java.util.Properties;
  82 import java.util.Set;
  83 
  84 /**
  85  *  任务执行时的流程方法
  86  * Date: 2020/2/17
  87  * Company: www.dtstack.com
  88  * @author maqi
  89  */
  90 public class ExecuteProcessHelper {
  91 
  92     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  93     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  94     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  95 
  96 
  97     public static ParamsInfo parseParams(String[] args) throws Exception {
  98         LOG.info(&quot;------------program params-------------------------&quot;);
  99         Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 100         LOG.info(&quot;-------------------------------------------&quot;);
 101 
 102         OptionParser optionParser = new OptionParser(args);
 103         Options options = optionParser.getOptions();
 104 
 105         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 106         String name = options.getName();
 107         String localSqlPluginPath = options.getLocalSqlPluginPath();
 108         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 109         String pluginLoadMode = options.getPluginLoadMode();
 110         String deployMode = options.getMode();
 111         String logLevel = options.getLogLevel();
 112 
<abbr title=" 113         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),"> 113         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 114                 &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 115         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 116         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 117 
 118         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 119 
 120         return ParamsInfo.builder()
 121                 .setSql(sql)
 122                 .setName(name)
 123                 .setLocalSqlPluginPath(localSqlPluginPath)
 124                 .setRemoteSqlPluginPath(remoteSqlPluginPath)
 125                 .setPluginLoadMode(pluginLoadMode)
 126                 .setDeployMode(deployMode)
 127                 .setConfProp(confProperties)
 128                 .setJarUrlList(jarUrlList)
 129                 .build();
 130 
 131     }
 132 
 133     /**
 134      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 135      * @param remoteSqlPluginPath
 136      * @param deployMode
 137      * @param pluginLoadMode
 138      * @return
 139      */
<abbr title=" 140     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 140     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 141         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 142             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 143                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 144         }
 145         return true;
 146     }
 147 
 148 
 149     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 150         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 150         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 151 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 152         StreamTableEnvironment tableEnv = getStreamTableEnv(env,paramsInfo.getConfProp());</span>
 153 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 154         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 155         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 155         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 156 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 157         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());</span>
 158 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 159         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 160         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 160         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 161         // init global flinkPlanner</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 162         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.getTypeFactory());"> 162         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.ge🔵</abbr></span>
 163 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 164 
 165         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 166         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 167 
 168         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 169         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 170 
 171         //register udf
 172         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 173         //register table schema
<abbr title=" 174         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 174         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
<abbr title=" 175                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 175                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, regist🔵</abbr>
 176         // cache classPathSets
 177         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 178 
<abbr title=" 179         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache);"> 179         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 180 
 181         if (env instanceof MyLocalStreamEnvironment) {
 182             ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 183         }
 184         return env;
 185     }
 186 
 187 
 188     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 189         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 190         if (Strings.isNullOrEmpty(addJarListStr)) {
 191             return jarUrlList;
 192         }
 193 
<abbr title=" 194         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 194         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 195         //Get External jar to load
 196         for (String addJarPath : addJarFileList) {
 197             jarUrlList.add(new File(addJarPath).toURI().toURL());
 198         }
 199         return jarUrlList;
 200     }
 201 
 202     private static void sqlTranslation(String localSqlPluginPath,
 203                                        StreamTableEnvironment tableEnv,
 204                                        SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 205                                        Map&lt;String, Table&gt; registerTableCache) throws Exception {
 206 
 207         SideSqlExec sideSqlExec = new SideSqlExec();
 208         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 209 
 210         int scope = 0;
 211         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
 212 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 213             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, result);</span>
 214 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 215         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 216             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 216             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 217         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 218 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 219         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {</span>
 220 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 221             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result, scope + &quot;&quot;);"> 221             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 222             scope++;</span>
 223 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 224         }
 225 
 226         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 227             if (LOG.isInfoEnabled()) {
 228                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 229             }
 230 
 231             boolean isSide = false;
 232             for (String tableName : result.getTargetTableList()) {
 233                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 234                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 235                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 236 
 237                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 238                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 239                     String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 240                     tmp.setExecSql(tmpSql);
 241 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 242                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, tmp);</span>
 243 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 244                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 244                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 245                 } else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246                     for (String sourceTable : result.getSourceTableList()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 247                         if (sideTableMap.containsKey(sourceTable)) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 248                             isSide = true;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 249                             break;</span>
 250 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 251                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp, scope + &quot;&quot;);"> 251                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr></span>
 252 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 253                 } else {
 254                     for (String sourceTable : result.getSourceTableList()) {
 255                         if (sideTableMap.containsKey(sourceTable)) {
 256                             isSide = true;
 257                             break;
 258                         }
 259                     }
 260                     if (isSide) {
 261                         //sql-dimensional table contains the dimension table of execution
 262 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title=" 263                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, null);"> 263                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
 264 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 265                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 265                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 266                     } else {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 267                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 268                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 268                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 269                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 270                         if (LOG.isInfoEnabled()) {</span>
 271 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 272                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null, null);"> 272                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
 273 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 274                     } else {
 275                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 276                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 276                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 277                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql());
 278                         if (LOG.isInfoEnabled()) {
 279                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 280                         }
 281                     }
 282                 }
 283 
 284                 scope++;
 285             }
 286         }
 287     }
 288 
<abbr title=" 289     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 289     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 290             throws IllegalAccessException, InvocationTargetException {
 291         // udf和tableEnv须由同一个类加载器加载
 292         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 293         URLClassLoader classLoader = null;
 294         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 295         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 296             //classloader
 297             if (classLoader == null) {
<abbr title=" 298                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);"> 298                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoad🔵</abbr>
 299             }
<abbr title=" 300             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 300             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 301         }
 302     }
 303 
 304     /**
 305      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 306      * @param sqlTree
 307      * @param env
 308      * @param tableEnv
 309      * @param localSqlPluginPath
 310      * @param remoteSqlPluginPath
 311      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 312      * @param sideTableMap
 313      * @param registerTableCache
 314      * @return
 315      * @throws Exception
 316      */
<abbr title=" 317     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 317     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
<abbr title=" 318                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 318                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, A🔵</abbr>
 319         Set&lt;URL&gt; pluginClassPathSets = Sets.newHashSet();
 320         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 321         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 322 
 323             if (tableInfo instanceof AbstractSourceTableInfo) {
 324 
 325                 AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 326                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 326                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 327                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 328                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 328                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 329                 //Create table in which the function is arranged only need adaptation sql
 330                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 331                 Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 332 
<abbr title=" 333                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 333                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
 334                 DataStream adaptStream = tableEnv.toAppendStream(adaptTable, typeInfo);
 335 
 336                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 337 
 338                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 339                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 339                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 340                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 341                 } else {
 342                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 343                 }
 344 
 345                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 346                 tableEnv.registerTable(tableInfo.getName(), regTable);
 347                 if (LOG.isInfoEnabled()) {
 348                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 349                 }
 350                 registerTableCache.put(tableInfo.getName(), regTable);
 351 
<abbr title=" 352                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 352                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 353                 pluginClassPathSets.add(sourceTablePathUrl);
 354             } else if (tableInfo instanceof AbstractTargetTableInfo) {
 355 
<abbr title=" 356                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 356                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo,🔵</abbr>
<abbr title=" 357                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 357                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 358                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 358                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
 359 
<abbr title=" 360                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 360                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 361                 pluginClassPathSets.add(sinkTablePathUrl);
 362             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 363                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 363                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).ge🔵</abbr>
 364                 sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 365 
<abbr title=" 366                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 366                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 367                 pluginClassPathSets.add(sideTablePathUrl);
 368             } else {
 369                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 370             }
 371         }
 372         return pluginClassPathSets;
 373     }
 374 
 375     /**
 376      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 377      * @param env
 378      * @param classPathSet
 379      */
<abbr title=" 380     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 380     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 381         int i = 0;
 382         for (URL url : classPathSet) {
 383             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 384             env.registerCachedFile(url.getPath(), classFileName, true);
 385             i++;
 386         }
 387     }
 388 
<abbr title=" 389     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 389     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 390         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 391                 StreamExecutionEnvironment.getExecutionEnvironment() :
 392                 new MyLocalStreamEnvironment();
 393 
 394         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 395         return env;
 396     }
 397 
<abbr title=" 398     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties confProperties) {"> 398     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties co🔵</abbr>
 399         // use blink and streammode
 400         EnvironmentSettings settings = EnvironmentSettings.newInstance()
 401                 .useBlinkPlanner()
 402                 .inStreamingMode()
 403                 .build();
 404 
 405         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);
 406         StreamEnvConfigManager.streamTableEnvironmentStateTTLConfig(tableEnv, confProperties);
 407         return tableEnv;
 408     }
 409 
 410 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.exec;
  19 
  20 import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  21 import com.dtstack.flink.sql.constrant.ConfigConstrant;
  22 import com.dtstack.flink.sql.enums.ClusterMode;
  23 import com.dtstack.flink.sql.enums.ECacheType;
  24 import com.dtstack.flink.sql.enums.EPluginLoadMode;
  25 import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  26 import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  27 import com.dtstack.flink.sql.function.FunctionManager;
  28 import com.dtstack.flink.sql.option.OptionParser;
  29 import com.dtstack.flink.sql.option.Options;
  30 import com.dtstack.flink.sql.parser.CreateFuncParser;
  31 import com.dtstack.flink.sql.parser.CreateTmpTableParser;
  32 import com.dtstack.flink.sql.parser.FlinkPlanner;
  33 import com.dtstack.flink.sql.parser.InsertSqlParser;
  34 import com.dtstack.flink.sql.parser.SqlParser;
  35 import com.dtstack.flink.sql.parser.SqlTree;
  36 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  37 import com.dtstack.flink.sql.side.SideSqlExec;
  38 import com.dtstack.flink.sql.sink.StreamSinkFactory;
  39 import com.dtstack.flink.sql.source.StreamSourceFactory;
  40 import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  41 import com.dtstack.flink.sql.table.AbstractTableInfo;
  42 import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  43 import com.dtstack.flink.sql.util.DtStringUtil;
  44 import com.dtstack.flink.sql.util.PluginUtil;
  45 import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  46 import com.fasterxml.jackson.databind.ObjectMapper;
  47 import com.google.common.base.Preconditions;
  48 import com.google.common.base.Strings;
  49 import com.google.common.collect.Lists;
  50 import com.google.common.collect.Maps;
  51 import com.google.common.collect.Sets;
  52 import java.io.File;
  53 import java.lang.reflect.InvocationTargetException;
  54 import java.net.URL;
  55 import java.net.URLClassLoader;
  56 import java.net.URLDecoder;
  57 import java.util.Arrays;
  58 import java.util.List;
  59 import java.util.Map;
  60 import java.util.Properties;
  61 import java.util.Set;
  62 import org.apache.calcite.sql.SqlInsert;
  63 import org.apache.calcite.sql.SqlNode;
  64 import org.apache.commons.io.Charsets;
  65 import org.apache.commons.lang3.StringUtils;
  66 import org.apache.flink.api.common.typeinfo.TypeInformation;
  67 import org.apache.flink.api.java.tuple.Tuple2;
  68 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  69 import org.apache.flink.streaming.api.datastream.DataStream;
  70 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
  71 import org.apache.flink.table.api.EnvironmentSettings;
  72 import org.apache.flink.table.api.Table;
  73 import org.apache.flink.table.api.TableEnvironment;
  74 import org.apache.flink.table.api.java.StreamTableEnvironment;
  75 import org.apache.flink.table.calcite.FlinkPlannerImpl;
  76 import org.apache.flink.table.sinks.TableSink;
  77 import org.apache.flink.types.Row;
  78 import org.slf4j.Logger;
  79 import org.slf4j.LoggerFactory;
  80 
  81 
  82 /**
  83  *  任务执行时的流程方法
  84  * Date: 2020/2/17
  85  * Company: www.dtstack.com
  86  * @author maqi
  87  */
  88 public class ExecuteProcessHelper {
  89 
  90     private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  91     private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  92     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  93 
  94 
  95     public static ParamsInfo parseParams(String[] args) throws Exception {
  96         LOG.info(&quot;------------program params-------------------------&quot;);
  97         Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
  98         LOG.info(&quot;-------------------------------------------&quot;);
  99 
 100         OptionParser optionParser = new OptionParser(args);
 101         Options options = optionParser.getOptions();
 102 
 103         String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 104         String name = options.getName();
 105         String localSqlPluginPath = options.getLocalSqlPluginPath();
 106         String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 107         String pluginLoadMode = options.getPluginLoadMode();
 108         String deployMode = options.getMode();
 109         String logLevel = options.getLogLevel();
 110 
<abbr title=" 111         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),"> 111         Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadM🔵</abbr>
 112                 &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 113         String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 114         Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 115 
 116         List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 117 
 118         return ParamsInfo.builder()
 119                 .setSql(sql)
 120                 .setName(name)
 121                 .setLocalSqlPluginPath(localSqlPluginPath)
 122                 .setRemoteSqlPluginPath(remoteSqlPluginPath)
 123                 .setPluginLoadMode(pluginLoadMode)
 124                 .setDeployMode(deployMode)
 125                 .setConfProp(confProperties)
 126                 .setJarUrlList(jarUrlList)
 127                 .build();
 128 
 129     }
 130 
 131     /**
 132      *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 133      * @param remoteSqlPluginPath
 134      * @param deployMode
 135      * @param pluginLoadMode
 136      * @return
 137      */
<abbr title=" 138     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 138     public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String 🔵</abbr>
 139         if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 140             return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 141                     || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 142         }
 143         return true;
 144     }
 145 
 146 
 147     public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 148         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 148         StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), p🔵</abbr>
 149 
 150 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 151         StreamTableEnvironment tableEnv = getStreamTableEnv(env,paramsInfo.getConfProp());</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 152 </span>
 153 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 154 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 154 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 155 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 156 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 157         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 158         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 158         StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, param🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 159         // init global flinkPlanner</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 160         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.getTypeFactory());"> 160         FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.ge🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 161 </span>
 162 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 163 
 164         SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 165         SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 166 
 167         Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 168         Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 169 
 170         //register udf
 171         ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 172         //register table schema
<abbr title=" 173         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 173         Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.ge🔵</abbr>
<abbr title=" 174                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 174                 paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, regist🔵</abbr>
 175         // cache classPathSets
 176         ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 177 
<abbr title=" 178         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache);"> 178         ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTa🔵</abbr>
 179 
 180         if (env instanceof MyLocalStreamEnvironment) {
 181             ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 182         }
 183         return env;
 184     }
 185 
 186 
 187     public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 188         List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 189         if (Strings.isNullOrEmpty(addJarListStr)) {
 190             return jarUrlList;
 191         }
 192 
<abbr title=" 193         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 193         List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.U🔵</abbr>
 194         //Get External jar to load
 195         for (String addJarPath : addJarFileList) {
 196             jarUrlList.add(new File(addJarPath).toURI().toURL());
 197         }
 198         return jarUrlList;
 199     }
 200 
 201     private static void sqlTranslation(String localSqlPluginPath,
 202                                        StreamTableEnvironment tableEnv,
 203                                        SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 204                                        Map&lt;String, Table&gt; registerTableCache) throws Exception {
 205 
 206         SideSqlExec sideSqlExec = new SideSqlExec();
 207         sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
 208 
 209         int scope = 0;
 210         for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
 211 
 212 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 213             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, result);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 214 </span>
 215 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 216 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 216 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 217 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 218 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 219             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result, scope + &quot;&quot;);"> 219             sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 220             scope++;</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 221 </span>
 222 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 223         }
 224 
 225         for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 226             if (LOG.isInfoEnabled()) {
 227                 LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 228             }
 229 
 230             boolean isSide = false;
 231             for (String tableName : result.getTargetTableList()) {
 232                 if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 233                     CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 234                     String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 235 
 236                     FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();
 237                     SqlNode sqlNode = flinkPlanner.parse(realSql);
 238                     String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 239                     tmp.setExecSql(tmpSql);
 240 
 241 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 242                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, tmp);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 243 </span>
 244 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 245 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 245 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 246 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 247 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 248                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp, scope + &quot;&quot;);"> 248                     sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryC🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 249 </span>
 250 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 251                 } else {
 252                     for (String sourceTable : result.getSourceTableList()) {
 253                         if (sideTableMap.containsKey(sourceTable)) {
 254                             isSide = true;
 255                             break;
 256                         }
 257                     }
 258                     if (isSide) {
 259                         //sql-dimensional table contains the dimension table of execution
 260 
 261 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title=" 262                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, null);"> 262                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 263 </span>
 264 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 265 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 265 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 266 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 267 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 268                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null, null);"> 268                         sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache,🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 269 </span>
 270 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 271                     } else {
 272                         LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
<abbr title=" 273                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());"> 273                         LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getEx🔵</abbr>
 274                         FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql());
 275                         if (LOG.isInfoEnabled()) {
 276                             LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 277                         }
 278                     }
 279                 }
 280 
 281                 scope++;
 282             }
 283         }
 284     }
 285 
<abbr title=" 286     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 286     public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironmen🔵</abbr>
 287             throws IllegalAccessException, InvocationTargetException {
 288         // udf和tableEnv须由同一个类加载器加载
 289         ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 290         URLClassLoader classLoader = null;
 291         List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 292         for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 293             //classloader
 294             if (classLoader == null) {
<abbr title=" 295                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);"> 295                 classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoad🔵</abbr>
 296             }
<abbr title=" 297             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 297             FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), 🔵</abbr>
 298         }
 299     }
 300 
 301     /**
 302      *    向Flink注册源表和结果表，返回执行时插件包的全路径
 303      * @param sqlTree
 304      * @param env
 305      * @param tableEnv
 306      * @param localSqlPluginPath
 307      * @param remoteSqlPluginPath
 308      * @param pluginLoadMode   插件加载模式 classpath or shipfile
 309      * @param sideTableMap
 310      * @param registerTableCache
 311      * @return
 312      * @throws Exception
 313      */
<abbr title=" 314     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 314     public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvi🔵</abbr>
<abbr title=" 315                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 315                                          String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, A🔵</abbr>
 316         Set&lt;URL&gt; pluginClassPathSets = Sets.newHashSet();
 317         WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 318         for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 319 
 320             if (tableInfo instanceof AbstractSourceTableInfo) {
 321 
 322                 AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 323                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 323                 Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSq🔵</abbr>
 324                 tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 325                 //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 325                 //Note --- parameter conversion function can not be used inside a function of the type of🔵</abbr>
 326                 //Create table in which the function is arranged only need adaptation sql
 327                 String adaptSql = sourceTableInfo.getAdaptSelectSql();
 328                 Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 329 
<abbr title=" 330                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 330                 RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable🔵</abbr>
 331                 DataStream adaptStream = tableEnv.toAppendStream(adaptTable, typeInfo);
 332 
 333                 String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 334 
 335                 if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
<abbr title=" 336                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);"> 336                     adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTabl🔵</abbr>
 337                     fields += &quot;,ROWTIME.ROWTIME&quot;;
 338                 } else {
 339                     fields += &quot;,PROCTIME.PROCTIME&quot;;
 340                 }
 341 
 342                 Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 343                 tableEnv.registerTable(tableInfo.getName(), regTable);
 344                 if (LOG.isInfoEnabled()) {
 345                     LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 346                 }
 347                 registerTableCache.put(tableInfo.getName(), regTable);
 348 
<abbr title=" 349                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 349                 URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(),🔵</abbr>
 350                 pluginClassPathSets.add(sourceTablePathUrl);
 351             } else if (tableInfo instanceof AbstractTargetTableInfo) {
 352 
<abbr title=" 353                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 353                 TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo,🔵</abbr>
<abbr title=" 354                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());"> 354                 TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses()🔵</abbr>
<abbr title=" 355                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);"> 355                 tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableS🔵</abbr>
 356 
<abbr title=" 357                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 357                 URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), A🔵</abbr>
 358                 pluginClassPathSets.add(sinkTablePathUrl);
 359             } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 360                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 360                 String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).ge🔵</abbr>
 361                 sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 362 
<abbr title=" 363                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 363                 URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperat🔵</abbr>
 364                 pluginClassPathSets.add(sideTablePathUrl);
 365             } else {
 366                 throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 367             }
 368         }
 369         return pluginClassPathSets;
 370     }
 371 
 372     /**
 373      *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 374      * @param env
 375      * @param classPathSet
 376      */
<abbr title=" 377     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {"> 377     public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSe🔵</abbr>
 378         int i = 0;
 379         for (URL url : classPathSet) {
 380             String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 381             env.registerCachedFile(url.getPath(), classFileName, true);
 382             i++;
 383         }
 384     }
 385 
<abbr title=" 386     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 386     public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode🔵</abbr>
 387         StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 388                 StreamExecutionEnvironment.getExecutionEnvironment() :
 389                 new MyLocalStreamEnvironment();
 390 
 391         StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 392         return env;
 393     }
 394 
 395 
 396 &lt;&lt;&lt;&lt;&lt;&lt;&lt; LEFT
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"><abbr title=" 397     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties confProperties) {"> 397     private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties co🔵</abbr></span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 398         // use blink and streammode</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 399         EnvironmentSettings settings = EnvironmentSettings.newInstance()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 400                 .useBlinkPlanner()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 401                 .inStreamingMode()</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 402                 .build();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 403 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 404         StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 405         StreamEnvConfigManager.streamTableEnvironmentStateTTLConfig(tableEnv, confProperties);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 406         return tableEnv;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 407     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 408 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 409 </span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 410     public static void setLogLevel(ParamsInfo paramsInfo){</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 411         String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 412         if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 413             return;</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 414         }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 415         ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 416         logLevelProcess.process(logLevel);</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 417     }</span>
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 418 </span>
 419 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 420 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kwohrp23k5b6vdk93d3r*/"> 420 /*d94z9sk0k4hf9j3ijd - note the base isn&#x27;t actually empty, spork simply doesn&#x27;t generate a base - gd930kw🔵</abbr></span>
 421 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 422 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 423 </span>
 424 &gt;&gt;&gt;&gt;&gt;&gt;&gt; RIGHT
 425 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.exec;
  20  
  21  import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;



















  22  import com.dtstack.flink.sql.classloader.ClassLoaderManager;
  23  import com.dtstack.flink.sql.config.CalciteConfig;
  24  import com.dtstack.flink.sql.constrant.ConfigConstrant;
  25  import com.dtstack.flink.sql.enums.ClusterMode;
  26  import com.dtstack.flink.sql.enums.ECacheType;
  27  import com.dtstack.flink.sql.enums.EPluginLoadMode;
  28  import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  29  import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  30  import com.dtstack.flink.sql.function.FunctionManager;
  31  import com.dtstack.flink.sql.option.OptionParser;
  32  import com.dtstack.flink.sql.option.Options;
  33  import com.dtstack.flink.sql.parser.CreateFuncParser;
  34  import com.dtstack.flink.sql.parser.CreateTmpTableParser;
  35  import com.dtstack.flink.sql.parser.InsertSqlParser;
  36  import com.dtstack.flink.sql.parser.SqlParser;
  37  import com.dtstack.flink.sql.parser.SqlTree;
  38  import com.dtstack.flink.sql.side.SideSqlExec;
  39  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  40  import com.dtstack.flink.sql.sink.StreamSinkFactory;
  41  import com.dtstack.flink.sql.source.StreamSourceFactory;
  42  import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  43  import com.dtstack.flink.sql.table.AbstractTableInfo;
  44  import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  45  import com.dtstack.flink.sql.util.DtStringUtil;
  46  import com.dtstack.flink.sql.util.PluginUtil;
  47  import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  48  import com.fasterxml.jackson.databind.ObjectMapper;
  49  import com.google.common.base.Preconditions;
  50  import com.google.common.base.Strings;
  51  import com.google.common.collect.Lists;
  52  import com.google.common.collect.Maps;
  53  import com.google.common.collect.Sets;
  54  import org.apache.calcite.sql.SqlInsert;
  55  import org.apache.calcite.sql.SqlNode;
  56  import org.apache.commons.io.Charsets;
  57  import org.apache.commons.lang3.StringUtils;
  58  import org.apache.flink.api.common.typeinfo.TypeInformation;
  59  import org.apache.flink.api.java.tuple.Tuple2;
  60  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  61  import org.apache.flink.streaming.api.datastream.DataStream;
  62  import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  63 -import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  64 +import org.apache.flink.table.api.EnvironmentSettings;</span>
  65  import org.apache.flink.table.api.Table;
  66  import org.apache.flink.table.api.TableEnvironment;
  67  import org.apache.flink.table.api.java.StreamTableEnvironment;
  68  import org.apache.flink.table.sinks.TableSink;
  69  import org.apache.flink.types.Row;
  70  import org.slf4j.Logger;
  71  import org.slf4j.LoggerFactory;
  72  
  73  import java.io.File;
  74  import java.lang.reflect.InvocationTargetException;
  75  import java.net.URL;
  76  import java.net.URLClassLoader;
  77  import java.net.URLDecoder;
  78  import java.util.Arrays;
  79  import java.util.List;
  80  import java.util.Map;
  81  import java.util.Properties;
  82  import java.util.Set;
  83  
  84  /**
  85   *  任务执行时的流程方法
  86   * Date: 2020/2/17
  87   * Company: www.dtstack.com
  88   * @author maqi
  89   */
  90  public class ExecuteProcessHelper {
  91  
  92      private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
  93      private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
  94      private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
  95  
  96  
  97      public static ParamsInfo parseParams(String[] args) throws Exception {
  98          LOG.info(&quot;------------program params-------------------------&quot;);
  99          Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 100          LOG.info(&quot;-------------------------------------------&quot;);
 101  
 102          OptionParser optionParser = new OptionParser(args);
 103          Options options = optionParser.getOptions();
 104  
 105          String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 106          String name = options.getName();
 107          String localSqlPluginPath = options.getLocalSqlPluginPath();
 108          String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 109          String pluginLoadMode = options.getPluginLoadMode();
 110          String deployMode = options.getMode();
 111          String logLevel = options.getLogLevel();
 112  
 113          Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),
 114                  &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 115          String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 116          Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 117  
 118          List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 119  
 120          return ParamsInfo.builder()
 121                  .setSql(sql)
 122                  .setName(name)
 123                  .setLocalSqlPluginPath(localSqlPluginPath)
 124                  .setRemoteSqlPluginPath(remoteSqlPluginPath)
 125                  .setPluginLoadMode(pluginLoadMode)
 126                  .setDeployMode(deployMode)
 127                  .setConfProp(confProperties)
 128                  .setJarUrlList(jarUrlList)
 129                  .build();
 130  
 131      }
 132  
 133      /**
 134       *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 135       * @param remoteSqlPluginPath
 136       * @param deployMode
 137       * @param pluginLoadMode
 138       * @return
 139       */
<abbr title=" 140      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 140      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoa🔵</abbr>
 141          if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 142              return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 143                      || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 144          }
 145          return true;
 146      }
 147  
 148  
 149      public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 150          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 150          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 151 -        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 152 -        StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 152 -        StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.get🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 153 +        StreamTableEnvironment tableEnv = getStreamTableEnv(env,paramsInfo.getConfProp());</span>

 154  
 155          SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 156          SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 157  
 158          Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 159          Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 160  
 161          //register udf
 162          ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 163          //register table schema
<abbr title=" 164          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 164          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSql🔵</abbr>
<abbr title=" 165                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 165                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCa🔵</abbr>
 166          // cache classPathSets
 167          ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 168  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 169 -        ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 169 -        ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, r🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 170 +        ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache);"> 170 +        ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, r🔵</abbr></span>
 171  
 172          if (env instanceof MyLocalStreamEnvironment) {
 173              ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 174          }
 175          return env;
 176      }
 177  
 178  
 179      public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 180          List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 181          if (Strings.isNullOrEmpty(addJarListStr)) {
 182              return jarUrlList;
 183          }
 184  
<abbr title=" 185          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 185          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name🔵</abbr>
 186          //Get External jar to load
 187          for (String addJarPath : addJarFileList) {
 188              jarUrlList.add(new File(addJarPath).toURI().toURL());
 189          }
 190          return jarUrlList;
 191      }
 192  
 193      private static void sqlTranslation(String localSqlPluginPath,
 194                                         StreamTableEnvironment tableEnv,
 195                                         SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 196 -                                       Map&lt;String, Table&gt; registerTableCache,</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 197 -                                       StreamQueryConfig queryConfig) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 198 +                                       Map&lt;String, Table&gt; registerTableCache) throws Exception {</span>
 199  
 200          SideSqlExec sideSqlExec = new SideSqlExec();
 201          sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);


 202          for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 203 -            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 203 -            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result)🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 204 +            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, result);</span>

 205          }
 206  
 207          for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 208              if (LOG.isInfoEnabled()) {
 209                  LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 210              }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 211 +</span>
 212              boolean isSide = false;
 213              for (String tableName : result.getTargetTableList()) {
 214                  if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 215                      CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 216                      String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 217  
<abbr title=" 218                      SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_LEX_CONFIG).parseStmt();"> 218                      SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_🔵</abbr>


 219                      String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 220                      tmp.setExecSql(tmpSql);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 221 -                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 221 -                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tm🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 222 +                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, tmp);</span>
 223                  } else {
 224                      for (String sourceTable : result.getSourceTableList()) {
 225                          if (sideTableMap.containsKey(sourceTable)) {
 226                              isSide = true;
 227                              break;
 228                          }
 229                      }
 230                      if (isSide) {
 231                          //sql-dimensional table contains the dimension table of execution
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 232 -                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 232 -                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryCon🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 233 +                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, null);</span>
 234                      } else {
 235                          LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
 236                          LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 237 -                        FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 238 +                        FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql());</span>
 239                          if (LOG.isInfoEnabled()) {
 240                              LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 241                          }
 242                      }
 243                  }


 244              }
 245          }
 246      }
 247  
<abbr title=" 248      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 248      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEn🔵</abbr>
 249              throws IllegalAccessException, InvocationTargetException {
 250          // udf和tableEnv须由同一个类加载器加载
 251          ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 252          URLClassLoader classLoader = null;
 253          List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 254          for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 255              //classloader
 256              if (classLoader == null) {
 257                  classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);
 258              }
<abbr title=" 259              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 259              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv,🔵</abbr>
 260          }
 261      }
 262  
 263      /**
 264       *    向Flink注册源表和结果表，返回执行时插件包的全路径
 265       * @param sqlTree
 266       * @param env
 267       * @param tableEnv
 268       * @param localSqlPluginPath
 269       * @param remoteSqlPluginPath
 270       * @param pluginLoadMode   插件加载模式 classpath or shipfile
 271       * @param sideTableMap
 272       * @param registerTableCache
 273       * @return
 274       * @throws Exception
 275       */
<abbr title=" 276      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 276      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment t🔵</abbr>
<abbr title=" 277                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 277                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSi🔵</abbr>
 278          Set&lt;URL&gt; pluginClassPathSets = Sets.newHashSet();
 279          WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 280          for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 281  
 282              if (tableInfo instanceof AbstractSourceTableInfo) {
 283  
 284                  AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 285                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 285                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPa🔵</abbr>
 286                  tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 287                  //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 287                  //Note --- parameter conversion function can not be used inside a function of the type of polymeri🔵</abbr>
 288                  //Create table in which the function is arranged only need adaptation sql
 289                  String adaptSql = sourceTableInfo.getAdaptSelectSql();
 290                  Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 291  
<abbr title=" 292                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 292                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchem🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 293 -                DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 294 -                        .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 295 -                            return f0.f1;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 296 -                        })</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 297 -                        .returns(typeInfo);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 298 +                DataStream adaptStream = tableEnv.toAppendStream(adaptTable, typeInfo);</span>
 299  
 300                  String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 301  
 302                  if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
 303                      adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);
 304                      fields += &quot;,ROWTIME.ROWTIME&quot;;
 305                  } else {
 306                      fields += &quot;,PROCTIME.PROCTIME&quot;;
 307                  }
 308  
 309                  Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 310                  tableEnv.registerTable(tableInfo.getName(), regTable);
 311                  if (LOG.isInfoEnabled()) {
 312                      LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 313                  }
 314                  registerTableCache.put(tableInfo.getName(), regTable);
 315  
<abbr title=" 316                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 316                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), Abstract🔵</abbr>
 317                  pluginClassPathSets.add(sourceTablePathUrl);
 318              } else if (tableInfo instanceof AbstractTargetTableInfo) {
 319  
<abbr title=" 320                  TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 320                  TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSql🔵</abbr>
 321                  TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());
 322                  tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);
 323  
<abbr title=" 324                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 324                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTa🔵</abbr>
 325                  pluginClassPathSets.add(sinkTablePathUrl);
 326              } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 327                  String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 327                  String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheTyp🔵</abbr>
 328                  sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 329  
<abbr title=" 330                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 330                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, Abstr🔵</abbr>
 331                  pluginClassPathSets.add(sideTablePathUrl);
 332              } else {
 333                  throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 334              }
 335          }
 336          return pluginClassPathSets;
 337      }
 338  
 339      /**
 340       *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 341       * @param env
 342       * @param classPathSet
 343       */
 344      public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {
 345          int i = 0;
 346          for (URL url : classPathSet) {
 347              String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 348              env.registerCachedFile(url.getPath(), classFileName, true);
 349              i++;
 350          }
 351      }
 352  
<abbr title=" 353      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 353      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws 🔵</abbr>
 354          StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 355                  StreamExecutionEnvironment.getExecutionEnvironment() :
 356                  new MyLocalStreamEnvironment();
 357  
 358          StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 359          return env;
 360      }
 361  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 362 +    private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties confProperties) {"> 362 +    private static StreamTableEnvironment getStreamTableEnv(StreamExecutionEnvironment env, Properties confPropert🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 363 +        // use blink and streammode</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 364 +        EnvironmentSettings settings = EnvironmentSettings.newInstance()</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 365 +                .useBlinkPlanner()</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 366 +                .inStreamingMode()</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 367 +                .build();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 368 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 369 +        StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env, settings);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 370 +        StreamEnvConfigManager.streamTableEnvironmentStateTTLConfig(tableEnv, confProperties);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 371 +        return tableEnv;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 372 +    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 373 +</span>
 374  
 375      public static void setLogLevel(ParamsInfo paramsInfo){
 376          String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);
 377          if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){
 378              return;
 379          }
 380          ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();
 381          logLevelProcess.process(logLevel);
 382      }
 383  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.exec;
  20  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  21 -import com.aiweiergou.tool.logger.api.ChangeLogLevelProcess;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  22 +import com.dtstack.flink.sql.parser.CreateFuncParser;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  23 +import com.dtstack.flink.sql.parser.CreateTmpTableParser;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  24 +import com.dtstack.flink.sql.parser.FlinkPlanner;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  25 +import com.dtstack.flink.sql.parser.InsertSqlParser;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  26 +import com.dtstack.flink.sql.parser.SqlParser;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  27 +import com.dtstack.flink.sql.parser.SqlTree;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  28 +import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  30 +import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  31 +import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  32 +import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  33 +import org.apache.flink.table.api.StreamQueryConfig;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  34 +import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  35 +import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  36 +import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  37 +import org.apache.flink.table.calcite.FlinkPlannerImpl;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  38 +import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  39 +import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  40 +</span>
  41  import com.dtstack.flink.sql.classloader.ClassLoaderManager;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  42 -import com.dtstack.flink.sql.config.CalciteConfig;</span>
  43  import com.dtstack.flink.sql.constrant.ConfigConstrant;
  44  import com.dtstack.flink.sql.enums.ClusterMode;
  45  import com.dtstack.flink.sql.enums.ECacheType;
  46  import com.dtstack.flink.sql.enums.EPluginLoadMode;
  47  import com.dtstack.flink.sql.environment.MyLocalStreamEnvironment;
  48  import com.dtstack.flink.sql.environment.StreamEnvConfigManager;
  49  import com.dtstack.flink.sql.function.FunctionManager;
  50  import com.dtstack.flink.sql.option.OptionParser;
  51  import com.dtstack.flink.sql.option.Options;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  52 -import com.dtstack.flink.sql.parser.CreateFuncParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  53 -import com.dtstack.flink.sql.parser.CreateTmpTableParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  54 -import com.dtstack.flink.sql.parser.InsertSqlParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  55 -import com.dtstack.flink.sql.parser.SqlParser;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  56 -import com.dtstack.flink.sql.parser.SqlTree;</span>
  57  import com.dtstack.flink.sql.side.SideSqlExec;
  58  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  59  import com.dtstack.flink.sql.sink.StreamSinkFactory;
  60  import com.dtstack.flink.sql.source.StreamSourceFactory;
  61  import com.dtstack.flink.sql.table.AbstractSourceTableInfo;
  62  import com.dtstack.flink.sql.table.AbstractTableInfo;
  63  import com.dtstack.flink.sql.table.AbstractTargetTableInfo;
  64  import com.dtstack.flink.sql.util.DtStringUtil;
  65  import com.dtstack.flink.sql.util.PluginUtil;
  66  import com.dtstack.flink.sql.watermarker.WaterMarkerAssigner;
  67  import com.fasterxml.jackson.databind.ObjectMapper;
  68  import com.google.common.base.Preconditions;
  69  import com.google.common.base.Strings;
  70  import com.google.common.collect.Lists;
  71  import com.google.common.collect.Maps;
  72  import com.google.common.collect.Sets;
  73  import org.apache.calcite.sql.SqlInsert;
  74  import org.apache.calcite.sql.SqlNode;
  75  import org.apache.commons.io.Charsets;
  76  import org.apache.commons.lang3.StringUtils;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  77 -import org.apache.flink.api.common.typeinfo.TypeInformation;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  78 -import org.apache.flink.api.java.tuple.Tuple2;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  79 -import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  80 -import org.apache.flink.streaming.api.datastream.DataStream;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  81 -import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  82 -import org.apache.flink.table.api.StreamQueryConfig;</span>

<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  83 -import org.apache.flink.table.api.Table;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  84 -import org.apache.flink.table.api.TableEnvironment;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  85 -import org.apache.flink.table.api.java.StreamTableEnvironment;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  86 -import org.apache.flink.table.sinks.TableSink;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  87 -import org.apache.flink.types.Row;</span>
  88  import org.slf4j.Logger;
  89  import org.slf4j.LoggerFactory;
  90  
  91  import java.io.File;
  92  import java.lang.reflect.InvocationTargetException;
  93  import java.net.URL;
  94  import java.net.URLClassLoader;
  95  import java.net.URLDecoder;
  96  import java.util.Arrays;
  97  import java.util.List;
  98  import java.util.Map;
  99  import java.util.Properties;
 100  import java.util.Set;
 101  
 102  /**
 103   *  任务执行时的流程方法
 104   * Date: 2020/2/17
 105   * Company: www.dtstack.com
 106   * @author maqi
 107   */
 108  public class ExecuteProcessHelper {
 109  
 110      private static final String CLASS_FILE_NAME_FMT = &quot;class_path_%d&quot;;
 111      private static final Logger LOG = LoggerFactory.getLogger(ExecuteProcessHelper.class);
 112      private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
 113  
 114  
 115      public static ParamsInfo parseParams(String[] args) throws Exception {
 116          LOG.info(&quot;------------program params-------------------------&quot;);
 117          Arrays.stream(args).forEach(arg -&gt; LOG.info(&quot;{}&quot;, arg));
 118          LOG.info(&quot;-------------------------------------------&quot;);
 119  
 120          OptionParser optionParser = new OptionParser(args);
 121          Options options = optionParser.getOptions();
 122  
 123          String sql = URLDecoder.decode(options.getSql(), Charsets.UTF_8.name());
 124          String name = options.getName();
 125          String localSqlPluginPath = options.getLocalSqlPluginPath();
 126          String remoteSqlPluginPath = options.getRemoteSqlPluginPath();
 127          String pluginLoadMode = options.getPluginLoadMode();
 128          String deployMode = options.getMode();
 129          String logLevel = options.getLogLevel();
 130  
 131          Preconditions.checkArgument(checkRemoteSqlPluginPath(remoteSqlPluginPath, deployMode, pluginLoadMode),
 132                  &quot;Non-local mode or shipfile deployment mode, remoteSqlPluginPath is required&quot;);
 133          String confProp = URLDecoder.decode(options.getConfProp(), Charsets.UTF_8.toString());
 134          Properties confProperties = PluginUtil.jsonStrToObject(confProp, Properties.class);
 135  
 136          List&lt;URL&gt; jarUrlList = getExternalJarUrls(options.getAddjar());
 137  
 138          return ParamsInfo.builder()
 139                  .setSql(sql)
 140                  .setName(name)
 141                  .setLocalSqlPluginPath(localSqlPluginPath)
 142                  .setRemoteSqlPluginPath(remoteSqlPluginPath)
 143                  .setPluginLoadMode(pluginLoadMode)
 144                  .setDeployMode(deployMode)
 145                  .setConfProp(confProperties)
 146                  .setJarUrlList(jarUrlList)
 147                  .build();
 148  
 149      }
 150  
 151      /**
 152       *   非local模式或者shipfile部署模式，remoteSqlPluginPath必填
 153       * @param remoteSqlPluginPath
 154       * @param deployMode
 155       * @param pluginLoadMode
 156       * @return
 157       */
<abbr title=" 158      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoadMode) {"> 158      public static boolean checkRemoteSqlPluginPath(String remoteSqlPluginPath, String deployMode, String pluginLoa🔵</abbr>
 159          if (StringUtils.isEmpty(remoteSqlPluginPath)) {
 160              return StringUtils.equalsIgnoreCase(pluginLoadMode, EPluginLoadMode.SHIPFILE.name())
 161                      || StringUtils.equalsIgnoreCase(deployMode, ClusterMode.local.name());
 162          }
 163          return true;
 164      }
 165  
 166  
 167      public static StreamExecutionEnvironment getStreamExecution(ParamsInfo paramsInfo) throws Exception {
<abbr title=" 168          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo.getDeployMode());"> 168          StreamExecutionEnvironment env = ExecuteProcessHelper.getStreamExeEnv(paramsInfo.getConfProp(), paramsInfo🔵</abbr>
 169          StreamTableEnvironment tableEnv = StreamTableEnvironment.create(env);
<abbr title=" 170          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.getConfProp());"> 170          StreamQueryConfig streamQueryConfig = StreamEnvConfigManager.getStreamQueryConfig(tableEnv, paramsInfo.get🔵</abbr>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 171 +        // init global flinkPlanner</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 172 +        FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.getTypeFactory());"> 172 +        FlinkPlanner.createFlinkPlanner(tableEnv.getFrameworkConfig(), tableEnv.getPlanner(), tableEnv.getTypeFact🔵</abbr></span>
 173  
 174          SqlParser.setLocalSqlPluginRoot(paramsInfo.getLocalSqlPluginPath());
 175          SqlTree sqlTree = SqlParser.parseSql(paramsInfo.getSql());
 176  
 177          Map&lt;String, AbstractSideTableInfo&gt; sideTableMap = Maps.newHashMap();
 178          Map&lt;String, Table&gt; registerTableCache = Maps.newHashMap();
 179  
 180          //register udf
 181          ExecuteProcessHelper.registerUserDefinedFunction(sqlTree, paramsInfo.getJarUrlList(), tableEnv);
 182          //register table schema
<abbr title=" 183          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSqlPluginPath(),"> 183          Set&lt;URL&gt; classPathSets = ExecuteProcessHelper.registerTable(sqlTree, env, tableEnv, paramsInfo.getLocalSql🔵</abbr>
<abbr title=" 184                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCache);"> 184                  paramsInfo.getRemoteSqlPluginPath(), paramsInfo.getPluginLoadMode(), sideTableMap, registerTableCa🔵</abbr>
 185          // cache classPathSets
 186          ExecuteProcessHelper.registerPluginUrlToCachedFile(env, classPathSets);
 187  
<abbr title=" 188          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, registerTableCache, streamQueryConfig);"> 188          ExecuteProcessHelper.sqlTranslation(paramsInfo.getLocalSqlPluginPath(), tableEnv, sqlTree, sideTableMap, r🔵</abbr>

 189  
 190          if (env instanceof MyLocalStreamEnvironment) {
 191              ((MyLocalStreamEnvironment) env).setClasspaths(ClassLoaderManager.getClassPath());
 192          }
 193          return env;
 194      }
 195  
 196  
 197      public static List&lt;URL&gt; getExternalJarUrls(String addJarListStr) throws java.io.IOException {
 198          List&lt;URL&gt; jarUrlList = Lists.newArrayList();
 199          if (Strings.isNullOrEmpty(addJarListStr)) {
 200              return jarUrlList;
 201          }
 202  
<abbr title=" 203          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name()), List.class);"> 203          List&lt;String&gt; addJarFileList = OBJECT_MAPPER.readValue(URLDecoder.decode(addJarListStr, Charsets.UTF_8.name🔵</abbr>
 204          //Get External jar to load
 205          for (String addJarPath : addJarFileList) {
 206              jarUrlList.add(new File(addJarPath).toURI().toURL());
 207          }
 208          return jarUrlList;
 209      }
 210  
 211      private static void sqlTranslation(String localSqlPluginPath,
 212                                         StreamTableEnvironment tableEnv,
 213                                         SqlTree sqlTree,Map&lt;String, AbstractSideTableInfo&gt; sideTableMap,
 214                                         Map&lt;String, Table&gt; registerTableCache,
 215                                         StreamQueryConfig queryConfig) throws Exception {

 216  
 217          SideSqlExec sideSqlExec = new SideSqlExec();
 218          sideSqlExec.setLocalSqlPluginPath(localSqlPluginPath);
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 219 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 220 +        int scope = 0;</span>
 221          for (CreateTmpTableParser.SqlParserResult result : sqlTree.getTmpSqlList()) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 222 -            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result);"> 222 -            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result)🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 223 +            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result, scope + &quot;&quot;);"> 223 +            sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, result,🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 224 +            scope++;</span>
 225          }
 226  
 227          for (InsertSqlParser.SqlParseResult result : sqlTree.getExecSqlList()) {
 228              if (LOG.isInfoEnabled()) {
 229                  LOG.info(&quot;exe-sql:\n&quot; + result.getExecSql());
 230              }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 231 +</span>
 232              boolean isSide = false;
 233              for (String tableName : result.getTargetTableList()) {
 234                  if (sqlTree.getTmpTableMap().containsKey(tableName)) {
 235                      CreateTmpTableParser.SqlParserResult tmp = sqlTree.getTmpTableMap().get(tableName);
 236                      String realSql = DtStringUtil.replaceIgnoreQuota(result.getExecSql(), &quot;`&quot;, &quot;&quot;);
 237  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 238 -                    SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_LEX_CONFIG).parseStmt();"> 238 -                    SqlNode sqlNode = org.apache.calcite.sql.parser.SqlParser.create(realSql, CalciteConfig.MYSQL_🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 239 +                    FlinkPlannerImpl flinkPlanner = FlinkPlanner.getFlinkPlanner();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 240 +                    SqlNode sqlNode = flinkPlanner.parse(realSql);</span>
 241                      String tmpSql = ((SqlInsert) sqlNode).getSource().toString();
 242                      tmp.setExecSql(tmpSql);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 243 -                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp);"> 243 -                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tm🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 244 +                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tmp, scope + &quot;&quot;);"> 244 +                    sideSqlExec.exec(tmp.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, tm🔵</abbr></span>
 245                  } else {
 246                      for (String sourceTable : result.getSourceTableList()) {
 247                          if (sideTableMap.containsKey(sourceTable)) {
 248                              isSide = true;
 249                              break;
 250                          }
 251                      }
 252                      if (isSide) {
 253                          //sql-dimensional table contains the dimension table of execution
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 254 -                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null);"> 254 -                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryCon🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 255 +                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryConfig, null, null);"> 255 +                        sideSqlExec.exec(result.getExecSql(), sideTableMap, tableEnv, registerTableCache, queryCon🔵</abbr></span>
 256                      } else {
 257                          LOG.info(&quot;----------exec sql without dimension join-----------&quot;);
 258                          LOG.info(&quot;----------real sql exec is--------------------------\n{}&quot;, result.getExecSql());
 259                          FlinkSQLExec.sqlUpdate(tableEnv, result.getExecSql(), queryConfig);

 260                          if (LOG.isInfoEnabled()) {
 261                              LOG.info(&quot;exec sql: &quot; + result.getExecSql());
 262                          }
 263                      }
 264                  }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 265 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 266 +                scope++;</span>
 267              }
 268          }
 269      }
 270  
<abbr title=" 271      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEnv)"> 271      public static void registerUserDefinedFunction(SqlTree sqlTree, List&lt;URL&gt; jarUrlList, TableEnvironment tableEn🔵</abbr>
 272              throws IllegalAccessException, InvocationTargetException {
 273          // udf和tableEnv须由同一个类加载器加载
 274          ClassLoader levelClassLoader = tableEnv.getClass().getClassLoader();
 275          URLClassLoader classLoader = null;
 276          List&lt;CreateFuncParser.SqlParserResult&gt; funcList = sqlTree.getFunctionList();
 277          for (CreateFuncParser.SqlParserResult funcInfo : funcList) {
 278              //classloader
 279              if (classLoader == null) {
 280                  classLoader = ClassLoaderManager.loadExtraJar(jarUrlList, (URLClassLoader) levelClassLoader);
 281              }
<abbr title=" 282              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv, classLoader);"> 282              FunctionManager.registerUDF(funcInfo.getType(), funcInfo.getClassName(), funcInfo.getName(), tableEnv,🔵</abbr>
 283          }
 284      }
 285  
 286      /**
 287       *    向Flink注册源表和结果表，返回执行时插件包的全路径
 288       * @param sqlTree
 289       * @param env
 290       * @param tableEnv
 291       * @param localSqlPluginPath
 292       * @param remoteSqlPluginPath
 293       * @param pluginLoadMode   插件加载模式 classpath or shipfile
 294       * @param sideTableMap
 295       * @param registerTableCache
 296       * @return
 297       * @throws Exception
 298       */
<abbr title=" 299      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment tableEnv, String localSqlPluginPath,"> 299      public static Set&lt;URL&gt; registerTable(SqlTree sqlTree, StreamExecutionEnvironment env, StreamTableEnvironment t🔵</abbr>
<abbr title=" 300                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSideTableInfo&gt; sideTableMap, Map&lt;String, Table&gt; registerTableCache) throws Exception {"> 300                                           String remoteSqlPluginPath, String pluginLoadMode, Map&lt;String, AbstractSi🔵</abbr>
 301          Set&lt;URL&gt; pluginClassPathSets = Sets.newHashSet();
 302          WaterMarkerAssigner waterMarkerAssigner = new WaterMarkerAssigner();
 303          for (AbstractTableInfo tableInfo : sqlTree.getTableInfoMap().values()) {
 304  
 305              if (tableInfo instanceof AbstractSourceTableInfo) {
 306  
 307                  AbstractSourceTableInfo sourceTableInfo = (AbstractSourceTableInfo) tableInfo;
<abbr title=" 308                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPath);"> 308                  Table table = StreamSourceFactory.getStreamSource(sourceTableInfo, env, tableEnv, localSqlPluginPa🔵</abbr>
 309                  tableEnv.registerTable(sourceTableInfo.getAdaptName(), table);
<abbr title=" 310                  //Note --- parameter conversion function can not be used inside a function of the type of polymerization"> 310                  //Note --- parameter conversion function can not be used inside a function of the type of polymeri🔵</abbr>
 311                  //Create table in which the function is arranged only need adaptation sql
 312                  String adaptSql = sourceTableInfo.getAdaptSelectSql();
 313                  Table adaptTable = adaptSql == null ? table : tableEnv.sqlQuery(adaptSql);
 314  
<abbr title=" 315                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchema().getFieldNames());"> 315                  RowTypeInfo typeInfo = new RowTypeInfo(adaptTable.getSchema().getFieldTypes(), adaptTable.getSchem🔵</abbr>
 316                  DataStream adaptStream = tableEnv.toRetractStream(adaptTable, typeInfo)
 317                          .map((Tuple2&lt;Boolean, Row&gt; f0) -&gt; {
 318                              return f0.f1;
 319                          })
 320                          .returns(typeInfo);

 321  
 322                  String fields = String.join(&quot;,&quot;, typeInfo.getFieldNames());
 323  
 324                  if (waterMarkerAssigner.checkNeedAssignWaterMarker(sourceTableInfo)) {
 325                      adaptStream = waterMarkerAssigner.assignWaterMarker(adaptStream, typeInfo, sourceTableInfo);
 326                      fields += &quot;,ROWTIME.ROWTIME&quot;;
 327                  } else {
 328                      fields += &quot;,PROCTIME.PROCTIME&quot;;
 329                  }
 330  
 331                  Table regTable = tableEnv.fromDataStream(adaptStream, fields);
 332                  tableEnv.registerTable(tableInfo.getName(), regTable);
 333                  if (LOG.isInfoEnabled()) {
 334                      LOG.info(&quot;registe table {} success.&quot;, tableInfo.getName());
 335                  }
 336                  registerTableCache.put(tableInfo.getName(), regTable);
 337  
<abbr title=" 338                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractSourceTableInfo.SOURCE_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 338                  URL sourceTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), Abstract🔵</abbr>
 339                  pluginClassPathSets.add(sourceTablePathUrl);
 340              } else if (tableInfo instanceof AbstractTargetTableInfo) {
 341  
<abbr title=" 342                  TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSqlPluginPath);"> 342                  TableSink tableSink = StreamSinkFactory.getTableSink((AbstractTargetTableInfo) tableInfo, localSql🔵</abbr>
 343                  TypeInformation[] flinkTypes = FunctionManager.transformTypes(tableInfo.getFieldClasses());
 344                  tableEnv.registerTableSink(tableInfo.getName(), tableInfo.getFields(), flinkTypes, tableSink);
 345  
<abbr title=" 346                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTargetTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 346                  URL sinkTablePathUrl = PluginUtil.buildSourceAndSinkPathByLoadMode(tableInfo.getType(), AbstractTa🔵</abbr>
 347                  pluginClassPathSets.add(sinkTablePathUrl);
 348              } else if (tableInfo instanceof AbstractSideTableInfo) {
<abbr title=" 349                  String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheType()) ? &quot;all&quot; : &quot;async&quot;;"> 349                  String sideOperator = ECacheType.ALL.name().equals(((AbstractSideTableInfo) tableInfo).getCacheTyp🔵</abbr>
 350                  sideTableMap.put(tableInfo.getName(), (AbstractSideTableInfo) tableInfo);
 351  
<abbr title=" 352                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, AbstractSideTableInfo.TARGET_SUFFIX, localSqlPluginPath, remoteSqlPluginPath, pluginLoadMode);"> 352                  URL sideTablePathUrl = PluginUtil.buildSidePathByLoadMode(tableInfo.getType(), sideOperator, Abstr🔵</abbr>
 353                  pluginClassPathSets.add(sideTablePathUrl);
 354              } else {
 355                  throw new RuntimeException(&quot;not support table type:&quot; + tableInfo.getType());
 356              }
 357          }
 358          return pluginClassPathSets;
 359      }
 360  
 361      /**
 362       *   perjob模式将job依赖的插件包路径存储到cacheFile，在外围将插件包路径传递给jobgraph
 363       * @param env
 364       * @param classPathSet
 365       */
 366      public static void registerPluginUrlToCachedFile(StreamExecutionEnvironment env, Set&lt;URL&gt; classPathSet) {
 367          int i = 0;
 368          for (URL url : classPathSet) {
 369              String classFileName = String.format(CLASS_FILE_NAME_FMT, i);
 370              env.registerCachedFile(url.getPath(), classFileName, true);
 371              i++;
 372          }
 373      }
 374  
<abbr title=" 375      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws Exception {"> 375      public static StreamExecutionEnvironment getStreamExeEnv(Properties confProperties, String deployMode) throws 🔵</abbr>
 376          StreamExecutionEnvironment env = !ClusterMode.local.name().equals(deployMode) ?
 377                  StreamExecutionEnvironment.getExecutionEnvironment() :
 378                  new MyLocalStreamEnvironment();
 379  
 380          StreamEnvConfigManager.streamExecutionEnvironmentConfig(env, confProperties);
 381          return env;
 382      }
 383  












<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 384 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 385 -    public static void setLogLevel(ParamsInfo paramsInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 386 -        String logLevel = paramsInfo.getConfProp().getProperty(ConfigConstrant.LOG_LEVEL_KEY);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 387 -        if(org.apache.commons.lang3.StringUtils.isBlank(logLevel)){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 388 -            return;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 389 -        }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 390 -        ChangeLogLevelProcess logLevelProcess = new ChangeLogLevelProcess();</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 391 -        logLevelProcess.process(logLevel);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 392 -    }</span>
 393  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            