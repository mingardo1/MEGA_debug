<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>347</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    347
                    <a href="346.html">prev</a>
                    <a href="348.html">next</a>
                    <a href="347_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_7b89a5ce3fc5cfad0ee8e27efc1cf00cbfaf38a8_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7b89a5ce3fc5cfad0ee8e27efc1cf00cbfaf38a8:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7b89a5ce3fc5cfad0ee8e27efc1cf00cbfaf38a8^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;7b89a5ce3fc5cfad0ee8e27efc1cf00cbfaf38a8^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;8cb6d5aea72f25034c7f3626ec6ef98783b1bee5:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b], [b]], subset: [[b], [b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
  30 ||||||| GitAnalyzerPlus_base
  31 &lt;&lt;&lt;&lt;&lt;&lt;&lt; OURS
  32 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  33 import com.dtstack.flink.sql.util.RowDataComplete;</span>
  34 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  35 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  36 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  37 import com.dtstack.flink.sql.util.RowDataComplete;</span>
  38 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  39 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  40 import com.google.common.collect.Maps;</span>
  41 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  42 import com.google.common.collect.Maps;</span>
  43 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  44 import org.apache.calcite.sql.JoinType;
  45 import org.apache.commons.collections.map.HashedMap;
  46 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  47 import com.google.common.collect.Maps;
  48 import org.apache.flink.table.dataformat.BaseRow;
  49 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  50 import org.apache.flink.types.Row;
  51 import org.apache.flink.util.Collector;
  52 import org.apache.hadoop.conf.Configuration;
  53 import org.apache.hadoop.hbase.Cell;
  54 import org.apache.hadoop.hbase.CellUtil;
  55 import org.apache.hadoop.hbase.TableName;
  56 import org.apache.hadoop.hbase.client.Connection;
  57 import org.apache.hadoop.hbase.client.ConnectionFactory;
  58 import org.apache.hadoop.hbase.client.Result;
  59 import org.apache.hadoop.hbase.client.ResultScanner;
  60 import org.apache.hadoop.hbase.client.Scan;
  61 import org.apache.hadoop.hbase.client.Table;
  62 import org.apache.hadoop.hbase.util.Bytes;
  63 import org.apache.hadoop.security.UserGroupInformation;
  64 import org.slf4j.Logger;
  65 import org.slf4j.LoggerFactory;
  66 
  67 import java.io.IOException;
  68 
  69 import java.security.PrivilegedAction;
  70 import java.sql.SQLException;
  71 import java.sql.Timestamp;
  72 import java.time.LocalDateTime;
  73 import java.util.Calendar;
  74 import java.util.HashMap;
  75 import java.util.List;
  76 import java.util.Map;
  77 import java.util.concurrent.atomic.AtomicReference;
  78 
  79 public class HbaseAllReqRow extends BaseAllReqRow {
  80 
  81     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  82 
  83     private String tableName;
  84 
  85     private Map&lt;String, String&gt; aliasNameInversion;
  86 
  87     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  88     private Connection conn = null;
  89     private Table table = null;
  90     private ResultScanner resultScanner = null;
  91     private Configuration conf = null;
  92 
<abbr title="  93     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  93     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  94         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  95         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  96 
  97         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  98         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  99         aliasNameInversion = new HashMap&lt;&gt;();
 100         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
 101             aliasNameInversion.put(entry.getValue(), entry.getKey());
 102         }
 103     }
 104 
 105     @Override
 106     public Row fillData(Row input, Object sideInput) {
 107         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
 108         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 109         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 110             Object obj = input.getField(entry.getValue());
<abbr title=" 111             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 111             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
 112 
<abbr title=" 113             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 113             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 114             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 115                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 116             }
 117 
 118             row.setField(entry.getKey(), obj);
 119         }
 120 
 121         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 122             if(sideInputList == null){
 123                 row.setField(entry.getKey(), null);
 124             }else{
 125                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 126                 key = aliasNameInversion.get(key);
 127                 row.setField(entry.getKey(), sideInputList.get(key));
 128             }
 129         }
 130         return row;
 131     }
 132 
 133     @Override
 134     protected void initCache() throws SQLException {
 135         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 136         cacheRef.set(newCache);
 137         loadData(newCache);
 138     }
 139 
 140     @Override
 141     protected void reloadCache() {
 142         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 143         try {
 144             loadData(newCache);
 145         } catch (SQLException e) {
 146             LOG.error(&quot;&quot;, e);
 147         }
 148 
 149         cacheRef.set(newCache);
 150         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 151     }
 152 
 153     @Override
 154     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 155         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 156         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 157             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 158             Object equalObj = input.getField(conValIndex);
 159             if (equalObj == null) {
 160                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 161                     Row data = fillData(input, null);
 162                     RowDataComplete.collectRow(out, data);
 163                 }
 164                 return;
 165             }
 166             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 167         }
 168 
 169         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 170 
 171         Map&lt;String, Object&gt; cacheList = null;
 172 
 173         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 174         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 175         if (hbaseSideTableInfo.isPreRowKey()) {
 176             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 177                 if (entry.getKey().startsWith(rowKeyStr)) {
 178                     cacheList = cacheRef.get().get(entry.getKey());
 179                     Row row = fillData(input, cacheList);
 180                     RowDataComplete.collectRow(out, row);
 181                 }
 182             }
 183         } else {
 184             cacheList = cacheRef.get().get(rowKeyStr);
 185             Row row = fillData(input, cacheList);
 186             RowDataComplete.collectRow(out, row);
 187         }
 188 
 189     }
 190 
 191     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 192         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 193         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 194         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 195         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 196         int loadDataCount = 0;
 197         try {
 198             if (openKerberos) {
 199                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 200                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 201                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 201                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 202                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 203                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 204 
<abbr title=" 205                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 205                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 206                 Configuration finalConf = conf;
 207                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 208                     @Override
 209                     public Connection run() {
 210                         try {
 211                             return ConnectionFactory.createConnection(finalConf);
 212                         } catch (IOException e) {
 213                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 214                             throw new RuntimeException(e);
 215                         }
 216                     }
 217                 });
 218 
 219             } else {
 220                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 221                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 222                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 222                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 223                 conn = ConnectionFactory.createConnection(conf);
 224             }
 225 
 226             table = conn.getTable(TableName.valueOf(tableName));
 227             resultScanner = table.getScanner(new Scan());
 228             for (Result r : resultScanner) {
 229                 Map&lt;String, Object&gt; kv = new HashedMap();
 230                 for (Cell cell : r.listCells()) {
 231                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 232                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 233                     StringBuilder key = new StringBuilder();
 234                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 235                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 235                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 236                     kv.put(aliasNameInversion.get(key.toString()), value);
 237                 }
 238                 loadDataCount++;
 239                 tmpCache.put(new String(r.getRow()), kv);
 240             }
 241         } catch (IOException e) {
 242             throw new RuntimeException(e);
 243         } finally {
 244             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 245             try {
 246                 if (null != conn) {
 247                     conn.close();
 248                 }
 249 
 250                 if (null != table) {
 251                     table.close();
 252                 }
 253 
 254                 if (null != resultScanner) {
 255                     resultScanner.close();
 256                 }
 257             } catch (IOException e) {
 258                 LOG.error(&quot;&quot;, e);
 259             }
 260         }
 261     }
 262 
 263 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  29 import com.dtstack.flink.sql.util.RowDataComplete;
  30 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  31 import com.google.common.collect.Maps;
  32 import org.apache.calcite.sql.JoinType;
  33 import org.apache.commons.collections.map.HashedMap;
  34 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  35 import com.google.common.collect.Maps;
  36 import org.apache.flink.table.dataformat.BaseRow;
  37 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  38 import org.apache.flink.types.Row;
  39 import org.apache.flink.util.Collector;
  40 import org.apache.hadoop.conf.Configuration;
  41 import org.apache.hadoop.hbase.Cell;
  42 import org.apache.hadoop.hbase.CellUtil;
  43 import org.apache.hadoop.hbase.TableName;
  44 import org.apache.hadoop.hbase.client.Connection;
  45 import org.apache.hadoop.hbase.client.ConnectionFactory;
  46 import org.apache.hadoop.hbase.client.Result;
  47 import org.apache.hadoop.hbase.client.ResultScanner;
  48 import org.apache.hadoop.hbase.client.Scan;
  49 import org.apache.hadoop.hbase.client.Table;
  50 import org.apache.hadoop.hbase.util.Bytes;
  51 import org.apache.hadoop.security.UserGroupInformation;
  52 import org.slf4j.Logger;
  53 import org.slf4j.LoggerFactory;
  54 
  55 import java.io.IOException;
  56 
  57 import java.security.PrivilegedAction;
  58 import java.sql.SQLException;
  59 import java.sql.Timestamp;
  60 import java.time.LocalDateTime;
  61 import java.util.Calendar;
  62 import java.util.HashMap;
  63 import java.util.List;
  64 import java.util.Map;
  65 import java.util.concurrent.atomic.AtomicReference;
  66 
  67 public class HbaseAllReqRow extends BaseAllReqRow {
  68 
  69     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  70 
  71     private String tableName;
  72 
  73     private Map&lt;String, String&gt; aliasNameInversion;
  74 
  75     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  76     private Connection conn = null;
  77     private Table table = null;
  78     private ResultScanner resultScanner = null;
  79     private Configuration conf = null;
  80 
<abbr title="  81     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  81     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  82         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  83         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  84 
  85         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  86         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  87         aliasNameInversion = new HashMap&lt;&gt;();
  88         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  89             aliasNameInversion.put(entry.getValue(), entry.getKey());
  90         }
  91     }
  92 
  93     @Override
  94     public Row fillData(Row input, Object sideInput) {
  95         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  96         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  97         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  98             Object obj = input.getField(entry.getValue());
<abbr title="  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  99             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
 100 
<abbr title=" 101             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 101             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
 102             if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {
 103                 obj = Timestamp.valueOf(((LocalDateTime) obj));
 104             }
 105             row.setField(entry.getKey(), obj);
 106         }
 107 
 108         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 109             if(sideInputList == null){
 110                 row.setField(entry.getKey(), null);
 111             }else{
 112                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 113                 key = aliasNameInversion.get(key);
 114                 row.setField(entry.getKey(), sideInputList.get(key));
 115             }
 116         }
 117         return row;
 118     }
 119 
 120     @Override
 121     protected void initCache() throws SQLException {
 122         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 123         cacheRef.set(newCache);
 124         loadData(newCache);
 125     }
 126 
 127     @Override
 128     protected void reloadCache() {
 129         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 130         try {
 131             loadData(newCache);
 132         } catch (SQLException e) {
 133             LOG.error(&quot;&quot;, e);
 134         }
 135 
 136         cacheRef.set(newCache);
 137         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 138     }
 139 
 140     @Override
 141     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 142         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 143         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 144             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 145             Object equalObj = input.getField(conValIndex);
 146             if (equalObj == null) {
 147                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 148                     Row data = fillData(input, null);
 149                     RowDataComplete.collectRow(out, data);
 150                 }
 151                 return;
 152             }
 153             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 154         }
 155 
 156         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 157 
 158         Map&lt;String, Object&gt; cacheList = null;
 159 
 160         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 161         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 162         if (hbaseSideTableInfo.isPreRowKey()) {
 163             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 164                 if (entry.getKey().startsWith(rowKeyStr)) {
 165                     cacheList = cacheRef.get().get(entry.getKey());
 166                     Row row = fillData(input, cacheList);
 167                     RowDataComplete.collectRow(out, row);
 168                 }
 169             }
 170         } else {
 171             cacheList = cacheRef.get().get(rowKeyStr);
 172             Row row = fillData(input, cacheList);
 173             RowDataComplete.collectRow(out, row);
 174         }
 175 
 176     }
 177 
 178     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 179         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 180         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 181         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 182         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 183         int loadDataCount = 0;
 184         try {
 185             if (openKerberos) {
 186                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 187                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 188                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 188                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 189                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 190                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 191 
<abbr title=" 192                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 192                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 193                 Configuration finalConf = conf;
 194                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 195                     @Override
 196                     public Connection run() {
 197                         try {
 198                             return ConnectionFactory.createConnection(finalConf);
 199                         } catch (IOException e) {
 200                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 201                             throw new RuntimeException(e);
 202                         }
 203                     }
 204                 });
 205 
 206             } else {
 207                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 208                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 209                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 209                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 210                 conn = ConnectionFactory.createConnection(conf);
 211             }
 212 
 213             table = conn.getTable(TableName.valueOf(tableName));
 214             resultScanner = table.getScanner(new Scan());
 215             for (Result r : resultScanner) {
 216                 Map&lt;String, Object&gt; kv = new HashedMap();
 217                 for (Cell cell : r.listCells()) {
 218                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 219                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 220                     StringBuilder key = new StringBuilder();
 221                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 222                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 222                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 223                     kv.put(aliasNameInversion.get(key.toString()), value);
 224                 }
 225                 loadDataCount++;
 226                 tmpCache.put(new String(r.getRow()), kv);
 227             }
 228         } catch (IOException e) {
 229             throw new RuntimeException(e);
 230         } finally {
 231             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 232             try {
 233                 if (null != conn) {
 234                     conn.close();
 235                 }
 236 
 237                 if (null != table) {
 238                     table.close();
 239                 }
 240 
 241                 if (null != resultScanner) {
 242                     resultScanner.close();
 243                 }
 244             } catch (IOException e) {
 245                 LOG.error(&quot;&quot;, e);
 246             }
 247         }
 248     }
 249 
 250 }
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  26 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  27 import com.dtstack.flink.sql.util.RowDataComplete;
  28 import com.google.common.collect.Maps;
  29 import java.io.IOException;
  30 import java.security.PrivilegedAction;
  31 import java.sql.SQLException;
  32 import java.sql.Timestamp;
  33 import java.time.LocalDateTime;
  34 import java.util.Calendar;
  35 import java.util.HashMap;
  36 import java.util.List;
  37 import java.util.Map;
  38 import java.util.concurrent.atomic.AtomicReference;
  39 import org.apache.calcite.sql.JoinType;
  40 import org.apache.commons.collections.map.HashedMap;
  41 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  42 import org.apache.flink.table.dataformat.BaseRow;
  43 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  44 import org.apache.flink.types.Row;
  45 import org.apache.flink.util.Collector;
  46 import org.apache.hadoop.conf.Configuration;
  47 import org.apache.hadoop.hbase.Cell;
  48 import org.apache.hadoop.hbase.CellUtil;
  49 import org.apache.hadoop.hbase.TableName;
  50 import org.apache.hadoop.hbase.client.Connection;
  51 import org.apache.hadoop.hbase.client.ConnectionFactory;
  52 import org.apache.hadoop.hbase.client.Result;
  53 import org.apache.hadoop.hbase.client.ResultScanner;
  54 import org.apache.hadoop.hbase.client.Scan;
  55 import org.apache.hadoop.hbase.client.Table;
  56 import org.apache.hadoop.hbase.util.Bytes;
  57 import org.apache.hadoop.security.UserGroupInformation;
  58 import org.slf4j.Logger;
  59 import org.slf4j.LoggerFactory;
  60 
  61 
  62 public class HbaseAllReqRow extends BaseAllReqRow {
  63     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  64 
  65     private String tableName;
  66 
  67     private Map&lt;String, String&gt; aliasNameInversion;
  68 
  69     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  70 
  71     private Connection conn = null;
  72 
  73     private Table table = null;
  74 
  75     private ResultScanner resultScanner = null;
  76 
  77     private Configuration conf = null;
  78 
<abbr title="  79     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  79     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, A🔵</abbr>
  80         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  81         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  82         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  83         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  84         aliasNameInversion = new HashMap&lt;&gt;();
  85         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  86             aliasNameInversion.put(entry.getValue(), entry.getKey());
  87         }
  88     }
  89 
  90     @Override
  91     public Row fillData(Row input, Object sideInput) {
  92         Map&lt;String, Object&gt; sideInputList = ((Map&lt;String, Object&gt;) (sideInput));
  93         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  94         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
  95             Object obj = input.getField(entry.getValue());
<abbr title="  96             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  96             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr>
<abbr title="  97             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  97             //Type information for indicating event or processing time. However, it behaves like a regula🔵</abbr>
  98             if ((obj instanceof LocalDateTime) &amp;&amp; isTimeIndicatorTypeInfo) {
  99                 obj = Timestamp.valueOf(((LocalDateTime) (obj)));
 100             }
 101             row.setField(entry.getKey(), obj);
 102         }
 103         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 104             if (sideInputList == null) {
 105                 row.setField(entry.getKey(), null);
 106             } else {
 107                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 108                 key = aliasNameInversion.get(key);
 109                 row.setField(entry.getKey(), sideInputList.get(key));
 110             }
 111         }
 112         return row;
 113     }
 114 
 115     @Override
 116     protected void initCache() throws SQLException {
 117         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 118         cacheRef.set(newCache);
 119         loadData(newCache);
 120     }
 121 
 122     @Override
 123     protected void reloadCache() {
 124         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 125         try {
 126             loadData(newCache);
 127         } catch (SQLException e) {
 128             LOG.error(&quot;&quot;, e);
 129         }
 130 
 131         cacheRef.set(newCache);
 132         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 133     }
 134 
 135     @Override
 136     public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {
 137         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 138         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 139             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 140             Object equalObj = input.getField(conValIndex);
 141             if (equalObj == null) {
 142                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 143                     Row data = fillData(input, null);
 144                     RowDataComplete.collectRow(out, data);
 145                 }
 146                 return;
 147             }
 148             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 149         }
 150         String rowKeyStr = ((HbaseAllSideInfo) (sideInfo)).getRowKeyBuilder().getRowKey(refData);
 151         Map&lt;String, Object&gt; cacheList = null;
 152         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 153         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 154         if (hbaseSideTableInfo.isPreRowKey()) {
 155             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 156                 if (entry.getKey().startsWith(rowKeyStr)) {
 157                     cacheList = cacheRef.get().get(entry.getKey());
 158                     Row row = fillData(input, cacheList);
 159                     RowDataComplete.collectRow(out, row);
 160                 }
 161             }
 162         } else {
 163             cacheList = cacheRef.get().get(rowKeyStr);
 164             Row row = fillData(input, cacheList);
 165             RowDataComplete.collectRow(out, row);
 166         }
 167     }
 168 
 169     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 170         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 171         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo) (sideInfo)).getColRefType();
 172         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 173         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 174         int loadDataCount = 0;
 175         try {
 176             if (openKerberos) {
 177                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 178                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 179                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 179                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 180                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 181                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
<abbr title=" 182                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 182                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prin🔵</abbr>
 183                 Configuration finalConf = conf;
 184                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 185                     @Override
 186                     public Connection run() {
 187                         try {
 188                             return ConnectionFactory.createConnection(finalConf);
 189                         } catch (IOException e) {
 190                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 191                             throw new RuntimeException(e);
 192                         }
 193                     }
 194                 });
 195             } else {
 196                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 197                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 198                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 198                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(🔵</abbr>
 199                 conn = ConnectionFactory.createConnection(conf);
 200             }
 201             table = conn.getTable(TableName.valueOf(tableName));
 202             resultScanner = table.getScanner(new Scan());
 203             for (Result r : resultScanner) {
 204                 Map&lt;String, Object&gt; kv = new HashedMap();
 205                 for (Cell cell : r.listCells()) {
 206                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 207                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 208                     StringBuilder key = new StringBuilder();
 209                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 210                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 210                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.t🔵</abbr>
 211                     kv.put(aliasNameInversion.get(key.toString()), value);
 212                 }
 213                 loadDataCount++;
 214                 tmpCache.put(new String(r.getRow()), kv);
 215             }
 216         } catch (IOException e) {
 217             throw new RuntimeException(e);
 218         } finally {
 219             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 220             try {
 221                 if (null != conn) {
 222                     conn.close();
 223                 }
 224                 if (null != table) {
 225                     table.close();
 226                 }
 227                 if (null != resultScanner) {
 228                     resultScanner.close();
 229                 }
 230             } catch (IOException e) {
 231                 LOG.error(&quot;&quot;, e);
 232             }
 233         }
 234     }
 235 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;

  29  import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  30 -import com.google.common.collect.Maps;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  31 +import com.dtstack.flink.sql.util.RowDataComplete;</span>
  32  import org.apache.calcite.sql.JoinType;
  33  import org.apache.commons.collections.map.HashedMap;
  34  import org.apache.flink.api.java.typeutils.RowTypeInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  35 -import org.apache.flink.table.runtime.types.CRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  36 +import com.google.common.collect.Maps;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  37 +import org.apache.flink.table.dataformat.BaseRow;</span>
  38  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  39  import org.apache.flink.types.Row;
  40  import org.apache.flink.util.Collector;
  41  import org.apache.hadoop.conf.Configuration;
  42  import org.apache.hadoop.hbase.Cell;
  43  import org.apache.hadoop.hbase.CellUtil;
  44  import org.apache.hadoop.hbase.TableName;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  45 -import org.apache.hadoop.hbase.client.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  46 +import org.apache.hadoop.hbase.client.Connection;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  47 +import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  48 +import org.apache.hadoop.hbase.client.Result;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  49 +import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import org.apache.hadoop.hbase.client.Scan;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import org.apache.hadoop.hbase.client.Table;</span>
  52  import org.apache.hadoop.hbase.util.Bytes;
  53  import org.apache.hadoop.security.UserGroupInformation;
  54  import org.slf4j.Logger;
  55  import org.slf4j.LoggerFactory;
  56  
  57  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +</span>
  59  import java.security.PrivilegedAction;
  60  import java.sql.SQLException;
  61  import java.sql.Timestamp;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  62 +import java.time.LocalDateTime;</span>
  63  import java.util.Calendar;
  64  import java.util.HashMap;
  65  import java.util.List;
  66  import java.util.Map;
  67  import java.util.concurrent.atomic.AtomicReference;
  68  
  69  public class HbaseAllReqRow extends BaseAllReqRow {
  70  
  71      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  72  
  73      private String tableName;
  74  
  75      private Map&lt;String, String&gt; aliasNameInversion;
  76  
  77      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  78      private Connection conn = null;
  79      private Table table = null;
  80      private ResultScanner resultScanner = null;
  81      private Configuration conf = null;
  82  
<abbr title="  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  84          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  85          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  86  
  87          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  88          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  89          aliasNameInversion = new HashMap&lt;&gt;();
  90          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  91              aliasNameInversion.put(entry.getValue(), entry.getKey());
  92          }
  93      }
  94  
  95      @Override
  96      public Row fillData(Row input, Object sideInput) {
  97          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  98          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  99          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 100              Object obj = input.getField(entry.getValue());
<abbr title=" 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 102  
<abbr title=" 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 104 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 105 -                //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 106 -                obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());</span>


<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 107 -            }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 108 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 109 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 110 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 111 +            }</span>
 112              row.setField(entry.getKey(), obj);
 113          }
 114  
 115          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 116              if(sideInputList == null){
 117                  row.setField(entry.getKey(), null);
 118              }else{
 119                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 120 +                key = aliasNameInversion.get(key);</span>
 121                  row.setField(entry.getKey(), sideInputList.get(key));
 122              }
 123          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 124 -</span>
 125          return row;
 126      }
 127  
 128      @Override
 129      protected void initCache() throws SQLException {
 130          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 131          cacheRef.set(newCache);
 132          loadData(newCache);
 133      }
 134  
 135      @Override
 136      protected void reloadCache() {
 137          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 138          try {
 139              loadData(newCache);
 140          } catch (SQLException e) {
 141              LOG.error(&quot;&quot;, e);
 142          }
 143  
 144          cacheRef.set(newCache);
 145          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 146      }
 147  
 148      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 149 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 150 +    public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {</span>
 151          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 152          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 153              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 154 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 155 +            Object equalObj = input.getField(conValIndex);</span>
 156              if (equalObj == null) {
 157                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 158 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 159 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 160 +                    Row data = fillData(input, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 161 +                    RowDataComplete.collectRow(out, data);</span>
 162                  }
 163                  return;
 164              }
 165              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 166          }
 167  
 168          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 169  
 170          Map&lt;String, Object&gt; cacheList = null;
 171  
 172          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 173          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 174          if (hbaseSideTableInfo.isPreRowKey()) {
 175              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 176                  if (entry.getKey().startsWith(rowKeyStr)) {
 177                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 178 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 179 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 180 +                    Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 181 +                    RowDataComplete.collectRow(out, row);</span>
 182                  }
 183              }
 184          } else {
 185              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 186 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 187 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 188 +            Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 189 +            RowDataComplete.collectRow(out, row);</span>
 190          }
 191  
 192      }
 193  
 194      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 195          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 196          Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 197          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 198          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 199          int loadDataCount = 0;
 200          try {
 201              if (openKerberos) {
 202                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 203                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 204                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 205                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 206                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 207  
<abbr title=" 208                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 208                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 209                  Configuration finalConf = conf;
 210                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 211                      @Override
 212                      public Connection run() {
 213                          try {
 214                              return ConnectionFactory.createConnection(finalConf);
 215                          } catch (IOException e) {
 216                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 217                              throw new RuntimeException(e);
 218                          }
 219                      }
 220                  });
 221  
 222              } else {
 223                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 224                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 225                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 226                  conn = ConnectionFactory.createConnection(conf);
 227              }
 228  
 229              table = conn.getTable(TableName.valueOf(tableName));
 230              resultScanner = table.getScanner(new Scan());
 231              for (Result r : resultScanner) {
 232                  Map&lt;String, Object&gt; kv = new HashedMap();
 233                  for (Cell cell : r.listCells()) {
 234                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 235                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 236                      StringBuilder key = new StringBuilder();
 237                      key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 238                      Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 238                      Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()🔵</abbr>
 239                      kv.put(aliasNameInversion.get(key.toString()), value);
 240                  }
 241                  loadDataCount++;
 242                  tmpCache.put(new String(r.getRow()), kv);
 243              }
 244          } catch (IOException e) {
 245              throw new RuntimeException(e);
 246          } finally {
 247              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 248              try {
 249                  if (null != conn) {
 250                      conn.close();
 251                  }
 252  
 253                  if (null != table) {
 254                      table.close();
 255                  }
 256  
 257                  if (null != resultScanner) {
 258                      resultScanner.close();
 259                  }
 260              } catch (IOException e) {
 261                  LOG.error(&quot;&quot;, e);
 262              }
 263          }
 264      }
 265  
 266  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28  import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  29 +import com.dtstack.flink.sql.util.RowDataComplete;</span>
  30  import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  31  import com.google.common.collect.Maps;

  32  import org.apache.calcite.sql.JoinType;
  33  import org.apache.commons.collections.map.HashedMap;
  34  import org.apache.flink.api.java.typeutils.RowTypeInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  35 -import org.apache.flink.table.runtime.types.CRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  36 +import com.google.common.collect.Maps;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  37 +import org.apache.flink.table.dataformat.BaseRow;</span>
  38  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  39  import org.apache.flink.types.Row;
  40  import org.apache.flink.util.Collector;
  41  import org.apache.hadoop.conf.Configuration;
  42  import org.apache.hadoop.hbase.Cell;
  43  import org.apache.hadoop.hbase.CellUtil;
  44  import org.apache.hadoop.hbase.TableName;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  45 -import org.apache.hadoop.hbase.client.*;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  46 +import org.apache.hadoop.hbase.client.Connection;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  47 +import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  48 +import org.apache.hadoop.hbase.client.Result;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  49 +import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import org.apache.hadoop.hbase.client.Scan;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import org.apache.hadoop.hbase.client.Table;</span>
  52  import org.apache.hadoop.hbase.util.Bytes;
  53  import org.apache.hadoop.security.UserGroupInformation;
  54  import org.slf4j.Logger;
  55  import org.slf4j.LoggerFactory;
  56  
  57  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +</span>
  59  import java.security.PrivilegedAction;
  60  import java.sql.SQLException;
  61  import java.sql.Timestamp;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  62 +import java.time.LocalDateTime;</span>
  63  import java.util.Calendar;
  64  import java.util.HashMap;
  65  import java.util.List;
  66  import java.util.Map;
  67  import java.util.concurrent.atomic.AtomicReference;
  68  
  69  public class HbaseAllReqRow extends BaseAllReqRow {
  70  
  71      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  72  
  73      private String tableName;
  74  
  75      private Map&lt;String, String&gt; aliasNameInversion;
  76  
  77      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  78      private Connection conn = null;
  79      private Table table = null;
  80      private ResultScanner resultScanner = null;
  81      private Configuration conf = null;
  82  
<abbr title="  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  83      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSi🔵</abbr>
  84          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  85          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  86  
  87          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  88          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  89          aliasNameInversion = new HashMap&lt;&gt;();
  90          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  91              aliasNameInversion.put(entry.getValue(), entry.getKey());
  92          }
  93      }
  94  
  95      @Override
  96      public Row fillData(Row input, Object sideInput) {
  97          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  98          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  99          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 100              Object obj = input.getField(entry.getValue());
<abbr title=" 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 101              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 102  
<abbr title=" 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 103              //Type information for indicating event or processing time. However, it behaves like a regular SQL tim🔵</abbr>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 104 -            if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 105 -                //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 106 -                obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 107 +            if (obj instanceof LocalDateTime &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 108 +                obj = Timestamp.valueOf(((LocalDateTime) obj));</span>
 109              }
 110  



 111              row.setField(entry.getKey(), obj);
 112          }
 113  
 114          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 115              if(sideInputList == null){
 116                  row.setField(entry.getKey(), null);
 117              }else{
 118                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 119 +                key = aliasNameInversion.get(key);</span>
 120                  row.setField(entry.getKey(), sideInputList.get(key));
 121              }
 122          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 123 -</span>
 124          return row;
 125      }
 126  
 127      @Override
 128      protected void initCache() throws SQLException {
 129          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 130          cacheRef.set(newCache);
 131          loadData(newCache);
 132      }
 133  
 134      @Override
 135      protected void reloadCache() {
 136          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 137          try {
 138              loadData(newCache);
 139          } catch (SQLException e) {
 140              LOG.error(&quot;&quot;, e);
 141          }
 142  
 143          cacheRef.set(newCache);
 144          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 145      }
 146  
 147      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 148 -    public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 149 +    public void flatMap(Row input, Collector&lt;BaseRow&gt; out) throws Exception {</span>
 150          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 151          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 152              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 153 -            Object equalObj = input.row().getField(conValIndex);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 154 +            Object equalObj = input.getField(conValIndex);</span>
 155              if (equalObj == null) {
 156                  if (sideInfo.getJoinType() == JoinType.LEFT) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 157 -                    Row data = fillData(input.row(), null);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 158 -                    out.collect(new CRow(data, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 159 +                    Row data = fillData(input, null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 160 +                    RowDataComplete.collectRow(out, data);</span>
 161                  }
 162                  return;
 163              }
 164              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 165          }
 166  
 167          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 168  
 169          Map&lt;String, Object&gt; cacheList = null;
 170  
 171          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 172          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 173          if (hbaseSideTableInfo.isPreRowKey()) {
 174              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 175                  if (entry.getKey().startsWith(rowKeyStr)) {
 176                      cacheList = cacheRef.get().get(entry.getKey());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 177 -                    Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 178 -                    out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 179 +                    Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 180 +                    RowDataComplete.collectRow(out, row);</span>
 181                  }
 182              }
 183          } else {
 184              cacheList = cacheRef.get().get(rowKeyStr);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 185 -            Row row = fillData(input.row(), cacheList);</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 186 -            out.collect(new CRow(row, input.change()));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 187 +            Row row = fillData(input, cacheList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 188 +            RowDataComplete.collectRow(out, row);</span>
 189          }
 190  
 191      }
 192  
 193      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 194          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 195          Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 196          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 197          boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 198          int loadDataCount = 0;
 199          try {
 200              if (openKerberos) {
 201                  conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 202                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 203                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 204                  String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 205                  String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 206  
<abbr title=" 207                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 207                  UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, ke🔵</abbr>
 208                  Configuration finalConf = conf;
 209                  conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 210                      @Override
 211                      public Connection run() {
 212                          try {
 213                              return ConnectionFactory.createConnection(finalConf);
 214                          } catch (IOException e) {
 215                              LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 216                              throw new RuntimeException(e);
 217                          }
 218                      }
 219                  });
 220  
 221              } else {
 222                  conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 223                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
 224                  conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());
 225                  conn = ConnectionFactory.createConnection(conf);
 226              }
 227  
 228              table = conn.getTable(TableName.valueOf(tableName));
 229              resultScanner = table.getScanner(new Scan());
 230              for (Result r : resultScanner) {
 231                  Map&lt;String, Object&gt; kv = new HashedMap();
 232                  for (Cell cell : r.listCells()) {
 233                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 234                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 235                      StringBuilder key = new StringBuilder();
 236                      key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 237                      Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 237                      Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()🔵</abbr>
 238                      kv.put(aliasNameInversion.get(key.toString()), value);
 239                  }
 240                  loadDataCount++;
 241                  tmpCache.put(new String(r.getRow()), kv);
 242              }
 243          } catch (IOException e) {
 244              throw new RuntimeException(e);
 245          } finally {
 246              LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 247              try {
 248                  if (null != conn) {
 249                      conn.close();
 250                  }
 251  
 252                  if (null != table) {
 253                      table.close();
 254                  }
 255  
 256                  if (null != resultScanner) {
 257                      resultScanner.close();
 258                  }
 259              } catch (IOException e) {
 260                  LOG.error(&quot;&quot;, e);
 261              }
 262          }
 263      }
 264  
 265  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            