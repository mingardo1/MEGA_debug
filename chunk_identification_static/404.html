<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>404</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    404
                    <a href="403.html">prev</a>
                    <a href="405.html">next</a>
                    <a href="404_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_79c38d3c3186879c6d2f3fedd038be6e77ef3b40_rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;79c38d3c3186879c6d2f3fedd038be6e77ef3b40:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;79c38d3c3186879c6d2f3fedd038be6e77ef3b40^1:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;79c38d3c3186879c6d2f3fedd038be6e77ef3b40^2:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;19d27b4360c0ec7e7da465cf964780cc5dcf0c67:rdb/rdb-side/src/main/java/com/dtstack/flink/sql/side/rdb/all/AbstractRdbAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[bj]], subset: [[bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.configuration.Configuration;
  23 import org.apache.flink.table.runtime.types.CRow;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 import org.apache.flink.util.Collector;
  27 
  28 
  29 import com.dtstack.flink.sql.side.BaseAllReqRow;
  30 import com.dtstack.flink.sql.side.BaseSideInfo;
  31 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33 import com.google.common.collect.Lists;
  34 import com.google.common.collect.Maps;
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.CollectionUtils;
  37 import org.apache.commons.lang3.StringUtils;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 import java.util.List;
  48 import java.util.Map;
  49 import java.util.Objects;
  50 import java.util.Calendar;
  51 import java.util.concurrent.atomic.AtomicReference;
  52 import java.util.stream.Collectors;
  53 
  54 /**
  55  * side operator with cache for all(period reload)
  56  * Date: 2018/11/26
  57  * Company: www.dtstack.com
  58  *
  59  * @author maqi
  60  */
  61 
  62 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  63 
  64     private static final long serialVersionUID = 2098635140857937718L;
  65 
  66     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  67 
  68     private static final int CONN_RETRY_NUM = 3;
  69 
  70     private static final int DEFAULT_FETCH_SIZE = 1000;
  71 
  72     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73 
  74     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  75         super(sideInfo);
  76     }
  77 
  78     @Override
  79     public void open(Configuration parameters) throws Exception {
  80         super.open(parameters);
  81         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  82         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  83     }
  84 
  85 
  86     @Override
  87     protected void initCache() throws SQLException {
  88         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  89         cacheRef.set(newCache);
  90         loadData(newCache);
  91     }
  92 
  93     @Override
  94     protected void reloadCache() {
  95         //reload cacheRef and replace to old cacheRef
  96         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  97         try {
  98             loadData(newCache);
  99         } catch (SQLException e) {
 100             throw new RuntimeException(e);
 101         }
 102         cacheRef.set(newCache);
 103         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 104     }
 105 
 106     @Override
 107     public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {
 108         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 109         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 110                 .map(value.row()::getField)
 111                 .filter(Objects::nonNull)
 112                 .collect(Collectors.toCollection(ArrayList::new));
 113 
 114         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 115             out.collect(new CRow(fillData(value.row(), null), value.change()));
 116             return;
 117         }
 118 
 119         String cacheKey = inputParams.stream()
 120                 .map(Object::toString)
 121                 .collect(Collectors.joining(&quot;_&quot;));
 122 
 123         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 124         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 125             out.collect(new CRow(fillData(value.row(), null), value.change()));
 126         } else if (!CollectionUtils.isEmpty(cacheList)) {
 127             cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));
 128         }
 129 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
 130 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 131         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));"> 131         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change()ðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 132     }</span>
 133 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 134 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 135         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 136 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 137     }
 138 
 139     @Override
 140     public Row fillData(Row input, Object sideInput) {
 141         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 142         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 143 
 144         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 145             // origin value
 146             Object obj = input.getField(entry.getValue());
<abbr title=" 147             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 147             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),ðŸ”µ</abbr>
 148             row.setField(entry.getKey(), obj);
 149         }
 150 
 151         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 152             if (cacheInfo == null) {
 153                 row.setField(entry.getKey(), null);
 154             } else {
 155                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 156             }
 157 
 158         }
 159         return row;
 160     }
 161 
 162     /**
 163      * covert flink time attribute.Type information for indicating event or processing time.
 164      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 165      *
 166      * @param entry
 167      * @param obj
 168      * @return
 169      */
 170     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 171         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 172         if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 173             obj = ((Timestamp) obj).getTime();
 174         }
 175         return obj;
 176     }
 177 
 178     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 179         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 180         Connection connection = null;
 181 
 182         try {
 183             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 184                 try {
<abbr title=" 185                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 185                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswoðŸ”µ</abbr>
 186                     break;
 187                 } catch (Exception e) {
 188                     if (i == CONN_RETRY_NUM - 1) {
 189                         throw new RuntimeException(&quot;&quot;, e);
 190                     }
 191                     try {
<abbr title=" 192                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 192                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserNðŸ”µ</abbr>
 193                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 194                         Thread.sleep(5 * 1000);
 195                     } catch (InterruptedException e1) {
 196                         LOG.error(&quot;&quot;, e1);
 197                     }
 198                 }
 199             }
 200             queryAndFillData(tmpCache, connection);
 201         } catch (Exception e) {
 202             LOG.error(&quot;&quot;, e);
 203             throw new SQLException(e);
 204         } finally {
 205             if (connection != null) {
 206                 connection.close();
 207             }
 208         }
 209     }
 210 
<abbr title=" 211     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 211     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)ðŸ”µ</abbr>
 212         //load data from table
 213         String sql = sideInfo.getSqlCondition();
 214         Statement statement = connection.createStatement();
 215         statement.setFetchSize(getFetchSize());
 216         ResultSet resultSet = statement.executeQuery(sql);
 217 
 218         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 219         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 220         while (resultSet.next()) {
 221             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 222             for (String fieldName : sideFieldNames) {
 223                 Object object = resultSet.getObject(fieldName.trim());
 224                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 225                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 226                 oneRow.put(fieldName.trim(), object);
 227             }
 228 
 229             String cacheKey = sideInfo.getEqualFieldList().stream()
 230                     .map(oneRow::get)
 231                     .map(Object::toString)
 232                     .collect(Collectors.joining(&quot;_&quot;));
 233 
 234             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 235                     .add(oneRow);
 236         }
 237     }
 238 
 239     public int getFetchSize() {
 240         return DEFAULT_FETCH_SIZE;
 241     }
 242 
 243     /**
 244      * get jdbc connection
 245      *
 246      * @param dbURL
 247      * @param userName
 248      * @param password
 249      * @return
 250      */
 251     public abstract Connection getConn(String dbURL, String userName, String password);
 252 
 253 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 package com.dtstack.flink.sql.side.rdb.all;
  20 
  21 import org.apache.flink.api.common.typeinfo.TypeInformation;
  22 import org.apache.flink.configuration.Configuration;
  23 import org.apache.flink.table.runtime.types.CRow;
  24 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25 import org.apache.flink.types.Row;
  26 import org.apache.flink.util.Collector;
  27 
  28 
  29 import com.dtstack.flink.sql.side.BaseAllReqRow;
  30 import com.dtstack.flink.sql.side.BaseSideInfo;
  31 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33 import com.google.common.collect.Lists;
  34 import com.google.common.collect.Maps;
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.CollectionUtils;
  37 import org.apache.commons.lang3.StringUtils;
  38 import org.slf4j.Logger;
  39 import org.slf4j.LoggerFactory;
  40 
  41 import java.sql.Connection;
  42 import java.sql.ResultSet;
  43 import java.sql.SQLException;
  44 import java.sql.Statement;
  45 import java.sql.Timestamp;
  46 import java.util.ArrayList;
  47 import java.util.List;
  48 import java.util.Map;
  49 import java.util.Objects;
  50 import java.util.Calendar;
  51 import java.util.concurrent.atomic.AtomicReference;
  52 import java.util.stream.Collectors;
  53 
  54 /**
  55  * side operator with cache for all(period reload)
  56  * Date: 2018/11/26
  57  * Company: www.dtstack.com
  58  *
  59  * @author maqi
  60  */
  61 
  62 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  63 
  64     private static final long serialVersionUID = 2098635140857937718L;
  65 
  66     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  67 
  68     private static final int CONN_RETRY_NUM = 3;
  69 
  70     private static final int DEFAULT_FETCH_SIZE = 1000;
  71 
  72     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  73 
  74     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  75         super(sideInfo);
  76     }
  77 
  78     @Override
  79     public void open(Configuration parameters) throws Exception {
  80         super.open(parameters);
  81         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  82         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  83     }
  84 
  85 
  86     @Override
  87     protected void initCache() throws SQLException {
  88         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  89         cacheRef.set(newCache);
  90         loadData(newCache);
  91     }
  92 
  93     @Override
  94     protected void reloadCache() {
  95         //reload cacheRef and replace to old cacheRef
  96         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  97         try {
  98             loadData(newCache);
  99         } catch (SQLException e) {
 100             throw new RuntimeException(e);
 101         }
 102         cacheRef.set(newCache);
 103         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 104     }
 105 
 106     @Override
 107     public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {
 108         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 109         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 110                 .map(value.row()::getField)
 111                 .filter(Objects::nonNull)
 112                 .collect(Collectors.toCollection(ArrayList::new));
 113 
 114         if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 115             out.collect(new CRow(fillData(value.row(), null), value.change()));
 116             return;
 117         }
 118 
 119         String cacheKey = inputParams.stream()
 120                 .map(Object::toString)
 121                 .collect(Collectors.joining(&quot;_&quot;));
 122 
 123         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 124         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 125             out.collect(new CRow(fillData(value.row(), null), value.change()));
 126         } else if (!CollectionUtils.isEmpty(cacheList)) {
 127             cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));
 128         }
 129 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
 130 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 131 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 132         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));"> 132         cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change()ðŸ”µ</abbr></span>
 133 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 134 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 135         cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
 136 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 137     }
 138 
 139     @Override
 140     public Row fillData(Row input, Object sideInput) {
 141         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 142         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 143 
 144         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 145             // origin value
 146             Object obj = input.getField(entry.getValue());
<abbr title=" 147             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 147             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),ðŸ”µ</abbr>
 148             row.setField(entry.getKey(), obj);
 149         }
 150 
 151         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 152             if (cacheInfo == null) {
 153                 row.setField(entry.getKey(), null);
 154             } else {
 155                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 156             }
 157 
 158         }
 159         return row;
 160     }
 161 
 162     /**
 163      * covert flink time attribute.Type information for indicating event or processing time.
 164      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 165      *
 166      * @param entry
 167      * @param obj
 168      * @return
 169      */
 170     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 171         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 172         if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 173             obj = ((Timestamp) obj).getTime();
 174         }
 175         return obj;
 176     }
 177 
 178     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 179         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 180         Connection connection = null;
 181 
 182         try {
 183             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 184                 try {
<abbr title=" 185                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 185                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswoðŸ”µ</abbr>
 186                     break;
 187                 } catch (Exception e) {
 188                     if (i == CONN_RETRY_NUM - 1) {
 189                         throw new RuntimeException(&quot;&quot;, e);
 190                     }
 191                     try {
<abbr title=" 192                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 192                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserNðŸ”µ</abbr>
 193                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 194                         Thread.sleep(5 * 1000);
 195                     } catch (InterruptedException e1) {
 196                         LOG.error(&quot;&quot;, e1);
 197                     }
 198                 }
 199             }
 200             queryAndFillData(tmpCache, connection);
 201         } catch (Exception e) {
 202             LOG.error(&quot;&quot;, e);
 203             throw new SQLException(e);
 204         } finally {
 205             if (connection != null) {
 206                 connection.close();
 207             }
 208         }
 209     }
 210 
<abbr title=" 211     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 211     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)ðŸ”µ</abbr>
 212         //load data from table
 213         String sql = sideInfo.getSqlCondition();
 214         Statement statement = connection.createStatement();
 215         statement.setFetchSize(getFetchSize());
 216         ResultSet resultSet = statement.executeQuery(sql);
 217 
 218         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 219         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 220         while (resultSet.next()) {
 221             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 222             for (String fieldName : sideFieldNames) {
 223                 Object object = resultSet.getObject(fieldName.trim());
 224                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 225                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 226                 oneRow.put(fieldName.trim(), object);
 227             }
 228 
 229             String cacheKey = sideInfo.getEqualFieldList().stream()
 230                     .map(oneRow::get)
 231                     .map(Object::toString)
 232                     .collect(Collectors.joining(&quot;_&quot;));
 233 
 234             tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 235                     .add(oneRow);
 236         }
 237     }
 238 
 239     public int getFetchSize() {
 240         return DEFAULT_FETCH_SIZE;
 241     }
 242 
 243     /**
 244      * get jdbc connection
 245      *
 246      * @param dbURL
 247      * @param userName
 248      * @param password
 249      * @return
 250      */
 251     public abstract Connection getConn(String dbURL, String userName, String password);
 252 
 253 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.rdb.all;
  19 
  20 import com.dtstack.flink.sql.side.BaseAllReqRow;
  21 import com.dtstack.flink.sql.side.BaseSideInfo;
  22 import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  23 import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  24 import com.google.common.collect.Lists;
  25 import com.google.common.collect.Maps;
  26 import java.sql.Connection;
  27 import java.sql.ResultSet;
  28 import java.sql.SQLException;
  29 import java.sql.Statement;
  30 import java.sql.Timestamp;
  31 import java.util.ArrayList;
  32 import java.util.Calendar;
  33 import java.util.List;
  34 import java.util.Map;
  35 import java.util.Objects;
  36 import java.util.concurrent.atomic.AtomicReference;
  37 import java.util.stream.Collectors;
  38 import org.apache.calcite.sql.JoinType;
  39 import org.apache.commons.collections.CollectionUtils;
  40 import org.apache.commons.lang3.StringUtils;
  41 import org.apache.flink.api.common.typeinfo.TypeInformation;
  42 import org.apache.flink.configuration.Configuration;
  43 import org.apache.flink.table.runtime.types.CRow;
  44 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  45 import org.apache.flink.types.Row;
  46 import org.apache.flink.util.Collector;
  47 import org.slf4j.Logger;
  48 import org.slf4j.LoggerFactory;
  49 
  50 
  51 /**
  52  * side operator with cache for all(period reload)
  53  * Date: 2018/11/26
  54  * Company: www.dtstack.com
  55  *
  56  * @author maqi
  57  */
  58 public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  59     private static final long serialVersionUID = 2098635140857937718L;
  60 
  61     private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  62 
  63     private static final int CONN_RETRY_NUM = 3;
  64 
  65     private static final int DEFAULT_FETCH_SIZE = 1000;
  66 
  67     private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  68 
  69     public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  70         super(sideInfo);
  71     }
  72 
  73     @Override
  74     public void open(Configuration parameters) throws Exception {
  75         super.open(parameters);
  76         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  77         LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  78     }
  79 
  80     @Override
  81     protected void initCache() throws SQLException {
  82         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  83         cacheRef.set(newCache);
  84         loadData(newCache);
  85     }
  86 
  87     @Override
  88     protected void reloadCache() {
  89         // reload cacheRef and replace to old cacheRef
  90         Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  91         try {
  92             loadData(newCache);
  93         } catch (SQLException e) {
  94             throw new RuntimeException(e);
  95         }
  96         cacheRef.set(newCache);
  97         LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
  98     }
  99 
 100     @Override
 101     public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {
 102         List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
<abbr title=" 103         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.row()::getField).filter(Objects::nonNull).collect(Collectors.toCollection(ArrayList::new));"> 103         ArrayList&lt;Object&gt; inputParams = equalValIndex.stream().map(value.row()::getField).filter(Objects:ðŸ”µ</abbr>
 104         if ((inputParams.size() != equalValIndex.size()) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 105             out.collect(new CRow(fillData(value.row(), null), value.change()));
 106             return;
 107         }
 108         String cacheKey = inputParams.stream().map(Object::toString).collect(Collectors.joining(&quot;_&quot;));
 109         List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 110         if (CollectionUtils.isEmpty(cacheList) &amp;&amp; (sideInfo.getJoinType() == JoinType.LEFT)) {
 111             out.collect(new CRow(fillData(value.row(), null), value.change()));
 112         } else if (!CollectionUtils.isEmpty(cacheList)) {
<abbr title=" 113             cacheList.forEach(( one) -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));"> 113             cacheList.forEach(( one) -&gt; out.collect(new CRow(fillData(value.row(), one), value.change()))ðŸ”µ</abbr>
 114         }
 115     }
 116 
 117     @Override
 118     public Row fillData(Row input, Object sideInput) {
 119         Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 120         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 121 
 122         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 123             // origin value
 124             Object obj = input.getField(entry.getValue());
<abbr title=" 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);"> 125             obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(),ðŸ”µ</abbr>
 126             row.setField(entry.getKey(), obj);
 127         }
 128 
 129         for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 130             if (cacheInfo == null) {
 131                 row.setField(entry.getKey(), null);
 132             } else {
 133                 row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 134             }
 135 
 136         }
 137         return row;
 138     }
 139 
 140     /**
 141      * covert flink time attribute.Type information for indicating event or processing time.
 142      * However, it behaves like a regular SQL timestamp but is serialized as Long.
 143      *
 144      * @param entry
 145      *
 146      * @param obj
 147      *
 148      * @return
 149      */
 150     protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 151         boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 152         if ((obj instanceof Timestamp) &amp;&amp; isTimeIndicatorTypeInfo) {
 153             obj = ((Timestamp) (obj)).getTime();
 154         }
 155         return obj;
 156     }
 157 
 158     private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 159         RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 160         Connection connection = null;
 161 
 162         try {
 163             for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 164                 try {
<abbr title=" 165                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());"> 165                     connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPasswoðŸ”µ</abbr>
 166                     break;
 167                 } catch (Exception e) {
 168                     if (i == CONN_RETRY_NUM - 1) {
 169                         throw new RuntimeException(&quot;&quot;, e);
 170                     }
 171                     try {
<abbr title=" 172                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 172                         String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserNðŸ”µ</abbr>
 173                         LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 174                         Thread.sleep(5 * 1000);
 175                     } catch (InterruptedException e1) {
 176                         LOG.error(&quot;&quot;, e1);
 177                     }
 178                 }
 179             }
 180             queryAndFillData(tmpCache, connection);
 181         } catch (Exception e) {
 182             LOG.error(&quot;&quot;, e);
 183             throw new SQLException(e);
 184         } finally {
 185             if (connection != null) {
 186                 connection.close();
 187             }
 188         }
 189     }
 190 
<abbr title=" 191     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 191     private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection)ðŸ”µ</abbr>
 192         // load data from table
 193         String sql = sideInfo.getSqlCondition();
 194         Statement statement = connection.createStatement();
 195         statement.setFetchSize(getFetchSize());
 196         ResultSet resultSet = statement.executeQuery(sql);
 197         String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 198         String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 199         while (resultSet.next()) {
 200             Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 201             for (String fieldName : sideFieldNames) {
 202                 Object object = resultSet.getObject(fieldName.trim());
 203                 int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 204                 object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 205                 oneRow.put(fieldName.trim(), object);
 206             }
<abbr title=" 207             String cacheKey = sideInfo.getEqualFieldList().stream().map(oneRow::get).map(Object::toString).collect(Collectors.joining(&quot;_&quot;));"> 207             String cacheKey = sideInfo.getEqualFieldList().stream().map(oneRow::get).map(Object::toStringðŸ”µ</abbr>
 208             tmpCache.computeIfAbsent(cacheKey, ( key) -&gt; Lists.newArrayList()).add(oneRow);
 209         }
 210     }
 211 
 212     public int getFetchSize() {
 213         return DEFAULT_FETCH_SIZE;
 214     }
 215 
 216     /**
 217      *  get jdbc connection
 218      * @param dbURL
 219      * @param userName
 220      * @param password
 221      * @return
 222      */
 223     public abstract Connection getConn(String dbURL, String userName, String password);
 224 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;
  22  import org.apache.flink.configuration.Configuration;
  23  import org.apache.flink.table.runtime.types.CRow;
  24  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25  import org.apache.flink.types.Row;
  26  import org.apache.flink.util.Collector;
  27  
  28  
  29  import com.dtstack.flink.sql.side.BaseAllReqRow;
  30  import com.dtstack.flink.sql.side.BaseSideInfo;
  31  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33  import com.google.common.collect.Lists;
  34  import com.google.common.collect.Maps;
  35  import org.apache.calcite.sql.JoinType;
  36  import org.apache.commons.collections.CollectionUtils;
  37  import org.apache.commons.lang3.StringUtils;
  38  import org.slf4j.Logger;
  39  import org.slf4j.LoggerFactory;
  40  
  41  import java.sql.Connection;
  42  import java.sql.ResultSet;
  43  import java.sql.SQLException;
  44  import java.sql.Statement;
  45  import java.sql.Timestamp;
  46  import java.util.ArrayList;
  47  import java.util.Calendar;
  48  import java.util.List;
  49  import java.util.Map;


  50  import java.util.concurrent.atomic.AtomicReference;
  51  import java.util.stream.Collectors;
  52  
  53  /**
  54   * side operator with cache for all(period reload)
  55   * Date: 2018/11/26
  56   * Company: www.dtstack.com
  57   *
  58   * @author maqi
  59   */
  60  
  61  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  62  
  63      private static final long serialVersionUID = 2098635140857937718L;
  64  
  65      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  66  
  67      private static final int CONN_RETRY_NUM = 3;
  68  
  69      private static final int DEFAULT_FETCH_SIZE = 1000;
  70  
  71      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  72  
  73      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  74          super(sideInfo);
  75      }
  76  
  77      @Override
  78      public void open(Configuration parameters) throws Exception {
  79          super.open(parameters);
  80          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  81          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  82      }
  83  
  84  
  85      @Override
  86      protected void initCache() throws SQLException {
  87          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  88          cacheRef.set(newCache);
  89          loadData(newCache);
  90      }
  91  
  92      @Override
  93      protected void reloadCache() {
  94          //reload cacheRef and replace to old cacheRef
  95          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  96 -        cacheRef.set(newCache);</span>
  97          try {
  98              loadData(newCache);
  99          } catch (SQLException e) {
 100              throw new RuntimeException(e);
 101          }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 102 +        cacheRef.set(newCache);</span>
 103          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 104      }
 105  
 106      @Override
 107      public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {
 108          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 109          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 110                  .map(value.row()::getField)
 111                  .filter(object -&gt; null != object)

 112                  .collect(Collectors.toCollection(ArrayList::new));
 113  
 114          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 115              out.collect(new CRow(fillData(value.row(), null), value.change()));
 116              return;
 117          }
 118  
 119          String cacheKey = inputParams.stream()
 120                  .map(Object::toString)
 121                  .collect(Collectors.joining(&quot;_&quot;));
 122  
 123          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 124          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 125              out.collect(new CRow(fillData(value.row(), null), value.change()));
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 126 -        }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 127 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 128 -        cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 129 +        } else if (!CollectionUtils.isEmpty(cacheList)) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 130 +            cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 131 +        }</span>
 132      }
 133  
 134      @Override
 135      public Row fillData(Row input, Object sideInput) {
 136          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 137          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 138  
 139          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 140              // origin value
 141              Object obj = input.getField(entry.getValue());
 142              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 143              row.setField(entry.getKey(), obj);
 144          }
 145  
 146          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 147              if (cacheInfo == null) {
 148                  row.setField(entry.getKey(), null);
 149              } else {
 150                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 151              }
 152  
 153          }
 154          return row;
 155      }
 156  
 157      /**
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 158 -     *  covert flink time attribute.Type information for indicating event or processing time.</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 159 -     *  However, it behaves like a regular SQL timestamp but is serialized as Long.</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 160 +     * covert flink time attribute.Type information for indicating event or processing time.</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 161 +     * However, it behaves like a regular SQL timestamp but is serialized as Long.</span>
 162       *
 163       * @param entry
 164       * @param obj
 165       * @return
 166       */
 167      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 168          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 169          if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 170              obj = ((Timestamp) obj).getTime();
 171          }
 172          return obj;
 173      }
 174  
 175      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 176          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 177          Connection connection = null;
 178  
 179          try {
 180              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 181                  try {
 182                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 183                      break;
 184                  } catch (Exception e) {
 185                      if (i == CONN_RETRY_NUM - 1) {
 186                          throw new RuntimeException(&quot;&quot;, e);
 187                      }
 188                      try {
<abbr title=" 189                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 189                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;ðŸ”µ</abbr>
 190                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 191                          Thread.sleep(5 * 1000);
 192                      } catch (InterruptedException e1) {
 193                          LOG.error(&quot;&quot;, e1);
 194                      }
 195                  }
 196              }
 197              queryAndFillData(tmpCache, connection);
 198          } catch (Exception e) {
 199              LOG.error(&quot;&quot;, e);
 200              throw new SQLException(e);
 201          } finally {
 202              if (connection != null) {
 203                  connection.close();
 204              }
 205          }
 206      }
 207  
<abbr title=" 208      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 208      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SðŸ”µ</abbr>
 209          //load data from table
 210          String sql = sideInfo.getSqlCondition();
 211          Statement statement = connection.createStatement();
 212          statement.setFetchSize(getFetchSize());
 213          ResultSet resultSet = statement.executeQuery(sql);
 214  
 215          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 216          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 217          while (resultSet.next()) {
 218              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 219              for (String fieldName : sideFieldNames) {
 220                  Object object = resultSet.getObject(fieldName.trim());
 221                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 222                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 223                  oneRow.put(fieldName.trim(), object);
 224              }
 225  
 226              String cacheKey = sideInfo.getEqualFieldList().stream()
 227                      .map(equalField -&gt; oneRow.get(equalField))

 228                      .map(Object::toString)
 229                      .collect(Collectors.joining(&quot;_&quot;));
 230  
 231              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 232                      .add(oneRow);
 233          }
 234      }
 235  
 236      public int getFetchSize() {
 237          return DEFAULT_FETCH_SIZE;
 238      }
 239  
 240      /**
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 241 -     *  get jdbc connection</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 242 +     * get jdbc connection</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 243 +     *</span>
 244       * @param dbURL
 245       * @param userName
 246       * @param password
 247       * @return
 248       */
 249      public abstract Connection getConn(String dbURL, String userName, String password);
 250  
 251  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  package com.dtstack.flink.sql.side.rdb.all;
  20  
  21  import org.apache.flink.api.common.typeinfo.TypeInformation;
  22  import org.apache.flink.configuration.Configuration;
  23  import org.apache.flink.table.runtime.types.CRow;
  24  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  25  import org.apache.flink.types.Row;
  26  import org.apache.flink.util.Collector;
  27  
  28  
  29  import com.dtstack.flink.sql.side.BaseAllReqRow;
  30  import com.dtstack.flink.sql.side.BaseSideInfo;
  31  import com.dtstack.flink.sql.side.rdb.table.RdbSideTableInfo;
  32  import com.dtstack.flink.sql.side.rdb.util.SwitchUtil;
  33  import com.google.common.collect.Lists;
  34  import com.google.common.collect.Maps;
  35  import org.apache.calcite.sql.JoinType;
  36  import org.apache.commons.collections.CollectionUtils;
  37  import org.apache.commons.lang3.StringUtils;
  38  import org.slf4j.Logger;
  39  import org.slf4j.LoggerFactory;
  40  
  41  import java.sql.Connection;
  42  import java.sql.ResultSet;
  43  import java.sql.SQLException;
  44  import java.sql.Statement;
  45  import java.sql.Timestamp;
  46  import java.util.ArrayList;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  47 -import java.util.Calendar;</span>
  48  import java.util.List;
  49  import java.util.Map;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import java.util.Objects;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  51 +import java.util.Calendar;</span>
  52  import java.util.concurrent.atomic.AtomicReference;
  53  import java.util.stream.Collectors;
  54  
  55  /**
  56   * side operator with cache for all(period reload)
  57   * Date: 2018/11/26
  58   * Company: www.dtstack.com
  59   *
  60   * @author maqi
  61   */
  62  
  63  public abstract class AbstractRdbAllReqRow extends BaseAllReqRow {
  64  
  65      private static final long serialVersionUID = 2098635140857937718L;
  66  
  67      private static final Logger LOG = LoggerFactory.getLogger(AbstractRdbAllReqRow.class);
  68  
  69      private static final int CONN_RETRY_NUM = 3;
  70  
  71      private static final int DEFAULT_FETCH_SIZE = 1000;
  72  
  73      private AtomicReference&lt;Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  74  
  75      public AbstractRdbAllReqRow(BaseSideInfo sideInfo) {
  76          super(sideInfo);
  77      }
  78  
  79      @Override
  80      public void open(Configuration parameters) throws Exception {
  81          super.open(parameters);
  82          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
  83          LOG.info(&quot;rdb dim table config info: {} &quot;, tableInfo.toString());
  84      }
  85  
  86  
  87      @Override
  88      protected void initCache() throws SQLException {
  89          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  90          cacheRef.set(newCache);
  91          loadData(newCache);
  92      }
  93  
  94      @Override
  95      protected void reloadCache() {
  96          //reload cacheRef and replace to old cacheRef
  97          Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; newCache = Maps.newConcurrentMap();
  98          cacheRef.set(newCache);
  99          try {
 100              loadData(newCache);
 101          } catch (SQLException e) {
 102              throw new RuntimeException(e);
 103          }

 104          LOG.info(&quot;----- rdb all cacheRef reload end:{}&quot;, Calendar.getInstance());
 105      }
 106  
 107      @Override
 108      public void flatMap(CRow value, Collector&lt;CRow&gt; out) throws Exception {
 109          List&lt;Integer&gt; equalValIndex = sideInfo.getEqualValIndex();
 110          ArrayList&lt;Object&gt; inputParams = equalValIndex.stream()
 111                  .map(value.row()::getField)
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 112 -                .filter(object -&gt; null != object)</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 113 +                .filter(Objects::nonNull)</span>
 114                  .collect(Collectors.toCollection(ArrayList::new));
 115  
 116          if (inputParams.size() != equalValIndex.size() &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 117              out.collect(new CRow(fillData(value.row(), null), value.change()));
 118              return;
 119          }
 120  
 121          String cacheKey = inputParams.stream()
 122                  .map(Object::toString)
 123                  .collect(Collectors.joining(&quot;_&quot;));
 124  
 125          List&lt;Map&lt;String, Object&gt;&gt; cacheList = cacheRef.get().get(cacheKey);
 126          if (CollectionUtils.isEmpty(cacheList) &amp;&amp; sideInfo.getJoinType() == JoinType.LEFT) {
 127              out.collect(new CRow(fillData(value.row(), null), value.change()));
 128          }
 129  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 130 -        cacheList.stream().forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 131 +        cacheList.forEach(one -&gt; out.collect(new CRow(fillData(value.row(), one), value.change())));</span>


 132      }
 133  
 134      @Override
 135      public Row fillData(Row input, Object sideInput) {
 136          Map&lt;String, Object&gt; cacheInfo = (Map&lt;String, Object&gt;) sideInput;
 137          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 138  
 139          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 140              // origin value
 141              Object obj = input.getField(entry.getValue());
 142              obj = dealTimeAttributeType(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass(), obj);
 143              row.setField(entry.getKey(), obj);
 144          }
 145  
 146          for (Map.Entry&lt;Integer, String&gt; entry : sideInfo.getSideFieldNameIndex().entrySet()) {
 147              if (cacheInfo == null) {
 148                  row.setField(entry.getKey(), null);
 149              } else {
 150                  row.setField(entry.getKey(), cacheInfo.get(entry.getValue()));
 151              }
 152  
 153          }
 154          return row;
 155      }
 156  
 157      /**
 158       *  covert flink time attribute.Type information for indicating event or processing time.
 159       *  However, it behaves like a regular SQL timestamp but is serialized as Long.


 160       *
 161       * @param entry
 162       * @param obj
 163       * @return
 164       */
 165      protected Object dealTimeAttributeType(Class&lt;? extends TypeInformation&gt; entry, Object obj) {
 166          boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(entry);
 167          if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
 168              obj = ((Timestamp) obj).getTime();
 169          }
 170          return obj;
 171      }
 172  
 173      private void loadData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache) throws SQLException {
 174          RdbSideTableInfo tableInfo = (RdbSideTableInfo) sideInfo.getSideTableInfo();
 175          Connection connection = null;
 176  
 177          try {
 178              for (int i = 0; i &lt; CONN_RETRY_NUM; i++) {
 179                  try {
 180                      connection = getConn(tableInfo.getUrl(), tableInfo.getUserName(), tableInfo.getPassword());
 181                      break;
 182                  } catch (Exception e) {
 183                      if (i == CONN_RETRY_NUM - 1) {
 184                          throw new RuntimeException(&quot;&quot;, e);
 185                      }
 186                      try {
<abbr title=" 187                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;,pwd:&quot; + tableInfo.getPassword();"> 187                          String connInfo = &quot;url:&quot; + tableInfo.getUrl() + &quot;;userName:&quot; + tableInfo.getUserName() + &quot;ðŸ”µ</abbr>
 188                          LOG.warn(&quot;get conn fail, wait for 5 sec and try again, connInfo:&quot; + connInfo);
 189                          Thread.sleep(5 * 1000);
 190                      } catch (InterruptedException e1) {
 191                          LOG.error(&quot;&quot;, e1);
 192                      }
 193                  }
 194              }
 195              queryAndFillData(tmpCache, connection);
 196          } catch (Exception e) {
 197              LOG.error(&quot;&quot;, e);
 198              throw new SQLException(e);
 199          } finally {
 200              if (connection != null) {
 201                  connection.close();
 202              }
 203          }
 204      }
 205  
<abbr title=" 206      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SQLException {"> 206      private void queryAndFillData(Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; tmpCache, Connection connection) throws SðŸ”µ</abbr>
 207          //load data from table
 208          String sql = sideInfo.getSqlCondition();
 209          Statement statement = connection.createStatement();
 210          statement.setFetchSize(getFetchSize());
 211          ResultSet resultSet = statement.executeQuery(sql);
 212  
 213          String[] sideFieldNames = StringUtils.split(sideInfo.getSideSelectFields(), &quot;,&quot;);
 214          String[] fields = sideInfo.getSideTableInfo().getFieldTypes();
 215          while (resultSet.next()) {
 216              Map&lt;String, Object&gt; oneRow = Maps.newHashMap();
 217              for (String fieldName : sideFieldNames) {
 218                  Object object = resultSet.getObject(fieldName.trim());
 219                  int fieldIndex = sideInfo.getSideTableInfo().getFieldList().indexOf(fieldName.trim());
 220                  object = SwitchUtil.getTarget(object, fields[fieldIndex]);
 221                  oneRow.put(fieldName.trim(), object);
 222              }
 223  
 224              String cacheKey = sideInfo.getEqualFieldList().stream()
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 225 -                    .map(equalField -&gt; oneRow.get(equalField))</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 226 +                    .map(oneRow::get)</span>
 227                      .map(Object::toString)
 228                      .collect(Collectors.joining(&quot;_&quot;));
 229  
 230              tmpCache.computeIfAbsent(cacheKey, key -&gt; Lists.newArrayList())
 231                      .add(oneRow);
 232          }
 233      }
 234  
 235      public int getFetchSize() {
 236          return DEFAULT_FETCH_SIZE;
 237      }
 238  
 239      /**
 240       *  get jdbc connection


 241       * @param dbURL
 242       * @param userName
 243       * @param password
 244       * @return
 245       */
 246      public abstract Connection getConn(String dbURL, String userName, String password);
 247  
 248  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            