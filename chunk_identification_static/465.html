<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>465</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    465
                    <a href="464.html">prev</a>
                    <a href="466.html">next</a>
                    <a href="465_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_631bffe66cfca86f7bb0f3bc85c1a2fa76b54a1a_hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;631bffe66cfca86f7bb0f3bc85c1a2fa76b54a1a:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;631bffe66cfca86f7bb0f3bc85c1a2fa76b54a1a^1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;631bffe66cfca86f7bb0f3bc85c1a2fa76b54a1a^2:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;33047f6a8f2cee0ed59b9a65e8bf5b7a1f15f8a1:hbase/hbase-side/hbase-all-side/src/main/java/com/dtstack/flink/sql/side/hbase/HbaseAllReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[b]], subset: [[b]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0">  29 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;</span>
  30 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0">  31 import org.apache.calcite.sql.JoinType;</span>
  32 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0">  33 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;</span>
  34 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
  35 import org.apache.calcite.sql.JoinType;
  36 import org.apache.commons.collections.map.HashedMap;
  37 import org.apache.commons.lang.StringUtils;
  38 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  39 import com.google.common.collect.Maps;
  40 import org.apache.flink.table.runtime.types.CRow;
  41 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  42 import org.apache.flink.types.Row;
  43 import org.apache.flink.util.Collector;
  44 import org.apache.hadoop.conf.Configuration;
  45 import org.apache.hadoop.hbase.Cell;
  46 import org.apache.hadoop.hbase.CellUtil;
  47 import org.apache.hadoop.hbase.HBaseConfiguration;
  48 import org.apache.hadoop.hbase.TableName;
  49 import org.apache.hadoop.hbase.client.Connection;
  50 import org.apache.hadoop.hbase.client.ConnectionFactory;
  51 import org.apache.hadoop.hbase.client.Result;
  52 import org.apache.hadoop.hbase.client.ResultScanner;
  53 import org.apache.hadoop.hbase.client.Scan;
  54 import org.apache.hadoop.hbase.client.Table;
  55 import org.apache.hadoop.hbase.util.Bytes;
  56 import org.apache.hadoop.security.UserGroupInformation;
  57 import org.slf4j.Logger;
  58 import org.slf4j.LoggerFactory;
  59 
  60 import java.io.File;
  61 import java.io.IOException;
  62 import java.security.PrivilegedAction;
  63 import java.sql.SQLException;
  64 import java.sql.Timestamp;
  65 import java.util.Calendar;
  66 import java.util.HashMap;
  67 import java.util.List;
  68 import java.util.Map;
  69 import java.util.concurrent.atomic.AtomicReference;
  70 
  71 public class HbaseAllReqRow extends BaseAllReqRow {
  72 
  73     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  74 
  75     private String tableName;
  76 
  77     private Map&lt;String, String&gt; aliasNameInversion;
  78 
  79     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  80     private Connection conn = null;
  81     private Table table = null;
  82     private ResultScanner resultScanner = null;
  83     private Configuration conf = null;
  84 
<abbr title="  85     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  85     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  86         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  87         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  88 
  89         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  90         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  91         aliasNameInversion = new HashMap&lt;&gt;();
  92         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  93             aliasNameInversion.put(entry.getValue(), entry.getKey());
  94         }
  95     }
  96 
  97     @Override
  98     public Row fillData(Row input, Object sideInput) {
  99         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
 100         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 101         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
 102             Object obj = input.getField(entry.getValue());
<abbr title=" 103             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 103             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
 104 
<abbr title=" 105             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 105             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
 106             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 107                 obj = ((Timestamp)obj).getTime();
 108             }
 109             row.setField(entry.getKey(), obj);
 110         }
 111 
 112         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 113             if(sideInputList == null){
 114                 row.setField(entry.getKey(), null);
 115             }else{
 116                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 117                 row.setField(entry.getKey(), sideInputList.get(key));
 118             }
 119         }
 120 
 121         return row;
 122     }
 123 
 124     @Override
 125     protected void initCache() throws SQLException {
 126         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 127         cacheRef.set(newCache);
 128         loadData(newCache);
 129     }
 130 
 131     @Override
 132     protected void reloadCache() {
 133         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 134         try {
 135             loadData(newCache);
 136         } catch (SQLException e) {
 137             LOG.error(&quot;&quot;, e);
 138         }
 139 
 140         cacheRef.set(newCache);
 141         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 142     }
 143 
 144     @Override
 145     public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {
 146         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 147         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 148             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 149             Object equalObj = input.row().getField(conValIndex);
 150             if (equalObj == null) {
 151                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 152                     Row data = fillData(input.row(), null);
 153                     out.collect(new CRow(data, input.change()));
 154                 }
 155                 return;
 156             }
 157             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 158         }
 159 
 160         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 161 
 162         Map&lt;String, Object&gt; cacheList = null;
 163 
 164         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 165         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 166         if (hbaseSideTableInfo.isPreRowKey()) {
 167             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 168                 if (entry.getKey().startsWith(rowKeyStr)) {
 169                     cacheList = cacheRef.get().get(entry.getKey());
 170                     Row row = fillData(input.row(), cacheList);
 171                     out.collect(new CRow(row, input.change()));
 172                 }
 173             }
 174         } else {
 175             cacheList = cacheRef.get().get(rowKeyStr);
 176             Row row = fillData(input.row(), cacheList);
 177             out.collect(new CRow(row, input.change()));
 178         }
 179 
 180     }
 181 
 182     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 183         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 184         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 185         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 186         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 187         int loadDataCount = 0;
 188         try {
 189             if (openKerberos) {
 190                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 191                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 192                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 192                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 193                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 194                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 195 
<abbr title=" 196                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 196                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 197                 Configuration finalConf = conf;
 198                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 199                     @Override
 200                     public Connection run() {
 201                         try {
 202                             return ConnectionFactory.createConnection(finalConf);
 203                         } catch (IOException e) {
 204                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 205                             throw new RuntimeException(e);
 206                         }
 207                     }
 208                 });
 209 
 210             } else {
 211                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 212                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 213                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 213                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 214                 conn = ConnectionFactory.createConnection(conf);
 215             }
 216 
 217             table = conn.getTable(TableName.valueOf(tableName));
 218             resultScanner = table.getScanner(new Scan());
 219             for (Result r : resultScanner) {
 220                 Map&lt;String, Object&gt; kv = new HashedMap();
 221                 for (Cell cell : r.listCells()) {
 222                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 223                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 224                     StringBuilder key = new StringBuilder();
 225                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 226                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 226                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.tðŸ”µ</abbr>
 227                     kv.put(aliasNameInversion.get(key.toString()), value);
 228                 }
 229                 loadDataCount++;
 230                 tmpCache.put(new String(r.getRow()), kv);
 231             }
 232         } catch (IOException e) {
 233             throw new RuntimeException(e);
 234         } finally {
 235             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 236             try {
 237                 if (null != conn) {
 238                     conn.close();
 239                 }
 240 
 241                 if (null != table) {
 242                     table.close();
 243                 }
 244 
 245                 if (null != resultScanner) {
 246                     resultScanner.close();
 247                 }
 248             } catch (IOException e) {
 249                 LOG.error(&quot;&quot;, e);
 250             }
 251         }
 252     }
 253 
 254 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 
  21 package com.dtstack.flink.sql.side.hbase;
  22 
  23 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24 import com.dtstack.flink.sql.side.BaseAllReqRow;
  25 import com.dtstack.flink.sql.side.FieldInfo;
  26 import com.dtstack.flink.sql.side.JoinInfo;
  27 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  28 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  29 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  30 import org.apache.calcite.sql.JoinType;
  31 import org.apache.commons.collections.map.HashedMap;
  32 import org.apache.commons.lang.StringUtils;
  33 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  34 import com.google.common.collect.Maps;
  35 import org.apache.flink.table.runtime.types.CRow;
  36 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  37 import org.apache.flink.types.Row;
  38 import org.apache.flink.util.Collector;
  39 import org.apache.hadoop.conf.Configuration;
  40 import org.apache.hadoop.hbase.Cell;
  41 import org.apache.hadoop.hbase.CellUtil;
  42 import org.apache.hadoop.hbase.HBaseConfiguration;
  43 import org.apache.hadoop.hbase.TableName;
  44 import org.apache.hadoop.hbase.client.Connection;
  45 import org.apache.hadoop.hbase.client.ConnectionFactory;
  46 import org.apache.hadoop.hbase.client.Result;
  47 import org.apache.hadoop.hbase.client.ResultScanner;
  48 import org.apache.hadoop.hbase.client.Scan;
  49 import org.apache.hadoop.hbase.client.Table;
  50 import org.apache.hadoop.hbase.util.Bytes;
  51 import org.apache.hadoop.security.UserGroupInformation;
  52 import org.slf4j.Logger;
  53 import org.slf4j.LoggerFactory;
  54 
  55 import java.io.File;
  56 import java.io.IOException;
  57 import java.security.PrivilegedAction;
  58 import java.sql.SQLException;
  59 import java.sql.Timestamp;
  60 import java.util.Calendar;
  61 import java.util.HashMap;
  62 import java.util.List;
  63 import java.util.Map;
  64 import java.util.concurrent.atomic.AtomicReference;
  65 
  66 public class HbaseAllReqRow extends BaseAllReqRow {
  67 
  68     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  69 
  70     private String tableName;
  71 
  72     private Map&lt;String, String&gt; aliasNameInversion;
  73 
  74     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  75     private Connection conn = null;
  76     private Table table = null;
  77     private ResultScanner resultScanner = null;
  78     private Configuration conf = null;
  79 
<abbr title="  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  81         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  82         tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  83 
  84         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  85         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  86         aliasNameInversion = new HashMap&lt;&gt;();
  87         for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  88             aliasNameInversion.put(entry.getValue(), entry.getKey());
  89         }
  90     }
  91 
  92     @Override
  93     public Row fillData(Row input, Object sideInput) {
  94         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  95         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  96         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  97             Object obj = input.getField(entry.getValue());
<abbr title="  98             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  98             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
  99 
<abbr title=" 100             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long."> 100             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
 101             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 102                 obj = ((Timestamp)obj).getTime();
 103             }
 104             row.setField(entry.getKey(), obj);
 105         }
 106 
 107         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 108             if(sideInputList == null){
 109                 row.setField(entry.getKey(), null);
 110             }else{
 111                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 112                 row.setField(entry.getKey(), sideInputList.get(key));
 113             }
 114         }
 115 
 116         return row;
 117     }
 118 
 119     @Override
 120     protected void initCache() throws SQLException {
 121         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 122         cacheRef.set(newCache);
 123         loadData(newCache);
 124     }
 125 
 126     @Override
 127     protected void reloadCache() {
 128         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 129         try {
 130             loadData(newCache);
 131         } catch (SQLException e) {
 132             LOG.error(&quot;&quot;, e);
 133         }
 134 
 135         cacheRef.set(newCache);
 136         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 137     }
 138 
 139     @Override
 140     public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {
 141         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 142         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 143             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 144             Object equalObj = input.row().getField(conValIndex);
 145             if (equalObj == null) {
 146                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 147                     Row data = fillData(input.row(), null);
 148                     out.collect(new CRow(data, input.change()));
 149                 }
 150                 return;
 151             }
 152             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 153         }
 154 
 155         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 156 
 157         Map&lt;String, Object&gt; cacheList = null;
 158 
 159         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 160         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 161         if (hbaseSideTableInfo.isPreRowKey()) {
 162             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 163                 if (entry.getKey().startsWith(rowKeyStr)) {
 164                     cacheList = cacheRef.get().get(entry.getKey());
 165                     Row row = fillData(input.row(), cacheList);
 166                     out.collect(new CRow(row, input.change()));
 167                 }
 168             }
 169         } else {
 170             cacheList = cacheRef.get().get(rowKeyStr);
 171             Row row = fillData(input.row(), cacheList);
 172             out.collect(new CRow(row, input.change()));
 173         }
 174 
 175     }
 176 
 177     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 178         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 179         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();
 180         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 181         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 182         int loadDataCount = 0;
 183         try {
 184             if (openKerberos) {
 185                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 186                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 187                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 187                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 188                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 189                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
 190 
<abbr title=" 191                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 191                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 192                 Configuration finalConf = conf;
 193                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 194                     @Override
 195                     public Connection run() {
 196                         try {
 197                             return ConnectionFactory.createConnection(finalConf);
 198                         } catch (IOException e) {
 199                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 200                             throw new RuntimeException(e);
 201                         }
 202                     }
 203                 });
 204 
 205             } else {
 206                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 207                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 208                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 208                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 209             conn = ConnectionFactory.createConnection(conf);
 210             }
 211 
 212             table = conn.getTable(TableName.valueOf(tableName));
 213             resultScanner = table.getScanner(new Scan());
 214             for (Result r : resultScanner) {
 215                 Map&lt;String, Object&gt; kv = new HashedMap();
 216                 for (Cell cell : r.listCells()) {
 217                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 218                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 219                     StringBuilder key = new StringBuilder();
 220                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 221                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 221                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.tðŸ”µ</abbr>
 222                     kv.put(aliasNameInversion.get(key.toString()), value);
 223                 }
 224                 loadDataCount++;
 225                 tmpCache.put(new String(r.getRow()), kv);
 226             }
 227         } catch (IOException e) {
 228             throw new RuntimeException(e);
 229         } finally {
 230             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 231             try {
 232                 if (null != conn) {
 233                     conn.close();
 234                 }
 235 
 236                 if (null != table) {
 237                     table.close();
 238                 }
 239 
 240                 if (null != resultScanner) {
 241                     resultScanner.close();
 242                 }
 243             } catch (IOException e) {
 244                 LOG.error(&quot;&quot;, e);
 245             }
 246         }
 247     }
 248 
 249 }
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.hbase;
  19 
  20 import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  21 import com.dtstack.flink.sql.side.BaseAllReqRow;
  22 import com.dtstack.flink.sql.side.FieldInfo;
  23 import com.dtstack.flink.sql.side.JoinInfo;
  24 import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
  25 import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;
  26 import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;
  27 import com.google.common.collect.Maps;
  28 import java.io.File;
  29 import java.io.IOException;
  30 import java.security.PrivilegedAction;
  31 import java.sql.SQLException;
  32 import java.sql.Timestamp;
  33 import java.util.Calendar;
  34 import java.util.HashMap;
  35 import java.util.List;
  36 import java.util.Map;
  37 import java.util.concurrent.atomic.AtomicReference;
  38 import org.apache.calcite.sql.JoinType;
  39 import org.apache.commons.collections.map.HashedMap;
  40 import org.apache.commons.lang.StringUtils;
  41 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  42 import org.apache.flink.table.runtime.types.CRow;
  43 import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  44 import org.apache.flink.types.Row;
  45 import org.apache.flink.util.Collector;
  46 import org.apache.hadoop.conf.Configuration;
  47 import org.apache.hadoop.hbase.Cell;
  48 import org.apache.hadoop.hbase.CellUtil;
  49 import org.apache.hadoop.hbase.HBaseConfiguration;
  50 import org.apache.hadoop.hbase.TableName;
  51 import org.apache.hadoop.hbase.client.Connection;
  52 import org.apache.hadoop.hbase.client.ConnectionFactory;
  53 import org.apache.hadoop.hbase.client.Result;
  54 import org.apache.hadoop.hbase.client.ResultScanner;
  55 import org.apache.hadoop.hbase.client.Scan;
  56 import org.apache.hadoop.hbase.client.Table;
  57 import org.apache.hadoop.hbase.util.Bytes;
  58 import org.apache.hadoop.security.UserGroupInformation;
  59 import org.slf4j.Logger;
  60 import org.slf4j.LoggerFactory;
  61 
  62 
  63 public class HbaseAllReqRow extends BaseAllReqRow {
  64     private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  65 
  66     private String tableName;
  67 
  68     private Map&lt;String, String&gt; aliasNameInversion;
  69 
  70     private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
  71 
  72     private Connection conn = null;
  73 
  74     private Table table = null;
  75 
  76     private ResultScanner resultScanner = null;
  77 
  78     private Configuration conf = null;
  79 
<abbr title="  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  80     public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AðŸ”µ</abbr>
  81         super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  82         tableName = ((HbaseSideTableInfo) (sideTableInfo)).getTableName();
  83         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
  84         Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  85         aliasNameInversion = new HashMap&lt;&gt;();
  86         for (Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()) {
  87             aliasNameInversion.put(entry.getValue(), entry.getKey());
  88         }
  89     }
  90 
  91     @Override
  92     public Row fillData(Row input, Object sideInput) {
  93         Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  94         Row row = new Row(sideInfo.getOutFieldInfoList().size());
  95         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  96             Object obj = input.getField(entry.getValue());
<abbr title="  97             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  97             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRoðŸ”µ</abbr>
  98 
<abbr title="  99             //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  99             //Type information for indicating event or processing time. However, it behaves like a regulaðŸ”µ</abbr>
 100             if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 101                 obj = ((Timestamp)obj).getTime();
 102             }
 103             row.setField(entry.getKey(), obj);
 104         }
 105 
 106         for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 107             if(sideInputList == null){
 108                 row.setField(entry.getKey(), null);
 109             }else{
 110                 String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 111                 row.setField(entry.getKey(), sideInputList.get(key));
 112             }
 113         }
 114 
 115         return row;
 116     }
 117 
 118     @Override
 119     protected void initCache() throws SQLException {
 120         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 121         cacheRef.set(newCache);
 122         loadData(newCache);
 123     }
 124 
 125     @Override
 126     protected void reloadCache() {
 127         Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 128         try {
 129             loadData(newCache);
 130         } catch (SQLException e) {
 131             LOG.error(&quot;&quot;, e);
 132         }
 133 
 134         cacheRef.set(newCache);
 135         LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 136     }
 137 
 138     @Override
 139     public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {
 140         Map&lt;String, Object&gt; refData = Maps.newHashMap();
 141         for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 142             Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 143             Object equalObj = input.row().getField(conValIndex);
 144             if (equalObj == null) {
 145                 if (sideInfo.getJoinType() == JoinType.LEFT) {
 146                     Row data = fillData(input.row(), null);
 147                     out.collect(new CRow(data, input.change()));
 148                 }
 149                 return;
 150             }
 151             refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 152         }
 153 
 154         String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 155 
 156         Map&lt;String, Object&gt; cacheList = null;
 157 
 158         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 159         HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 160         if (hbaseSideTableInfo.isPreRowKey()) {
 161             for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 162                 if (entry.getKey().startsWith(rowKeyStr)) {
 163                     cacheList = cacheRef.get().get(entry.getKey());
 164                     Row row = fillData(input.row(), cacheList);
 165                     out.collect(new CRow(row, input.change()));
 166                 }
 167             }
 168         } else {
 169             cacheList = cacheRef.get().get(rowKeyStr);
 170             Row row = fillData(input.row(), cacheList);
 171             out.collect(new CRow(row, input.change()));
 172         }
 173 
 174     }
 175 
 176     private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 177         AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 178         Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo) (sideInfo)).getColRefType();
 179         HbaseSideTableInfo hbaseSideTableInfo = ((HbaseSideTableInfo) (sideTableInfo));
 180         boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();
 181         int loadDataCount = 0;
 182         try {
 183             if (openKerberos) {
 184                 conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());
 185                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 186                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 186                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 187                 String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());
 188                 String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());
<abbr title=" 189                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 189                 UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, prinðŸ”µ</abbr>
 190                 Configuration finalConf = conf;
 191                 conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {
 192                     @Override
 193                     public Connection run() {
 194                         try {
 195                             return ConnectionFactory.createConnection(finalConf);
 196                         } catch (IOException e) {
 197                             LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);
 198                             throw new RuntimeException(e);
 199                         }
 200                     }
 201                 });
 202             } else {
 203                 conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());
 204                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());
<abbr title=" 205                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());"> 205                 conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent(ðŸ”µ</abbr>
 206                 conn = ConnectionFactory.createConnection(conf);
 207             }
 208             table = conn.getTable(TableName.valueOf(tableName));
 209             resultScanner = table.getScanner(new Scan());
 210             for (Result r : resultScanner) {
 211                 Map&lt;String, Object&gt; kv = new HashedMap();
 212                 for (Cell cell : r.listCells()) {
 213                     String family = Bytes.toString(CellUtil.cloneFamily(cell));
 214                     String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 215                     StringBuilder key = new StringBuilder();
 216                     key.append(family).append(&quot;:&quot;).append(qualifier);
<abbr title=" 217                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 217                     Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.tðŸ”µ</abbr>
 218                     kv.put(aliasNameInversion.get(key.toString()), value);
 219                 }
 220                 loadDataCount++;
 221                 tmpCache.put(new String(r.getRow()), kv);
 222             }
 223         } catch (IOException e) {
 224             throw new RuntimeException(e);
 225         } finally {
 226             LOG.info(&quot;load Data count: {}&quot;, loadDataCount);
 227             try {
 228                 if (null != conn) {
 229                     conn.close();
 230                 }
 231                 if (null != table) {
 232                     table.close();
 233                 }
 234                 if (null != resultScanner) {
 235                     resultScanner.close();
 236                 }
 237             } catch (IOException e) {
 238                 LOG.error(&quot;&quot;, e);
 239             }
 240         }
 241     }
 242 }
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  28 +import com.dtstack.flink.sql.side.hbase.utils.HbaseUtils;</span>
  29  import org.apache.calcite.sql.JoinType;
  30  import org.apache.commons.collections.map.HashedMap;

  31  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  32  import com.google.common.collect.Maps;
  33  import org.apache.flink.table.runtime.types.CRow;
  34  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  35  import org.apache.flink.types.Row;
  36  import org.apache.flink.util.Collector;
  37  import org.apache.hadoop.conf.Configuration;
  38  import org.apache.hadoop.hbase.Cell;
  39  import org.apache.hadoop.hbase.CellUtil;

  40  import org.apache.hadoop.hbase.TableName;
  41  import org.apache.hadoop.hbase.client.Connection;
  42  import org.apache.hadoop.hbase.client.ConnectionFactory;
  43  import org.apache.hadoop.hbase.client.Result;
  44  import org.apache.hadoop.hbase.client.ResultScanner;
  45  import org.apache.hadoop.hbase.client.Scan;
  46  import org.apache.hadoop.hbase.client.Table;
  47  import org.apache.hadoop.hbase.util.Bytes;

  48  import org.slf4j.Logger;
  49  import org.slf4j.LoggerFactory;
  50  

  51  import java.io.IOException;

  52  import java.sql.SQLException;
  53  import java.sql.Timestamp;
  54  import java.util.Calendar;
  55  import java.util.HashMap;
  56  import java.util.List;
  57  import java.util.Map;
  58  import java.util.concurrent.atomic.AtomicReference;
  59  
  60  public class HbaseAllReqRow extends BaseAllReqRow {
  61  
  62      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  63  
  64      private String tableName;
  65  
  66      private Map&lt;String, String&gt; aliasNameInversion;
  67  
  68      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();




  69  
<abbr title="  70      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  70      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  71          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  72          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  73  
  74          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  75          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  76          aliasNameInversion = new HashMap&lt;&gt;();
  77          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  78              aliasNameInversion.put(entry.getValue(), entry.getKey());
  79          }
  80      }
  81  
  82      @Override
  83      public Row fillData(Row input, Object sideInput) {
  84          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  85          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  86          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  87              Object obj = input.getField(entry.getValue());
<abbr title="  88              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  88              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  89  
<abbr title="  90              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  90              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
  91              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
  92                  obj = ((Timestamp)obj).getTime();
  93              }
  94              row.setField(entry.getKey(), obj);
  95          }
  96  
  97          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
  98              if(sideInputList == null){
  99                  row.setField(entry.getKey(), null);
 100              }else{
 101                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 102                  row.setField(entry.getKey(), sideInputList.get(key));
 103              }
 104          }
 105  
 106          return row;
 107      }
 108  
 109      @Override
 110      protected void initCache() throws SQLException {
 111          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 112          cacheRef.set(newCache);
 113          loadData(newCache);
 114      }
 115  
 116      @Override
 117      protected void reloadCache() {
 118          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 119          try {
 120              loadData(newCache);
 121          } catch (SQLException e) {
 122              LOG.error(&quot;&quot;, e);
 123          }
 124  
 125          cacheRef.set(newCache);
 126          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 127      }
 128  
 129      @Override
 130      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {
 131          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 132          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 133              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 134              Object equalObj = input.row().getField(conValIndex);
 135              if (equalObj == null) {
 136                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 137                      Row data = fillData(input.row(), null);
 138                      out.collect(new CRow(data, input.change()));
 139                  }
 140                  return;
 141              }
 142              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 143          }
 144  
 145          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 146  
 147          Map&lt;String, Object&gt; cacheList = null;
 148  
 149          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 150          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 151          if (hbaseSideTableInfo.isPreRowKey()) {
 152              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 153                  if (entry.getKey().startsWith(rowKeyStr)) {
 154                      cacheList = cacheRef.get().get(entry.getKey());
 155                      Row row = fillData(input.row(), cacheList);
 156                      out.collect(new CRow(row, input.change()));
 157                  }
 158              }
 159          } else {
 160              cacheList = cacheRef.get().get(rowKeyStr);
 161              Row row = fillData(input.row(), cacheList);
 162              out.collect(new CRow(row, input.change()));
 163          }
 164  
 165      }
 166  
 167      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 168          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 169 +        Map&lt;String, String&gt; colRefType = ((HbaseAllSideInfo)sideInfo).getColRefType();</span>
 170          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 171          Configuration conf = new Configuration();
 172          conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());
 173          Connection conn = null;
 174          Table table = null;
 175          ResultScanner resultScanner = null;


 176          try {
 177              conn = ConnectionFactory.createConnection(conf);




























 178              table = conn.getTable(TableName.valueOf(tableName));
 179              resultScanner = table.getScanner(new Scan());
 180              for (Result r : resultScanner) {
 181                  Map&lt;String, Object&gt; kv = new HashedMap();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 182 -                for (Cell cell : r.listCells())</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 183 -                {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 184 +                for (Cell cell : r.listCells()) {</span>
 185                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 186                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 187 -                    String value = Bytes.toString(CellUtil.cloneValue(cell));</span>
 188                      StringBuilder key = new StringBuilder();
 189                      key.append(family).append(&quot;:&quot;).append(qualifier);
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 190 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 191 +                    Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()));"> 191 +                    Object value = HbaseUtils.convertByte(CellUtil.cloneValue(cell), colRefType.get(key.toString()ðŸ”µ</abbr></span>
 192                      kv.put(aliasNameInversion.get(key.toString()), value);
 193                  }

 194                  tmpCache.put(new String(r.getRow()), kv);
 195              }
 196          } catch (IOException e) {
 197              LOG.error(&quot;&quot;, e);

 198          } finally {

 199              try {
 200                  if (null != conn &amp;&amp; !conn.isClosed()) {

 201                      conn.close();
 202                  }
 203  
 204                  if (null != table) {
 205                      table.close();
 206                  }
 207  
 208                  if (null != resultScanner) {
 209                      resultScanner.close();
 210                  }
 211              } catch (IOException e) {
 212                  LOG.error(&quot;&quot;, e);
 213              }
 214          }
 215      }

 216  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  
  21  package com.dtstack.flink.sql.side.hbase;
  22  
  23  import com.dtstack.flink.sql.side.AbstractSideTableInfo;
  24  import com.dtstack.flink.sql.side.BaseAllReqRow;
  25  import com.dtstack.flink.sql.side.FieldInfo;
  26  import com.dtstack.flink.sql.side.JoinInfo;
  27  import com.dtstack.flink.sql.side.hbase.table.HbaseSideTableInfo;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  28 +import com.dtstack.flink.sql.side.hbase.utils.HbaseConfigUtils;</span>
  29  import org.apache.calcite.sql.JoinType;
  30  import org.apache.commons.collections.map.HashedMap;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  31 +import org.apache.commons.lang.StringUtils;</span>
  32  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  33  import com.google.common.collect.Maps;
  34  import org.apache.flink.table.runtime.types.CRow;
  35  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  36  import org.apache.flink.types.Row;
  37  import org.apache.flink.util.Collector;
  38  import org.apache.hadoop.conf.Configuration;
  39  import org.apache.hadoop.hbase.Cell;
  40  import org.apache.hadoop.hbase.CellUtil;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  41 +import org.apache.hadoop.hbase.HBaseConfiguration;</span>
  42  import org.apache.hadoop.hbase.TableName;
  43  import org.apache.hadoop.hbase.client.Connection;
  44  import org.apache.hadoop.hbase.client.ConnectionFactory;
  45  import org.apache.hadoop.hbase.client.Result;
  46  import org.apache.hadoop.hbase.client.ResultScanner;
  47  import org.apache.hadoop.hbase.client.Scan;
  48  import org.apache.hadoop.hbase.client.Table;
  49  import org.apache.hadoop.hbase.util.Bytes;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  50 +import org.apache.hadoop.security.UserGroupInformation;</span>
  51  import org.slf4j.Logger;
  52  import org.slf4j.LoggerFactory;
  53  
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  54 +import java.io.File;</span>
  55  import java.io.IOException;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  56 +import java.security.PrivilegedAction;</span>
  57  import java.sql.SQLException;
  58  import java.sql.Timestamp;
  59  import java.util.Calendar;
  60  import java.util.HashMap;
  61  import java.util.List;
  62  import java.util.Map;
  63  import java.util.concurrent.atomic.AtomicReference;
  64  
  65  public class HbaseAllReqRow extends BaseAllReqRow {
  66  
  67      private static final Logger LOG = LoggerFactory.getLogger(HbaseAllReqRow.class);
  68  
  69      private String tableName;
  70  
  71      private Map&lt;String, String&gt; aliasNameInversion;
  72  
  73      private AtomicReference&lt;Map&lt;String, Map&lt;String, Object&gt;&gt;&gt; cacheRef = new AtomicReference&lt;&gt;();
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  74 +    private Connection conn = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  75 +    private Table table = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  76 +    private ResultScanner resultScanner = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  77 +    private Configuration conf = null;</span>
  78  
<abbr title="  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  79      public HbaseAllReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSiðŸ”µ</abbr>
  80          super(new HbaseAllSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  81          tableName = ((HbaseSideTableInfo)sideTableInfo).getTableName();
  82  
  83          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
  84          Map&lt;String, String&gt; aliasNameRef = hbaseSideTableInfo.getAliasNameRef();
  85          aliasNameInversion = new HashMap&lt;&gt;();
  86          for(Map.Entry&lt;String, String&gt; entry : aliasNameRef.entrySet()){
  87              aliasNameInversion.put(entry.getValue(), entry.getKey());
  88          }
  89      }
  90  
  91      @Override
  92      public Row fillData(Row input, Object sideInput) {
  93          Map&lt;String, Object&gt; sideInputList = (Map&lt;String, Object&gt;) sideInput;
  94          Row row = new Row(sideInfo.getOutFieldInfoList().size());
  95          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()){
  96              Object obj = input.getField(entry.getValue());
<abbr title="  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());">  97              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfoðŸ”µ</abbr>
  98  
<abbr title="  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL timestamp but is serialized as Long.">  99              //Type information for indicating event or processing time. However, it behaves like a regular SQL timðŸ”µ</abbr>
 100              if(obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo){
 101                  obj = ((Timestamp)obj).getTime();
 102              }
 103              row.setField(entry.getKey(), obj);
 104          }
 105  
 106          for(Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()){
 107              if(sideInputList == null){
 108                  row.setField(entry.getKey(), null);
 109              }else{
 110                  String key = sideInfo.getSideFieldNameIndex().get(entry.getKey());
 111                  row.setField(entry.getKey(), sideInputList.get(key));
 112              }
 113          }
 114  
 115          return row;
 116      }
 117  
 118      @Override
 119      protected void initCache() throws SQLException {
 120          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 121          cacheRef.set(newCache);
 122          loadData(newCache);
 123      }
 124  
 125      @Override
 126      protected void reloadCache() {
 127          Map&lt;String, Map&lt;String, Object&gt;&gt; newCache = Maps.newConcurrentMap();
 128          try {
 129              loadData(newCache);
 130          } catch (SQLException e) {
 131              LOG.error(&quot;&quot;, e);
 132          }
 133  
 134          cacheRef.set(newCache);
 135          LOG.info(&quot;----- HBase all cacheRef reload end:{}&quot;, Calendar.getInstance());
 136      }
 137  
 138      @Override
 139      public void flatMap(CRow input, Collector&lt;CRow&gt; out) throws Exception {
 140          Map&lt;String, Object&gt; refData = Maps.newHashMap();
 141          for (int i = 0; i &lt; sideInfo.getEqualValIndex().size(); i++) {
 142              Integer conValIndex = sideInfo.getEqualValIndex().get(i);
 143              Object equalObj = input.row().getField(conValIndex);
 144              if (equalObj == null) {
 145                  if (sideInfo.getJoinType() == JoinType.LEFT) {
 146                      Row data = fillData(input.row(), null);
 147                      out.collect(new CRow(data, input.change()));
 148                  }
 149                  return;
 150              }
 151              refData.put(sideInfo.getEqualFieldList().get(i), equalObj);
 152          }
 153  
 154          String rowKeyStr = ((HbaseAllSideInfo) sideInfo).getRowKeyBuilder().getRowKey(refData);
 155  
 156          Map&lt;String, Object&gt; cacheList = null;
 157  
 158          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();
 159          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
 160          if (hbaseSideTableInfo.isPreRowKey()) {
 161              for (Map.Entry&lt;String, Map&lt;String, Object&gt;&gt; entry : cacheRef.get().entrySet()) {
 162                  if (entry.getKey().startsWith(rowKeyStr)) {
 163                      cacheList = cacheRef.get().get(entry.getKey());
 164                      Row row = fillData(input.row(), cacheList);
 165                      out.collect(new CRow(row, input.change()));
 166                  }
 167              }
 168          } else {
 169              cacheList = cacheRef.get().get(rowKeyStr);
 170              Row row = fillData(input.row(), cacheList);
 171              out.collect(new CRow(row, input.change()));
 172          }
 173  
 174      }
 175  
 176      private void loadData(Map&lt;String, Map&lt;String, Object&gt;&gt; tmpCache) throws SQLException {
 177          AbstractSideTableInfo sideTableInfo = sideInfo.getSideTableInfo();

 178          HbaseSideTableInfo hbaseSideTableInfo = (HbaseSideTableInfo) sideTableInfo;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 179 -        Configuration conf = new Configuration();</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 180 -        conf.set(&quot;hbase.zookeeper.quorum&quot;, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 181 -        Connection conn = null;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 182 -        Table table = null;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 183 -        ResultScanner resultScanner = null;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 184 +        boolean openKerberos = hbaseSideTableInfo.isKerberosAuthEnable();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 185 +        int loadDataCount = 0;</span>
 186          try {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 187 -            conn = ConnectionFactory.createConnection(conf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 188 +            if (openKerberos) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 189 +                conf = HbaseConfigUtils.getHadoopConfiguration(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 190 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 191 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 192 +                String principal = HbaseConfigUtils.getPrincipal(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 193 +                String keytab = HbaseConfigUtils.getKeytab(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 194 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 195 +                UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keytab);"> 195 +                UserGroupInformation userGroupInformation = HbaseConfigUtils.loginAndReturnUGI(conf, principal, keðŸ”µ</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 196 +                Configuration finalConf = conf;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 197 +                conn = userGroupInformation.doAs(new PrivilegedAction&lt;Connection&gt;() {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 198 +                    @Override</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 199 +                    public Connection run() {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 200 +                        try {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 201 +                            return ConnectionFactory.createConnection(finalConf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 202 +                        } catch (IOException e) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 203 +                            LOG.error(&quot;Get connection fail with config:{}&quot;, finalConf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 204 +                            throw new RuntimeException(e);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 205 +                        }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 206 +                    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 207 +                });</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 208 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 209 +            } else {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 210 +                conf = HbaseConfigUtils.getConfig(hbaseSideTableInfo.getHbaseConfig());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 211 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_QUORUM, hbaseSideTableInfo.getHost());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 212 +                conf.set(HbaseConfigUtils.KEY_HBASE_ZOOKEEPER_ZNODE_QUORUM, hbaseSideTableInfo.getParent());</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 213 +                conn = ConnectionFactory.createConnection(conf);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 214 +            }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 215 +</span>
 216              table = conn.getTable(TableName.valueOf(tableName));
 217              resultScanner = table.getScanner(new Scan());
 218              for (Result r : resultScanner) {
 219                  Map&lt;String, Object&gt; kv = new HashedMap();
 220                  for (Cell cell : r.listCells())
 221                  {

 222                      String family = Bytes.toString(CellUtil.cloneFamily(cell));
 223                      String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));
 224                      String value = Bytes.toString(CellUtil.cloneValue(cell));
 225                      StringBuilder key = new StringBuilder();
 226                      key.append(family).append(&quot;:&quot;).append(qualifier);
 227  

 228                      kv.put(aliasNameInversion.get(key.toString()), value);
 229                  }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 230 +                loadDataCount++;</span>
 231                  tmpCache.put(new String(r.getRow()), kv);
 232              }
 233          } catch (IOException e) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 234 -            LOG.error(&quot;&quot;, e);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 235 +            throw new RuntimeException(e);</span>
 236          } finally {
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 237 +            LOG.info(&quot;load Data count: {}&quot;, loadDataCount);</span>
 238              try {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 239 -                if (null != conn &amp;&amp; !conn.isClosed()) {</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 240 +                if (null != conn) {</span>
 241                      conn.close();
 242                  }
 243  
 244                  if (null != table) {
 245                      table.close();
 246                  }
 247  
 248                  if (null != resultScanner) {
 249                      resultScanner.close();
 250                  }
 251              } catch (IOException e) {
 252                  LOG.error(&quot;&quot;, e);
 253              }
 254          }
 255      }
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 256 +</span>
 257  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            