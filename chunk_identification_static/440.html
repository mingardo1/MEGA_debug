<!DOCTYPE html>
    <html lang="en">
              <head>
                <meta charset="utf-8">
                <title>440</title>
                    <style>
                        #top {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        #bottom {
                            height: 48vh;
                            overflow-y: auto;
                        }
                        abbr {
                          /* Here is the delay */
                          transition-delay:0s;
                        }
                    </style>
              </head>
              <body>
                <span style="height: 4vh">
                    440
                    <a href="439.html">prev</a>
                    <a href="441.html">next</a>
                    <a href="440_chunks.html">chunks</a>
                    <a href="index.html">index</a>
                    DTStack/flinkStreamSQL_5553ee5c6410a412ab4ed61d9499805adee8995a_cassandra/cassandra-side/cassandra-async-side/src/main/java/com/dtstack/flink/sql/side/cassandra/CassandraAsyncReqRow.java
                    <textarea rows=1 onclick='navigator.clipboard.writeText(this.value)'>cd C:\studies\se\mega\git-analyzer-plus\notebooks\debug
del /Q *
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a:cassandra/cassandra-side/cassandra-async-side/src/main/java/com/dtstack/flink/sql/side/cassandra/CassandraAsyncReqRow.java&quot; &gt; committed.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a^1:cassandra/cassandra-side/cassandra-async-side/src/main/java/com/dtstack/flink/sql/side/cassandra/CassandraAsyncReqRow.java&quot; &gt; ours.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;5553ee5c6410a412ab4ed61d9499805adee8995a^2:cassandra/cassandra-side/cassandra-async-side/src/main/java/com/dtstack/flink/sql/side/cassandra/CassandraAsyncReqRow.java&quot; &gt; theirs.java
git -C C:\studies\se\mega\project-dirs\projects_Java_desc-stars-1000\DTStack\flinkStreamSQL show &quot;e0a10435dcb243a911c0405daebc6aa667d5119d:cassandra/cassandra-side/cassandra-async-side/src/main/java/com/dtstack/flink/sql/side/cassandra/CassandraAsyncReqRow.java&quot; &gt; base.java
copy ours.java 1ours.java
copy ours.java 2ours.java
copy theirs.java 1theirs.java
copy theirs.java 2theirs.java
copy base.java 1base.java
copy base.java 2base.java
&quot;C:\Program Files\Java\jdk1.8.0_241\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\jFSTMerge\build\libs\jFSTMerge-all.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\1theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\jfstmerge.java --show-base
&quot;C:\Program Files\Eclipse Adoptium\jdk-17.0.11.9-hotspot\bin\java.exe&quot; -Dfile.encoding=UTF-8 -jar &quot;C:\studies\se\spork\target\spork-0.5.0-SNAPSHOT.jar&quot; C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2ours.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2base.java C:\studies\se\mega\git-analyzer-plus\notebooks\debug\2theirs.java -o C:\studies\se\mega\git-analyzer-plus\notebooks\debug\spork.java
del /Q 1*.java
del /Q 2*.java
del /Q jfstmerge.java.merge
</textarea>
                    {strict: [[bj]], subset: [[bj]]}
                </span>
                <div id="top">

                    <table>
                        <tr>
                            <th>line based (standard git)</th>
                            <th>jfstmerge</th>
                            <th>spork</th>
                        </tr>
                        <tr>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.side.cassandra;
  21 
  22 import com.datastax.driver.core.*;
  23 import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;
  24 import com.datastax.driver.core.policies.RetryPolicy;
  25 import com.dtstack.flink.sql.enums.ECacheContentType;
  26 import com.dtstack.flink.sql.side.*;
  27 import com.dtstack.flink.sql.side.cache.CacheObj;
  28 import com.dtstack.flink.sql.side.cassandra.table.CassandraSideTableInfo;
  29 import com.dtstack.flink.sql.util.RowDataComplete;
  30 import com.google.common.base.Function;
  31 import com.google.common.collect.Lists;
  32 import com.google.common.util.concurrent.AsyncFunction;
  33 import com.google.common.util.concurrent.FutureCallback;
  34 import com.google.common.util.concurrent.Futures;
  35 import com.google.common.util.concurrent.ListenableFuture;
  36 import org.apache.commons.lang3.StringUtils;
  37 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  38 import org.apache.flink.configuration.Configuration;
  39 import org.apache.flink.streaming.api.functions.async.ResultFuture;
  40 import org.apache.flink.table.dataformat.BaseRow;
  41 import org.apache.flink.types.Row;
  42 import org.slf4j.Logger;
  43 import org.slf4j.LoggerFactory;
  44 
  45 import java.net.InetAddress;
  46 import java.util.ArrayList;
  47 import java.util.Collections;
  48 import java.util.List;
  49 import java.util.Map;
  50 import java.util.TimeZone;
  51 
  52 /**
  53  * Reason:
  54  * Date: 2018/11/22
  55  *
  56  * @author xuqianjin
  57  */
  58 public class CassandraAsyncReqRow extends BaseAsyncReqRow {
  59 
  60     private static final long serialVersionUID = 6631584128079864735L;
  61 
  62     private static final Logger LOG = LoggerFactory.getLogger(CassandraAsyncReqRow.class);
  63 
  64     private static final TimeZone LOCAL_TZ = TimeZone.getDefault();
  65 
  66     private final static int DEFAULT_VERTX_EVENT_LOOP_POOL_SIZE = 10;
  67 
  68     private final static int DEFAULT_VERTX_WORKER_POOL_SIZE = 20;
  69 
  70     private final static int DEFAULT_MAX_DB_CONN_POOL_SIZE = 20;
  71 
  72     private transient Cluster cluster;
  73     private transient ListenableFuture session;
  74     private transient CassandraSideTableInfo cassandraSideTableInfo;
  75 
<abbr title="  76     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  76     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoL🔵</abbr>
<abbr title="  77         super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));">  77         super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outF🔵</abbr>
  78     }
  79 
  80 
  81     @Override
  82     public void open(Configuration parameters) throws Exception {
  83         super.open(parameters);
  84         cassandraSideTableInfo = (CassandraSideTableInfo) sideInfo.getSideTableInfo();
  85         connCassandraDB(cassandraSideTableInfo);
  86     }
  87 
  88     private void connCassandraDB(CassandraSideTableInfo tableInfo) {
  89         try {
  90             if (session == null) {
  91                 QueryOptions queryOptions = new QueryOptions();
  92                 //The default consistency level for queries: ConsistencyLevel.TWO.
  93                 queryOptions.setConsistencyLevel(ConsistencyLevel.QUORUM);
<abbr title="  94                 Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo.getMaxRequestsPerConnection();">  94                 Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : 🔵</abbr>
<abbr title="  95                 Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.getCoreConnectionsPerHost();">  95                 Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tabl🔵</abbr>
<abbr title="  96                 Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.getMaxConnectionsPerHost();">  96                 Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : ta🔵</abbr>
<abbr title="  97                 Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQueueSize();">  97                 Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQue🔵</abbr>
<abbr title="  98                 Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTimeoutMillis();">  98                 Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.🔵</abbr>
<abbr title="  99                 Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.getConnectTimeoutMillis();">  99                 Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tabl🔵</abbr>
<abbr title=" 100                 Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTimeoutMillis();"> 100                 Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.🔵</abbr>
 101                 Integer cassandraPort = 0;
 102                 String address = tableInfo.getAddress();
 103                 String userName = tableInfo.getUserName();
 104                 String password = tableInfo.getPassword();
 105                 String database = tableInfo.getDatabase();
 106 
 107                 ArrayList serversList = new ArrayList();
 108                 //Read timeout or connection timeout Settings
 109                 SocketOptions so = new SocketOptions()
 110                         .setReadTimeoutMillis(readTimeoutMillis)
 111                         .setConnectTimeoutMillis(connectTimeoutMillis);
 112 
 113                 //The cluster USES hostdistance.local in the same machine room
 114                 //Hostdistance. REMOTE is used for different machine rooms
 115                 //Ignore use HostDistance. IGNORED
 116                 PoolingOptions poolingOptions = new PoolingOptions()
 117                         //Each connection allows a maximum of 64 concurrent requests
 118                         .setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnection)
 119                         //Have at least two connections to each machine in the cluster
 120                         .setCoreConnectionsPerHost(HostDistance.LOCAL, coreConnectionsPerHost)
 121                         //There are up to eight connections to each machine in the cluster
 122                         .setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnectionsPerHost)
 123                         .setMaxQueueSize(maxQueueSize)
 124                         .setPoolTimeoutMillis(poolTimeoutMillis);
 125                 //重试策略
 126                 RetryPolicy retryPolicy = DowngradingConsistencyRetryPolicy.INSTANCE;
 127 
 128                 for (String server : StringUtils.split(address, &quot;,&quot;)) {
 129                     cassandraPort = Integer.parseInt(StringUtils.split(server, &quot;:&quot;)[1]);
 130                     serversList.add(InetAddress.getByName(StringUtils.split(server, &quot;:&quot;)[0]));
 131                 }
 132 
 133                 if (userName == null || userName.isEmpty() || password == null || password.isEmpty()) {
<abbr title=" 134                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)"> 134                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 135                             .withPort(cassandraPort)
 136                             .withPoolingOptions(poolingOptions).withSocketOptions(so)
 137                             .withQueryOptions(queryOptions).build();
 138                 } else {
<abbr title=" 139                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)"> 139                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 140                             .withPort(cassandraPort)
 141                             .withPoolingOptions(poolingOptions).withSocketOptions(so)
 142                             .withCredentials(userName, password)
 143                             .withQueryOptions(queryOptions).build();
 144                 }
 145                 // 建立连接 连接已存在的键空间
 146                 session = cluster.connectAsync(database);
 147                 LOG.info(&quot;connect cassandra is successed!&quot;);
 148             }
 149         } catch (Exception e) {
 150             LOG.error(&quot;connect cassandra is error:&quot; + e.getMessage());
 151         }
 152     }
 153 
 154     @Override
<abbr title=" 155     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resultFuture) throws Exception {"> 155     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resul🔵</abbr>
 156 
 157         String key = buildCacheKey(inputParams);
 158         //connect Cassandra
 159         connCassandraDB(cassandraSideTableInfo);
 160 
<abbr title=" 161         String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTERING &quot;;"> 161         String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  AL🔵</abbr>
 162         LOG.info(&quot;sqlCondition:{}&quot; + sqlCondition);
 163 
 164         ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session,
 165                 new AsyncFunction&lt;Session, ResultSet&gt;() {
 166                     @Override
 167                     public ListenableFuture&lt;ResultSet&gt; apply(Session session) throws Exception {
 168                         return session.executeAsync(sqlCondition);
 169                     }
 170                 });
 171 
 172         ListenableFuture&lt;List&lt;com.datastax.driver.core.Row&gt;&gt; data = Futures.transform(resultSet,
 173                 new Function&lt;ResultSet, List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 174                     @Override
 175                     public List&lt;com.datastax.driver.core.Row&gt; apply(ResultSet rs) {
 176                         return rs.all();
 177                     }
 178                 });
 179 
 180         Futures.addCallback(data, new FutureCallback&lt;List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 181             @Override
 182             public void onSuccess(List&lt;com.datastax.driver.core.Row&gt; rows) {
 183                 cluster.closeAsync();
 184                 if (rows.size() &gt; 0) {
 185                     List&lt;com.datastax.driver.core.Row&gt; cacheContent = Lists.newArrayList();
 186                     List&lt;Row&gt; rowList = Lists.newArrayList();
 187                     for (com.datastax.driver.core.Row line : rows) {
 188                         Row row = fillData(input, line);
 189                         if (openCache()) {
 190                             cacheContent.add(line);
 191                         }
 192                         rowList.add(row);
 193                     }
 194                     RowDataComplete.completeRow(resultFuture, rowList);
 195                     if (openCache()) {
 196                         putCache(key, CacheObj.buildCacheObj(ECacheContentType.MultiLine, cacheContent));
 197                     }
 198                 } else {
 199                     dealMissKey(input, resultFuture);
 200                     if (openCache()) {
 201                         putCache(key, CacheMissVal.getMissKeyObj());
 202                     }
 203                     resultFuture.complete(Collections.EMPTY_LIST);
 204                 }
 205             }
 206 
 207             @Override
 208             public void onFailure(Throwable t) {
 209                 LOG.error(&quot;Failed to retrieve the data: %s%n&quot;,
 210                         t.getMessage());
 211                 cluster.closeAsync();
 212                 resultFuture.completeExceptionally(t);
 213             }
 214         });
 215     }
 216 
 217     @Override
 218     public String buildCacheKey(Map&lt;String, Object&gt; inputParams) {
 219         StringBuilder sb = new StringBuilder();
 220         for (Object ele : inputParams.values()) {
 221             sb.append(ele.toString()).append(&quot;_&quot;);
 222         }
 223         return sb.toString();
 224     }
 225 
 226     private String buildWhereCondition(Map&lt;String, Object&gt; inputParams){
 227         StringBuilder sb = new StringBuilder(&quot; where &quot;);
 228         for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){
<abbr title=" 229             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();"> 229             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getV🔵</abbr>
 230             sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));
 231         }
 232         return sb.toString();
 233     }
 234 
 235     @Override
 236     public Row fillData(Row input, Object line) {
 237         com.datastax.driver.core.Row rowArray = (com.datastax.driver.core.Row) line;
 238         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 239         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 240             Object obj = input.getField(entry.getValue());
 241 &lt;&lt;&lt;&lt;&lt;&lt;&lt; GitAnalyzerPlus_ours
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 242             obj = convertTimeIndictorTypeInfo(entry.getValue(), obj);</span>
 243 ||||||| GitAnalyzerPlus_base
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 244         for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 245             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();"> 245             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getV🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246             sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 247         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 248         return sb.toString();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 249     }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 250 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 251     @Override</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 252     public Row fillData(Row input, Object line) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 253         com.datastax.driver.core.Row rowArray = (com.datastax.driver.core.Row) line;</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 254         Row row = new Row(sideInfo.getOutFieldInfoList().size());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 255         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 256             Object obj = input.getField(entry.getValue());</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 257             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 257             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 258 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 259             if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 260                 obj = ((Timestamp) obj).getTime();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 261             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 262 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 263             row.setField(entry.getKey(), obj);</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 264         }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 265 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 266         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {</span>
 267 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 268             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 268             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 269 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 270             if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 271                 //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 272                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());"> 272                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime())🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 273             }</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 274 </span>
 275 &gt;&gt;&gt;&gt;&gt;&gt;&gt; GitAnalyzerPlus_theirs
 276             row.setField(entry.getKey(), obj);
 277         }
 278 
 279         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 280             if (rowArray == null) {
 281                 row.setField(entry.getKey(), null);
 282             } else {
 283                 row.setField(entry.getKey(), rowArray.getObject(entry.getValue()));
 284             }
 285         }
 286 
 287         return row;
 288     }
 289 
 290     @Override
 291     public void close() throws Exception {
 292         super.close();
 293         if (cluster != null) {
 294             cluster.close();
 295             cluster = null;
 296         }
 297     }
 298 }</pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 
  19 
  20 package com.dtstack.flink.sql.side.cassandra;
  21 
  22 import com.datastax.driver.core.*;
  23 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  24 import org.apache.flink.configuration.Configuration;
  25 import org.apache.flink.streaming.api.functions.async.ResultFuture;
  26 import org.apache.flink.table.dataformat.BaseRow;
  27 import org.apache.flink.types.Row;
  28 import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;
  29 import com.datastax.driver.core.policies.RetryPolicy;
  30 import com.dtstack.flink.sql.enums.ECacheContentType;
  31 import com.dtstack.flink.sql.side.*;
  32 import com.dtstack.flink.sql.side.cache.CacheObj;
  33 import com.dtstack.flink.sql.side.cassandra.table.CassandraSideTableInfo;
  34 import com.dtstack.flink.sql.util.RowDataComplete;
  35 import com.google.common.base.Function;
  36 import com.google.common.collect.Lists;
  37 import com.google.common.util.concurrent.AsyncFunction;
  38 import com.google.common.util.concurrent.FutureCallback;
  39 import com.google.common.util.concurrent.Futures;
  40 import com.google.common.util.concurrent.ListenableFuture;
  41 import org.apache.commons.lang3.StringUtils;
  42 import org.slf4j.Logger;
  43 import org.slf4j.LoggerFactory;
  44 
  45 import java.net.InetAddress;
  46 import java.util.ArrayList;
  47 import java.util.Collections;
  48 import java.util.List;
  49 import java.util.Map;
  50 import java.util.TimeZone;
  51 
  52 /**
  53  * Reason:
  54  * Date: 2018/11/22
  55  *
  56  * @author xuqianjin
  57  */
  58 public class CassandraAsyncReqRow extends BaseAsyncReqRow {
  59 
  60     private static final long serialVersionUID = 6631584128079864735L;
  61 
  62     private static final Logger LOG = LoggerFactory.getLogger(CassandraAsyncReqRow.class);
  63 
  64     private static final TimeZone LOCAL_TZ = TimeZone.getDefault();
  65 
  66     private final static int DEFAULT_VERTX_EVENT_LOOP_POOL_SIZE = 10;
  67 
  68     private final static int DEFAULT_VERTX_WORKER_POOL_SIZE = 20;
  69 
  70     private final static int DEFAULT_MAX_DB_CONN_POOL_SIZE = 20;
  71 
  72     private transient Cluster cluster;
  73     private transient ListenableFuture session;
  74     private transient CassandraSideTableInfo cassandraSideTableInfo;
  75 
<abbr title="  76     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  76     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoL🔵</abbr>
<abbr title="  77         super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));">  77         super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outF🔵</abbr>
  78     }
  79 
  80 
  81     @Override
  82     public void open(Configuration parameters) throws Exception {
  83         super.open(parameters);
  84         cassandraSideTableInfo = (CassandraSideTableInfo) sideInfo.getSideTableInfo();
  85         connCassandraDB(cassandraSideTableInfo);
  86     }
  87 
  88     private void connCassandraDB(CassandraSideTableInfo tableInfo) {
  89         try {
  90             if (session == null) {
  91                 QueryOptions queryOptions = new QueryOptions();
  92                 //The default consistency level for queries: ConsistencyLevel.TWO.
  93                 queryOptions.setConsistencyLevel(ConsistencyLevel.QUORUM);
<abbr title="  94                 Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo.getMaxRequestsPerConnection();">  94                 Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : 🔵</abbr>
<abbr title="  95                 Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.getCoreConnectionsPerHost();">  95                 Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tabl🔵</abbr>
<abbr title="  96                 Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.getMaxConnectionsPerHost();">  96                 Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : ta🔵</abbr>
<abbr title="  97                 Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQueueSize();">  97                 Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQue🔵</abbr>
<abbr title="  98                 Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTimeoutMillis();">  98                 Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.🔵</abbr>
<abbr title="  99                 Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.getConnectTimeoutMillis();">  99                 Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tabl🔵</abbr>
<abbr title=" 100                 Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTimeoutMillis();"> 100                 Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.🔵</abbr>
 101                 Integer cassandraPort = 0;
 102                 String address = tableInfo.getAddress();
 103                 String userName = tableInfo.getUserName();
 104                 String password = tableInfo.getPassword();
 105                 String database = tableInfo.getDatabase();
 106 
 107                 ArrayList serversList = new ArrayList();
 108                 //Read timeout or connection timeout Settings
 109                 SocketOptions so = new SocketOptions()
 110                         .setReadTimeoutMillis(readTimeoutMillis)
 111                         .setConnectTimeoutMillis(connectTimeoutMillis);
 112 
 113                 //The cluster USES hostdistance.local in the same machine room
 114                 //Hostdistance. REMOTE is used for different machine rooms
 115                 //Ignore use HostDistance. IGNORED
 116                 PoolingOptions poolingOptions = new PoolingOptions()
 117                         //Each connection allows a maximum of 64 concurrent requests
 118                         .setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnection)
 119                         //Have at least two connections to each machine in the cluster
 120                         .setCoreConnectionsPerHost(HostDistance.LOCAL, coreConnectionsPerHost)
 121                         //There are up to eight connections to each machine in the cluster
 122                         .setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnectionsPerHost)
 123                         .setMaxQueueSize(maxQueueSize)
 124                         .setPoolTimeoutMillis(poolTimeoutMillis);
 125                 //重试策略
 126                 RetryPolicy retryPolicy = DowngradingConsistencyRetryPolicy.INSTANCE;
 127 
 128                 for (String server : StringUtils.split(address, &quot;,&quot;)) {
 129                     cassandraPort = Integer.parseInt(StringUtils.split(server, &quot;:&quot;)[1]);
 130                     serversList.add(InetAddress.getByName(StringUtils.split(server, &quot;:&quot;)[0]));
 131                 }
 132 
 133                 if (userName == null || userName.isEmpty() || password == null || password.isEmpty()) {
<abbr title=" 134                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)"> 134                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 135                             .withPort(cassandraPort)
 136                             .withPoolingOptions(poolingOptions).withSocketOptions(so)
 137                             .withQueryOptions(queryOptions).build();
 138                 } else {
<abbr title=" 139                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)"> 139                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 140                             .withPort(cassandraPort)
 141                             .withPoolingOptions(poolingOptions).withSocketOptions(so)
 142                             .withCredentials(userName, password)
 143                             .withQueryOptions(queryOptions).build();
 144                 }
 145                 // 建立连接 连接已存在的键空间
 146                 session = cluster.connectAsync(database);
 147                 LOG.info(&quot;connect cassandra is successed!&quot;);
 148             }
 149         } catch (Exception e) {
 150             LOG.error(&quot;connect cassandra is error:&quot; + e.getMessage());
 151         }
 152     }
 153 
 154     @Override
<abbr title=" 155     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resultFuture) throws Exception {"> 155     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resul🔵</abbr>
 156 
 157         String key = buildCacheKey(inputParams);
 158         //connect Cassandra
 159         connCassandraDB(cassandraSideTableInfo);
 160 
<abbr title=" 161         String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTERING &quot;;"> 161         String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  AL🔵</abbr>
 162         LOG.info(&quot;sqlCondition:{}&quot; + sqlCondition);
 163 
 164         ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session,
 165                 new AsyncFunction&lt;Session, ResultSet&gt;() {
 166                     @Override
 167                     public ListenableFuture&lt;ResultSet&gt; apply(Session session) throws Exception {
 168                         return session.executeAsync(sqlCondition);
 169                     }
 170                 });
 171 
 172         ListenableFuture&lt;List&lt;com.datastax.driver.core.Row&gt;&gt; data = Futures.transform(resultSet,
 173                 new Function&lt;ResultSet, List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 174                     @Override
 175                     public List&lt;com.datastax.driver.core.Row&gt; apply(ResultSet rs) {
 176                         return rs.all();
 177                     }
 178                 });
 179 
 180         Futures.addCallback(data, new FutureCallback&lt;List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 181             @Override
 182             public void onSuccess(List&lt;com.datastax.driver.core.Row&gt; rows) {
 183                 cluster.closeAsync();
 184                 if (rows.size() &gt; 0) {
 185                     List&lt;com.datastax.driver.core.Row&gt; cacheContent = Lists.newArrayList();
 186                     List&lt;Row&gt; rowList = Lists.newArrayList();
 187                     for (com.datastax.driver.core.Row line : rows) {
 188                         Row row = fillData(input, line);
 189                         if (openCache()) {
 190                             cacheContent.add(line);
 191                         }
 192                         rowList.add(row);
 193                     }
 194                     RowDataComplete.completeRow(resultFuture, rowList);
 195                     if (openCache()) {
 196                         putCache(key, CacheObj.buildCacheObj(ECacheContentType.MultiLine, cacheContent));
 197                     }
 198                 } else {
 199                     dealMissKey(input, resultFuture);
 200                     if (openCache()) {
 201                         putCache(key, CacheMissVal.getMissKeyObj());
 202                     }
 203                     resultFuture.complete(Collections.EMPTY_LIST);
 204                 }
 205             }
 206 
 207             @Override
 208             public void onFailure(Throwable t) {
 209                 LOG.error(&quot;Failed to retrieve the data: %s%n&quot;,
 210                         t.getMessage());
 211                 cluster.closeAsync();
 212                 resultFuture.completeExceptionally(t);
 213             }
 214         });
 215     }
 216 
 217     @Override
 218     public String buildCacheKey(Map&lt;String, Object&gt; inputParams) {
 219         StringBuilder sb = new StringBuilder();
 220         for (Object ele : inputParams.values()) {
 221             sb.append(ele.toString()).append(&quot;_&quot;);
 222         }
 223         return sb.toString();
 224     }
 225 
 226     private String buildWhereCondition(Map&lt;String, Object&gt; inputParams){
 227         StringBuilder sb = new StringBuilder(&quot; where &quot;);
 228         for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){
<abbr title=" 229             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();"> 229             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getV🔵</abbr>
 230             sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));
 231         }
 232         return sb.toString();
 233     }
 234 
 235     @Override
 236     public Row fillData(Row input, Object line) {
 237         com.datastax.driver.core.Row rowArray = (com.datastax.driver.core.Row) line;
 238         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 239         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 240             Object obj = input.getField(entry.getValue());
 241 &lt;&lt;&lt;&lt;&lt;&lt;&lt; MINE
<span style="background-color: rgba(255, 167, 0, 0.24); margin: 0"> 242             obj = convertTimeIndictorTypeInfo(entry.getValue(), obj);</span>
 243 ||||||| BASE
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"><abbr title=" 244             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 244             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr></span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 245 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 246             if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 247                 obj = ((Timestamp) obj).getTime();</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 248             }</span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 249 </span>
<span style="background-color: rgba(0, 0, 0, 0.15); margin: 0"> 250             row.setField(entry.getKey(), obj);</span>
 251 =======
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 252             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 252             boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRo🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 253 </span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 254             if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 255                 //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"><abbr title=" 256                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());"> 256                 obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime())🔵</abbr></span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 257             }</span>
<span style="background-color: rgba(0, 0, 255, 0.24); margin: 0"> 258 </span>
 259 &gt;&gt;&gt;&gt;&gt;&gt;&gt; YOURS
 260             row.setField(entry.getKey(), obj);
 261         }
 262 
 263         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 264             if (rowArray == null) {
 265                 row.setField(entry.getKey(), null);
 266             } else {
 267                 row.setField(entry.getKey(), rowArray.getObject(entry.getValue()));
 268             }
 269         }
 270 
 271         return row;
 272     }
 273 
 274     @Override
 275     public void close() throws Exception {
 276         super.close();
 277         if (cluster != null) {
 278             cluster.close();
 279             cluster = null;
 280         }
 281     }
 282 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                            <td><pre>   1 /*
   2  * Licensed to the Apache Software Foundation (ASF) under one
   3  * or more contributor license agreements.  See the NOTICE file
   4  * distributed with this work for additional information
   5  * regarding copyright ownership.  The ASF licenses this file
   6  * to you under the Apache License, Version 2.0 (the
   7  * &quot;License&quot;); you may not use this file except in compliance
   8  * with the License.  You may obtain a copy of the License at
   9  *
  10  *     http://www.apache.org/licenses/LICENSE-2.0
  11  *
  12  * Unless required by applicable law or agreed to in writing, software
  13  * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15  * See the License for the specific language governing permissions and
  16  * limitations under the License.
  17  */
  18 package com.dtstack.flink.sql.side.cassandra;
  19 
  20 import com.datastax.driver.core.*;
  21 import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;
  22 import com.datastax.driver.core.policies.RetryPolicy;
  23 import com.dtstack.flink.sql.enums.ECacheContentType;
  24 import com.dtstack.flink.sql.side.*;
  25 import com.dtstack.flink.sql.side.cache.CacheObj;
  26 import com.dtstack.flink.sql.side.cassandra.table.CassandraSideTableInfo;
  27 import com.dtstack.flink.sql.util.RowDataComplete;
  28 import com.google.common.base.Function;
  29 import com.google.common.collect.Lists;
  30 import com.google.common.util.concurrent.AsyncFunction;
  31 import com.google.common.util.concurrent.FutureCallback;
  32 import com.google.common.util.concurrent.Futures;
  33 import com.google.common.util.concurrent.ListenableFuture;
  34 import java.net.InetAddress;
  35 import java.util.ArrayList;
  36 import java.util.Collections;
  37 import java.util.List;
  38 import java.util.Map;
  39 import java.util.TimeZone;
  40 import org.apache.commons.lang3.StringUtils;
  41 import org.apache.flink.api.java.typeutils.RowTypeInfo;
  42 import org.apache.flink.configuration.Configuration;
  43 import org.apache.flink.streaming.api.functions.async.ResultFuture;
  44 import org.apache.flink.table.dataformat.BaseRow;
  45 import org.apache.flink.types.Row;
  46 import org.slf4j.Logger;
  47 import org.slf4j.LoggerFactory;
  48 
  49 
  50 /**
  51  * Reason:
  52  * Date: 2018/11/22
  53  *
  54  * @author xuqianjin
  55  */
  56 public class CassandraAsyncReqRow extends BaseAsyncReqRow {
  57     private static final long serialVersionUID = 6631584128079864735L;
  58 
  59     private static final Logger LOG = LoggerFactory.getLogger(CassandraAsyncReqRow.class);
  60 
  61     private static final TimeZone LOCAL_TZ = TimeZone.getDefault();
  62 
  63     private final static int DEFAULT_VERTX_EVENT_LOOP_POOL_SIZE = 10;
  64 
  65     private final static int DEFAULT_VERTX_WORKER_POOL_SIZE = 20;
  66 
  67     private final static int DEFAULT_MAX_DB_CONN_POOL_SIZE = 20;
  68 
  69     private transient Cluster cluster;
  70 
  71     private transient ListenableFuture session;
  72 
  73     private transient CassandraSideTableInfo cassandraSideTableInfo;
  74 
<abbr title="  75     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  75     public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoL🔵</abbr>
  76         super(new CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));
  77     }
  78 
  79     @Override
  80     public void open(Configuration parameters) throws Exception {
  81         super.open(parameters);
  82         cassandraSideTableInfo = ((CassandraSideTableInfo) (sideInfo.getSideTableInfo()));
  83         connCassandraDB(cassandraSideTableInfo);
  84     }
  85 
  86     private void connCassandraDB(CassandraSideTableInfo tableInfo) {
  87         try {
  88             if (session == null) {
  89                 QueryOptions queryOptions = new QueryOptions();
  90                 //The default consistency level for queries: ConsistencyLevel.TWO.
  91                 queryOptions.setConsistencyLevel(ConsistencyLevel.QUORUM);
<abbr title="  92                 Integer maxRequestsPerConnection = (tableInfo.getMaxRequestsPerConnection() == null) ? 1 : tableInfo.getMaxRequestsPerConnection();">  92                 Integer maxRequestsPerConnection = (tableInfo.getMaxRequestsPerConnection() == null) ? 1 🔵</abbr>
<abbr title="  93                 Integer coreConnectionsPerHost = (tableInfo.getCoreConnectionsPerHost() == null) ? 8 : tableInfo.getCoreConnectionsPerHost();">  93                 Integer coreConnectionsPerHost = (tableInfo.getCoreConnectionsPerHost() == null) ? 8 : ta🔵</abbr>
<abbr title="  94                 Integer maxConnectionsPerHost = (tableInfo.getMaxConnectionsPerHost() == null) ? 32768 : tableInfo.getMaxConnectionsPerHost();">  94                 Integer maxConnectionsPerHost = (tableInfo.getMaxConnectionsPerHost() == null) ? 32768 : 🔵</abbr>
<abbr title="  95                 Integer maxQueueSize = (tableInfo.getMaxQueueSize() == null) ? 100000 : tableInfo.getMaxQueueSize();">  95                 Integer maxQueueSize = (tableInfo.getMaxQueueSize() == null) ? 100000 : tableInfo.getMaxQ🔵</abbr>
<abbr title="  96                 Integer readTimeoutMillis = (tableInfo.getReadTimeoutMillis() == null) ? 60000 : tableInfo.getReadTimeoutMillis();">  96                 Integer readTimeoutMillis = (tableInfo.getReadTimeoutMillis() == null) ? 60000 : tableInf🔵</abbr>
<abbr title="  97                 Integer connectTimeoutMillis = (tableInfo.getConnectTimeoutMillis() == null) ? 60000 : tableInfo.getConnectTimeoutMillis();">  97                 Integer connectTimeoutMillis = (tableInfo.getConnectTimeoutMillis() == null) ? 60000 : ta🔵</abbr>
<abbr title="  98                 Integer poolTimeoutMillis = (tableInfo.getPoolTimeoutMillis() == null) ? 60000 : tableInfo.getPoolTimeoutMillis();">  98                 Integer poolTimeoutMillis = (tableInfo.getPoolTimeoutMillis() == null) ? 60000 : tableInf🔵</abbr>
  99                 Integer cassandraPort = 0;
 100                 String address = tableInfo.getAddress();
 101                 String userName = tableInfo.getUserName();
 102                 String password = tableInfo.getPassword();
 103                 String database = tableInfo.getDatabase();
 104                 ArrayList serversList = new ArrayList();
 105                 //Read timeout or connection timeout Settings
<abbr title=" 106                 SocketOptions so = new SocketOptions().setReadTimeoutMillis(readTimeoutMillis).setConnectTimeoutMillis(connectTimeoutMillis);"> 106                 SocketOptions so = new SocketOptions().setReadTimeoutMillis(readTimeoutMillis).setConnect🔵</abbr>
 107                 //The cluster USES hostdistance.local in the same machine room
 108                 //Hostdistance. REMOTE is used for different machine rooms
 109                 //Ignore use HostDistance. IGNORED
<abbr title=" 110                 PoolingOptions poolingOptions = //There are up to eight connections to each machine in the cluster"> 110                 PoolingOptions poolingOptions = //There are up to eight connections to each machine in th🔵</abbr>
 111                         //Have at least two connections to each machine in the cluster
 112                         //Each connection allows a maximum of 64 concurrent requests
<abbr title=" 113                 new PoolingOptions().setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnection).setCoreConnectionsPerHost(HostDistance.LOCAL, coreConnectionsPerHost).setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnectionsPerHost).setMaxQueueSize(maxQueueSize).setPoolTimeoutMillis(poolTimeoutMillis);"> 113                 new PoolingOptions().setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnec🔵</abbr>
 114                 // 重试策略
 115                 RetryPolicy retryPolicy = DowngradingConsistencyRetryPolicy.INSTANCE;
 116                 for (String server : StringUtils.split(address, &quot;,&quot;)) {
 117                     cassandraPort = Integer.parseInt(StringUtils.split(server, &quot;:&quot;)[1]);
 118                     serversList.add(InetAddress.getByName(StringUtils.split(server, &quot;:&quot;)[0]));
 119                 }
<abbr title=" 120                 if ((((userName == null) || userName.isEmpty()) || (password == null)) || password.isEmpty()) {"> 120                 if ((((userName == null) || userName.isEmpty()) || (password == null)) || password.isEmpt🔵</abbr>
<abbr title=" 121                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy).withPort(cassandraPort).withPoolingOptions(poolingOptions).withSocketOptions(so).withQueryOptions(queryOptions).build();"> 121                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 122                 } else {
<abbr title=" 123                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy).withPort(cassandraPort).withPoolingOptions(poolingOptions).withSocketOptions(so).withCredentials(userName, password).withQueryOptions(queryOptions).build();"> 123                     cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy🔵</abbr>
 124                 }
 125                 // 建立连接 连接已存在的键空间
 126                 session = cluster.connectAsync(database);
 127                 LOG.info(&quot;connect cassandra is successed!&quot;);
 128             }
 129         } catch (java.lang.Exception e) {
 130             LOG.error(&quot;connect cassandra is error:&quot; + e.getMessage());
 131         }
 132     }
 133 
 134     @Override
<abbr title=" 135     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resultFuture) throws Exception {"> 135     public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resul🔵</abbr>
 136         String key = buildCacheKey(inputParams);
 137         // connect Cassandra
 138         connCassandraDB(cassandraSideTableInfo);
<abbr title=" 139         String sqlCondition = ((sideInfo.getSqlCondition() + &quot; &quot;) + buildWhereCondition(inputParams)) + &quot;  ALLOW FILTERING &quot;;"> 139         String sqlCondition = ((sideInfo.getSqlCondition() + &quot; &quot;) + buildWhereCondition(inputParams)) + &quot;🔵</abbr>
 140         LOG.info(&quot;sqlCondition:{}&quot; + sqlCondition);
<abbr title=" 141         ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session, new AsyncFunction&lt;Session, ResultSet&gt;() {"> 141         ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session, new AsyncFunction&lt;Session🔵</abbr>
 142             @Override
 143             public ListenableFuture&lt;ResultSet&gt; apply(Session session) throws Exception {
 144                 return session.executeAsync(sqlCondition);
 145             }
 146         });
<abbr title=" 147         ListenableFuture&lt;List&lt;Row&gt;&gt; data = Futures.transform(resultSet, new Function&lt;ResultSet, List&lt;Row&gt;&gt;() {"> 147         ListenableFuture&lt;List&lt;Row&gt;&gt; data = Futures.transform(resultSet, new Function&lt;ResultSet, List&lt;Row&gt;🔵</abbr>
 148             @Override
 149             public List&lt;Row&gt; apply(ResultSet rs) {
 150                 return rs.all();
 151             }
 152         });
 153         Futures.addCallback(data, new FutureCallback&lt;List&lt;Row&gt;&gt;() {
 154             @Override
 155             public void onSuccess(List&lt;Row&gt; rows) {
 156                 cluster.closeAsync();
 157                 if (rows.size() &gt; 0) {
 158                     List&lt;Row&gt; cacheContent = Lists.newArrayList();
 159                     List&lt;Row&gt; rowList = Lists.newArrayList();
 160                     for (Row line : rows) {
 161                         Row row = fillData(input, line);
 162                         if (openCache()) {
 163                             cacheContent.add(line);
 164                         }
 165                         rowList.add(row);
 166                     }
 167                     RowDataComplete.completeRow(resultFuture, rowList);
 168                     if (openCache()) {
 169                         putCache(key, CacheObj.buildCacheObj(ECacheContentType.MultiLine, cacheContent));
 170                     }
 171                 } else {
 172                     dealMissKey(input, resultFuture);
 173                     if (openCache()) {
 174                         putCache(key, CacheMissVal.getMissKeyObj());
 175                     }
 176                     resultFuture.complete(Collections.EMPTY_LIST);
 177                 }
 178             }
 179 
 180             @Override
 181             public void onFailure(Throwable t) {
 182                 LOG.error(&quot;Failed to retrieve the data: %s%n&quot;, t.getMessage());
 183                 cluster.closeAsync();
 184                 resultFuture.completeExceptionally(t);
 185             }
 186         });
 187     }
 188 
 189     @Override
 190     public String buildCacheKey(Map&lt;String, Object&gt; inputParams) {
 191         StringBuilder sb = new StringBuilder();
 192         for (Object ele : inputParams.values()) {
 193             sb.append(ele.toString()).append(&quot;_&quot;);
 194         }
 195         return sb.toString();
 196     }
 197 
 198     private String buildWhereCondition(Map&lt;String, Object&gt; inputParams){
 199         StringBuilder sb = new StringBuilder(&quot; where &quot;);
 200         for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){
<abbr title=" 201             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();"> 201             Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getV🔵</abbr>
 202             sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));
 203         }
 204         return sb.toString();
 205     }
 206 
 207     @Override
 208     public Row fillData(Row input, Object line) {
 209         Row rowArray = ((Row) (line));
 210         Row row = new Row(sideInfo.getOutFieldInfoList().size());
 211         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 212             Object obj = input.getField(entry.getValue());
 213             obj = convertTimeIndictorTypeInfo(entry.getValue(), obj);
 214             row.setField(entry.getKey(), obj);
 215         }
 216         for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 217             if (rowArray == null) {
 218                 row.setField(entry.getKey(), null);
 219             } else {
 220                 row.setField(entry.getKey(), rowArray.getObject(entry.getValue()));
 221             }
 222         }
 223         return row;
 224     }
 225 
 226     @Override
 227     public void close() throws Exception {
 228         super.close();
 229         if (cluster != null) {
 230             cluster.close();
 231             cluster = null;
 232         }
 233     }
 234 }
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 </pre></td>
                        </tr>
                    </table>
                </div>
                <div id="bottom">
                    <table style="margin:auto">
                        <tr>
                            <th>ours vs. base</th>
                            <th>theirs vs. base</th>
                        </tr>
                        <tr>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.side.cassandra;
  21  
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  22 -import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  23 -import org.apache.flink.configuration.Configuration;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  24 -import org.apache.flink.streaming.api.functions.async.ResultFuture;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  25 -import org.apache.flink.table.runtime.types.CRow;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  26 -import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  27 -import org.apache.flink.types.Row;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  28 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  29 -import com.datastax.driver.core.Cluster;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  30 -import com.datastax.driver.core.ConsistencyLevel;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  31 -import com.datastax.driver.core.HostDistance;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  32 -import com.datastax.driver.core.PoolingOptions;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  33 -import com.datastax.driver.core.QueryOptions;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  34 -import com.datastax.driver.core.ResultSet;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  35 -import com.datastax.driver.core.Session;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  36 -import com.datastax.driver.core.SocketOptions;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  37 +import com.datastax.driver.core.*;</span>
  38  import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;
  39  import com.datastax.driver.core.policies.RetryPolicy;
  40  import com.dtstack.flink.sql.enums.ECacheContentType;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  41 -import com.dtstack.flink.sql.side.BaseAsyncReqRow;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  42 -import com.dtstack.flink.sql.side.CacheMissVal;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  43 -import com.dtstack.flink.sql.side.FieldInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  44 -import com.dtstack.flink.sql.side.JoinInfo;</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  45 -import com.dtstack.flink.sql.side.AbstractSideTableInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  46 +import com.dtstack.flink.sql.side.*;</span>
  47  import com.dtstack.flink.sql.side.cache.CacheObj;
  48  import com.dtstack.flink.sql.side.cassandra.table.CassandraSideTableInfo;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  49 +import com.dtstack.flink.sql.util.RowDataComplete;</span>
  50  import com.google.common.base.Function;
  51  import com.google.common.collect.Lists;
  52  import com.google.common.util.concurrent.AsyncFunction;
  53  import com.google.common.util.concurrent.FutureCallback;
  54  import com.google.common.util.concurrent.Futures;
  55  import com.google.common.util.concurrent.ListenableFuture;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  56 -import io.vertx.core.json.JsonArray;</span>
  57  import org.apache.commons.lang3.StringUtils;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  58 +import org.apache.flink.api.java.typeutils.RowTypeInfo;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  59 +import org.apache.flink.configuration.Configuration;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  60 +import org.apache.flink.streaming.api.functions.async.ResultFuture;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  61 +import org.apache.flink.table.dataformat.BaseRow;</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  62 +import org.apache.flink.types.Row;</span>
  63  import org.slf4j.Logger;
  64  import org.slf4j.LoggerFactory;
  65  
  66  import java.net.InetAddress;
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0">  67 -import java.sql.Timestamp;</span>
  68  import java.util.ArrayList;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  69 +import java.util.Collections;</span>
  70  import java.util.List;
  71  import java.util.Map;

  72  
  73  /**
  74   * Reason:
  75   * Date: 2018/11/22
  76   *
  77   * @author xuqianjin
  78   */
  79  public class CassandraAsyncReqRow extends BaseAsyncReqRow {
  80  
  81      private static final long serialVersionUID = 6631584128079864735L;
  82  
  83      private static final Logger LOG = LoggerFactory.getLogger(CassandraAsyncReqRow.class);


  84  
  85      private final static int DEFAULT_VERTX_EVENT_LOOP_POOL_SIZE = 10;
  86  
  87      private final static int DEFAULT_VERTX_WORKER_POOL_SIZE = 20;
  88  
  89      private final static int DEFAULT_MAX_DB_CONN_POOL_SIZE = 20;
  90  
  91      private transient Cluster cluster;
  92      private transient ListenableFuture session;
  93      private transient CassandraSideTableInfo cassandraSideTableInfo;
  94  
<abbr title="  95      public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  95      public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, Abst🔵</abbr>
<abbr title="  96          super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));">  96          super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoL🔵</abbr>
  97      }
  98  
  99  
 100      @Override
 101      public void open(Configuration parameters) throws Exception {
 102          super.open(parameters);
 103          cassandraSideTableInfo = (CassandraSideTableInfo) sideInfo.getSideTableInfo();
 104          connCassandraDB(cassandraSideTableInfo);
 105      }
 106  
 107      private void connCassandraDB(CassandraSideTableInfo tableInfo) {
 108          try {
 109              if (session == null) {
 110                  QueryOptions queryOptions = new QueryOptions();
 111                  //The default consistency level for queries: ConsistencyLevel.TWO.
 112                  queryOptions.setConsistencyLevel(ConsistencyLevel.QUORUM);
<abbr title=" 113                  Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo.getMaxRequestsPerConnection();"> 113                  Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo🔵</abbr>
<abbr title=" 114                  Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.getCoreConnectionsPerHost();"> 114                  Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.get🔵</abbr>
<abbr title=" 115                  Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.getMaxConnectionsPerHost();"> 115                  Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.g🔵</abbr>
 116                  Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQueueSize();
<abbr title=" 117                  Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTimeoutMillis();"> 117                  Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTi🔵</abbr>
<abbr title=" 118                  Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.getConnectTimeoutMillis();"> 118                  Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.get🔵</abbr>
<abbr title=" 119                  Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTimeoutMillis();"> 119                  Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTi🔵</abbr>
 120                  Integer cassandraPort = 0;
 121                  String address = tableInfo.getAddress();
 122                  String userName = tableInfo.getUserName();
 123                  String password = tableInfo.getPassword();
 124                  String database = tableInfo.getDatabase();
 125  
 126                  ArrayList serversList = new ArrayList();
 127                  //Read timeout or connection timeout Settings
 128                  SocketOptions so = new SocketOptions()
 129                          .setReadTimeoutMillis(readTimeoutMillis)
 130                          .setConnectTimeoutMillis(connectTimeoutMillis);
 131  
 132                  //The cluster USES hostdistance.local in the same machine room
 133                  //Hostdistance. REMOTE is used for different machine rooms
 134                  //Ignore use HostDistance. IGNORED
 135                  PoolingOptions poolingOptions = new PoolingOptions()
 136                          //Each connection allows a maximum of 64 concurrent requests
 137                          .setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnection)
 138                          //Have at least two connections to each machine in the cluster
 139                          .setCoreConnectionsPerHost(HostDistance.LOCAL, coreConnectionsPerHost)
 140                          //There are up to eight connections to each machine in the cluster
 141                          .setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnectionsPerHost)
 142                          .setMaxQueueSize(maxQueueSize)
 143                          .setPoolTimeoutMillis(poolTimeoutMillis);
 144                  //重试策略
 145                  RetryPolicy retryPolicy = DowngradingConsistencyRetryPolicy.INSTANCE;
 146  
 147                  for (String server : StringUtils.split(address, &quot;,&quot;)) {
 148                      cassandraPort = Integer.parseInt(StringUtils.split(server, &quot;:&quot;)[1]);
 149                      serversList.add(InetAddress.getByName(StringUtils.split(server, &quot;:&quot;)[0]));
 150                  }
 151  
 152                  if (userName == null || userName.isEmpty() || password == null || password.isEmpty()) {
 153                      cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)
 154                              .withPort(cassandraPort)
 155                              .withPoolingOptions(poolingOptions).withSocketOptions(so)
 156                              .withQueryOptions(queryOptions).build();
 157                  } else {
 158                      cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)
 159                              .withPort(cassandraPort)
 160                              .withPoolingOptions(poolingOptions).withSocketOptions(so)
 161                              .withCredentials(userName, password)
 162                              .withQueryOptions(queryOptions).build();
 163                  }
 164                  // 建立连接 连接已存在的键空间
 165                  session = cluster.connectAsync(database);
 166                  LOG.info(&quot;connect cassandra is successed!&quot;);
 167              }
 168          } catch (Exception e) {
 169              LOG.error(&quot;connect cassandra is error:&quot; + e.getMessage());
 170          }
 171      }
 172  
 173      @Override
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 174 -    public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, CRow input, ResultFuture&lt;CRow&gt; resultFuture) throws Exception {"> 174 -    public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, CRow input, ResultFuture&lt;CRow&gt; resultFuture) th🔵</abbr></span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"><abbr title=" 175 +    public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resultFuture) throws Exception {"> 175 +    public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, Row input, ResultFuture&lt;BaseRow&gt; resultFuture) 🔵</abbr></span>
 176  
 177          String key = buildCacheKey(inputParams);
 178          //connect Cassandra
 179          connCassandraDB(cassandraSideTableInfo);
 180  
<abbr title=" 181          String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTERING &quot;;"> 181          String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTE🔵</abbr>
 182          LOG.info(&quot;sqlCondition:{}&quot; + sqlCondition);
 183  
 184          ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session,
 185                  new AsyncFunction&lt;Session, ResultSet&gt;() {
 186                      @Override
 187                      public ListenableFuture&lt;ResultSet&gt; apply(Session session) throws Exception {
 188                          return session.executeAsync(sqlCondition);
 189                      }
 190                  });
 191  
 192          ListenableFuture&lt;List&lt;com.datastax.driver.core.Row&gt;&gt; data = Futures.transform(resultSet,
 193                  new Function&lt;ResultSet, List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 194                      @Override
 195                      public List&lt;com.datastax.driver.core.Row&gt; apply(ResultSet rs) {
 196                          return rs.all();
 197                      }
 198                  });
 199  
 200          Futures.addCallback(data, new FutureCallback&lt;List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 201              @Override
 202              public void onSuccess(List&lt;com.datastax.driver.core.Row&gt; rows) {
 203                  cluster.closeAsync();
 204                  if (rows.size() &gt; 0) {
 205                      List&lt;com.datastax.driver.core.Row&gt; cacheContent = Lists.newArrayList();
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 206 -                    List&lt;CRow&gt; rowList = Lists.newArrayList();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 207 +                    List&lt;Row&gt; rowList = Lists.newArrayList();</span>
 208                      for (com.datastax.driver.core.Row line : rows) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 209 -                        Row row = fillData(input.row(), line);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 210 +                        Row row = fillData(input, line);</span>
 211                          if (openCache()) {
 212                              cacheContent.add(line);
 213                          }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 214 -                        rowList.add(new CRow(row, input.change()));</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 215 -                    }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 216 -                    resultFuture.complete(rowList);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 217 +                        rowList.add(row);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 218 +                    }</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 219 +                    RowDataComplete.completeRow(resultFuture, rowList);</span>
 220                      if (openCache()) {
 221                          putCache(key, CacheObj.buildCacheObj(ECacheContentType.MultiLine, cacheContent));
 222                      }
 223                  } else {
 224                      dealMissKey(input, resultFuture);
 225                      if (openCache()) {
 226                          putCache(key, CacheMissVal.getMissKeyObj());
 227                      }
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 228 -                    resultFuture.complete(null);</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 229 +                    resultFuture.complete(Collections.EMPTY_LIST);</span>
 230                  }
 231              }
 232  
 233              @Override
 234              public void onFailure(Throwable t) {
 235                  LOG.error(&quot;Failed to retrieve the data: %s%n&quot;,
 236                          t.getMessage());
 237                  cluster.closeAsync();
 238                  resultFuture.completeExceptionally(t);
 239              }
 240          });
 241      }
 242  
 243      @Override
 244      public String buildCacheKey(Map&lt;String, Object&gt; inputParams) {
 245          StringBuilder sb = new StringBuilder();
 246          for (Object ele : inputParams.values()) {
 247              sb.append(ele.toString()).append(&quot;_&quot;);
 248          }
 249          return sb.toString();
 250      }
 251  
 252      private String buildWhereCondition(Map&lt;String, Object&gt; inputParams){
 253          StringBuilder sb = new StringBuilder(&quot; where &quot;);
 254          for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){
 255              Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();
 256              sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));
 257          }
 258          return sb.toString();
 259      }
 260  
 261      @Override
 262      public Row fillData(Row input, Object line) {
 263          com.datastax.driver.core.Row rowArray = (com.datastax.driver.core.Row) line;
 264          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 265          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 266              Object obj = input.getField(entry.getValue());
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"><abbr title=" 267 -            boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 267 -            boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr></span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 268 -</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 269 -            if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 270 -                obj = ((Timestamp) obj).getTime();</span>


<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 271 -            }</span>
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 272 -</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 273 +            obj = convertTimeIndictorTypeInfo(entry.getValue(), obj);</span>
 274              row.setField(entry.getKey(), obj);
 275          }
 276  
 277          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 278              if (rowArray == null) {
 279                  row.setField(entry.getKey(), null);
 280              } else {
 281                  row.setField(entry.getKey(), rowArray.getObject(entry.getValue()));
 282              }
 283          }
 284  
 285          return row;
 286      }
 287  
 288      @Override
 289      public void close() throws Exception {
 290          super.close();
 291          if (cluster != null) {
 292              cluster.close();
 293              cluster = null;
 294          }
 295      }
 296  }</pre></td>
                            <td><pre>   1  /*
   2   * Licensed to the Apache Software Foundation (ASF) under one
   3   * or more contributor license agreements.  See the NOTICE file
   4   * distributed with this work for additional information
   5   * regarding copyright ownership.  The ASF licenses this file
   6   * to you under the Apache License, Version 2.0 (the
   7   * &quot;License&quot;); you may not use this file except in compliance
   8   * with the License.  You may obtain a copy of the License at
   9   *
  10   *     http://www.apache.org/licenses/LICENSE-2.0
  11   *
  12   * Unless required by applicable law or agreed to in writing, software
  13   * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
  14   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  15   * See the License for the specific language governing permissions and
  16   * limitations under the License.
  17   */
  18  
  19  
  20  package com.dtstack.flink.sql.side.cassandra;
  21  
  22  import org.apache.flink.api.java.typeutils.RowTypeInfo;
  23  import org.apache.flink.configuration.Configuration;
  24  import org.apache.flink.streaming.api.functions.async.ResultFuture;
  25  import org.apache.flink.table.runtime.types.CRow;
  26  import org.apache.flink.table.typeutils.TimeIndicatorTypeInfo;
  27  import org.apache.flink.types.Row;
  28  
  29  import com.datastax.driver.core.Cluster;
  30  import com.datastax.driver.core.ConsistencyLevel;
  31  import com.datastax.driver.core.HostDistance;
  32  import com.datastax.driver.core.PoolingOptions;
  33  import com.datastax.driver.core.QueryOptions;
  34  import com.datastax.driver.core.ResultSet;
  35  import com.datastax.driver.core.Session;
  36  import com.datastax.driver.core.SocketOptions;

  37  import com.datastax.driver.core.policies.DowngradingConsistencyRetryPolicy;
  38  import com.datastax.driver.core.policies.RetryPolicy;
  39  import com.dtstack.flink.sql.enums.ECacheContentType;
  40  import com.dtstack.flink.sql.side.BaseAsyncReqRow;
  41  import com.dtstack.flink.sql.side.CacheMissVal;
  42  import com.dtstack.flink.sql.side.FieldInfo;
  43  import com.dtstack.flink.sql.side.JoinInfo;
  44  import com.dtstack.flink.sql.side.AbstractSideTableInfo;

  45  import com.dtstack.flink.sql.side.cache.CacheObj;
  46  import com.dtstack.flink.sql.side.cassandra.table.CassandraSideTableInfo;

  47  import com.google.common.base.Function;
  48  import com.google.common.collect.Lists;
  49  import com.google.common.util.concurrent.AsyncFunction;
  50  import com.google.common.util.concurrent.FutureCallback;
  51  import com.google.common.util.concurrent.Futures;
  52  import com.google.common.util.concurrent.ListenableFuture;
  53  import io.vertx.core.json.JsonArray;
  54  import org.apache.commons.lang3.StringUtils;





  55  import org.slf4j.Logger;
  56  import org.slf4j.LoggerFactory;
  57  
  58  import java.net.InetAddress;
  59  import java.sql.Timestamp;
  60  import java.util.ArrayList;

  61  import java.util.List;
  62  import java.util.Map;
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  63 +import java.util.TimeZone;</span>
  64  
  65  /**
  66   * Reason:
  67   * Date: 2018/11/22
  68   *
  69   * @author xuqianjin
  70   */
  71  public class CassandraAsyncReqRow extends BaseAsyncReqRow {
  72  
  73      private static final long serialVersionUID = 6631584128079864735L;
  74  
  75      private static final Logger LOG = LoggerFactory.getLogger(CassandraAsyncReqRow.class);
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  76 +</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0">  77 +    private static final TimeZone LOCAL_TZ = TimeZone.getDefault();</span>
  78  
  79      private final static int DEFAULT_VERTX_EVENT_LOOP_POOL_SIZE = 10;
  80  
  81      private final static int DEFAULT_VERTX_WORKER_POOL_SIZE = 20;
  82  
  83      private final static int DEFAULT_MAX_DB_CONN_POOL_SIZE = 20;
  84  
  85      private transient Cluster cluster;
  86      private transient ListenableFuture session;
  87      private transient CassandraSideTableInfo cassandraSideTableInfo;
  88  
<abbr title="  89      public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, AbstractSideTableInfo sideTableInfo) {">  89      public CassandraAsyncReqRow(RowTypeInfo rowTypeInfo, JoinInfo joinInfo, List&lt;FieldInfo&gt; outFieldInfoList, Abst🔵</abbr>
<abbr title="  90          super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoList, sideTableInfo));">  90          super(new com.dtstack.flink.sql.side.cassandra.CassandraAsyncSideInfo(rowTypeInfo, joinInfo, outFieldInfoL🔵</abbr>
  91      }
  92  
  93  
  94      @Override
  95      public void open(Configuration parameters) throws Exception {
  96          super.open(parameters);
  97          cassandraSideTableInfo = (CassandraSideTableInfo) sideInfo.getSideTableInfo();
  98          connCassandraDB(cassandraSideTableInfo);
  99      }
 100  
 101      private void connCassandraDB(CassandraSideTableInfo tableInfo) {
 102          try {
 103              if (session == null) {
 104                  QueryOptions queryOptions = new QueryOptions();
 105                  //The default consistency level for queries: ConsistencyLevel.TWO.
 106                  queryOptions.setConsistencyLevel(ConsistencyLevel.QUORUM);
<abbr title=" 107                  Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo.getMaxRequestsPerConnection();"> 107                  Integer maxRequestsPerConnection = tableInfo.getMaxRequestsPerConnection() == null ? 1 : tableInfo🔵</abbr>
<abbr title=" 108                  Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.getCoreConnectionsPerHost();"> 108                  Integer coreConnectionsPerHost = tableInfo.getCoreConnectionsPerHost() == null ? 8 : tableInfo.get🔵</abbr>
<abbr title=" 109                  Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.getMaxConnectionsPerHost();"> 109                  Integer maxConnectionsPerHost = tableInfo.getMaxConnectionsPerHost() == null ? 32768 : tableInfo.g🔵</abbr>
 110                  Integer maxQueueSize = tableInfo.getMaxQueueSize() == null ? 100000 : tableInfo.getMaxQueueSize();
<abbr title=" 111                  Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTimeoutMillis();"> 111                  Integer readTimeoutMillis = tableInfo.getReadTimeoutMillis() == null ? 60000 : tableInfo.getReadTi🔵</abbr>
<abbr title=" 112                  Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.getConnectTimeoutMillis();"> 112                  Integer connectTimeoutMillis = tableInfo.getConnectTimeoutMillis() == null ? 60000 : tableInfo.get🔵</abbr>
<abbr title=" 113                  Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTimeoutMillis();"> 113                  Integer poolTimeoutMillis = tableInfo.getPoolTimeoutMillis() == null ? 60000 : tableInfo.getPoolTi🔵</abbr>
 114                  Integer cassandraPort = 0;
 115                  String address = tableInfo.getAddress();
 116                  String userName = tableInfo.getUserName();
 117                  String password = tableInfo.getPassword();
 118                  String database = tableInfo.getDatabase();
 119  
 120                  ArrayList serversList = new ArrayList();
 121                  //Read timeout or connection timeout Settings
 122                  SocketOptions so = new SocketOptions()
 123                          .setReadTimeoutMillis(readTimeoutMillis)
 124                          .setConnectTimeoutMillis(connectTimeoutMillis);
 125  
 126                  //The cluster USES hostdistance.local in the same machine room
 127                  //Hostdistance. REMOTE is used for different machine rooms
 128                  //Ignore use HostDistance. IGNORED
 129                  PoolingOptions poolingOptions = new PoolingOptions()
 130                          //Each connection allows a maximum of 64 concurrent requests
 131                          .setMaxRequestsPerConnection(HostDistance.LOCAL, maxRequestsPerConnection)
 132                          //Have at least two connections to each machine in the cluster
 133                          .setCoreConnectionsPerHost(HostDistance.LOCAL, coreConnectionsPerHost)
 134                          //There are up to eight connections to each machine in the cluster
 135                          .setMaxConnectionsPerHost(HostDistance.LOCAL, maxConnectionsPerHost)
 136                          .setMaxQueueSize(maxQueueSize)
 137                          .setPoolTimeoutMillis(poolTimeoutMillis);
 138                  //重试策略
 139                  RetryPolicy retryPolicy = DowngradingConsistencyRetryPolicy.INSTANCE;
 140  
 141                  for (String server : StringUtils.split(address, &quot;,&quot;)) {
 142                      cassandraPort = Integer.parseInt(StringUtils.split(server, &quot;:&quot;)[1]);
 143                      serversList.add(InetAddress.getByName(StringUtils.split(server, &quot;:&quot;)[0]));
 144                  }
 145  
 146                  if (userName == null || userName.isEmpty() || password == null || password.isEmpty()) {
 147                      cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)
 148                              .withPort(cassandraPort)
 149                              .withPoolingOptions(poolingOptions).withSocketOptions(so)
 150                              .withQueryOptions(queryOptions).build();
 151                  } else {
 152                      cluster = Cluster.builder().addContactPoints(serversList).withRetryPolicy(retryPolicy)
 153                              .withPort(cassandraPort)
 154                              .withPoolingOptions(poolingOptions).withSocketOptions(so)
 155                              .withCredentials(userName, password)
 156                              .withQueryOptions(queryOptions).build();
 157                  }
 158                  // 建立连接 连接已存在的键空间
 159                  session = cluster.connectAsync(database);
 160                  LOG.info(&quot;connect cassandra is successed!&quot;);
 161              }
 162          } catch (Exception e) {
 163              LOG.error(&quot;connect cassandra is error:&quot; + e.getMessage());
 164          }
 165      }
 166  
 167      @Override
<abbr title=" 168      public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, CRow input, ResultFuture&lt;CRow&gt; resultFuture) throws Exception {"> 168      public void handleAsyncInvoke(Map&lt;String, Object&gt; inputParams, CRow input, ResultFuture&lt;CRow&gt; resultFuture) th🔵</abbr>

 169  
 170          String key = buildCacheKey(inputParams);
 171          //connect Cassandra
 172          connCassandraDB(cassandraSideTableInfo);
 173  
<abbr title=" 174          String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTERING &quot;;"> 174          String sqlCondition = sideInfo.getSqlCondition() + &quot; &quot; + buildWhereCondition(inputParams) + &quot;  ALLOW FILTE🔵</abbr>
 175          LOG.info(&quot;sqlCondition:{}&quot; + sqlCondition);
 176  
 177          ListenableFuture&lt;ResultSet&gt; resultSet = Futures.transformAsync(session,
 178                  new AsyncFunction&lt;Session, ResultSet&gt;() {
 179                      @Override
 180                      public ListenableFuture&lt;ResultSet&gt; apply(Session session) throws Exception {
 181                          return session.executeAsync(sqlCondition);
 182                      }
 183                  });
 184  
 185          ListenableFuture&lt;List&lt;com.datastax.driver.core.Row&gt;&gt; data = Futures.transform(resultSet,
 186                  new Function&lt;ResultSet, List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 187                      @Override
 188                      public List&lt;com.datastax.driver.core.Row&gt; apply(ResultSet rs) {
 189                          return rs.all();
 190                      }
 191                  });
 192  
 193          Futures.addCallback(data, new FutureCallback&lt;List&lt;com.datastax.driver.core.Row&gt;&gt;() {
 194              @Override
 195              public void onSuccess(List&lt;com.datastax.driver.core.Row&gt; rows) {
 196                  cluster.closeAsync();
 197                  if (rows.size() &gt; 0) {
 198                      List&lt;com.datastax.driver.core.Row&gt; cacheContent = Lists.newArrayList();
 199                      List&lt;CRow&gt; rowList = Lists.newArrayList();

 200                      for (com.datastax.driver.core.Row line : rows) {
 201                          Row row = fillData(input.row(), line);

 202                          if (openCache()) {
 203                              cacheContent.add(line);
 204                          }
 205                          rowList.add(new CRow(row, input.change()));
 206                      }
 207                      resultFuture.complete(rowList);



 208                      if (openCache()) {
 209                          putCache(key, CacheObj.buildCacheObj(ECacheContentType.MultiLine, cacheContent));
 210                      }
 211                  } else {
 212                      dealMissKey(input, resultFuture);
 213                      if (openCache()) {
 214                          putCache(key, CacheMissVal.getMissKeyObj());
 215                      }
 216                      resultFuture.complete(null);

 217                  }
 218              }
 219  
 220              @Override
 221              public void onFailure(Throwable t) {
 222                  LOG.error(&quot;Failed to retrieve the data: %s%n&quot;,
 223                          t.getMessage());
 224                  cluster.closeAsync();
 225                  resultFuture.completeExceptionally(t);
 226              }
 227          });
 228      }
 229  
 230      @Override
 231      public String buildCacheKey(Map&lt;String, Object&gt; inputParams) {
 232          StringBuilder sb = new StringBuilder();
 233          for (Object ele : inputParams.values()) {
 234              sb.append(ele.toString()).append(&quot;_&quot;);
 235          }
 236          return sb.toString();
 237      }
 238  
 239      private String buildWhereCondition(Map&lt;String, Object&gt; inputParams){
 240          StringBuilder sb = new StringBuilder(&quot; where &quot;);
 241          for(Map.Entry&lt;String, Object&gt; entry : inputParams.entrySet()){
 242              Object value = entry.getValue() instanceof String ? &quot;&#x27;&quot; + entry.getValue() + &quot;&#x27;&quot; : entry.getValue();
 243              sb.append(String.format(&quot;%s = %s&quot;, entry.getKey(), value));
 244          }
 245          return sb.toString();
 246      }
 247  
 248      @Override
 249      public Row fillData(Row input, Object line) {
 250          com.datastax.driver.core.Row rowArray = (com.datastax.driver.core.Row) line;
 251          Row row = new Row(sideInfo.getOutFieldInfoList().size());
 252          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getInFieldIndex().entrySet()) {
 253              Object obj = input.getField(entry.getValue());
<abbr title=" 254              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo().getTypeAt(entry.getValue()).getClass());"> 254              boolean isTimeIndicatorTypeInfo = TimeIndicatorTypeInfo.class.isAssignableFrom(sideInfo.getRowTypeInfo🔵</abbr>
 255  
 256              if (obj instanceof Timestamp &amp;&amp; isTimeIndicatorTypeInfo) {
<span style="background-color: rgba(255, 0, 0, 0.2);; margin: 0"> 257 -                obj = ((Timestamp) obj).getTime();</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 258 +                //去除上一层OutputRowtimeProcessFunction 调用时区导致的影响</span>
<span style="background-color: rgba(0, 255, 0, 0.2); margin: 0"> 259 +                obj = ((Timestamp) obj).getTime() + (long)LOCAL_TZ.getOffset(((Timestamp) obj).getTime());</span>
 260              }
 261  

 262              row.setField(entry.getKey(), obj);
 263          }
 264  
 265          for (Map.Entry&lt;Integer, Integer&gt; entry : sideInfo.getSideFieldIndex().entrySet()) {
 266              if (rowArray == null) {
 267                  row.setField(entry.getKey(), null);
 268              } else {
 269                  row.setField(entry.getKey(), rowArray.getObject(entry.getValue()));
 270              }
 271          }
 272  
 273          return row;
 274      }
 275  
 276      @Override
 277      public void close() throws Exception {
 278          super.close();
 279          if (cluster != null) {
 280              cluster.close();
 281              cluster = null;
 282          }
 283      }
 284  }</pre></td>
                        </tr>
                    </table>
                </div>
              </body>
            </html>
            