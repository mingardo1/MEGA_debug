<!DOCTYPE html>
<html lang="en">
          <head>
            <meta charset="utf-8">
            <title>464 chunks</title>
                <style>
                    #top {
                        height: 48vh;
                        overflow-y: auto;
                    }
                    #bottom {
                        height: 48vh;
                        overflow-y: auto;
                    }
                </style>
          </head>
          <body>
            <pre>[[{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.flinkKafkaProducer = &#x27;
                         &#x27;(FlinkKafkaProducer&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducerFactory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafkaSinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        this.flinkKafkaProducer = &#x27;
                           &#x27;(FlinkKafkaProducer&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducerFactory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        this.flinkKafkaProducer = &#x27;
                         &#x27;(FlinkKafkaProducer&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducerFactory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafkaSinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        this.flinkKafkaProducer = &#x27;
                           &#x27;(FlinkKafkaProducer&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducerFactory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;
                           &#x27;                .setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;mapDataStream.addSink(flinkKafkaProducer).name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}],
 [{&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        this.flinkKafkaProducer = &#x27;
                         &#x27;(FlinkKafkaProducer&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducerFactory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafkaSinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        this.flinkKafkaProducer = &#x27;
                           &#x27;(FlinkKafkaProducer&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducerFactory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;},
          {&#x27;CHUNK_OURS&#x27;: &#x27;        this.flinkKafkaProducer = &#x27;
                         &#x27;(FlinkKafkaProducer&lt;Row&gt;) new &#x27;
                         &#x27;KafkaProducerFactory()\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                         &#x27;getOutputType().getTypeAt(1), properties, &#x27;
                         &#x27;partitioner, partitionKeys);\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;        this.sinkOperatorName = &#x27;
                         &#x27;SINK_OPERATOR_NAME_TPL.replace(&quot;${topic}&quot;, &#x27;
                         &#x27;topic).replace(&quot;${table}&quot;, &#x27;
                         &#x27;kafkaSinkTableInfo.getName());\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        typeInformation = new CRowTypeInfo(new &#x27;
                           &#x27;RowTypeInfo(fieldTypes, fieldNames));\n&#x27;
                           &#x27;        this.flinkKafkaProducer = &#x27;
                           &#x27;(FlinkKafkaProducer&lt;CRow&gt;) new &#x27;
                           &#x27;KafkaProducerFactory()\n&#x27;
                           &#x27;                &#x27;
                           &#x27;.createKafkaProducer(kafkaSinkTableInfo, &#x27;
                           &#x27;typeInformation, properties, partitioner, &#x27;
                           &#x27;partitionKeys);\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;, &#x27;jfstmerge&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;
                         &#x27;    }\n&#x27;
                         &#x27;\n&#x27;
                         &#x27;    @Override\n&#x27;
                         &#x27;    public DataStreamSink&lt;Row&gt; &#x27;
                         &#x27;consumeDataStream(DataStream&lt;Tuple2&lt;Boolean, Row&gt;&gt; &#x27;
                         &#x27;dataStream) {\n&#x27;
                         &#x27;        DataStream&lt;Row&gt; ds = dataStream\n&#x27;
                         &#x27;                .filter((Tuple2&lt;Boolean, Row&gt; &#x27;
                         &#x27;record) -&gt; record.f0)\n&#x27;
                         &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                         &#x27;-&gt; record.f1)\n&#x27;
                         &#x27;                &#x27;
                         &#x27;.returns(getOutputType().getTypeAt(1))\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;baseline&#x27;}},
  {&#x27;eq&#x27;: [{&#x27;CHUNK_OURS&#x27;: &#x27;        consumeDataStream(dataStream);\n&#x27;,
           &#x27;CHUNK_THEIRS&#x27;: &#x27;        DataStream&lt;CRow&gt; mapDataStream = &#x27;
                           &#x27;dataStream\n&#x27;
                           &#x27;                .map((Tuple2&lt;Boolean, Row&gt; record) &#x27;
                           &#x27;-&gt; new CRow(record.f1, record.f0))\n&#x27;
                           &#x27;                .returns(typeInformation)\n&#x27;
                           &#x27;                .setParallelism(parallelism);\n&#x27;
                           &#x27;\n&#x27;
                           &#x27;        &#x27;
                           &#x27;mapDataStream.addSink(flinkKafkaProducer).name(TableConnectorUtils.generateRuntimeName(this.getClass(), &#x27;
                           &#x27;getFieldNames()));\n&#x27;}],
   &#x27;mergers&#x27;: {&#x27;jfstmerge&#x27;}}]]</pre>
          </body>
        </html>
        